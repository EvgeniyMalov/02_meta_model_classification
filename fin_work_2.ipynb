{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["3jCoMY8vJysz","WGL8TFkSaxVE","dPT5eLgKavIm","20KVqeno4WXF","Rylp2PwJlHG2","W_jW2QK1lHaL"],"authorship_tag":"ABX9TyMeOCD7zm7JCOWplnbKy+jU"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"CsLjBGqkVM4d","executionInfo":{"status":"ok","timestamp":1708682580056,"user_tz":-240,"elapsed":9,"user":{"displayName":"Евгений Малов","userId":"06257165098392198337"}}},"outputs":[],"source":["# путь до данных на компьютере\n","path = '/content/drive/MyDrive/files_and_description/train_data'"]},{"cell_type":"code","source":["# для работающих в Google Colab\n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"CopkZyGyVSXu","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1708682610017,"user_tz":-240,"elapsed":27211,"user":{"displayName":"Евгений Малов","userId":"06257165098392198337"}},"outputId":"93b85500-aa0f-4885-af96-63ab64781a73"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["!pip install catboost -q"],"metadata":{"id":"gZxuZv7dsmkz","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1708682626504,"user_tz":-240,"elapsed":14428,"user":{"displayName":"Евгений Малов","userId":"06257165098392198337"}},"outputId":"bb01f912-b3f2-4e17-ba25-1af12874f776"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.7/98.7 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}]},{"cell_type":"code","source":["!pip install optuna -q"],"metadata":{"id":"bb-yE0qxsmpN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1708682643038,"user_tz":-240,"elapsed":14365,"user":{"displayName":"Евгений Малов","userId":"06257165098392198337"}},"outputId":"794692ed-4513-4f87-c757-080b090d36f4"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m413.4/413.4 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.4/233.4 kB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.7/78.7 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}]},{"cell_type":"code","source":["!pip install dill -q"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FX5d8v_EXteI","executionInfo":{"status":"ok","timestamp":1708682659449,"user_tz":-240,"elapsed":13005,"user":{"displayName":"Евгений Малов","userId":"06257165098392198337"}},"outputId":"90a61f0f-501e-4f0f-b4f4-2269cdba87bc"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/116.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[32m112.6/116.3 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}]},{"cell_type":"code","source":["import os\n","import pandas as pd\n","import numpy as np\n","\n","import matplotlib.pyplot as plt\n","\n","from sklearn.linear_model import LogisticRegression\n","from catboost import CatBoostClassifier\n","from lightgbm import LGBMClassifier\n","from xgboost import XGBClassifier\n","from sklearn.utils.class_weight import compute_class_weight\n","from sklearn.model_selection import cross_val_score\n","from sklearn.metrics import roc_auc_score\n","from sklearn.metrics import confusion_matrix\n","from sklearn.metrics import make_scorer\n","#from math import sqrt\n","\n","import optuna\n","\n","from sklearn.ensemble import StackingClassifier\n","from sklearn.ensemble import GradientBoostingClassifier\n","from sklearn.ensemble import RandomForestClassifier\n","\n","import dill\n","import pickle\n","\n","import warnings\n","warnings.filterwarnings('ignore')"],"metadata":{"id":"8qFLzT-5VSbE","executionInfo":{"status":"ok","timestamp":1708682668209,"user_tz":-240,"elapsed":5420,"user":{"displayName":"Евгений Малов","userId":"06257165098392198337"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["## Снижение размерности"],"metadata":{"id":"3jCoMY8vJysz"}},{"cell_type":"code","source":["# путь до данных на компьютере\n","path = '/content/drive/MyDrive/files_and_description/train_data'"],"metadata":{"id":"sR3VOjXiMi_U"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# для работающих в Google Colab\n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Cv9jeEqsMlnR","executionInfo":{"status":"ok","timestamp":1707586002845,"user_tz":-240,"elapsed":2667,"user":{"displayName":"Евгений Малов","userId":"06257165098392198337"}},"outputId":"443af2a3-7022-4ba2-c50d-1d83c07383c6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["import os\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","from sklearn.decomposition import TruncatedSVD\n","\n","import warnings\n","warnings.filterwarnings('ignore')"],"metadata":{"id":"8_AYsXiEJu5f"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["x_train = pd.read_parquet(path + '/min_x_train.parquet').drop('id', axis=1)\n","x_test = pd.read_parquet(path + '/min_x_test.parquet').drop('id', axis=1)\n","y_train = pd.read_parquet(path + '/min_y_train.parquet').drop('id', axis=1)\n","y_test = pd.read_parquet(path + '/min_y_test.parquet').drop('id', axis=1)\n"],"metadata":{"id":"r4ZBbT3_Ju9F"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_train = pd.read_parquet(path + '/min_y_train.parquet').drop('id', axis=1)\n","y_test = pd.read_parquet(path + '/min_y_test.parquet').drop('id', axis=1)"],"metadata":{"id":"z7sLp7sKsOxc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["columns = x_train.columns.to_list()"],"metadata":{"id":"6fFalzA-JvAl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["x_train.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"w2nDF-AILpBA","executionInfo":{"status":"ok","timestamp":1707571761033,"user_tz":-240,"elapsed":394,"user":{"displayName":"Евгений Малов","userId":"06257165098392198337"}},"outputId":"0077bfc8-33d4-449c-b2b7-7a3b3248716d"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(2100000, 220)"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["comp = []\n","res = []\n","for i in range(20, 100, 10):\n","    trun_svd =  TruncatedSVD(n_components = i)\n","    trun_svd.fit(x_train)\n","    result = sum(trun_svd.explained_variance_ratio_)\n","    comp.append(i)\n","    res.append(round(result, 4))\n","    print(f'comp: {i}, res: {result}')\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lyTcUl49UZIw","executionInfo":{"status":"ok","timestamp":1707576528814,"user_tz":-240,"elapsed":923345,"user":{"displayName":"Евгений Малов","userId":"06257165098392198337"}},"outputId":"845b7d87-d09c-4261-9554-0afe1326de43"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["comp: 20, res: 0.9623806596993247\n","comp: 30, res: 0.9697688743350334\n","comp: 40, res: 0.9751147302246989\n","comp: 50, res: 0.9794928665877318\n","comp: 60, res: 0.9833859388746309\n","comp: 70, res: 0.9869932549840441\n","comp: 80, res: 0.9901517069543571\n","comp: 90, res: 0.9928155988071952\n"]}]},{"cell_type":"code","source":["plt.plot(comp, res,'ro-')\n","plt.xlabel('Оставлено компонент', fontsize=8)\n","plt.ylabel('Доля дисперсии', fontsize=8)\n","plt.savefig('Prop_of_Var.png')\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":445},"id":"BGQgbjEmUZQW","executionInfo":{"status":"ok","timestamp":1707576983207,"user_tz":-240,"elapsed":477,"user":{"displayName":"Евгений Малов","userId":"06257165098392198337"}},"outputId":"77778037-81a0-483b-e605-79e1dac0a431"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"code","source":["trun_svd =  TruncatedSVD(n_components = 50)\n","x_train_feat_sel = trun_svd.fit_transform(x_train)\n","x_test_feat_sel = trun_svd.transform(x_test)\n"],"metadata":{"id":"56TQGHg4MWgb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["x_test_feat_sel.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0n-ZiGJKMWjg","executionInfo":{"status":"ok","timestamp":1707581360713,"user_tz":-240,"elapsed":457,"user":{"displayName":"Евгений Малов","userId":"06257165098392198337"}},"outputId":"6d305288-97de-44f2-b3d9-b69f94063371"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(900000, 70)"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["x_test_feat_sel"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"T-zHQkQDxein","executionInfo":{"status":"ok","timestamp":1707581363252,"user_tz":-240,"elapsed":425,"user":{"displayName":"Евгений Малов","userId":"06257165098392198337"}},"outputId":"38058562-62f6-4aea-f5df-5ab3f478b171"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[ 4.77481362e+01, -1.13499921e+01,  8.67365288e+00, ...,\n","        -2.77343682e-01,  4.08403432e-02, -3.16664602e-01],\n","       [ 5.30657564e+00,  1.82886806e+00, -2.96041031e-01, ...,\n","        -1.65112403e-01,  4.16090670e-01,  2.77108375e-01],\n","       [ 4.64558646e+01, -3.17774256e+00,  2.24358900e+00, ...,\n","         9.34049240e-01,  9.44524026e-01, -4.14347559e-01],\n","       ...,\n","       [ 1.52264039e+01,  6.92694514e-01,  1.64685665e+00, ...,\n","        -3.90138573e-01, -1.14749775e-01,  1.77320227e-01],\n","       [ 2.56372427e+01,  7.99172738e+00, -8.49602142e-01, ...,\n","        -1.05595847e-01, -4.89424822e-01,  5.33090710e-01],\n","       [ 2.33302286e+01, -7.08040537e+00,  3.73905639e+00, ...,\n","        -8.26924805e-02,  2.41281524e-02, -2.85804830e-01]])"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["cols = [str(i) for i in range(50)]"],"metadata":{"id":"Uml5Ssg7loNN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["x_train_feat_sel = pd.DataFrame(x_train_feat_sel, columns=cols)\n","x_test_feat_sel = pd.DataFrame(x_test_feat_sel, columns=cols)"],"metadata":{"id":"ZKfoDQ3qkWOM","colab":{"base_uri":"https://localhost:8080/","height":193},"executionInfo":{"status":"error","timestamp":1707736473954,"user_tz":-240,"elapsed":291,"user":{"displayName":"Евгений Малов","userId":"06257165098392198337"}},"outputId":"08c5ae7e-0268-484f-f574-3e8a987b1a75"},"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'x_train_feat_sel' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-7-ad62d5bc6bf4>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx_train_feat_sel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train_feat_sel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mx_test_feat_sel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test_feat_sel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'x_train_feat_sel' is not defined"]}]},{"cell_type":"code","source":["x_test_feat_sel.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":236},"id":"3wCE-qX-poB1","executionInfo":{"status":"ok","timestamp":1707586178949,"user_tz":-240,"elapsed":514,"user":{"displayName":"Евгений Малов","userId":"06257165098392198337"}},"outputId":"afa3b8fe-4e2d-4791-b167-b8d2674e7f41"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["           0          1         2         3         4         5         6  \\\n","0  47.748136 -11.349992  8.673653  4.138859  0.001739 -1.680629 -2.671339   \n","1   5.306576   1.828868 -0.296041  0.157137  2.056028 -0.762477  0.658295   \n","2  46.455865  -3.177743  2.243589 -2.127595  3.592635 -0.084988 -1.333395   \n","3  24.050128   0.009916  4.305968  0.249731  4.191759 -1.353285  0.979239   \n","4  19.902846   2.651239  1.765636  1.832136  0.311305 -2.188570  0.402448   \n","\n","          7         8         9  ...        40        41        42        43  \\\n","0 -3.907611  1.177955 -3.176397  ...  1.062923 -0.571625 -0.498686 -0.627054   \n","1 -0.722293 -0.078514 -0.164815  ... -0.624724  0.083548 -0.030163 -0.033021   \n","2 -0.760883 -0.364753 -1.527561  ...  0.443910 -0.378593  0.031117  0.202952   \n","3  0.276521 -2.477032  1.369812  ... -0.076358  0.554328  0.300944 -0.079756   \n","4 -2.216912  0.700683 -0.859193  ...  0.691996 -0.869009 -0.637925 -0.358820   \n","\n","         44        45        46        47        48        49  \n","0  0.290090  0.698243  0.336028 -0.062288  0.742550  0.249823  \n","1 -0.046462 -0.216834 -0.344722 -0.048524  0.020124 -0.129475  \n","2  1.119691  0.862797 -0.606316 -1.466994 -0.856730  0.412779  \n","3 -0.085979  0.797429  0.303029 -0.419720  1.142121  0.146824  \n","4 -0.120176 -0.185459 -0.153570 -0.757881  0.270647 -0.149319  \n","\n","[5 rows x 50 columns]"],"text/html":["\n","  <div id=\"df-03c20a7a-d7cc-4144-8d20-6ebfb4d5501d\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>6</th>\n","      <th>7</th>\n","      <th>8</th>\n","      <th>9</th>\n","      <th>...</th>\n","      <th>40</th>\n","      <th>41</th>\n","      <th>42</th>\n","      <th>43</th>\n","      <th>44</th>\n","      <th>45</th>\n","      <th>46</th>\n","      <th>47</th>\n","      <th>48</th>\n","      <th>49</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>47.748136</td>\n","      <td>-11.349992</td>\n","      <td>8.673653</td>\n","      <td>4.138859</td>\n","      <td>0.001739</td>\n","      <td>-1.680629</td>\n","      <td>-2.671339</td>\n","      <td>-3.907611</td>\n","      <td>1.177955</td>\n","      <td>-3.176397</td>\n","      <td>...</td>\n","      <td>1.062923</td>\n","      <td>-0.571625</td>\n","      <td>-0.498686</td>\n","      <td>-0.627054</td>\n","      <td>0.290090</td>\n","      <td>0.698243</td>\n","      <td>0.336028</td>\n","      <td>-0.062288</td>\n","      <td>0.742550</td>\n","      <td>0.249823</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>5.306576</td>\n","      <td>1.828868</td>\n","      <td>-0.296041</td>\n","      <td>0.157137</td>\n","      <td>2.056028</td>\n","      <td>-0.762477</td>\n","      <td>0.658295</td>\n","      <td>-0.722293</td>\n","      <td>-0.078514</td>\n","      <td>-0.164815</td>\n","      <td>...</td>\n","      <td>-0.624724</td>\n","      <td>0.083548</td>\n","      <td>-0.030163</td>\n","      <td>-0.033021</td>\n","      <td>-0.046462</td>\n","      <td>-0.216834</td>\n","      <td>-0.344722</td>\n","      <td>-0.048524</td>\n","      <td>0.020124</td>\n","      <td>-0.129475</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>46.455865</td>\n","      <td>-3.177743</td>\n","      <td>2.243589</td>\n","      <td>-2.127595</td>\n","      <td>3.592635</td>\n","      <td>-0.084988</td>\n","      <td>-1.333395</td>\n","      <td>-0.760883</td>\n","      <td>-0.364753</td>\n","      <td>-1.527561</td>\n","      <td>...</td>\n","      <td>0.443910</td>\n","      <td>-0.378593</td>\n","      <td>0.031117</td>\n","      <td>0.202952</td>\n","      <td>1.119691</td>\n","      <td>0.862797</td>\n","      <td>-0.606316</td>\n","      <td>-1.466994</td>\n","      <td>-0.856730</td>\n","      <td>0.412779</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>24.050128</td>\n","      <td>0.009916</td>\n","      <td>4.305968</td>\n","      <td>0.249731</td>\n","      <td>4.191759</td>\n","      <td>-1.353285</td>\n","      <td>0.979239</td>\n","      <td>0.276521</td>\n","      <td>-2.477032</td>\n","      <td>1.369812</td>\n","      <td>...</td>\n","      <td>-0.076358</td>\n","      <td>0.554328</td>\n","      <td>0.300944</td>\n","      <td>-0.079756</td>\n","      <td>-0.085979</td>\n","      <td>0.797429</td>\n","      <td>0.303029</td>\n","      <td>-0.419720</td>\n","      <td>1.142121</td>\n","      <td>0.146824</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>19.902846</td>\n","      <td>2.651239</td>\n","      <td>1.765636</td>\n","      <td>1.832136</td>\n","      <td>0.311305</td>\n","      <td>-2.188570</td>\n","      <td>0.402448</td>\n","      <td>-2.216912</td>\n","      <td>0.700683</td>\n","      <td>-0.859193</td>\n","      <td>...</td>\n","      <td>0.691996</td>\n","      <td>-0.869009</td>\n","      <td>-0.637925</td>\n","      <td>-0.358820</td>\n","      <td>-0.120176</td>\n","      <td>-0.185459</td>\n","      <td>-0.153570</td>\n","      <td>-0.757881</td>\n","      <td>0.270647</td>\n","      <td>-0.149319</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 50 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-03c20a7a-d7cc-4144-8d20-6ebfb4d5501d')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-03c20a7a-d7cc-4144-8d20-6ebfb4d5501d button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-03c20a7a-d7cc-4144-8d20-6ebfb4d5501d');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-c0a762a2-7da9-40ee-b66c-4ac8795d1ac7\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c0a762a2-7da9-40ee-b66c-4ac8795d1ac7')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-c0a762a2-7da9-40ee-b66c-4ac8795d1ac7 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["x_train_feat_sel = x_train_feat_sel.astype('float32')\n","x_test_feat_sel = x_test_feat_sel.astype('float32')"],"metadata":{"id":"1EzpvSh3y16D"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["x_test_feat_sel.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":236},"id":"QSAsggEwza11","executionInfo":{"status":"ok","timestamp":1707581750166,"user_tz":-240,"elapsed":386,"user":{"displayName":"Евгений Малов","userId":"06257165098392198337"}},"outputId":"f8ab896e-ca97-4e46-ca23-fa1cf48f97b5"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["           0          1         2         3         4         5         6  \\\n","0  47.750000 -11.351562  8.671875  4.140625  0.001740 -1.680664 -2.671875   \n","1   5.304688   1.829102 -0.296143  0.157104  2.056641 -0.762695  0.658203   \n","2  46.468750  -3.177734  2.244141 -2.126953  3.591797 -0.084961 -1.333008   \n","3  24.046875   0.009918  4.304688  0.249756  4.191406 -1.353516  0.979004   \n","4  19.906250   2.650391  1.765625  1.832031  0.311279 -2.189453  0.402344   \n","\n","          7         8         9  ...        60        61        62        63  \\\n","0 -3.908203  1.177734 -3.175781  ...  0.365967  0.129883  0.121094  0.082031   \n","1 -0.722168 -0.078491 -0.164795  ... -0.370117 -0.156860 -0.163940 -0.010147   \n","2 -0.760742 -0.364746 -1.527344  ... -0.081055 -0.395752 -0.463867 -0.028656   \n","3  0.276611 -2.476562  1.370117  ...  0.556152 -0.222656  0.141602 -0.159912   \n","4 -2.216797  0.700684 -0.859375  ...  0.228760 -0.562988  0.368652  0.459961   \n","\n","         64        65        66        67        68        69  \n","0  0.475830  0.267822  0.359375 -0.277344  0.040833 -0.316650  \n","1 -0.183838  0.136963 -0.185669 -0.165161  0.416016  0.277100  \n","2 -0.225830 -0.159302 -0.435547  0.934082  0.944336 -0.414307  \n","3  0.304199  0.468750  0.238403  0.596680 -0.012749 -0.527832  \n","4 -0.387939  0.046753  0.535156 -0.226318 -0.266357 -0.281494  \n","\n","[5 rows x 70 columns]"],"text/html":["\n","  <div id=\"df-ec3b3094-71a8-4675-b52b-06bf1bec2e88\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>6</th>\n","      <th>7</th>\n","      <th>8</th>\n","      <th>9</th>\n","      <th>...</th>\n","      <th>60</th>\n","      <th>61</th>\n","      <th>62</th>\n","      <th>63</th>\n","      <th>64</th>\n","      <th>65</th>\n","      <th>66</th>\n","      <th>67</th>\n","      <th>68</th>\n","      <th>69</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>47.750000</td>\n","      <td>-11.351562</td>\n","      <td>8.671875</td>\n","      <td>4.140625</td>\n","      <td>0.001740</td>\n","      <td>-1.680664</td>\n","      <td>-2.671875</td>\n","      <td>-3.908203</td>\n","      <td>1.177734</td>\n","      <td>-3.175781</td>\n","      <td>...</td>\n","      <td>0.365967</td>\n","      <td>0.129883</td>\n","      <td>0.121094</td>\n","      <td>0.082031</td>\n","      <td>0.475830</td>\n","      <td>0.267822</td>\n","      <td>0.359375</td>\n","      <td>-0.277344</td>\n","      <td>0.040833</td>\n","      <td>-0.316650</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>5.304688</td>\n","      <td>1.829102</td>\n","      <td>-0.296143</td>\n","      <td>0.157104</td>\n","      <td>2.056641</td>\n","      <td>-0.762695</td>\n","      <td>0.658203</td>\n","      <td>-0.722168</td>\n","      <td>-0.078491</td>\n","      <td>-0.164795</td>\n","      <td>...</td>\n","      <td>-0.370117</td>\n","      <td>-0.156860</td>\n","      <td>-0.163940</td>\n","      <td>-0.010147</td>\n","      <td>-0.183838</td>\n","      <td>0.136963</td>\n","      <td>-0.185669</td>\n","      <td>-0.165161</td>\n","      <td>0.416016</td>\n","      <td>0.277100</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>46.468750</td>\n","      <td>-3.177734</td>\n","      <td>2.244141</td>\n","      <td>-2.126953</td>\n","      <td>3.591797</td>\n","      <td>-0.084961</td>\n","      <td>-1.333008</td>\n","      <td>-0.760742</td>\n","      <td>-0.364746</td>\n","      <td>-1.527344</td>\n","      <td>...</td>\n","      <td>-0.081055</td>\n","      <td>-0.395752</td>\n","      <td>-0.463867</td>\n","      <td>-0.028656</td>\n","      <td>-0.225830</td>\n","      <td>-0.159302</td>\n","      <td>-0.435547</td>\n","      <td>0.934082</td>\n","      <td>0.944336</td>\n","      <td>-0.414307</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>24.046875</td>\n","      <td>0.009918</td>\n","      <td>4.304688</td>\n","      <td>0.249756</td>\n","      <td>4.191406</td>\n","      <td>-1.353516</td>\n","      <td>0.979004</td>\n","      <td>0.276611</td>\n","      <td>-2.476562</td>\n","      <td>1.370117</td>\n","      <td>...</td>\n","      <td>0.556152</td>\n","      <td>-0.222656</td>\n","      <td>0.141602</td>\n","      <td>-0.159912</td>\n","      <td>0.304199</td>\n","      <td>0.468750</td>\n","      <td>0.238403</td>\n","      <td>0.596680</td>\n","      <td>-0.012749</td>\n","      <td>-0.527832</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>19.906250</td>\n","      <td>2.650391</td>\n","      <td>1.765625</td>\n","      <td>1.832031</td>\n","      <td>0.311279</td>\n","      <td>-2.189453</td>\n","      <td>0.402344</td>\n","      <td>-2.216797</td>\n","      <td>0.700684</td>\n","      <td>-0.859375</td>\n","      <td>...</td>\n","      <td>0.228760</td>\n","      <td>-0.562988</td>\n","      <td>0.368652</td>\n","      <td>0.459961</td>\n","      <td>-0.387939</td>\n","      <td>0.046753</td>\n","      <td>0.535156</td>\n","      <td>-0.226318</td>\n","      <td>-0.266357</td>\n","      <td>-0.281494</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 70 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ec3b3094-71a8-4675-b52b-06bf1bec2e88')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-ec3b3094-71a8-4675-b52b-06bf1bec2e88 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-ec3b3094-71a8-4675-b52b-06bf1bec2e88');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-df240ed6-81a8-4e43-b3c7-e9af17c5610f\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-df240ed6-81a8-4e43-b3c7-e9af17c5610f')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-df240ed6-81a8-4e43-b3c7-e9af17c5610f button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":20}]},{"cell_type":"code","source":["x_test_feat_sel.columns"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_aA3jbxUk6Pw","executionInfo":{"status":"ok","timestamp":1707581387844,"user_tz":-240,"elapsed":381,"user":{"displayName":"Евгений Малов","userId":"06257165098392198337"}},"outputId":"7cedea84-9b9b-4493-e947-d679a4880236"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Index(['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12',\n","       '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24',\n","       '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36',\n","       '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48',\n","       '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60',\n","       '61', '62', '63', '64', '65', '66', '67', '68', '69'],\n","      dtype='object')"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["x_train_feat_sel.to_parquet(os.path.join(path, f'feat_sel_min_x_train.parquet')).astype('float16')\n","x_test_feat_sel.to_parquet(os.path.join(path, f'feat_sel_min_x_test.parquet')).astype('float16')"],"metadata":{"id":"fVOG1jN9gfaF","colab":{"base_uri":"https://localhost:8080/","height":159},"executionInfo":{"status":"error","timestamp":1708008136125,"user_tz":-240,"elapsed":461,"user":{"displayName":"Евгений Малов","userId":"06257165098392198337"}},"outputId":"0f17034b-b310-419e-d913-00183a1735cc"},"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'x_train_feat_sel' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-13-82ed0e33a574>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx_train_feat_sel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_parquet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf'feat_sel_min_x_train.parquet'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'float16'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mx_test_feat_sel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_parquet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf'feat_sel_min_x_test.parquet'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'float16'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'x_train_feat_sel' is not defined"]}]},{"cell_type":"code","source":["x_train_feat_sel = pd.read_parquet(path+'/feat_sel_min_x_train.parquet').astype('float16')\n","x_test_feat_sel = pd.read_parquet(path+'/feat_sel_min_x_test.parquet').astype('float16')"],"metadata":{"id":"Bf1627_cOMEx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["x_train_feat_sel.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":256},"id":"BZJgIamXpYjW","executionInfo":{"status":"ok","timestamp":1707647043322,"user_tz":-240,"elapsed":275,"user":{"displayName":"Евгений Малов","userId":"06257165098392198337"}},"outputId":"737fc60e-cc6c-4377-af7f-07b0e349ff35"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["           0          1         2         3         4         5         6  \\\n","0  88.000000 -25.312500  7.734375  3.373047  4.585938  1.785156  0.276367   \n","1  15.320312   1.814453 -0.877930 -0.210205  5.609375 -0.002474  1.201172   \n","2  19.921875  -7.984375  0.605469  0.604492  2.587891  1.683594  0.000898   \n","3  13.578125  -6.636719  1.875977 -0.917969  1.704102 -1.853516 -0.118530   \n","4  81.812500  -2.052734 -2.914062  1.449219  9.203125 -0.133911 -0.528320   \n","\n","          7         8         9  ...        40        41        42        43  \\\n","0 -1.389648 -3.546875 -2.556641  ... -1.347656  0.611816  0.282227  0.625977   \n","1  1.243164 -1.426758 -0.181030  ... -0.156616  0.471680 -0.489258  0.185791   \n","2  2.214844  1.952148  1.559570  ... -0.614258  0.030060 -0.505859  0.486572   \n","3  0.548828 -1.237305  0.521973  ...  0.136597 -0.637695 -0.045349 -0.135010   \n","4  6.472656  0.043945  0.380859  ...  0.740723 -1.570312  0.380859  1.030273   \n","\n","         44        45        46        47        48        49  \n","0 -0.291016  0.920410  0.759766 -0.171143  1.277344  0.189331  \n","1 -0.222168  0.621094 -0.050751 -0.648926 -0.432617 -0.103699  \n","2  0.080444 -0.255371  0.388184  0.740234 -1.104492  0.531738  \n","3 -0.350830  0.044342 -0.118896 -0.098633 -0.018661 -0.490479  \n","4  0.771973  1.149414  0.612305  1.340820  0.762695 -0.582031  \n","\n","[5 rows x 50 columns]"],"text/html":["\n","  <div id=\"df-5f9e53d1-a871-4b74-8199-674186b8159d\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>6</th>\n","      <th>7</th>\n","      <th>8</th>\n","      <th>9</th>\n","      <th>...</th>\n","      <th>40</th>\n","      <th>41</th>\n","      <th>42</th>\n","      <th>43</th>\n","      <th>44</th>\n","      <th>45</th>\n","      <th>46</th>\n","      <th>47</th>\n","      <th>48</th>\n","      <th>49</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>88.000000</td>\n","      <td>-25.312500</td>\n","      <td>7.734375</td>\n","      <td>3.373047</td>\n","      <td>4.585938</td>\n","      <td>1.785156</td>\n","      <td>0.276367</td>\n","      <td>-1.389648</td>\n","      <td>-3.546875</td>\n","      <td>-2.556641</td>\n","      <td>...</td>\n","      <td>-1.347656</td>\n","      <td>0.611816</td>\n","      <td>0.282227</td>\n","      <td>0.625977</td>\n","      <td>-0.291016</td>\n","      <td>0.920410</td>\n","      <td>0.759766</td>\n","      <td>-0.171143</td>\n","      <td>1.277344</td>\n","      <td>0.189331</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>15.320312</td>\n","      <td>1.814453</td>\n","      <td>-0.877930</td>\n","      <td>-0.210205</td>\n","      <td>5.609375</td>\n","      <td>-0.002474</td>\n","      <td>1.201172</td>\n","      <td>1.243164</td>\n","      <td>-1.426758</td>\n","      <td>-0.181030</td>\n","      <td>...</td>\n","      <td>-0.156616</td>\n","      <td>0.471680</td>\n","      <td>-0.489258</td>\n","      <td>0.185791</td>\n","      <td>-0.222168</td>\n","      <td>0.621094</td>\n","      <td>-0.050751</td>\n","      <td>-0.648926</td>\n","      <td>-0.432617</td>\n","      <td>-0.103699</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>19.921875</td>\n","      <td>-7.984375</td>\n","      <td>0.605469</td>\n","      <td>0.604492</td>\n","      <td>2.587891</td>\n","      <td>1.683594</td>\n","      <td>0.000898</td>\n","      <td>2.214844</td>\n","      <td>1.952148</td>\n","      <td>1.559570</td>\n","      <td>...</td>\n","      <td>-0.614258</td>\n","      <td>0.030060</td>\n","      <td>-0.505859</td>\n","      <td>0.486572</td>\n","      <td>0.080444</td>\n","      <td>-0.255371</td>\n","      <td>0.388184</td>\n","      <td>0.740234</td>\n","      <td>-1.104492</td>\n","      <td>0.531738</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>13.578125</td>\n","      <td>-6.636719</td>\n","      <td>1.875977</td>\n","      <td>-0.917969</td>\n","      <td>1.704102</td>\n","      <td>-1.853516</td>\n","      <td>-0.118530</td>\n","      <td>0.548828</td>\n","      <td>-1.237305</td>\n","      <td>0.521973</td>\n","      <td>...</td>\n","      <td>0.136597</td>\n","      <td>-0.637695</td>\n","      <td>-0.045349</td>\n","      <td>-0.135010</td>\n","      <td>-0.350830</td>\n","      <td>0.044342</td>\n","      <td>-0.118896</td>\n","      <td>-0.098633</td>\n","      <td>-0.018661</td>\n","      <td>-0.490479</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>81.812500</td>\n","      <td>-2.052734</td>\n","      <td>-2.914062</td>\n","      <td>1.449219</td>\n","      <td>9.203125</td>\n","      <td>-0.133911</td>\n","      <td>-0.528320</td>\n","      <td>6.472656</td>\n","      <td>0.043945</td>\n","      <td>0.380859</td>\n","      <td>...</td>\n","      <td>0.740723</td>\n","      <td>-1.570312</td>\n","      <td>0.380859</td>\n","      <td>1.030273</td>\n","      <td>0.771973</td>\n","      <td>1.149414</td>\n","      <td>0.612305</td>\n","      <td>1.340820</td>\n","      <td>0.762695</td>\n","      <td>-0.582031</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 50 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5f9e53d1-a871-4b74-8199-674186b8159d')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-5f9e53d1-a871-4b74-8199-674186b8159d button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-5f9e53d1-a871-4b74-8199-674186b8159d');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-78e76894-b389-43d7-80b5-3f3d0c4a52e5\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-78e76894-b389-43d7-80b5-3f3d0c4a52e5')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-78e76894-b389-43d7-80b5-3f3d0c4a52e5 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["del x_train\n","del x_test"],"metadata":{"id":"a2fuEgpQ0mFw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model_log_reg = LogisticRegression()\n","model_log_reg.fit(x_train_feat_sel, y_train)\n","\n","pred_train = model_log_reg.predict(x_train_feat_sel)\n","pred_test = model_log_reg.predict(x_test_feat_sel)\n","\n","print(f'train: {roc_auc_score(y_train, pred_train)}')\n","print(f'test: {roc_auc_score(y_test, pred_test)}')\n","print(f'test conf matrix: \\n {confusion_matrix(y_test, pred_test)}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"v8hm6kT_gfg8","executionInfo":{"status":"ok","timestamp":1707586356731,"user_tz":-240,"elapsed":79196,"user":{"displayName":"Евгений Малов","userId":"06257165098392198337"}},"outputId":"28698e07-742a-418f-be9b-391fd76c12fc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["train: 0.500817912676988\n","test: 0.5006611230887893\n","test conf matrix: \n"," [[867832    182]\n"," [ 31937     49]]\n"]}]},{"cell_type":"code","source":["model_lgbm = LGBMClassifier()\n","model_lgbm.fit(x_train_feat_sel, y_train)\n","\n","pred_train = model_lgbm.predict(x_train_feat_sel)\n","pred_test = model_lgbm.predict(x_test_feat_sel)\n","\n","print(f'train: {roc_auc_score(y_train, pred_train)}')\n","print(f'test: {roc_auc_score(y_test, pred_test)}')\n","print(f'test conf matrix: \\n {confusion_matrix(y_test, pred_test)}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"s8VpN9Nd2uJr","executionInfo":{"status":"ok","timestamp":1707586503962,"user_tz":-240,"elapsed":140287,"user":{"displayName":"Евгений Малов","userId":"06257165098392198337"}},"outputId":"6c9fdb1d-1cba-4a91-ae74-ae0db5a8acd9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[LightGBM] [Info] Number of positive: 74456, number of negative: 2025544\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 2.098661 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 12750\n","[LightGBM] [Info] Number of data points in the train set: 2100000, number of used features: 50\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.035455 -> initscore=-3.303385\n","[LightGBM] [Info] Start training from score -3.303385\n","train: 0.5000589572961138\n","test: 0.5000607992729913\n","test conf matrix: \n"," [[868011      3]\n"," [ 31982      4]]\n"]}]},{"cell_type":"code","source":["# с балансировкой классов\n","model_lgbm = LGBMClassifier(class_weight='balanced')\n","model_lgbm.fit(x_train_feat_sel, y_train)\n","\n","pred_train = model_lgbm.predict(x_train_feat_sel)\n","pred_test = model_lgbm.predict(x_test_feat_sel)\n","\n","print(f'train: {roc_auc_score(y_train, pred_train)}')\n","print(f'test: {roc_auc_score(y_test, pred_test)}')\n","print(f'test conf matrix: \\n {confusion_matrix(y_test, pred_test)}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jDQCCogWPHYc","executionInfo":{"status":"ok","timestamp":1708008650702,"user_tz":-240,"elapsed":148565,"user":{"displayName":"Евгений Малов","userId":"06257165098392198337"}},"outputId":"c03b4fe7-a2c7-4722-9d30-518c8b38a52b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[LightGBM] [Info] Number of positive: 74456, number of negative: 2025544\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 1.323087 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 12750\n","[LightGBM] [Info] Number of data points in the train set: 2100000, number of used features: 50\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n","[LightGBM] [Info] Start training from score -0.000000\n","train: 0.675164837989934\n","test: 0.6626970538308848\n","test conf matrix: \n"," [[565136 302878]\n"," [ 10417  21569]]\n"]}]},{"cell_type":"code","source":["model_xbm = XGBClassifier()\n","model_xbm.fit(x_train_feat_sel, y_train)\n","\n","pred_train = model_xbm.predict(x_train_feat_sel)\n","pred_test = model_xbm.predict(x_test_feat_sel)\n","\n","print(f'train: {roc_auc_score(y_train, pred_train)}')\n","print(f'test: {roc_auc_score(y_test, pred_test)}')\n","print(f'test conf matrix: \\n {confusion_matrix(y_test, pred_test)}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uv9KH_Ic2y4h","executionInfo":{"status":"ok","timestamp":1708008766783,"user_tz":-240,"elapsed":95264,"user":{"displayName":"Евгений Малов","userId":"06257165098392198337"}},"outputId":"83fefd9d-74b5-4b2d-bd06-34dedc261ce6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["train: 0.5016318867516059\n","test: 0.500252571721952\n","test conf matrix: \n"," [[867964     50]\n"," [ 31968     18]]\n"]}]},{"cell_type":"code","source":["# с балансировкой классов\n","model_xbm = XGBClassifier(class_weight='balanced')\n","model_xbm.fit(x_train_feat_sel, y_train)\n","\n","pred_train = model_xbm.predict(x_train_feat_sel)\n","pred_test = model_xbm.predict(x_test_feat_sel)\n","\n","print(f'train: {roc_auc_score(y_train, pred_train)}')\n","print(f'test: {roc_auc_score(y_test, pred_test)}')\n","print(f'test conf matrix: \\n {confusion_matrix(y_test, pred_test)}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xlSLKpWLPl0y","executionInfo":{"status":"ok","timestamp":1708008981202,"user_tz":-240,"elapsed":77762,"user":{"displayName":"Евгений Малов","userId":"06257165098392198337"}},"outputId":"3ee2f150-668c-4d0c-efd9-edec5f0a4633"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["train: 0.5016318867516059\n","test: 0.500252571721952\n","test conf matrix: \n"," [[867964     50]\n"," [ 31968     18]]\n"]}]},{"cell_type":"code","source":["model_catb = CatBoostClassifier()\n","model_catb.fit(x_train_feat_sel, y_train)\n","\n","pred_train = model_catb.predict(x_train_feat_sel)\n","pred_test = model_catb.predict(x_test_feat_sel)\n","\n","print(f'train: {roc_auc_score(y_train, pred_train)}')\n","print(f'test: {roc_auc_score(y_test, pred_test)}')\n","print(f'test conf matrix: \\n {confusion_matrix(y_test, pred_test)}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nbuMGM882y8c","executionInfo":{"status":"ok","timestamp":1707587553823,"user_tz":-240,"elapsed":949838,"user":{"displayName":"Евгений Малов","userId":"06257165098392198337"}},"outputId":"8c67db77-2726-48c5-c892-b087f4a79da0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Learning rate set to 0.270098\n","0:\tlearn: 0.3747906\ttotal: 949ms\tremaining: 15m 48s\n","1:\tlearn: 0.2467902\ttotal: 1.77s\tremaining: 14m 43s\n","2:\tlearn: 0.1919636\ttotal: 2.54s\tremaining: 14m 3s\n","3:\tlearn: 0.1686874\ttotal: 3.55s\tremaining: 14m 43s\n","4:\tlearn: 0.1579861\ttotal: 4.63s\tremaining: 15m 20s\n","5:\tlearn: 0.1521504\ttotal: 5.98s\tremaining: 16m 30s\n","6:\tlearn: 0.1493038\ttotal: 7s\tremaining: 16m 32s\n","7:\tlearn: 0.1478711\ttotal: 7.72s\tremaining: 15m 57s\n","8:\tlearn: 0.1467517\ttotal: 8.4s\tremaining: 15m 24s\n","9:\tlearn: 0.1461108\ttotal: 9.05s\tremaining: 14m 56s\n","10:\tlearn: 0.1457055\ttotal: 9.77s\tremaining: 14m 38s\n","11:\tlearn: 0.1453585\ttotal: 10.4s\tremaining: 14m 18s\n","12:\tlearn: 0.1451379\ttotal: 11.2s\tremaining: 14m 7s\n","13:\tlearn: 0.1449114\ttotal: 12s\tremaining: 14m 3s\n","14:\tlearn: 0.1446737\ttotal: 12.7s\tremaining: 13m 54s\n","15:\tlearn: 0.1445186\ttotal: 13.4s\tremaining: 13m 46s\n","16:\tlearn: 0.1443788\ttotal: 14.1s\tremaining: 13m 36s\n","17:\tlearn: 0.1442796\ttotal: 14.8s\tremaining: 13m 26s\n","18:\tlearn: 0.1441376\ttotal: 15.4s\tremaining: 13m 14s\n","19:\tlearn: 0.1440041\ttotal: 16.1s\tremaining: 13m 9s\n","20:\tlearn: 0.1438962\ttotal: 16.8s\tremaining: 13m 4s\n","21:\tlearn: 0.1437965\ttotal: 18s\tremaining: 13m 19s\n","22:\tlearn: 0.1437139\ttotal: 19.3s\tremaining: 13m 38s\n","23:\tlearn: 0.1436342\ttotal: 20.4s\tremaining: 13m 47s\n","24:\tlearn: 0.1435555\ttotal: 21.2s\tremaining: 13m 48s\n","25:\tlearn: 0.1434899\ttotal: 21.8s\tremaining: 13m 38s\n","26:\tlearn: 0.1434321\ttotal: 22.5s\tremaining: 13m 30s\n","27:\tlearn: 0.1433592\ttotal: 23.2s\tremaining: 13m 24s\n","28:\tlearn: 0.1433004\ttotal: 23.9s\tremaining: 13m 20s\n","29:\tlearn: 0.1432327\ttotal: 24.6s\tremaining: 13m 16s\n","30:\tlearn: 0.1431621\ttotal: 25.4s\tremaining: 13m 14s\n","31:\tlearn: 0.1431029\ttotal: 26.2s\tremaining: 13m 12s\n","32:\tlearn: 0.1430547\ttotal: 26.9s\tremaining: 13m 8s\n","33:\tlearn: 0.1429958\ttotal: 27.6s\tremaining: 13m 5s\n","34:\tlearn: 0.1429539\ttotal: 28.4s\tremaining: 13m 1s\n","35:\tlearn: 0.1429166\ttotal: 29.1s\tremaining: 12m 58s\n","36:\tlearn: 0.1428710\ttotal: 29.9s\tremaining: 12m 58s\n","37:\tlearn: 0.1428230\ttotal: 30.6s\tremaining: 12m 54s\n","38:\tlearn: 0.1427811\ttotal: 32s\tremaining: 13m 9s\n","39:\tlearn: 0.1427310\ttotal: 33.4s\tremaining: 13m 22s\n","40:\tlearn: 0.1426749\ttotal: 34.8s\tremaining: 13m 34s\n","41:\tlearn: 0.1426340\ttotal: 35.5s\tremaining: 13m 30s\n","42:\tlearn: 0.1426051\ttotal: 36.3s\tremaining: 13m 27s\n","43:\tlearn: 0.1425761\ttotal: 37.1s\tremaining: 13m 26s\n","44:\tlearn: 0.1425379\ttotal: 37.9s\tremaining: 13m 23s\n","45:\tlearn: 0.1425109\ttotal: 38.5s\tremaining: 13m 19s\n","46:\tlearn: 0.1424707\ttotal: 39.3s\tremaining: 13m 16s\n","47:\tlearn: 0.1424350\ttotal: 40.1s\tremaining: 13m 15s\n","48:\tlearn: 0.1424066\ttotal: 40.8s\tremaining: 13m 10s\n","49:\tlearn: 0.1423829\ttotal: 41.5s\tremaining: 13m 8s\n","50:\tlearn: 0.1423528\ttotal: 42.2s\tremaining: 13m 5s\n","51:\tlearn: 0.1423195\ttotal: 42.9s\tremaining: 13m 1s\n","52:\tlearn: 0.1422730\ttotal: 43.5s\tremaining: 12m 57s\n","53:\tlearn: 0.1422364\ttotal: 44.4s\tremaining: 12m 57s\n","54:\tlearn: 0.1422003\ttotal: 45.1s\tremaining: 12m 54s\n","55:\tlearn: 0.1421669\ttotal: 46.3s\tremaining: 13m\n","56:\tlearn: 0.1421416\ttotal: 47.6s\tremaining: 13m 8s\n","57:\tlearn: 0.1421028\ttotal: 48.8s\tremaining: 13m 11s\n","58:\tlearn: 0.1420772\ttotal: 49.6s\tremaining: 13m 10s\n","59:\tlearn: 0.1420454\ttotal: 50.3s\tremaining: 13m 8s\n","60:\tlearn: 0.1420221\ttotal: 51s\tremaining: 13m 4s\n","61:\tlearn: 0.1419771\ttotal: 51.8s\tremaining: 13m 2s\n","62:\tlearn: 0.1419355\ttotal: 52.5s\tremaining: 13m 1s\n","63:\tlearn: 0.1418977\ttotal: 53.2s\tremaining: 12m 58s\n","64:\tlearn: 0.1418622\ttotal: 54s\tremaining: 12m 57s\n","65:\tlearn: 0.1418386\ttotal: 54.8s\tremaining: 12m 55s\n","66:\tlearn: 0.1418116\ttotal: 55.5s\tremaining: 12m 52s\n","67:\tlearn: 0.1417781\ttotal: 56.3s\tremaining: 12m 51s\n","68:\tlearn: 0.1417528\ttotal: 57s\tremaining: 12m 49s\n","69:\tlearn: 0.1417219\ttotal: 57.8s\tremaining: 12m 47s\n","70:\tlearn: 0.1416945\ttotal: 58.6s\tremaining: 12m 47s\n","71:\tlearn: 0.1416641\ttotal: 59.7s\tremaining: 12m 50s\n","72:\tlearn: 0.1416279\ttotal: 1m 1s\tremaining: 12m 57s\n","73:\tlearn: 0.1416006\ttotal: 1m 2s\tremaining: 13m 2s\n","74:\tlearn: 0.1415728\ttotal: 1m 3s\tremaining: 13m 2s\n","75:\tlearn: 0.1415457\ttotal: 1m 4s\tremaining: 13m 1s\n","76:\tlearn: 0.1415169\ttotal: 1m 5s\tremaining: 13m\n","77:\tlearn: 0.1414978\ttotal: 1m 5s\tremaining: 12m 57s\n","78:\tlearn: 0.1414697\ttotal: 1m 6s\tremaining: 12m 54s\n","79:\tlearn: 0.1414494\ttotal: 1m 7s\tremaining: 12m 53s\n","80:\tlearn: 0.1414247\ttotal: 1m 7s\tremaining: 12m 51s\n","81:\tlearn: 0.1414013\ttotal: 1m 8s\tremaining: 12m 49s\n","82:\tlearn: 0.1413710\ttotal: 1m 9s\tremaining: 12m 47s\n","83:\tlearn: 0.1413481\ttotal: 1m 10s\tremaining: 12m 45s\n","84:\tlearn: 0.1413220\ttotal: 1m 10s\tremaining: 12m 43s\n","85:\tlearn: 0.1412912\ttotal: 1m 11s\tremaining: 12m 41s\n","86:\tlearn: 0.1412603\ttotal: 1m 12s\tremaining: 12m 40s\n","87:\tlearn: 0.1412348\ttotal: 1m 13s\tremaining: 12m 40s\n","88:\tlearn: 0.1412119\ttotal: 1m 14s\tremaining: 12m 43s\n","89:\tlearn: 0.1411848\ttotal: 1m 15s\tremaining: 12m 47s\n","90:\tlearn: 0.1411609\ttotal: 1m 17s\tremaining: 12m 51s\n","91:\tlearn: 0.1411343\ttotal: 1m 18s\tremaining: 12m 50s\n","92:\tlearn: 0.1411137\ttotal: 1m 18s\tremaining: 12m 47s\n","93:\tlearn: 0.1410945\ttotal: 1m 19s\tremaining: 12m 45s\n","94:\tlearn: 0.1410746\ttotal: 1m 20s\tremaining: 12m 42s\n","95:\tlearn: 0.1410510\ttotal: 1m 20s\tremaining: 12m 40s\n","96:\tlearn: 0.1410297\ttotal: 1m 21s\tremaining: 12m 39s\n","97:\tlearn: 0.1410108\ttotal: 1m 22s\tremaining: 12m 38s\n","98:\tlearn: 0.1409849\ttotal: 1m 23s\tremaining: 12m 37s\n","99:\tlearn: 0.1409605\ttotal: 1m 24s\tremaining: 12m 36s\n","100:\tlearn: 0.1409442\ttotal: 1m 24s\tremaining: 12m 34s\n","101:\tlearn: 0.1409298\ttotal: 1m 25s\tremaining: 12m 32s\n","102:\tlearn: 0.1409030\ttotal: 1m 26s\tremaining: 12m 30s\n","103:\tlearn: 0.1408850\ttotal: 1m 26s\tremaining: 12m 28s\n","104:\tlearn: 0.1408685\ttotal: 1m 27s\tremaining: 12m 26s\n","105:\tlearn: 0.1408440\ttotal: 1m 28s\tremaining: 12m 30s\n","106:\tlearn: 0.1408218\ttotal: 1m 30s\tremaining: 12m 33s\n","107:\tlearn: 0.1407962\ttotal: 1m 31s\tremaining: 12m 34s\n","108:\tlearn: 0.1407744\ttotal: 1m 32s\tremaining: 12m 32s\n","109:\tlearn: 0.1407524\ttotal: 1m 32s\tremaining: 12m 32s\n","110:\tlearn: 0.1407349\ttotal: 1m 33s\tremaining: 12m 30s\n","111:\tlearn: 0.1407112\ttotal: 1m 34s\tremaining: 12m 28s\n","112:\tlearn: 0.1406790\ttotal: 1m 35s\tremaining: 12m 27s\n","113:\tlearn: 0.1406632\ttotal: 1m 35s\tremaining: 12m 25s\n","114:\tlearn: 0.1406391\ttotal: 1m 36s\tremaining: 12m 24s\n","115:\tlearn: 0.1406210\ttotal: 1m 37s\tremaining: 12m 21s\n","116:\tlearn: 0.1406085\ttotal: 1m 38s\tremaining: 12m 19s\n","117:\tlearn: 0.1405864\ttotal: 1m 38s\tremaining: 12m 18s\n","118:\tlearn: 0.1405705\ttotal: 1m 39s\tremaining: 12m 16s\n","119:\tlearn: 0.1405511\ttotal: 1m 40s\tremaining: 12m 14s\n","120:\tlearn: 0.1405334\ttotal: 1m 40s\tremaining: 12m 12s\n","121:\tlearn: 0.1405060\ttotal: 1m 41s\tremaining: 12m 13s\n","122:\tlearn: 0.1404879\ttotal: 1m 43s\tremaining: 12m 15s\n","123:\tlearn: 0.1404633\ttotal: 1m 44s\tremaining: 12m 17s\n","124:\tlearn: 0.1404443\ttotal: 1m 45s\tremaining: 12m 17s\n","125:\tlearn: 0.1404224\ttotal: 1m 46s\tremaining: 12m 16s\n","126:\tlearn: 0.1404036\ttotal: 1m 46s\tremaining: 12m 14s\n","127:\tlearn: 0.1403854\ttotal: 1m 47s\tremaining: 12m 12s\n","128:\tlearn: 0.1403643\ttotal: 1m 48s\tremaining: 12m 10s\n","129:\tlearn: 0.1403434\ttotal: 1m 49s\tremaining: 12m 9s\n","130:\tlearn: 0.1403211\ttotal: 1m 49s\tremaining: 12m 8s\n","131:\tlearn: 0.1403046\ttotal: 1m 50s\tremaining: 12m 6s\n","132:\tlearn: 0.1402859\ttotal: 1m 51s\tremaining: 12m 4s\n","133:\tlearn: 0.1402726\ttotal: 1m 51s\tremaining: 12m 2s\n","134:\tlearn: 0.1402545\ttotal: 1m 52s\tremaining: 12m\n","135:\tlearn: 0.1402358\ttotal: 1m 53s\tremaining: 11m 58s\n","136:\tlearn: 0.1402174\ttotal: 1m 53s\tremaining: 11m 56s\n","137:\tlearn: 0.1402005\ttotal: 1m 54s\tremaining: 11m 55s\n","138:\tlearn: 0.1401796\ttotal: 1m 55s\tremaining: 11m 54s\n","139:\tlearn: 0.1401658\ttotal: 1m 56s\tremaining: 11m 56s\n","140:\tlearn: 0.1401471\ttotal: 1m 57s\tremaining: 11m 58s\n","141:\tlearn: 0.1401280\ttotal: 1m 59s\tremaining: 11m 59s\n","142:\tlearn: 0.1401121\ttotal: 1m 59s\tremaining: 11m 58s\n","143:\tlearn: 0.1400977\ttotal: 2m\tremaining: 11m 56s\n","144:\tlearn: 0.1400842\ttotal: 2m 1s\tremaining: 11m 54s\n","145:\tlearn: 0.1400692\ttotal: 2m 1s\tremaining: 11m 52s\n","146:\tlearn: 0.1400477\ttotal: 2m 2s\tremaining: 11m 50s\n","147:\tlearn: 0.1400319\ttotal: 2m 3s\tremaining: 11m 49s\n","148:\tlearn: 0.1400118\ttotal: 2m 4s\tremaining: 11m 48s\n","149:\tlearn: 0.1399947\ttotal: 2m 4s\tremaining: 11m 47s\n","150:\tlearn: 0.1399735\ttotal: 2m 5s\tremaining: 11m 46s\n","151:\tlearn: 0.1399546\ttotal: 2m 6s\tremaining: 11m 44s\n","152:\tlearn: 0.1399353\ttotal: 2m 7s\tremaining: 11m 43s\n","153:\tlearn: 0.1399054\ttotal: 2m 7s\tremaining: 11m 42s\n","154:\tlearn: 0.1398867\ttotal: 2m 8s\tremaining: 11m 42s\n","155:\tlearn: 0.1398689\ttotal: 2m 9s\tremaining: 11m 41s\n","156:\tlearn: 0.1398557\ttotal: 2m 10s\tremaining: 11m 42s\n","157:\tlearn: 0.1398371\ttotal: 2m 12s\tremaining: 11m 44s\n","158:\tlearn: 0.1398118\ttotal: 2m 13s\tremaining: 11m 45s\n","159:\tlearn: 0.1397933\ttotal: 2m 14s\tremaining: 11m 44s\n","160:\tlearn: 0.1397688\ttotal: 2m 14s\tremaining: 11m 42s\n","161:\tlearn: 0.1397528\ttotal: 2m 15s\tremaining: 11m 40s\n","162:\tlearn: 0.1397300\ttotal: 2m 16s\tremaining: 11m 39s\n","163:\tlearn: 0.1397176\ttotal: 2m 16s\tremaining: 11m 38s\n","164:\tlearn: 0.1397015\ttotal: 2m 17s\tremaining: 11m 36s\n","165:\tlearn: 0.1396875\ttotal: 2m 18s\tremaining: 11m 34s\n","166:\tlearn: 0.1396715\ttotal: 2m 19s\tremaining: 11m 33s\n","167:\tlearn: 0.1396508\ttotal: 2m 19s\tremaining: 11m 32s\n","168:\tlearn: 0.1396274\ttotal: 2m 20s\tremaining: 11m 31s\n","169:\tlearn: 0.1396056\ttotal: 2m 21s\tremaining: 11m 30s\n","170:\tlearn: 0.1395908\ttotal: 2m 22s\tremaining: 11m 28s\n","171:\tlearn: 0.1395680\ttotal: 2m 22s\tremaining: 11m 27s\n","172:\tlearn: 0.1395490\ttotal: 2m 24s\tremaining: 11m 28s\n","173:\tlearn: 0.1395364\ttotal: 2m 25s\tremaining: 11m 29s\n","174:\tlearn: 0.1395219\ttotal: 2m 26s\tremaining: 11m 30s\n","175:\tlearn: 0.1395057\ttotal: 2m 27s\tremaining: 11m 30s\n","176:\tlearn: 0.1394910\ttotal: 2m 28s\tremaining: 11m 28s\n","177:\tlearn: 0.1394717\ttotal: 2m 28s\tremaining: 11m 27s\n","178:\tlearn: 0.1394566\ttotal: 2m 29s\tremaining: 11m 25s\n","179:\tlearn: 0.1394433\ttotal: 2m 30s\tremaining: 11m 24s\n","180:\tlearn: 0.1394240\ttotal: 2m 30s\tremaining: 11m 23s\n","181:\tlearn: 0.1394075\ttotal: 2m 31s\tremaining: 11m 21s\n","182:\tlearn: 0.1393925\ttotal: 2m 32s\tremaining: 11m 20s\n","183:\tlearn: 0.1393747\ttotal: 2m 33s\tremaining: 11m 19s\n","184:\tlearn: 0.1393584\ttotal: 2m 33s\tremaining: 11m 17s\n","185:\tlearn: 0.1393407\ttotal: 2m 34s\tremaining: 11m 16s\n","186:\tlearn: 0.1393235\ttotal: 2m 35s\tremaining: 11m 15s\n","187:\tlearn: 0.1393095\ttotal: 2m 36s\tremaining: 11m 13s\n","188:\tlearn: 0.1392998\ttotal: 2m 36s\tremaining: 11m 12s\n","189:\tlearn: 0.1392864\ttotal: 2m 37s\tremaining: 11m 12s\n","190:\tlearn: 0.1392635\ttotal: 2m 39s\tremaining: 11m 13s\n","191:\tlearn: 0.1392506\ttotal: 2m 40s\tremaining: 11m 14s\n","192:\tlearn: 0.1392366\ttotal: 2m 41s\tremaining: 11m 14s\n","193:\tlearn: 0.1392147\ttotal: 2m 42s\tremaining: 11m 13s\n","194:\tlearn: 0.1391961\ttotal: 2m 43s\tremaining: 11m 13s\n","195:\tlearn: 0.1391736\ttotal: 2m 43s\tremaining: 11m 12s\n","196:\tlearn: 0.1391611\ttotal: 2m 44s\tremaining: 11m 11s\n","197:\tlearn: 0.1391368\ttotal: 2m 45s\tremaining: 11m 10s\n","198:\tlearn: 0.1391231\ttotal: 2m 46s\tremaining: 11m 8s\n","199:\tlearn: 0.1391108\ttotal: 2m 46s\tremaining: 11m 7s\n","200:\tlearn: 0.1390957\ttotal: 2m 47s\tremaining: 11m 5s\n","201:\tlearn: 0.1390856\ttotal: 2m 48s\tremaining: 11m 4s\n","202:\tlearn: 0.1390733\ttotal: 2m 48s\tremaining: 11m 2s\n","203:\tlearn: 0.1390560\ttotal: 2m 49s\tremaining: 11m 1s\n","204:\tlearn: 0.1390376\ttotal: 2m 50s\tremaining: 11m\n","205:\tlearn: 0.1390189\ttotal: 2m 51s\tremaining: 10m 59s\n","206:\tlearn: 0.1389945\ttotal: 2m 52s\tremaining: 10m 59s\n","207:\tlearn: 0.1389814\ttotal: 2m 53s\tremaining: 10m 59s\n","208:\tlearn: 0.1389671\ttotal: 2m 54s\tremaining: 11m\n","209:\tlearn: 0.1389510\ttotal: 2m 55s\tremaining: 11m\n","210:\tlearn: 0.1389381\ttotal: 2m 56s\tremaining: 10m 58s\n","211:\tlearn: 0.1389212\ttotal: 2m 56s\tremaining: 10m 57s\n","212:\tlearn: 0.1389074\ttotal: 2m 57s\tremaining: 10m 56s\n","213:\tlearn: 0.1388912\ttotal: 2m 58s\tremaining: 10m 54s\n","214:\tlearn: 0.1388736\ttotal: 2m 59s\tremaining: 10m 53s\n","215:\tlearn: 0.1388576\ttotal: 2m 59s\tremaining: 10m 52s\n","216:\tlearn: 0.1388458\ttotal: 3m\tremaining: 10m 51s\n","217:\tlearn: 0.1388316\ttotal: 3m 1s\tremaining: 10m 49s\n","218:\tlearn: 0.1388119\ttotal: 3m 1s\tremaining: 10m 48s\n","219:\tlearn: 0.1387955\ttotal: 3m 2s\tremaining: 10m 47s\n","220:\tlearn: 0.1387805\ttotal: 3m 3s\tremaining: 10m 45s\n","221:\tlearn: 0.1387686\ttotal: 3m 3s\tremaining: 10m 44s\n","222:\tlearn: 0.1387572\ttotal: 3m 4s\tremaining: 10m 43s\n","223:\tlearn: 0.1387398\ttotal: 3m 5s\tremaining: 10m 41s\n","224:\tlearn: 0.1387233\ttotal: 3m 6s\tremaining: 10m 42s\n","225:\tlearn: 0.1387136\ttotal: 3m 7s\tremaining: 10m 42s\n","226:\tlearn: 0.1386905\ttotal: 3m 8s\tremaining: 10m 43s\n","227:\tlearn: 0.1386776\ttotal: 3m 9s\tremaining: 10m 42s\n","228:\tlearn: 0.1386613\ttotal: 3m 10s\tremaining: 10m 41s\n","229:\tlearn: 0.1386454\ttotal: 3m 11s\tremaining: 10m 40s\n","230:\tlearn: 0.1386303\ttotal: 3m 12s\tremaining: 10m 39s\n","231:\tlearn: 0.1386142\ttotal: 3m 12s\tremaining: 10m 38s\n","232:\tlearn: 0.1386015\ttotal: 3m 13s\tremaining: 10m 36s\n","233:\tlearn: 0.1385826\ttotal: 3m 14s\tremaining: 10m 35s\n","234:\tlearn: 0.1385664\ttotal: 3m 15s\tremaining: 10m 34s\n","235:\tlearn: 0.1385551\ttotal: 3m 15s\tremaining: 10m 33s\n","236:\tlearn: 0.1385366\ttotal: 3m 16s\tremaining: 10m 32s\n","237:\tlearn: 0.1385182\ttotal: 3m 17s\tremaining: 10m 31s\n","238:\tlearn: 0.1385090\ttotal: 3m 17s\tremaining: 10m 29s\n","239:\tlearn: 0.1384960\ttotal: 3m 18s\tremaining: 10m 28s\n","240:\tlearn: 0.1384867\ttotal: 3m 19s\tremaining: 10m 27s\n","241:\tlearn: 0.1384706\ttotal: 3m 20s\tremaining: 10m 26s\n","242:\tlearn: 0.1384558\ttotal: 3m 21s\tremaining: 10m 27s\n","243:\tlearn: 0.1384416\ttotal: 3m 22s\tremaining: 10m 27s\n","244:\tlearn: 0.1384295\ttotal: 3m 23s\tremaining: 10m 27s\n","245:\tlearn: 0.1384146\ttotal: 3m 24s\tremaining: 10m 26s\n","246:\tlearn: 0.1383988\ttotal: 3m 25s\tremaining: 10m 25s\n","247:\tlearn: 0.1383859\ttotal: 3m 26s\tremaining: 10m 24s\n","248:\tlearn: 0.1383709\ttotal: 3m 26s\tremaining: 10m 23s\n","249:\tlearn: 0.1383548\ttotal: 3m 27s\tremaining: 10m 22s\n","250:\tlearn: 0.1383363\ttotal: 3m 28s\tremaining: 10m 21s\n","251:\tlearn: 0.1383254\ttotal: 3m 28s\tremaining: 10m 20s\n","252:\tlearn: 0.1383111\ttotal: 3m 29s\tremaining: 10m 19s\n","253:\tlearn: 0.1383014\ttotal: 3m 30s\tremaining: 10m 17s\n","254:\tlearn: 0.1382899\ttotal: 3m 31s\tremaining: 10m 16s\n","255:\tlearn: 0.1382762\ttotal: 3m 31s\tremaining: 10m 15s\n","256:\tlearn: 0.1382629\ttotal: 3m 32s\tremaining: 10m 13s\n","257:\tlearn: 0.1382487\ttotal: 3m 33s\tremaining: 10m 12s\n","258:\tlearn: 0.1382401\ttotal: 3m 34s\tremaining: 10m 12s\n","259:\tlearn: 0.1382306\ttotal: 3m 35s\tremaining: 10m 12s\n","260:\tlearn: 0.1382157\ttotal: 3m 36s\tremaining: 10m 13s\n","261:\tlearn: 0.1381976\ttotal: 3m 37s\tremaining: 10m 13s\n","262:\tlearn: 0.1381818\ttotal: 3m 38s\tremaining: 10m 12s\n","263:\tlearn: 0.1381632\ttotal: 3m 39s\tremaining: 10m 10s\n","264:\tlearn: 0.1381453\ttotal: 3m 39s\tremaining: 10m 9s\n","265:\tlearn: 0.1381230\ttotal: 3m 40s\tremaining: 10m 8s\n","266:\tlearn: 0.1381075\ttotal: 3m 41s\tremaining: 10m 8s\n","267:\tlearn: 0.1380946\ttotal: 3m 42s\tremaining: 10m 6s\n","268:\tlearn: 0.1380803\ttotal: 3m 42s\tremaining: 10m 5s\n","269:\tlearn: 0.1380651\ttotal: 3m 43s\tremaining: 10m 4s\n","270:\tlearn: 0.1380506\ttotal: 3m 44s\tremaining: 10m 3s\n","271:\tlearn: 0.1380336\ttotal: 3m 45s\tremaining: 10m 2s\n","272:\tlearn: 0.1380179\ttotal: 3m 45s\tremaining: 10m 1s\n","273:\tlearn: 0.1380068\ttotal: 3m 46s\tremaining: 10m\n","274:\tlearn: 0.1379935\ttotal: 3m 47s\tremaining: 10m\n","275:\tlearn: 0.1379793\ttotal: 3m 49s\tremaining: 10m\n","276:\tlearn: 0.1379646\ttotal: 3m 50s\tremaining: 10m\n","277:\tlearn: 0.1379475\ttotal: 3m 51s\tremaining: 10m 1s\n","278:\tlearn: 0.1379285\ttotal: 3m 52s\tremaining: 10m 1s\n","279:\tlearn: 0.1379137\ttotal: 3m 53s\tremaining: 9m 59s\n","280:\tlearn: 0.1379005\ttotal: 3m 53s\tremaining: 9m 58s\n","281:\tlearn: 0.1378879\ttotal: 3m 54s\tremaining: 9m 57s\n","282:\tlearn: 0.1378750\ttotal: 3m 55s\tremaining: 9m 56s\n","283:\tlearn: 0.1378563\ttotal: 3m 56s\tremaining: 9m 55s\n","284:\tlearn: 0.1378406\ttotal: 3m 56s\tremaining: 9m 54s\n","285:\tlearn: 0.1378264\ttotal: 3m 57s\tremaining: 9m 53s\n","286:\tlearn: 0.1378130\ttotal: 3m 58s\tremaining: 9m 52s\n","287:\tlearn: 0.1378003\ttotal: 3m 59s\tremaining: 9m 51s\n","288:\tlearn: 0.1377885\ttotal: 3m 59s\tremaining: 9m 50s\n","289:\tlearn: 0.1377764\ttotal: 4m\tremaining: 9m 49s\n","290:\tlearn: 0.1377601\ttotal: 4m 1s\tremaining: 9m 48s\n","291:\tlearn: 0.1377483\ttotal: 4m 2s\tremaining: 9m 47s\n","292:\tlearn: 0.1377369\ttotal: 4m 3s\tremaining: 9m 47s\n","293:\tlearn: 0.1377237\ttotal: 4m 4s\tremaining: 9m 47s\n","294:\tlearn: 0.1377095\ttotal: 4m 5s\tremaining: 9m 47s\n","295:\tlearn: 0.1376931\ttotal: 4m 6s\tremaining: 9m 46s\n","296:\tlearn: 0.1376762\ttotal: 4m 7s\tremaining: 9m 45s\n","297:\tlearn: 0.1376636\ttotal: 4m 8s\tremaining: 9m 44s\n","298:\tlearn: 0.1376452\ttotal: 4m 9s\tremaining: 9m 43s\n","299:\tlearn: 0.1376345\ttotal: 4m 9s\tremaining: 9m 42s\n","300:\tlearn: 0.1376229\ttotal: 4m 10s\tremaining: 9m 41s\n","301:\tlearn: 0.1376108\ttotal: 4m 11s\tremaining: 9m 40s\n","302:\tlearn: 0.1375975\ttotal: 4m 11s\tremaining: 9m 39s\n","303:\tlearn: 0.1375869\ttotal: 4m 12s\tremaining: 9m 38s\n","304:\tlearn: 0.1375703\ttotal: 4m 13s\tremaining: 9m 36s\n","305:\tlearn: 0.1375583\ttotal: 4m 13s\tremaining: 9m 35s\n","306:\tlearn: 0.1375451\ttotal: 4m 14s\tremaining: 9m 34s\n","307:\tlearn: 0.1375366\ttotal: 4m 15s\tremaining: 9m 33s\n","308:\tlearn: 0.1375200\ttotal: 4m 16s\tremaining: 9m 33s\n","309:\tlearn: 0.1375078\ttotal: 4m 17s\tremaining: 9m 33s\n","310:\tlearn: 0.1374954\ttotal: 4m 18s\tremaining: 9m 33s\n","311:\tlearn: 0.1374794\ttotal: 4m 19s\tremaining: 9m 33s\n","312:\tlearn: 0.1374673\ttotal: 4m 20s\tremaining: 9m 31s\n","313:\tlearn: 0.1374563\ttotal: 4m 21s\tremaining: 9m 30s\n","314:\tlearn: 0.1374434\ttotal: 4m 22s\tremaining: 9m 29s\n","315:\tlearn: 0.1374319\ttotal: 4m 22s\tremaining: 9m 28s\n","316:\tlearn: 0.1374184\ttotal: 4m 23s\tremaining: 9m 27s\n","317:\tlearn: 0.1374014\ttotal: 4m 24s\tremaining: 9m 26s\n","318:\tlearn: 0.1373833\ttotal: 4m 24s\tremaining: 9m 25s\n","319:\tlearn: 0.1373684\ttotal: 4m 25s\tremaining: 9m 24s\n","320:\tlearn: 0.1373564\ttotal: 4m 26s\tremaining: 9m 23s\n","321:\tlearn: 0.1373443\ttotal: 4m 27s\tremaining: 9m 22s\n","322:\tlearn: 0.1373288\ttotal: 4m 28s\tremaining: 9m 21s\n","323:\tlearn: 0.1373170\ttotal: 4m 28s\tremaining: 9m 20s\n","324:\tlearn: 0.1373076\ttotal: 4m 29s\tremaining: 9m 19s\n","325:\tlearn: 0.1372946\ttotal: 4m 30s\tremaining: 9m 19s\n","326:\tlearn: 0.1372794\ttotal: 4m 32s\tremaining: 9m 19s\n","327:\tlearn: 0.1372681\ttotal: 4m 33s\tremaining: 9m 19s\n","328:\tlearn: 0.1372581\ttotal: 4m 34s\tremaining: 9m 19s\n","329:\tlearn: 0.1372437\ttotal: 4m 35s\tremaining: 9m 18s\n","330:\tlearn: 0.1372315\ttotal: 4m 35s\tremaining: 9m 17s\n","331:\tlearn: 0.1372207\ttotal: 4m 36s\tremaining: 9m 16s\n","332:\tlearn: 0.1372058\ttotal: 4m 37s\tremaining: 9m 15s\n","333:\tlearn: 0.1371909\ttotal: 4m 38s\tremaining: 9m 14s\n","334:\tlearn: 0.1371788\ttotal: 4m 38s\tremaining: 9m 13s\n","335:\tlearn: 0.1371638\ttotal: 4m 39s\tremaining: 9m 12s\n","336:\tlearn: 0.1371488\ttotal: 4m 40s\tremaining: 9m 11s\n","337:\tlearn: 0.1371337\ttotal: 4m 41s\tremaining: 9m 10s\n","338:\tlearn: 0.1371210\ttotal: 4m 41s\tremaining: 9m 9s\n","339:\tlearn: 0.1371054\ttotal: 4m 42s\tremaining: 9m 8s\n","340:\tlearn: 0.1370922\ttotal: 4m 43s\tremaining: 9m 7s\n","341:\tlearn: 0.1370814\ttotal: 4m 43s\tremaining: 9m 6s\n","342:\tlearn: 0.1370669\ttotal: 4m 44s\tremaining: 9m 5s\n","343:\tlearn: 0.1370562\ttotal: 4m 46s\tremaining: 9m 5s\n","344:\tlearn: 0.1370441\ttotal: 4m 47s\tremaining: 9m 5s\n","345:\tlearn: 0.1370320\ttotal: 4m 48s\tremaining: 9m 4s\n","346:\tlearn: 0.1370170\ttotal: 4m 48s\tremaining: 9m 3s\n","347:\tlearn: 0.1370040\ttotal: 4m 49s\tremaining: 9m 2s\n","348:\tlearn: 0.1369855\ttotal: 4m 50s\tremaining: 9m 1s\n","349:\tlearn: 0.1369749\ttotal: 4m 51s\tremaining: 9m\n","350:\tlearn: 0.1369647\ttotal: 4m 51s\tremaining: 8m 59s\n","351:\tlearn: 0.1369548\ttotal: 4m 52s\tremaining: 8m 58s\n","352:\tlearn: 0.1369433\ttotal: 4m 53s\tremaining: 8m 57s\n","353:\tlearn: 0.1369295\ttotal: 4m 54s\tremaining: 8m 56s\n","354:\tlearn: 0.1369170\ttotal: 4m 54s\tremaining: 8m 55s\n","355:\tlearn: 0.1369059\ttotal: 4m 55s\tremaining: 8m 54s\n","356:\tlearn: 0.1368935\ttotal: 4m 56s\tremaining: 8m 53s\n","357:\tlearn: 0.1368803\ttotal: 4m 57s\tremaining: 8m 52s\n","358:\tlearn: 0.1368669\ttotal: 4m 57s\tremaining: 8m 51s\n","359:\tlearn: 0.1368531\ttotal: 4m 59s\tremaining: 8m 51s\n","360:\tlearn: 0.1368368\ttotal: 5m\tremaining: 8m 51s\n","361:\tlearn: 0.1368258\ttotal: 5m 1s\tremaining: 8m 51s\n","362:\tlearn: 0.1368128\ttotal: 5m 2s\tremaining: 8m 50s\n","363:\tlearn: 0.1367968\ttotal: 5m 3s\tremaining: 8m 50s\n","364:\tlearn: 0.1367833\ttotal: 5m 4s\tremaining: 8m 49s\n","365:\tlearn: 0.1367749\ttotal: 5m 4s\tremaining: 8m 47s\n","366:\tlearn: 0.1367613\ttotal: 5m 5s\tremaining: 8m 47s\n","367:\tlearn: 0.1367449\ttotal: 5m 6s\tremaining: 8m 46s\n","368:\tlearn: 0.1367317\ttotal: 5m 7s\tremaining: 8m 45s\n","369:\tlearn: 0.1367215\ttotal: 5m 7s\tremaining: 8m 44s\n","370:\tlearn: 0.1367112\ttotal: 5m 8s\tremaining: 8m 43s\n","371:\tlearn: 0.1366954\ttotal: 5m 9s\tremaining: 8m 42s\n","372:\tlearn: 0.1366790\ttotal: 5m 10s\tremaining: 8m 41s\n","373:\tlearn: 0.1366687\ttotal: 5m 10s\tremaining: 8m 40s\n","374:\tlearn: 0.1366582\ttotal: 5m 11s\tremaining: 8m 39s\n","375:\tlearn: 0.1366444\ttotal: 5m 12s\tremaining: 8m 38s\n","376:\tlearn: 0.1366333\ttotal: 5m 13s\tremaining: 8m 38s\n","377:\tlearn: 0.1366214\ttotal: 5m 14s\tremaining: 8m 37s\n","378:\tlearn: 0.1366062\ttotal: 5m 15s\tremaining: 8m 37s\n","379:\tlearn: 0.1365928\ttotal: 5m 16s\tremaining: 8m 36s\n","380:\tlearn: 0.1365821\ttotal: 5m 17s\tremaining: 8m 35s\n","381:\tlearn: 0.1365671\ttotal: 5m 18s\tremaining: 8m 34s\n","382:\tlearn: 0.1365506\ttotal: 5m 19s\tremaining: 8m 34s\n","383:\tlearn: 0.1365348\ttotal: 5m 19s\tremaining: 8m 33s\n","384:\tlearn: 0.1365223\ttotal: 5m 20s\tremaining: 8m 32s\n","385:\tlearn: 0.1365102\ttotal: 5m 21s\tremaining: 8m 30s\n","386:\tlearn: 0.1364971\ttotal: 5m 21s\tremaining: 8m 29s\n","387:\tlearn: 0.1364830\ttotal: 5m 22s\tremaining: 8m 29s\n","388:\tlearn: 0.1364722\ttotal: 5m 23s\tremaining: 8m 28s\n","389:\tlearn: 0.1364561\ttotal: 5m 24s\tremaining: 8m 27s\n","390:\tlearn: 0.1364361\ttotal: 5m 25s\tremaining: 8m 26s\n","391:\tlearn: 0.1364282\ttotal: 5m 25s\tremaining: 8m 25s\n","392:\tlearn: 0.1364133\ttotal: 5m 26s\tremaining: 8m 24s\n","393:\tlearn: 0.1363974\ttotal: 5m 27s\tremaining: 8m 24s\n","394:\tlearn: 0.1363793\ttotal: 5m 28s\tremaining: 8m 23s\n","395:\tlearn: 0.1363670\ttotal: 5m 30s\tremaining: 8m 23s\n","396:\tlearn: 0.1363525\ttotal: 5m 31s\tremaining: 8m 22s\n","397:\tlearn: 0.1363399\ttotal: 5m 31s\tremaining: 8m 21s\n","398:\tlearn: 0.1363252\ttotal: 5m 32s\tremaining: 8m 20s\n","399:\tlearn: 0.1363146\ttotal: 5m 33s\tremaining: 8m 19s\n","400:\tlearn: 0.1363074\ttotal: 5m 34s\tremaining: 8m 18s\n","401:\tlearn: 0.1362920\ttotal: 5m 34s\tremaining: 8m 18s\n","402:\tlearn: 0.1362796\ttotal: 5m 35s\tremaining: 8m 17s\n","403:\tlearn: 0.1362602\ttotal: 5m 36s\tremaining: 8m 16s\n","404:\tlearn: 0.1362456\ttotal: 5m 36s\tremaining: 8m 15s\n","405:\tlearn: 0.1362366\ttotal: 5m 37s\tremaining: 8m 13s\n","406:\tlearn: 0.1362206\ttotal: 5m 38s\tremaining: 8m 12s\n","407:\tlearn: 0.1362107\ttotal: 5m 38s\tremaining: 8m 11s\n","408:\tlearn: 0.1361999\ttotal: 5m 39s\tremaining: 8m 10s\n","409:\tlearn: 0.1361895\ttotal: 5m 40s\tremaining: 8m 9s\n","410:\tlearn: 0.1361795\ttotal: 5m 41s\tremaining: 8m 9s\n","411:\tlearn: 0.1361636\ttotal: 5m 42s\tremaining: 8m 9s\n","412:\tlearn: 0.1361492\ttotal: 5m 44s\tremaining: 8m 8s\n","413:\tlearn: 0.1361411\ttotal: 5m 44s\tremaining: 8m 8s\n","414:\tlearn: 0.1361301\ttotal: 5m 45s\tremaining: 8m 7s\n","415:\tlearn: 0.1361162\ttotal: 5m 46s\tremaining: 8m 6s\n","416:\tlearn: 0.1360988\ttotal: 5m 47s\tremaining: 8m 5s\n","417:\tlearn: 0.1360859\ttotal: 5m 47s\tremaining: 8m 4s\n","418:\tlearn: 0.1360714\ttotal: 5m 48s\tremaining: 8m 3s\n","419:\tlearn: 0.1360577\ttotal: 5m 49s\tremaining: 8m 2s\n","420:\tlearn: 0.1360457\ttotal: 5m 50s\tremaining: 8m 1s\n","421:\tlearn: 0.1360368\ttotal: 5m 50s\tremaining: 8m\n","422:\tlearn: 0.1360250\ttotal: 5m 51s\tremaining: 7m 59s\n","423:\tlearn: 0.1360156\ttotal: 5m 52s\tremaining: 7m 58s\n","424:\tlearn: 0.1360031\ttotal: 5m 52s\tremaining: 7m 57s\n","425:\tlearn: 0.1359912\ttotal: 5m 53s\tremaining: 7m 56s\n","426:\tlearn: 0.1359822\ttotal: 5m 54s\tremaining: 7m 56s\n","427:\tlearn: 0.1359703\ttotal: 5m 56s\tremaining: 7m 55s\n","428:\tlearn: 0.1359529\ttotal: 5m 57s\tremaining: 7m 55s\n","429:\tlearn: 0.1359333\ttotal: 5m 58s\tremaining: 7m 55s\n","430:\tlearn: 0.1359224\ttotal: 5m 59s\tremaining: 7m 54s\n","431:\tlearn: 0.1359093\ttotal: 5m 59s\tremaining: 7m 53s\n","432:\tlearn: 0.1358978\ttotal: 6m\tremaining: 7m 52s\n","433:\tlearn: 0.1358832\ttotal: 6m 1s\tremaining: 7m 51s\n","434:\tlearn: 0.1358672\ttotal: 6m 2s\tremaining: 7m 50s\n","435:\tlearn: 0.1358501\ttotal: 6m 3s\tremaining: 7m 49s\n","436:\tlearn: 0.1358368\ttotal: 6m 3s\tremaining: 7m 48s\n","437:\tlearn: 0.1358252\ttotal: 6m 4s\tremaining: 7m 47s\n","438:\tlearn: 0.1358103\ttotal: 6m 5s\tremaining: 7m 46s\n","439:\tlearn: 0.1357985\ttotal: 6m 6s\tremaining: 7m 45s\n","440:\tlearn: 0.1357889\ttotal: 6m 6s\tremaining: 7m 44s\n","441:\tlearn: 0.1357791\ttotal: 6m 7s\tremaining: 7m 43s\n","442:\tlearn: 0.1357715\ttotal: 6m 8s\tremaining: 7m 42s\n","443:\tlearn: 0.1357568\ttotal: 6m 9s\tremaining: 7m 42s\n","444:\tlearn: 0.1357447\ttotal: 6m 10s\tremaining: 7m 42s\n","445:\tlearn: 0.1357316\ttotal: 6m 11s\tremaining: 7m 41s\n","446:\tlearn: 0.1357154\ttotal: 6m 12s\tremaining: 7m 41s\n","447:\tlearn: 0.1357087\ttotal: 6m 13s\tremaining: 7m 40s\n","448:\tlearn: 0.1357012\ttotal: 6m 14s\tremaining: 7m 39s\n","449:\tlearn: 0.1356933\ttotal: 6m 14s\tremaining: 7m 38s\n","450:\tlearn: 0.1356829\ttotal: 6m 15s\tremaining: 7m 37s\n","451:\tlearn: 0.1356688\ttotal: 6m 16s\tremaining: 7m 36s\n","452:\tlearn: 0.1356595\ttotal: 6m 17s\tremaining: 7m 35s\n","453:\tlearn: 0.1356468\ttotal: 6m 17s\tremaining: 7m 34s\n","454:\tlearn: 0.1356330\ttotal: 6m 18s\tremaining: 7m 33s\n","455:\tlearn: 0.1356218\ttotal: 6m 19s\tremaining: 7m 32s\n","456:\tlearn: 0.1356032\ttotal: 6m 20s\tremaining: 7m 31s\n","457:\tlearn: 0.1355922\ttotal: 6m 20s\tremaining: 7m 30s\n","458:\tlearn: 0.1355838\ttotal: 6m 21s\tremaining: 7m 29s\n","459:\tlearn: 0.1355718\ttotal: 6m 22s\tremaining: 7m 28s\n","460:\tlearn: 0.1355559\ttotal: 6m 23s\tremaining: 7m 28s\n","461:\tlearn: 0.1355428\ttotal: 6m 24s\tremaining: 7m 27s\n","462:\tlearn: 0.1355322\ttotal: 6m 25s\tremaining: 7m 27s\n","463:\tlearn: 0.1355214\ttotal: 6m 26s\tremaining: 7m 26s\n","464:\tlearn: 0.1355105\ttotal: 6m 27s\tremaining: 7m 25s\n","465:\tlearn: 0.1354953\ttotal: 6m 28s\tremaining: 7m 24s\n","466:\tlearn: 0.1354793\ttotal: 6m 28s\tremaining: 7m 23s\n","467:\tlearn: 0.1354711\ttotal: 6m 29s\tremaining: 7m 22s\n","468:\tlearn: 0.1354639\ttotal: 6m 30s\tremaining: 7m 21s\n","469:\tlearn: 0.1354504\ttotal: 6m 30s\tremaining: 7m 20s\n","470:\tlearn: 0.1354382\ttotal: 6m 31s\tremaining: 7m 19s\n","471:\tlearn: 0.1354289\ttotal: 6m 32s\tremaining: 7m 18s\n","472:\tlearn: 0.1354130\ttotal: 6m 33s\tremaining: 7m 17s\n","473:\tlearn: 0.1353992\ttotal: 6m 33s\tremaining: 7m 16s\n","474:\tlearn: 0.1353865\ttotal: 6m 34s\tremaining: 7m 15s\n","475:\tlearn: 0.1353752\ttotal: 6m 35s\tremaining: 7m 15s\n","476:\tlearn: 0.1353641\ttotal: 6m 35s\tremaining: 7m 14s\n","477:\tlearn: 0.1353497\ttotal: 6m 36s\tremaining: 7m 13s\n","478:\tlearn: 0.1353409\ttotal: 6m 38s\tremaining: 7m 13s\n","479:\tlearn: 0.1353301\ttotal: 6m 39s\tremaining: 7m 12s\n","480:\tlearn: 0.1353147\ttotal: 6m 40s\tremaining: 7m 12s\n","481:\tlearn: 0.1353003\ttotal: 6m 41s\tremaining: 7m 11s\n","482:\tlearn: 0.1352905\ttotal: 6m 42s\tremaining: 7m 10s\n","483:\tlearn: 0.1352778\ttotal: 6m 42s\tremaining: 7m 9s\n","484:\tlearn: 0.1352619\ttotal: 6m 43s\tremaining: 7m 8s\n","485:\tlearn: 0.1352507\ttotal: 6m 44s\tremaining: 7m 7s\n","486:\tlearn: 0.1352381\ttotal: 6m 45s\tremaining: 7m 6s\n","487:\tlearn: 0.1352240\ttotal: 6m 46s\tremaining: 7m 6s\n","488:\tlearn: 0.1352101\ttotal: 6m 46s\tremaining: 7m 5s\n","489:\tlearn: 0.1352016\ttotal: 6m 47s\tremaining: 7m 4s\n","490:\tlearn: 0.1351876\ttotal: 6m 48s\tremaining: 7m 3s\n","491:\tlearn: 0.1351761\ttotal: 6m 48s\tremaining: 7m 2s\n","492:\tlearn: 0.1351659\ttotal: 6m 49s\tremaining: 7m 1s\n","493:\tlearn: 0.1351553\ttotal: 6m 50s\tremaining: 7m\n","494:\tlearn: 0.1351440\ttotal: 6m 51s\tremaining: 6m 59s\n","495:\tlearn: 0.1351324\ttotal: 6m 52s\tremaining: 6m 59s\n","496:\tlearn: 0.1351181\ttotal: 6m 54s\tremaining: 6m 59s\n","497:\tlearn: 0.1351063\ttotal: 6m 54s\tremaining: 6m 58s\n","498:\tlearn: 0.1350918\ttotal: 6m 55s\tremaining: 6m 57s\n","499:\tlearn: 0.1350812\ttotal: 6m 56s\tremaining: 6m 56s\n","500:\tlearn: 0.1350738\ttotal: 6m 57s\tremaining: 6m 55s\n","501:\tlearn: 0.1350655\ttotal: 6m 57s\tremaining: 6m 54s\n","502:\tlearn: 0.1350524\ttotal: 6m 58s\tremaining: 6m 53s\n","503:\tlearn: 0.1350381\ttotal: 6m 59s\tremaining: 6m 52s\n","504:\tlearn: 0.1350275\ttotal: 6m 59s\tremaining: 6m 51s\n","505:\tlearn: 0.1350125\ttotal: 7m\tremaining: 6m 50s\n","506:\tlearn: 0.1349989\ttotal: 7m 1s\tremaining: 6m 49s\n","507:\tlearn: 0.1349846\ttotal: 7m 2s\tremaining: 6m 48s\n","508:\tlearn: 0.1349755\ttotal: 7m 2s\tremaining: 6m 47s\n","509:\tlearn: 0.1349585\ttotal: 7m 3s\tremaining: 6m 47s\n","510:\tlearn: 0.1349468\ttotal: 7m 4s\tremaining: 6m 46s\n","511:\tlearn: 0.1349360\ttotal: 7m 5s\tremaining: 6m 45s\n","512:\tlearn: 0.1349182\ttotal: 7m 6s\tremaining: 6m 45s\n","513:\tlearn: 0.1349072\ttotal: 7m 8s\tremaining: 6m 44s\n","514:\tlearn: 0.1348932\ttotal: 7m 8s\tremaining: 6m 44s\n","515:\tlearn: 0.1348795\ttotal: 7m 9s\tremaining: 6m 43s\n","516:\tlearn: 0.1348683\ttotal: 7m 10s\tremaining: 6m 42s\n","517:\tlearn: 0.1348554\ttotal: 7m 11s\tremaining: 6m 41s\n","518:\tlearn: 0.1348445\ttotal: 7m 12s\tremaining: 6m 40s\n","519:\tlearn: 0.1348316\ttotal: 7m 12s\tremaining: 6m 39s\n","520:\tlearn: 0.1348167\ttotal: 7m 13s\tremaining: 6m 38s\n","521:\tlearn: 0.1348052\ttotal: 7m 14s\tremaining: 6m 37s\n","522:\tlearn: 0.1347951\ttotal: 7m 14s\tremaining: 6m 36s\n","523:\tlearn: 0.1347796\ttotal: 7m 15s\tremaining: 6m 35s\n","524:\tlearn: 0.1347675\ttotal: 7m 16s\tremaining: 6m 34s\n","525:\tlearn: 0.1347582\ttotal: 7m 16s\tremaining: 6m 33s\n","526:\tlearn: 0.1347470\ttotal: 7m 17s\tremaining: 6m 32s\n","527:\tlearn: 0.1347338\ttotal: 7m 18s\tremaining: 6m 31s\n","528:\tlearn: 0.1347227\ttotal: 7m 19s\tremaining: 6m 31s\n","529:\tlearn: 0.1347140\ttotal: 7m 20s\tremaining: 6m 30s\n","530:\tlearn: 0.1346995\ttotal: 7m 21s\tremaining: 6m 30s\n","531:\tlearn: 0.1346908\ttotal: 7m 22s\tremaining: 6m 29s\n","532:\tlearn: 0.1346777\ttotal: 7m 23s\tremaining: 6m 28s\n","533:\tlearn: 0.1346673\ttotal: 7m 24s\tremaining: 6m 27s\n","534:\tlearn: 0.1346551\ttotal: 7m 25s\tremaining: 6m 26s\n","535:\tlearn: 0.1346388\ttotal: 7m 25s\tremaining: 6m 25s\n","536:\tlearn: 0.1346295\ttotal: 7m 26s\tremaining: 6m 25s\n","537:\tlearn: 0.1346137\ttotal: 7m 27s\tremaining: 6m 24s\n","538:\tlearn: 0.1346041\ttotal: 7m 28s\tremaining: 6m 23s\n","539:\tlearn: 0.1345911\ttotal: 7m 28s\tremaining: 6m 22s\n","540:\tlearn: 0.1345794\ttotal: 7m 29s\tremaining: 6m 21s\n","541:\tlearn: 0.1345628\ttotal: 7m 30s\tremaining: 6m 20s\n","542:\tlearn: 0.1345482\ttotal: 7m 31s\tremaining: 6m 19s\n","543:\tlearn: 0.1345385\ttotal: 7m 31s\tremaining: 6m 18s\n","544:\tlearn: 0.1345259\ttotal: 7m 32s\tremaining: 6m 17s\n","545:\tlearn: 0.1345150\ttotal: 7m 33s\tremaining: 6m 17s\n","546:\tlearn: 0.1345044\ttotal: 7m 34s\tremaining: 6m 16s\n","547:\tlearn: 0.1344889\ttotal: 7m 35s\tremaining: 6m 16s\n","548:\tlearn: 0.1344763\ttotal: 7m 37s\tremaining: 6m 15s\n","549:\tlearn: 0.1344645\ttotal: 7m 37s\tremaining: 6m 14s\n","550:\tlearn: 0.1344532\ttotal: 7m 38s\tremaining: 6m 13s\n","551:\tlearn: 0.1344445\ttotal: 7m 39s\tremaining: 6m 12s\n","552:\tlearn: 0.1344340\ttotal: 7m 39s\tremaining: 6m 11s\n","553:\tlearn: 0.1344217\ttotal: 7m 40s\tremaining: 6m 10s\n","554:\tlearn: 0.1344129\ttotal: 7m 41s\tremaining: 6m 9s\n","555:\tlearn: 0.1344037\ttotal: 7m 42s\tremaining: 6m 9s\n","556:\tlearn: 0.1343893\ttotal: 7m 42s\tremaining: 6m 8s\n","557:\tlearn: 0.1343756\ttotal: 7m 43s\tremaining: 6m 7s\n","558:\tlearn: 0.1343603\ttotal: 7m 44s\tremaining: 6m 6s\n","559:\tlearn: 0.1343509\ttotal: 7m 45s\tremaining: 6m 5s\n","560:\tlearn: 0.1343386\ttotal: 7m 46s\tremaining: 6m 4s\n","561:\tlearn: 0.1343275\ttotal: 7m 46s\tremaining: 6m 3s\n","562:\tlearn: 0.1343198\ttotal: 7m 47s\tremaining: 6m 3s\n","563:\tlearn: 0.1343101\ttotal: 7m 49s\tremaining: 6m 2s\n","564:\tlearn: 0.1342949\ttotal: 7m 50s\tremaining: 6m 2s\n","565:\tlearn: 0.1342872\ttotal: 7m 51s\tremaining: 6m 1s\n","566:\tlearn: 0.1342711\ttotal: 7m 52s\tremaining: 6m\n","567:\tlearn: 0.1342628\ttotal: 7m 52s\tremaining: 5m 59s\n","568:\tlearn: 0.1342524\ttotal: 7m 53s\tremaining: 5m 58s\n","569:\tlearn: 0.1342400\ttotal: 7m 54s\tremaining: 5m 57s\n","570:\tlearn: 0.1342269\ttotal: 7m 54s\tremaining: 5m 56s\n","571:\tlearn: 0.1342110\ttotal: 7m 55s\tremaining: 5m 55s\n","572:\tlearn: 0.1342005\ttotal: 7m 56s\tremaining: 5m 54s\n","573:\tlearn: 0.1341888\ttotal: 7m 57s\tremaining: 5m 54s\n","574:\tlearn: 0.1341784\ttotal: 7m 57s\tremaining: 5m 53s\n","575:\tlearn: 0.1341689\ttotal: 7m 58s\tremaining: 5m 52s\n","576:\tlearn: 0.1341513\ttotal: 7m 59s\tremaining: 5m 51s\n","577:\tlearn: 0.1341402\ttotal: 7m 59s\tremaining: 5m 50s\n","578:\tlearn: 0.1341259\ttotal: 8m\tremaining: 5m 49s\n","579:\tlearn: 0.1341173\ttotal: 8m 2s\tremaining: 5m 49s\n","580:\tlearn: 0.1341033\ttotal: 8m 3s\tremaining: 5m 48s\n","581:\tlearn: 0.1340873\ttotal: 8m 4s\tremaining: 5m 48s\n","582:\tlearn: 0.1340737\ttotal: 8m 5s\tremaining: 5m 47s\n","583:\tlearn: 0.1340606\ttotal: 8m 6s\tremaining: 5m 46s\n","584:\tlearn: 0.1340474\ttotal: 8m 6s\tremaining: 5m 45s\n","585:\tlearn: 0.1340331\ttotal: 8m 7s\tremaining: 5m 44s\n","586:\tlearn: 0.1340195\ttotal: 8m 8s\tremaining: 5m 43s\n","587:\tlearn: 0.1340073\ttotal: 8m 9s\tremaining: 5m 42s\n","588:\tlearn: 0.1339941\ttotal: 8m 9s\tremaining: 5m 41s\n","589:\tlearn: 0.1339848\ttotal: 8m 10s\tremaining: 5m 40s\n","590:\tlearn: 0.1339730\ttotal: 8m 11s\tremaining: 5m 39s\n","591:\tlearn: 0.1339644\ttotal: 8m 12s\tremaining: 5m 39s\n","592:\tlearn: 0.1339557\ttotal: 8m 12s\tremaining: 5m 38s\n","593:\tlearn: 0.1339378\ttotal: 8m 13s\tremaining: 5m 37s\n","594:\tlearn: 0.1339299\ttotal: 8m 14s\tremaining: 5m 36s\n","595:\tlearn: 0.1339170\ttotal: 8m 15s\tremaining: 5m 35s\n","596:\tlearn: 0.1339037\ttotal: 8m 16s\tremaining: 5m 35s\n","597:\tlearn: 0.1338896\ttotal: 8m 17s\tremaining: 5m 34s\n","598:\tlearn: 0.1338741\ttotal: 8m 18s\tremaining: 5m 33s\n","599:\tlearn: 0.1338582\ttotal: 8m 19s\tremaining: 5m 33s\n","600:\tlearn: 0.1338460\ttotal: 8m 20s\tremaining: 5m 32s\n","601:\tlearn: 0.1338305\ttotal: 8m 21s\tremaining: 5m 31s\n","602:\tlearn: 0.1338217\ttotal: 8m 22s\tremaining: 5m 30s\n","603:\tlearn: 0.1338074\ttotal: 8m 22s\tremaining: 5m 29s\n","604:\tlearn: 0.1337939\ttotal: 8m 23s\tremaining: 5m 28s\n","605:\tlearn: 0.1337830\ttotal: 8m 24s\tremaining: 5m 27s\n","606:\tlearn: 0.1337719\ttotal: 8m 25s\tremaining: 5m 26s\n","607:\tlearn: 0.1337605\ttotal: 8m 25s\tremaining: 5m 26s\n","608:\tlearn: 0.1337497\ttotal: 8m 26s\tremaining: 5m 25s\n","609:\tlearn: 0.1337358\ttotal: 8m 27s\tremaining: 5m 24s\n","610:\tlearn: 0.1337221\ttotal: 8m 28s\tremaining: 5m 23s\n","611:\tlearn: 0.1337142\ttotal: 8m 29s\tremaining: 5m 22s\n","612:\tlearn: 0.1337041\ttotal: 8m 30s\tremaining: 5m 22s\n","613:\tlearn: 0.1336936\ttotal: 8m 31s\tremaining: 5m 21s\n","614:\tlearn: 0.1336824\ttotal: 8m 32s\tremaining: 5m 20s\n","615:\tlearn: 0.1336697\ttotal: 8m 33s\tremaining: 5m 20s\n","616:\tlearn: 0.1336565\ttotal: 8m 34s\tremaining: 5m 19s\n","617:\tlearn: 0.1336426\ttotal: 8m 34s\tremaining: 5m 18s\n","618:\tlearn: 0.1336325\ttotal: 8m 35s\tremaining: 5m 17s\n","619:\tlearn: 0.1336218\ttotal: 8m 36s\tremaining: 5m 16s\n","620:\tlearn: 0.1336149\ttotal: 8m 37s\tremaining: 5m 15s\n","621:\tlearn: 0.1336035\ttotal: 8m 37s\tremaining: 5m 14s\n","622:\tlearn: 0.1335936\ttotal: 8m 38s\tremaining: 5m 13s\n","623:\tlearn: 0.1335805\ttotal: 8m 39s\tremaining: 5m 12s\n","624:\tlearn: 0.1335696\ttotal: 8m 39s\tremaining: 5m 11s\n","625:\tlearn: 0.1335571\ttotal: 8m 40s\tremaining: 5m 11s\n","626:\tlearn: 0.1335435\ttotal: 8m 41s\tremaining: 5m 10s\n","627:\tlearn: 0.1335320\ttotal: 8m 42s\tremaining: 5m 9s\n","628:\tlearn: 0.1335275\ttotal: 8m 43s\tremaining: 5m 8s\n","629:\tlearn: 0.1335186\ttotal: 8m 44s\tremaining: 5m 7s\n","630:\tlearn: 0.1335109\ttotal: 8m 45s\tremaining: 5m 7s\n","631:\tlearn: 0.1334963\ttotal: 8m 46s\tremaining: 5m 6s\n","632:\tlearn: 0.1334855\ttotal: 8m 47s\tremaining: 5m 5s\n","633:\tlearn: 0.1334722\ttotal: 8m 48s\tremaining: 5m 5s\n","634:\tlearn: 0.1334633\ttotal: 8m 49s\tremaining: 5m 4s\n","635:\tlearn: 0.1334521\ttotal: 8m 49s\tremaining: 5m 3s\n","636:\tlearn: 0.1334408\ttotal: 8m 50s\tremaining: 5m 2s\n","637:\tlearn: 0.1334312\ttotal: 8m 51s\tremaining: 5m 1s\n","638:\tlearn: 0.1334234\ttotal: 8m 51s\tremaining: 5m\n","639:\tlearn: 0.1334072\ttotal: 8m 52s\tremaining: 4m 59s\n","640:\tlearn: 0.1333966\ttotal: 8m 53s\tremaining: 4m 58s\n","641:\tlearn: 0.1333828\ttotal: 8m 54s\tremaining: 4m 57s\n","642:\tlearn: 0.1333706\ttotal: 8m 54s\tremaining: 4m 56s\n","643:\tlearn: 0.1333597\ttotal: 8m 55s\tremaining: 4m 56s\n","644:\tlearn: 0.1333471\ttotal: 8m 56s\tremaining: 4m 55s\n","645:\tlearn: 0.1333363\ttotal: 8m 57s\tremaining: 4m 54s\n","646:\tlearn: 0.1333252\ttotal: 8m 58s\tremaining: 4m 53s\n","647:\tlearn: 0.1333097\ttotal: 8m 59s\tremaining: 4m 53s\n","648:\tlearn: 0.1333023\ttotal: 9m\tremaining: 4m 52s\n","649:\tlearn: 0.1332924\ttotal: 9m 1s\tremaining: 4m 51s\n","650:\tlearn: 0.1332808\ttotal: 9m 2s\tremaining: 4m 50s\n","651:\tlearn: 0.1332706\ttotal: 9m 3s\tremaining: 4m 49s\n","652:\tlearn: 0.1332621\ttotal: 9m 3s\tremaining: 4m 48s\n","653:\tlearn: 0.1332527\ttotal: 9m 4s\tremaining: 4m 48s\n","654:\tlearn: 0.1332404\ttotal: 9m 5s\tremaining: 4m 47s\n","655:\tlearn: 0.1332335\ttotal: 9m 5s\tremaining: 4m 46s\n","656:\tlearn: 0.1332191\ttotal: 9m 6s\tremaining: 4m 45s\n","657:\tlearn: 0.1332060\ttotal: 9m 7s\tremaining: 4m 44s\n","658:\tlearn: 0.1331899\ttotal: 9m 8s\tremaining: 4m 43s\n","659:\tlearn: 0.1331815\ttotal: 9m 8s\tremaining: 4m 42s\n","660:\tlearn: 0.1331670\ttotal: 9m 9s\tremaining: 4m 41s\n","661:\tlearn: 0.1331563\ttotal: 9m 10s\tremaining: 4m 41s\n","662:\tlearn: 0.1331448\ttotal: 9m 11s\tremaining: 4m 40s\n","663:\tlearn: 0.1331334\ttotal: 9m 14s\tremaining: 4m 40s\n","664:\tlearn: 0.1331221\ttotal: 9m 16s\tremaining: 4m 40s\n","665:\tlearn: 0.1331134\ttotal: 9m 18s\tremaining: 4m 40s\n","666:\tlearn: 0.1331002\ttotal: 9m 20s\tremaining: 4m 39s\n","667:\tlearn: 0.1330943\ttotal: 9m 21s\tremaining: 4m 39s\n","668:\tlearn: 0.1330833\ttotal: 9m 23s\tremaining: 4m 38s\n","669:\tlearn: 0.1330715\ttotal: 9m 25s\tremaining: 4m 38s\n","670:\tlearn: 0.1330575\ttotal: 9m 26s\tremaining: 4m 37s\n","671:\tlearn: 0.1330429\ttotal: 9m 27s\tremaining: 4m 37s\n","672:\tlearn: 0.1330330\ttotal: 9m 28s\tremaining: 4m 36s\n","673:\tlearn: 0.1330225\ttotal: 9m 29s\tremaining: 4m 35s\n","674:\tlearn: 0.1330110\ttotal: 9m 30s\tremaining: 4m 34s\n","675:\tlearn: 0.1330067\ttotal: 9m 31s\tremaining: 4m 33s\n","676:\tlearn: 0.1329932\ttotal: 9m 32s\tremaining: 4m 33s\n","677:\tlearn: 0.1329807\ttotal: 9m 33s\tremaining: 4m 32s\n","678:\tlearn: 0.1329723\ttotal: 9m 34s\tremaining: 4m 31s\n","679:\tlearn: 0.1329625\ttotal: 9m 34s\tremaining: 4m 30s\n","680:\tlearn: 0.1329501\ttotal: 9m 35s\tremaining: 4m 29s\n","681:\tlearn: 0.1329376\ttotal: 9m 36s\tremaining: 4m 28s\n","682:\tlearn: 0.1329238\ttotal: 9m 37s\tremaining: 4m 27s\n","683:\tlearn: 0.1329103\ttotal: 9m 37s\tremaining: 4m 26s\n","684:\tlearn: 0.1329005\ttotal: 9m 38s\tremaining: 4m 26s\n","685:\tlearn: 0.1328907\ttotal: 9m 39s\tremaining: 4m 25s\n","686:\tlearn: 0.1328837\ttotal: 9m 39s\tremaining: 4m 24s\n","687:\tlearn: 0.1328733\ttotal: 9m 40s\tremaining: 4m 23s\n","688:\tlearn: 0.1328659\ttotal: 9m 41s\tremaining: 4m 22s\n","689:\tlearn: 0.1328503\ttotal: 9m 42s\tremaining: 4m 21s\n","690:\tlearn: 0.1328354\ttotal: 9m 42s\tremaining: 4m 20s\n","691:\tlearn: 0.1328241\ttotal: 9m 44s\tremaining: 4m 19s\n","692:\tlearn: 0.1328160\ttotal: 9m 45s\tremaining: 4m 19s\n","693:\tlearn: 0.1328061\ttotal: 9m 46s\tremaining: 4m 18s\n","694:\tlearn: 0.1327911\ttotal: 9m 47s\tremaining: 4m 17s\n","695:\tlearn: 0.1327760\ttotal: 9m 48s\tremaining: 4m 17s\n","696:\tlearn: 0.1327646\ttotal: 9m 49s\tremaining: 4m 16s\n","697:\tlearn: 0.1327589\ttotal: 9m 49s\tremaining: 4m 15s\n","698:\tlearn: 0.1327485\ttotal: 9m 50s\tremaining: 4m 14s\n","699:\tlearn: 0.1327361\ttotal: 9m 51s\tremaining: 4m 13s\n","700:\tlearn: 0.1327257\ttotal: 9m 52s\tremaining: 4m 12s\n","701:\tlearn: 0.1327099\ttotal: 9m 52s\tremaining: 4m 11s\n","702:\tlearn: 0.1326946\ttotal: 9m 53s\tremaining: 4m 10s\n","703:\tlearn: 0.1326857\ttotal: 9m 54s\tremaining: 4m 9s\n","704:\tlearn: 0.1326721\ttotal: 9m 55s\tremaining: 4m 9s\n","705:\tlearn: 0.1326627\ttotal: 9m 55s\tremaining: 4m 8s\n","706:\tlearn: 0.1326488\ttotal: 9m 56s\tremaining: 4m 7s\n","707:\tlearn: 0.1326344\ttotal: 9m 57s\tremaining: 4m 6s\n","708:\tlearn: 0.1326219\ttotal: 9m 58s\tremaining: 4m 5s\n","709:\tlearn: 0.1326107\ttotal: 9m 59s\tremaining: 4m 4s\n","710:\tlearn: 0.1325996\ttotal: 10m 1s\tremaining: 4m 4s\n","711:\tlearn: 0.1325841\ttotal: 10m 2s\tremaining: 4m 3s\n","712:\tlearn: 0.1325696\ttotal: 10m 2s\tremaining: 4m 2s\n","713:\tlearn: 0.1325621\ttotal: 10m 3s\tremaining: 4m 1s\n","714:\tlearn: 0.1325522\ttotal: 10m 4s\tremaining: 4m\n","715:\tlearn: 0.1325381\ttotal: 10m 5s\tremaining: 4m\n","716:\tlearn: 0.1325308\ttotal: 10m 6s\tremaining: 3m 59s\n","717:\tlearn: 0.1325190\ttotal: 10m 6s\tremaining: 3m 58s\n","718:\tlearn: 0.1325047\ttotal: 10m 7s\tremaining: 3m 57s\n","719:\tlearn: 0.1324922\ttotal: 10m 8s\tremaining: 3m 56s\n","720:\tlearn: 0.1324830\ttotal: 10m 8s\tremaining: 3m 55s\n","721:\tlearn: 0.1324705\ttotal: 10m 9s\tremaining: 3m 54s\n","722:\tlearn: 0.1324585\ttotal: 10m 10s\tremaining: 3m 53s\n","723:\tlearn: 0.1324456\ttotal: 10m 11s\tremaining: 3m 53s\n","724:\tlearn: 0.1324394\ttotal: 10m 12s\tremaining: 3m 52s\n","725:\tlearn: 0.1324311\ttotal: 10m 13s\tremaining: 3m 51s\n","726:\tlearn: 0.1324218\ttotal: 10m 14s\tremaining: 3m 50s\n","727:\tlearn: 0.1324136\ttotal: 10m 15s\tremaining: 3m 50s\n","728:\tlearn: 0.1323999\ttotal: 10m 16s\tremaining: 3m 49s\n","729:\tlearn: 0.1323861\ttotal: 10m 17s\tremaining: 3m 48s\n","730:\tlearn: 0.1323752\ttotal: 10m 17s\tremaining: 3m 47s\n","731:\tlearn: 0.1323655\ttotal: 10m 18s\tremaining: 3m 46s\n","732:\tlearn: 0.1323544\ttotal: 10m 19s\tremaining: 3m 45s\n","733:\tlearn: 0.1323456\ttotal: 10m 20s\tremaining: 3m 44s\n","734:\tlearn: 0.1323369\ttotal: 10m 20s\tremaining: 3m 43s\n","735:\tlearn: 0.1323267\ttotal: 10m 21s\tremaining: 3m 42s\n","736:\tlearn: 0.1323119\ttotal: 10m 22s\tremaining: 3m 42s\n","737:\tlearn: 0.1323003\ttotal: 10m 23s\tremaining: 3m 41s\n","738:\tlearn: 0.1322859\ttotal: 10m 23s\tremaining: 3m 40s\n","739:\tlearn: 0.1322757\ttotal: 10m 24s\tremaining: 3m 39s\n","740:\tlearn: 0.1322655\ttotal: 10m 25s\tremaining: 3m 38s\n","741:\tlearn: 0.1322542\ttotal: 10m 25s\tremaining: 3m 37s\n","742:\tlearn: 0.1322435\ttotal: 10m 27s\tremaining: 3m 36s\n","743:\tlearn: 0.1322334\ttotal: 10m 28s\tremaining: 3m 36s\n","744:\tlearn: 0.1322226\ttotal: 10m 29s\tremaining: 3m 35s\n","745:\tlearn: 0.1322165\ttotal: 10m 30s\tremaining: 3m 34s\n","746:\tlearn: 0.1322057\ttotal: 10m 31s\tremaining: 3m 33s\n","747:\tlearn: 0.1321968\ttotal: 10m 31s\tremaining: 3m 32s\n","748:\tlearn: 0.1321877\ttotal: 10m 32s\tremaining: 3m 31s\n","749:\tlearn: 0.1321762\ttotal: 10m 33s\tremaining: 3m 31s\n","750:\tlearn: 0.1321652\ttotal: 10m 33s\tremaining: 3m 30s\n","751:\tlearn: 0.1321533\ttotal: 10m 34s\tremaining: 3m 29s\n","752:\tlearn: 0.1321439\ttotal: 10m 35s\tremaining: 3m 28s\n","753:\tlearn: 0.1321348\ttotal: 10m 36s\tremaining: 3m 27s\n","754:\tlearn: 0.1321245\ttotal: 10m 36s\tremaining: 3m 26s\n","755:\tlearn: 0.1321131\ttotal: 10m 37s\tremaining: 3m 25s\n","756:\tlearn: 0.1321027\ttotal: 10m 38s\tremaining: 3m 24s\n","757:\tlearn: 0.1320897\ttotal: 10m 39s\tremaining: 3m 24s\n","758:\tlearn: 0.1320781\ttotal: 10m 40s\tremaining: 3m 23s\n","759:\tlearn: 0.1320659\ttotal: 10m 41s\tremaining: 3m 22s\n","760:\tlearn: 0.1320557\ttotal: 10m 42s\tremaining: 3m 21s\n","761:\tlearn: 0.1320431\ttotal: 10m 44s\tremaining: 3m 21s\n","762:\tlearn: 0.1320340\ttotal: 10m 44s\tremaining: 3m 20s\n","763:\tlearn: 0.1320224\ttotal: 10m 45s\tremaining: 3m 19s\n","764:\tlearn: 0.1320142\ttotal: 10m 46s\tremaining: 3m 18s\n","765:\tlearn: 0.1320040\ttotal: 10m 47s\tremaining: 3m 17s\n","766:\tlearn: 0.1319974\ttotal: 10m 47s\tremaining: 3m 16s\n","767:\tlearn: 0.1319838\ttotal: 10m 48s\tremaining: 3m 15s\n","768:\tlearn: 0.1319732\ttotal: 10m 49s\tremaining: 3m 15s\n","769:\tlearn: 0.1319630\ttotal: 10m 49s\tremaining: 3m 14s\n","770:\tlearn: 0.1319499\ttotal: 10m 50s\tremaining: 3m 13s\n","771:\tlearn: 0.1319365\ttotal: 10m 51s\tremaining: 3m 12s\n","772:\tlearn: 0.1319244\ttotal: 10m 52s\tremaining: 3m 11s\n","773:\tlearn: 0.1319147\ttotal: 10m 52s\tremaining: 3m 10s\n","774:\tlearn: 0.1319011\ttotal: 10m 53s\tremaining: 3m 9s\n","775:\tlearn: 0.1318893\ttotal: 10m 54s\tremaining: 3m 9s\n","776:\tlearn: 0.1318810\ttotal: 10m 56s\tremaining: 3m 8s\n","777:\tlearn: 0.1318674\ttotal: 10m 57s\tremaining: 3m 7s\n","778:\tlearn: 0.1318542\ttotal: 10m 58s\tremaining: 3m 6s\n","779:\tlearn: 0.1318435\ttotal: 10m 58s\tremaining: 3m 5s\n","780:\tlearn: 0.1318303\ttotal: 10m 59s\tremaining: 3m 5s\n","781:\tlearn: 0.1318203\ttotal: 11m\tremaining: 3m 4s\n","782:\tlearn: 0.1318094\ttotal: 11m 1s\tremaining: 3m 3s\n","783:\tlearn: 0.1317987\ttotal: 11m 2s\tremaining: 3m 2s\n","784:\tlearn: 0.1317857\ttotal: 11m 2s\tremaining: 3m 1s\n","785:\tlearn: 0.1317784\ttotal: 11m 3s\tremaining: 3m\n","786:\tlearn: 0.1317701\ttotal: 11m 4s\tremaining: 2m 59s\n","787:\tlearn: 0.1317553\ttotal: 11m 4s\tremaining: 2m 58s\n","788:\tlearn: 0.1317463\ttotal: 11m 5s\tremaining: 2m 58s\n","789:\tlearn: 0.1317381\ttotal: 11m 6s\tremaining: 2m 57s\n","790:\tlearn: 0.1317263\ttotal: 11m 7s\tremaining: 2m 56s\n","791:\tlearn: 0.1317191\ttotal: 11m 7s\tremaining: 2m 55s\n","792:\tlearn: 0.1317057\ttotal: 11m 9s\tremaining: 2m 54s\n","793:\tlearn: 0.1316981\ttotal: 11m 10s\tremaining: 2m 53s\n","794:\tlearn: 0.1316871\ttotal: 11m 11s\tremaining: 2m 53s\n","795:\tlearn: 0.1316787\ttotal: 11m 12s\tremaining: 2m 52s\n","796:\tlearn: 0.1316653\ttotal: 11m 13s\tremaining: 2m 51s\n","797:\tlearn: 0.1316569\ttotal: 11m 13s\tremaining: 2m 50s\n","798:\tlearn: 0.1316455\ttotal: 11m 14s\tremaining: 2m 49s\n","799:\tlearn: 0.1316377\ttotal: 11m 15s\tremaining: 2m 48s\n","800:\tlearn: 0.1316262\ttotal: 11m 16s\tremaining: 2m 47s\n","801:\tlearn: 0.1316156\ttotal: 11m 16s\tremaining: 2m 47s\n","802:\tlearn: 0.1316086\ttotal: 11m 17s\tremaining: 2m 46s\n","803:\tlearn: 0.1315973\ttotal: 11m 18s\tremaining: 2m 45s\n","804:\tlearn: 0.1315839\ttotal: 11m 19s\tremaining: 2m 44s\n","805:\tlearn: 0.1315746\ttotal: 11m 19s\tremaining: 2m 43s\n","806:\tlearn: 0.1315665\ttotal: 11m 20s\tremaining: 2m 42s\n","807:\tlearn: 0.1315547\ttotal: 11m 21s\tremaining: 2m 41s\n","808:\tlearn: 0.1315442\ttotal: 11m 21s\tremaining: 2m 40s\n","809:\tlearn: 0.1315356\ttotal: 11m 22s\tremaining: 2m 40s\n","810:\tlearn: 0.1315306\ttotal: 11m 24s\tremaining: 2m 39s\n","811:\tlearn: 0.1315208\ttotal: 11m 25s\tremaining: 2m 38s\n","812:\tlearn: 0.1315128\ttotal: 11m 26s\tremaining: 2m 37s\n","813:\tlearn: 0.1315013\ttotal: 11m 27s\tremaining: 2m 37s\n","814:\tlearn: 0.1314912\ttotal: 11m 27s\tremaining: 2m 36s\n","815:\tlearn: 0.1314813\ttotal: 11m 28s\tremaining: 2m 35s\n","816:\tlearn: 0.1314712\ttotal: 11m 29s\tremaining: 2m 34s\n","817:\tlearn: 0.1314589\ttotal: 11m 30s\tremaining: 2m 33s\n","818:\tlearn: 0.1314505\ttotal: 11m 30s\tremaining: 2m 32s\n","819:\tlearn: 0.1314385\ttotal: 11m 31s\tremaining: 2m 31s\n","820:\tlearn: 0.1314289\ttotal: 11m 32s\tremaining: 2m 30s\n","821:\tlearn: 0.1314198\ttotal: 11m 32s\tremaining: 2m 30s\n","822:\tlearn: 0.1314091\ttotal: 11m 33s\tremaining: 2m 29s\n","823:\tlearn: 0.1314019\ttotal: 11m 34s\tremaining: 2m 28s\n","824:\tlearn: 0.1313945\ttotal: 11m 35s\tremaining: 2m 27s\n","825:\tlearn: 0.1313774\ttotal: 11m 35s\tremaining: 2m 26s\n","826:\tlearn: 0.1313654\ttotal: 11m 36s\tremaining: 2m 25s\n","827:\tlearn: 0.1313574\ttotal: 11m 38s\tremaining: 2m 25s\n","828:\tlearn: 0.1313420\ttotal: 11m 39s\tremaining: 2m 24s\n","829:\tlearn: 0.1313292\ttotal: 11m 40s\tremaining: 2m 23s\n","830:\tlearn: 0.1313169\ttotal: 11m 41s\tremaining: 2m 22s\n","831:\tlearn: 0.1313088\ttotal: 11m 41s\tremaining: 2m 21s\n","832:\tlearn: 0.1312974\ttotal: 11m 42s\tremaining: 2m 20s\n","833:\tlearn: 0.1312861\ttotal: 11m 43s\tremaining: 2m 19s\n","834:\tlearn: 0.1312725\ttotal: 11m 44s\tremaining: 2m 19s\n","835:\tlearn: 0.1312620\ttotal: 11m 44s\tremaining: 2m 18s\n","836:\tlearn: 0.1312496\ttotal: 11m 45s\tremaining: 2m 17s\n","837:\tlearn: 0.1312371\ttotal: 11m 46s\tremaining: 2m 16s\n","838:\tlearn: 0.1312269\ttotal: 11m 46s\tremaining: 2m 15s\n","839:\tlearn: 0.1312164\ttotal: 11m 47s\tremaining: 2m 14s\n","840:\tlearn: 0.1312055\ttotal: 11m 48s\tremaining: 2m 13s\n","841:\tlearn: 0.1311933\ttotal: 11m 49s\tremaining: 2m 13s\n","842:\tlearn: 0.1311791\ttotal: 11m 49s\tremaining: 2m 12s\n","843:\tlearn: 0.1311684\ttotal: 11m 50s\tremaining: 2m 11s\n","844:\tlearn: 0.1311623\ttotal: 11m 52s\tremaining: 2m 10s\n","845:\tlearn: 0.1311484\ttotal: 11m 53s\tremaining: 2m 9s\n","846:\tlearn: 0.1311392\ttotal: 11m 54s\tremaining: 2m 9s\n","847:\tlearn: 0.1311319\ttotal: 11m 55s\tremaining: 2m 8s\n","848:\tlearn: 0.1311188\ttotal: 11m 56s\tremaining: 2m 7s\n","849:\tlearn: 0.1311074\ttotal: 11m 56s\tremaining: 2m 6s\n","850:\tlearn: 0.1310938\ttotal: 11m 57s\tremaining: 2m 5s\n","851:\tlearn: 0.1310829\ttotal: 11m 58s\tremaining: 2m 4s\n","852:\tlearn: 0.1310700\ttotal: 11m 58s\tremaining: 2m 3s\n","853:\tlearn: 0.1310612\ttotal: 11m 59s\tremaining: 2m 3s\n","854:\tlearn: 0.1310494\ttotal: 12m\tremaining: 2m 2s\n","855:\tlearn: 0.1310367\ttotal: 12m 1s\tremaining: 2m 1s\n","856:\tlearn: 0.1310262\ttotal: 12m 1s\tremaining: 2m\n","857:\tlearn: 0.1310138\ttotal: 12m 2s\tremaining: 1m 59s\n","858:\tlearn: 0.1310098\ttotal: 12m 3s\tremaining: 1m 58s\n","859:\tlearn: 0.1309993\ttotal: 12m 4s\tremaining: 1m 57s\n","860:\tlearn: 0.1309922\ttotal: 12m 5s\tremaining: 1m 57s\n","861:\tlearn: 0.1309843\ttotal: 12m 6s\tremaining: 1m 56s\n","862:\tlearn: 0.1309740\ttotal: 12m 7s\tremaining: 1m 55s\n","863:\tlearn: 0.1309665\ttotal: 12m 8s\tremaining: 1m 54s\n","864:\tlearn: 0.1309549\ttotal: 12m 9s\tremaining: 1m 53s\n","865:\tlearn: 0.1309456\ttotal: 12m 10s\tremaining: 1m 52s\n","866:\tlearn: 0.1309360\ttotal: 12m 10s\tremaining: 1m 52s\n","867:\tlearn: 0.1309274\ttotal: 12m 11s\tremaining: 1m 51s\n","868:\tlearn: 0.1309156\ttotal: 12m 12s\tremaining: 1m 50s\n","869:\tlearn: 0.1309047\ttotal: 12m 13s\tremaining: 1m 49s\n","870:\tlearn: 0.1308949\ttotal: 12m 13s\tremaining: 1m 48s\n","871:\tlearn: 0.1308825\ttotal: 12m 14s\tremaining: 1m 47s\n","872:\tlearn: 0.1308725\ttotal: 12m 15s\tremaining: 1m 46s\n","873:\tlearn: 0.1308635\ttotal: 12m 15s\tremaining: 1m 46s\n","874:\tlearn: 0.1308537\ttotal: 12m 16s\tremaining: 1m 45s\n","875:\tlearn: 0.1308458\ttotal: 12m 17s\tremaining: 1m 44s\n","876:\tlearn: 0.1308348\ttotal: 12m 18s\tremaining: 1m 43s\n","877:\tlearn: 0.1308254\ttotal: 12m 19s\tremaining: 1m 42s\n","878:\tlearn: 0.1308109\ttotal: 12m 20s\tremaining: 1m 41s\n","879:\tlearn: 0.1308018\ttotal: 12m 21s\tremaining: 1m 41s\n","880:\tlearn: 0.1307915\ttotal: 12m 22s\tremaining: 1m 40s\n","881:\tlearn: 0.1307802\ttotal: 12m 23s\tremaining: 1m 39s\n","882:\tlearn: 0.1307696\ttotal: 12m 24s\tremaining: 1m 38s\n","883:\tlearn: 0.1307593\ttotal: 12m 25s\tremaining: 1m 37s\n","884:\tlearn: 0.1307451\ttotal: 12m 25s\tremaining: 1m 36s\n","885:\tlearn: 0.1307357\ttotal: 12m 26s\tremaining: 1m 36s\n","886:\tlearn: 0.1307281\ttotal: 12m 27s\tremaining: 1m 35s\n","887:\tlearn: 0.1307135\ttotal: 12m 28s\tremaining: 1m 34s\n","888:\tlearn: 0.1307008\ttotal: 12m 28s\tremaining: 1m 33s\n","889:\tlearn: 0.1306847\ttotal: 12m 29s\tremaining: 1m 32s\n","890:\tlearn: 0.1306762\ttotal: 12m 30s\tremaining: 1m 31s\n","891:\tlearn: 0.1306678\ttotal: 12m 31s\tremaining: 1m 30s\n","892:\tlearn: 0.1306539\ttotal: 12m 31s\tremaining: 1m 30s\n","893:\tlearn: 0.1306419\ttotal: 12m 32s\tremaining: 1m 29s\n","894:\tlearn: 0.1306275\ttotal: 12m 34s\tremaining: 1m 28s\n","895:\tlearn: 0.1306168\ttotal: 12m 35s\tremaining: 1m 27s\n","896:\tlearn: 0.1306079\ttotal: 12m 36s\tremaining: 1m 26s\n","897:\tlearn: 0.1305949\ttotal: 12m 37s\tremaining: 1m 26s\n","898:\tlearn: 0.1305871\ttotal: 12m 38s\tremaining: 1m 25s\n","899:\tlearn: 0.1305785\ttotal: 12m 38s\tremaining: 1m 24s\n","900:\tlearn: 0.1305708\ttotal: 12m 39s\tremaining: 1m 23s\n","901:\tlearn: 0.1305580\ttotal: 12m 40s\tremaining: 1m 22s\n","902:\tlearn: 0.1305473\ttotal: 12m 41s\tremaining: 1m 21s\n","903:\tlearn: 0.1305359\ttotal: 12m 41s\tremaining: 1m 20s\n","904:\tlearn: 0.1305271\ttotal: 12m 42s\tremaining: 1m 20s\n","905:\tlearn: 0.1305144\ttotal: 12m 43s\tremaining: 1m 19s\n","906:\tlearn: 0.1305100\ttotal: 12m 43s\tremaining: 1m 18s\n","907:\tlearn: 0.1304994\ttotal: 12m 44s\tremaining: 1m 17s\n","908:\tlearn: 0.1304915\ttotal: 12m 45s\tremaining: 1m 16s\n","909:\tlearn: 0.1304768\ttotal: 12m 46s\tremaining: 1m 15s\n","910:\tlearn: 0.1304651\ttotal: 12m 46s\tremaining: 1m 14s\n","911:\tlearn: 0.1304551\ttotal: 12m 48s\tremaining: 1m 14s\n","912:\tlearn: 0.1304437\ttotal: 12m 49s\tremaining: 1m 13s\n","913:\tlearn: 0.1304335\ttotal: 12m 50s\tremaining: 1m 12s\n","914:\tlearn: 0.1304211\ttotal: 12m 51s\tremaining: 1m 11s\n","915:\tlearn: 0.1304133\ttotal: 12m 52s\tremaining: 1m 10s\n","916:\tlearn: 0.1304058\ttotal: 12m 53s\tremaining: 1m 9s\n","917:\tlearn: 0.1303955\ttotal: 12m 53s\tremaining: 1m 9s\n","918:\tlearn: 0.1303858\ttotal: 12m 54s\tremaining: 1m 8s\n","919:\tlearn: 0.1303752\ttotal: 12m 55s\tremaining: 1m 7s\n","920:\tlearn: 0.1303679\ttotal: 12m 56s\tremaining: 1m 6s\n","921:\tlearn: 0.1303582\ttotal: 12m 56s\tremaining: 1m 5s\n","922:\tlearn: 0.1303464\ttotal: 12m 57s\tremaining: 1m 4s\n","923:\tlearn: 0.1303324\ttotal: 12m 58s\tremaining: 1m 3s\n","924:\tlearn: 0.1303206\ttotal: 12m 58s\tremaining: 1m 3s\n","925:\tlearn: 0.1303103\ttotal: 12m 59s\tremaining: 1m 2s\n","926:\tlearn: 0.1303020\ttotal: 13m\tremaining: 1m 1s\n","927:\tlearn: 0.1302947\ttotal: 13m 1s\tremaining: 1m\n","928:\tlearn: 0.1302841\ttotal: 13m 2s\tremaining: 59.8s\n","929:\tlearn: 0.1302705\ttotal: 13m 3s\tremaining: 59s\n","930:\tlearn: 0.1302633\ttotal: 13m 4s\tremaining: 58.2s\n","931:\tlearn: 0.1302606\ttotal: 13m 5s\tremaining: 57.3s\n","932:\tlearn: 0.1302523\ttotal: 13m 6s\tremaining: 56.5s\n","933:\tlearn: 0.1302392\ttotal: 13m 7s\tremaining: 55.6s\n","934:\tlearn: 0.1302242\ttotal: 13m 7s\tremaining: 54.8s\n","935:\tlearn: 0.1302167\ttotal: 13m 8s\tremaining: 53.9s\n","936:\tlearn: 0.1302055\ttotal: 13m 9s\tremaining: 53.1s\n","937:\tlearn: 0.1301921\ttotal: 13m 10s\tremaining: 52.2s\n","938:\tlearn: 0.1301847\ttotal: 13m 10s\tremaining: 51.4s\n","939:\tlearn: 0.1301752\ttotal: 13m 11s\tremaining: 50.5s\n","940:\tlearn: 0.1301634\ttotal: 13m 12s\tremaining: 49.7s\n","941:\tlearn: 0.1301552\ttotal: 13m 13s\tremaining: 48.8s\n","942:\tlearn: 0.1301435\ttotal: 13m 13s\tremaining: 48s\n","943:\tlearn: 0.1301349\ttotal: 13m 14s\tremaining: 47.1s\n","944:\tlearn: 0.1301251\ttotal: 13m 15s\tremaining: 46.3s\n","945:\tlearn: 0.1301139\ttotal: 13m 16s\tremaining: 45.5s\n","946:\tlearn: 0.1301015\ttotal: 13m 18s\tremaining: 44.7s\n","947:\tlearn: 0.1300921\ttotal: 13m 19s\tremaining: 43.8s\n","948:\tlearn: 0.1300834\ttotal: 13m 19s\tremaining: 43s\n","949:\tlearn: 0.1300774\ttotal: 13m 20s\tremaining: 42.1s\n","950:\tlearn: 0.1300661\ttotal: 13m 21s\tremaining: 41.3s\n","951:\tlearn: 0.1300539\ttotal: 13m 22s\tremaining: 40.4s\n","952:\tlearn: 0.1300437\ttotal: 13m 22s\tremaining: 39.6s\n","953:\tlearn: 0.1300373\ttotal: 13m 23s\tremaining: 38.7s\n","954:\tlearn: 0.1300275\ttotal: 13m 24s\tremaining: 37.9s\n","955:\tlearn: 0.1300170\ttotal: 13m 24s\tremaining: 37s\n","956:\tlearn: 0.1300081\ttotal: 13m 25s\tremaining: 36.2s\n","957:\tlearn: 0.1299982\ttotal: 13m 26s\tremaining: 35.4s\n","958:\tlearn: 0.1299875\ttotal: 13m 27s\tremaining: 34.5s\n","959:\tlearn: 0.1299762\ttotal: 13m 27s\tremaining: 33.7s\n","960:\tlearn: 0.1299686\ttotal: 13m 28s\tremaining: 32.8s\n","961:\tlearn: 0.1299555\ttotal: 13m 29s\tremaining: 32s\n","962:\tlearn: 0.1299451\ttotal: 13m 30s\tremaining: 31.1s\n","963:\tlearn: 0.1299337\ttotal: 13m 31s\tremaining: 30.3s\n","964:\tlearn: 0.1299222\ttotal: 13m 33s\tremaining: 29.5s\n","965:\tlearn: 0.1299114\ttotal: 13m 34s\tremaining: 28.7s\n","966:\tlearn: 0.1299017\ttotal: 13m 34s\tremaining: 27.8s\n","967:\tlearn: 0.1298932\ttotal: 13m 35s\tremaining: 27s\n","968:\tlearn: 0.1298849\ttotal: 13m 36s\tremaining: 26.1s\n","969:\tlearn: 0.1298727\ttotal: 13m 37s\tremaining: 25.3s\n","970:\tlearn: 0.1298641\ttotal: 13m 37s\tremaining: 24.4s\n","971:\tlearn: 0.1298484\ttotal: 13m 38s\tremaining: 23.6s\n","972:\tlearn: 0.1298376\ttotal: 13m 39s\tremaining: 22.7s\n","973:\tlearn: 0.1298248\ttotal: 13m 39s\tremaining: 21.9s\n","974:\tlearn: 0.1298117\ttotal: 13m 40s\tremaining: 21s\n","975:\tlearn: 0.1298044\ttotal: 13m 41s\tremaining: 20.2s\n","976:\tlearn: 0.1297928\ttotal: 13m 42s\tremaining: 19.4s\n","977:\tlearn: 0.1297806\ttotal: 13m 43s\tremaining: 18.5s\n","978:\tlearn: 0.1297687\ttotal: 13m 44s\tremaining: 17.7s\n","979:\tlearn: 0.1297564\ttotal: 13m 45s\tremaining: 16.8s\n","980:\tlearn: 0.1297453\ttotal: 13m 46s\tremaining: 16s\n","981:\tlearn: 0.1297376\ttotal: 13m 47s\tremaining: 15.2s\n","982:\tlearn: 0.1297275\ttotal: 13m 48s\tremaining: 14.3s\n","983:\tlearn: 0.1297161\ttotal: 13m 49s\tremaining: 13.5s\n","984:\tlearn: 0.1297073\ttotal: 13m 50s\tremaining: 12.6s\n","985:\tlearn: 0.1296928\ttotal: 13m 50s\tremaining: 11.8s\n","986:\tlearn: 0.1296840\ttotal: 13m 51s\tremaining: 11s\n","987:\tlearn: 0.1296752\ttotal: 13m 52s\tremaining: 10.1s\n","988:\tlearn: 0.1296647\ttotal: 13m 53s\tremaining: 9.27s\n","989:\tlearn: 0.1296581\ttotal: 13m 53s\tremaining: 8.42s\n","990:\tlearn: 0.1296509\ttotal: 13m 54s\tremaining: 7.58s\n","991:\tlearn: 0.1296390\ttotal: 13m 55s\tremaining: 6.73s\n","992:\tlearn: 0.1296296\ttotal: 13m 55s\tremaining: 5.89s\n","993:\tlearn: 0.1296213\ttotal: 13m 56s\tremaining: 5.05s\n","994:\tlearn: 0.1296106\ttotal: 13m 57s\tremaining: 4.21s\n","995:\tlearn: 0.1296000\ttotal: 13m 58s\tremaining: 3.37s\n","996:\tlearn: 0.1295897\ttotal: 13m 59s\tremaining: 2.53s\n","997:\tlearn: 0.1295820\ttotal: 14m\tremaining: 1.69s\n","998:\tlearn: 0.1295715\ttotal: 14m 1s\tremaining: 843ms\n","999:\tlearn: 0.1295590\ttotal: 14m 2s\tremaining: 0us\n","train: 0.5092418883036708\n","test: 0.5007043251569586\n","test conf matrix: \n"," [[867907    107]\n"," [ 31937     49]]\n"]}]},{"cell_type":"code","source":["# с балансировкой классов\n","classes = np.unique(y_train)\n","weights = compute_class_weight(class_weight='balanced', classes=classes, y=y_train['flag'])\n","class_weights = dict(zip(classes, weights))\n","\n","model_catb = CatBoostClassifier(class_weights=class_weights)\n","model_catb.fit(x_train_feat_sel, y_train)\n","\n","pred_train = model_catb.predict(x_train_feat_sel)\n","pred_test = model_catb.predict(x_test_feat_sel)\n","\n","print(f'train: {roc_auc_score(y_train, pred_train)}')\n","print(f'test: {roc_auc_score(y_test, pred_test)}')\n","print(f'test conf matrix: \\n {confusion_matrix(y_test, pred_test)}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3tzlGA2aPt1N","executionInfo":{"status":"ok","timestamp":1708011119200,"user_tz":-240,"elapsed":852315,"user":{"displayName":"Евгений Малов","userId":"06257165098392198337"}},"outputId":"faa11bb9-5d32-4284-e8d2-f4c520a9bcc2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Learning rate set to 0.270098\n","0:\tlearn: 0.6755841\ttotal: 984ms\tremaining: 16m 23s\n","1:\tlearn: 0.6637412\ttotal: 1.75s\tremaining: 14m 35s\n","2:\tlearn: 0.6568446\ttotal: 2.45s\tremaining: 13m 35s\n","3:\tlearn: 0.6516659\ttotal: 3.2s\tremaining: 13m 16s\n","4:\tlearn: 0.6473914\ttotal: 3.94s\tremaining: 13m 3s\n","5:\tlearn: 0.6440881\ttotal: 4.65s\tremaining: 12m 49s\n","6:\tlearn: 0.6416125\ttotal: 5.93s\tremaining: 14m\n","7:\tlearn: 0.6393363\ttotal: 7.19s\tremaining: 14m 51s\n","8:\tlearn: 0.6376989\ttotal: 8.32s\tremaining: 15m 15s\n","9:\tlearn: 0.6362489\ttotal: 9.06s\tremaining: 14m 57s\n","10:\tlearn: 0.6349790\ttotal: 10.4s\tremaining: 15m 39s\n","11:\tlearn: 0.6337167\ttotal: 11.2s\tremaining: 15m 22s\n","12:\tlearn: 0.6325831\ttotal: 11.9s\tremaining: 15m 4s\n","13:\tlearn: 0.6315619\ttotal: 12.6s\tremaining: 14m 49s\n","14:\tlearn: 0.6306662\ttotal: 13.4s\tremaining: 14m 37s\n","15:\tlearn: 0.6298219\ttotal: 14.1s\tremaining: 14m 25s\n","16:\tlearn: 0.6290827\ttotal: 14.8s\tremaining: 14m 13s\n","17:\tlearn: 0.6284062\ttotal: 15.4s\tremaining: 14m 1s\n","18:\tlearn: 0.6277214\ttotal: 16.1s\tremaining: 13m 52s\n","19:\tlearn: 0.6268970\ttotal: 16.8s\tremaining: 13m 41s\n","20:\tlearn: 0.6263551\ttotal: 17.4s\tremaining: 13m 33s\n","21:\tlearn: 0.6258569\ttotal: 18.1s\tremaining: 13m 26s\n","22:\tlearn: 0.6254268\ttotal: 18.9s\tremaining: 13m 22s\n","23:\tlearn: 0.6249882\ttotal: 19.9s\tremaining: 13m 29s\n","24:\tlearn: 0.6246228\ttotal: 21s\tremaining: 13m 39s\n","25:\tlearn: 0.6242382\ttotal: 22.2s\tremaining: 13m 52s\n","26:\tlearn: 0.6237150\ttotal: 22.8s\tremaining: 13m 41s\n","27:\tlearn: 0.6232549\ttotal: 23.5s\tremaining: 13m 35s\n","28:\tlearn: 0.6227395\ttotal: 24.2s\tremaining: 13m 31s\n","29:\tlearn: 0.6224014\ttotal: 24.9s\tremaining: 13m 24s\n","30:\tlearn: 0.6220371\ttotal: 25.7s\tremaining: 13m 22s\n","31:\tlearn: 0.6217023\ttotal: 26.4s\tremaining: 13m 19s\n","32:\tlearn: 0.6214488\ttotal: 27s\tremaining: 13m 12s\n","33:\tlearn: 0.6210834\ttotal: 27.7s\tremaining: 13m 6s\n","34:\tlearn: 0.6208131\ttotal: 28.3s\tremaining: 13m\n","35:\tlearn: 0.6204880\ttotal: 29s\tremaining: 12m 57s\n","36:\tlearn: 0.6201380\ttotal: 29.7s\tremaining: 12m 54s\n","37:\tlearn: 0.6198796\ttotal: 30.4s\tremaining: 12m 50s\n","38:\tlearn: 0.6194420\ttotal: 31.2s\tremaining: 12m 47s\n","39:\tlearn: 0.6191610\ttotal: 31.8s\tremaining: 12m 43s\n","40:\tlearn: 0.6189265\ttotal: 32.6s\tremaining: 12m 42s\n","41:\tlearn: 0.6186529\ttotal: 33.6s\tremaining: 12m 47s\n","42:\tlearn: 0.6183308\ttotal: 34.8s\tremaining: 12m 54s\n","43:\tlearn: 0.6180633\ttotal: 36s\tremaining: 13m 1s\n","44:\tlearn: 0.6178139\ttotal: 36.7s\tremaining: 12m 59s\n","45:\tlearn: 0.6175944\ttotal: 37.3s\tremaining: 12m 53s\n","46:\tlearn: 0.6173618\ttotal: 37.8s\tremaining: 12m 47s\n","47:\tlearn: 0.6171703\ttotal: 38.5s\tremaining: 12m 43s\n","48:\tlearn: 0.6169716\ttotal: 39.2s\tremaining: 12m 39s\n","49:\tlearn: 0.6167580\ttotal: 39.8s\tremaining: 12m 36s\n","50:\tlearn: 0.6164580\ttotal: 40.5s\tremaining: 12m 34s\n","51:\tlearn: 0.6161386\ttotal: 41.2s\tremaining: 12m 31s\n","52:\tlearn: 0.6158816\ttotal: 41.9s\tremaining: 12m 28s\n","53:\tlearn: 0.6156362\ttotal: 42.5s\tremaining: 12m 24s\n","54:\tlearn: 0.6154179\ttotal: 43s\tremaining: 12m 19s\n","55:\tlearn: 0.6150256\ttotal: 43.7s\tremaining: 12m 17s\n","56:\tlearn: 0.6146510\ttotal: 44.5s\tremaining: 12m 16s\n","57:\tlearn: 0.6143742\ttotal: 45.2s\tremaining: 12m 14s\n","58:\tlearn: 0.6141184\ttotal: 45.8s\tremaining: 12m 10s\n","59:\tlearn: 0.6138957\ttotal: 46.7s\tremaining: 12m 12s\n","60:\tlearn: 0.6136655\ttotal: 47.8s\tremaining: 12m 15s\n","61:\tlearn: 0.6132994\ttotal: 49.2s\tremaining: 12m 23s\n","62:\tlearn: 0.6130620\ttotal: 50.1s\tremaining: 12m 24s\n","63:\tlearn: 0.6128429\ttotal: 50.7s\tremaining: 12m 21s\n","64:\tlearn: 0.6126137\ttotal: 51.4s\tremaining: 12m 19s\n","65:\tlearn: 0.6123402\ttotal: 52.1s\tremaining: 12m 17s\n","66:\tlearn: 0.6120940\ttotal: 52.7s\tremaining: 12m 14s\n","67:\tlearn: 0.6118732\ttotal: 53.4s\tremaining: 12m 11s\n","68:\tlearn: 0.6116064\ttotal: 54.1s\tremaining: 12m 9s\n","69:\tlearn: 0.6113279\ttotal: 54.8s\tremaining: 12m 8s\n","70:\tlearn: 0.6110393\ttotal: 55.6s\tremaining: 12m 6s\n","71:\tlearn: 0.6107839\ttotal: 56.1s\tremaining: 12m 3s\n","72:\tlearn: 0.6105547\ttotal: 56.8s\tremaining: 12m 1s\n","73:\tlearn: 0.6103357\ttotal: 57.4s\tremaining: 11m 58s\n","74:\tlearn: 0.6100996\ttotal: 58.1s\tremaining: 11m 57s\n","75:\tlearn: 0.6098765\ttotal: 58.8s\tremaining: 11m 54s\n","76:\tlearn: 0.6096465\ttotal: 59.4s\tremaining: 11m 51s\n","77:\tlearn: 0.6094627\ttotal: 1m\tremaining: 11m 49s\n","78:\tlearn: 0.6092436\ttotal: 1m 1s\tremaining: 11m 54s\n","79:\tlearn: 0.6090625\ttotal: 1m 2s\tremaining: 11m 57s\n","80:\tlearn: 0.6088499\ttotal: 1m 3s\tremaining: 12m 1s\n","81:\tlearn: 0.6086255\ttotal: 1m 4s\tremaining: 11m 58s\n","82:\tlearn: 0.6084452\ttotal: 1m 4s\tremaining: 11m 55s\n","83:\tlearn: 0.6082611\ttotal: 1m 5s\tremaining: 11m 52s\n","84:\tlearn: 0.6080606\ttotal: 1m 6s\tremaining: 11m 50s\n","85:\tlearn: 0.6078154\ttotal: 1m 6s\tremaining: 11m 48s\n","86:\tlearn: 0.6076018\ttotal: 1m 7s\tremaining: 11m 48s\n","87:\tlearn: 0.6072945\ttotal: 1m 8s\tremaining: 11m 47s\n","88:\tlearn: 0.6070558\ttotal: 1m 8s\tremaining: 11m 45s\n","89:\tlearn: 0.6068294\ttotal: 1m 9s\tremaining: 11m 43s\n","90:\tlearn: 0.6066151\ttotal: 1m 10s\tremaining: 11m 41s\n","91:\tlearn: 0.6064415\ttotal: 1m 10s\tremaining: 11m 39s\n","92:\tlearn: 0.6062834\ttotal: 1m 11s\tremaining: 11m 36s\n","93:\tlearn: 0.6060911\ttotal: 1m 12s\tremaining: 11m 34s\n","94:\tlearn: 0.6059022\ttotal: 1m 12s\tremaining: 11m 32s\n","95:\tlearn: 0.6057145\ttotal: 1m 13s\tremaining: 11m 30s\n","96:\tlearn: 0.6055103\ttotal: 1m 14s\tremaining: 11m 34s\n","97:\tlearn: 0.6053177\ttotal: 1m 15s\tremaining: 11m 37s\n","98:\tlearn: 0.6051612\ttotal: 1m 16s\tremaining: 11m 37s\n","99:\tlearn: 0.6049806\ttotal: 1m 17s\tremaining: 11m 37s\n","100:\tlearn: 0.6048335\ttotal: 1m 18s\tremaining: 11m 35s\n","101:\tlearn: 0.6046483\ttotal: 1m 18s\tremaining: 11m 33s\n","102:\tlearn: 0.6044770\ttotal: 1m 19s\tremaining: 11m 31s\n","103:\tlearn: 0.6042916\ttotal: 1m 20s\tremaining: 11m 29s\n","104:\tlearn: 0.6041155\ttotal: 1m 20s\tremaining: 11m 28s\n","105:\tlearn: 0.6039310\ttotal: 1m 21s\tremaining: 11m 26s\n","106:\tlearn: 0.6037732\ttotal: 1m 21s\tremaining: 11m 23s\n","107:\tlearn: 0.6035883\ttotal: 1m 22s\tremaining: 11m 22s\n","108:\tlearn: 0.6034099\ttotal: 1m 23s\tremaining: 11m 20s\n","109:\tlearn: 0.6032071\ttotal: 1m 24s\tremaining: 11m 19s\n","110:\tlearn: 0.6030524\ttotal: 1m 24s\tremaining: 11m 17s\n","111:\tlearn: 0.6029120\ttotal: 1m 25s\tremaining: 11m 15s\n","112:\tlearn: 0.6027716\ttotal: 1m 25s\tremaining: 11m 13s\n","113:\tlearn: 0.6026143\ttotal: 1m 26s\tremaining: 11m 11s\n","114:\tlearn: 0.6024495\ttotal: 1m 27s\tremaining: 11m 9s\n","115:\tlearn: 0.6022556\ttotal: 1m 28s\tremaining: 11m 10s\n","116:\tlearn: 0.6020786\ttotal: 1m 29s\tremaining: 11m 13s\n","117:\tlearn: 0.6018976\ttotal: 1m 30s\tremaining: 11m 17s\n","118:\tlearn: 0.6017038\ttotal: 1m 31s\tremaining: 11m 17s\n","119:\tlearn: 0.6015220\ttotal: 1m 32s\tremaining: 11m 20s\n","120:\tlearn: 0.6013287\ttotal: 1m 34s\tremaining: 11m 23s\n","121:\tlearn: 0.6011678\ttotal: 1m 34s\tremaining: 11m 23s\n","122:\tlearn: 0.6010195\ttotal: 1m 35s\tremaining: 11m 21s\n","123:\tlearn: 0.6008690\ttotal: 1m 36s\tremaining: 11m 19s\n","124:\tlearn: 0.6006853\ttotal: 1m 36s\tremaining: 11m 17s\n","125:\tlearn: 0.6005310\ttotal: 1m 37s\tremaining: 11m 15s\n","126:\tlearn: 0.6003690\ttotal: 1m 38s\tremaining: 11m 14s\n","127:\tlearn: 0.6002073\ttotal: 1m 38s\tremaining: 11m 12s\n","128:\tlearn: 0.6000409\ttotal: 1m 39s\tremaining: 11m 10s\n","129:\tlearn: 0.5998739\ttotal: 1m 39s\tremaining: 11m 8s\n","130:\tlearn: 0.5997095\ttotal: 1m 40s\tremaining: 11m 6s\n","131:\tlearn: 0.5995615\ttotal: 1m 41s\tremaining: 11m 6s\n","132:\tlearn: 0.5994168\ttotal: 1m 42s\tremaining: 11m 8s\n","133:\tlearn: 0.5992486\ttotal: 1m 43s\tremaining: 11m 10s\n","134:\tlearn: 0.5990971\ttotal: 1m 44s\tremaining: 11m 11s\n","135:\tlearn: 0.5989505\ttotal: 1m 45s\tremaining: 11m 10s\n","136:\tlearn: 0.5987949\ttotal: 1m 46s\tremaining: 11m 8s\n","137:\tlearn: 0.5986455\ttotal: 1m 46s\tremaining: 11m 6s\n","138:\tlearn: 0.5984554\ttotal: 1m 47s\tremaining: 11m 5s\n","139:\tlearn: 0.5983025\ttotal: 1m 48s\tremaining: 11m 3s\n","140:\tlearn: 0.5981246\ttotal: 1m 48s\tremaining: 11m 2s\n","141:\tlearn: 0.5979879\ttotal: 1m 49s\tremaining: 11m\n","142:\tlearn: 0.5978381\ttotal: 1m 49s\tremaining: 10m 59s\n","143:\tlearn: 0.5976950\ttotal: 1m 50s\tremaining: 10m 57s\n","144:\tlearn: 0.5975776\ttotal: 1m 51s\tremaining: 10m 55s\n","145:\tlearn: 0.5974163\ttotal: 1m 51s\tremaining: 10m 54s\n","146:\tlearn: 0.5972606\ttotal: 1m 52s\tremaining: 10m 53s\n","147:\tlearn: 0.5971034\ttotal: 1m 53s\tremaining: 10m 52s\n","148:\tlearn: 0.5969497\ttotal: 1m 53s\tremaining: 10m 50s\n","149:\tlearn: 0.5967830\ttotal: 1m 54s\tremaining: 10m 49s\n","150:\tlearn: 0.5966136\ttotal: 1m 55s\tremaining: 10m 49s\n","151:\tlearn: 0.5964508\ttotal: 1m 56s\tremaining: 10m 52s\n","152:\tlearn: 0.5962937\ttotal: 1m 58s\tremaining: 10m 54s\n","153:\tlearn: 0.5961101\ttotal: 1m 59s\tremaining: 10m 54s\n","154:\tlearn: 0.5959674\ttotal: 1m 59s\tremaining: 10m 52s\n","155:\tlearn: 0.5958317\ttotal: 2m\tremaining: 10m 51s\n","156:\tlearn: 0.5956786\ttotal: 2m 1s\tremaining: 10m 50s\n","157:\tlearn: 0.5955521\ttotal: 2m 1s\tremaining: 10m 48s\n","158:\tlearn: 0.5954206\ttotal: 2m 2s\tremaining: 10m 46s\n","159:\tlearn: 0.5952972\ttotal: 2m 2s\tremaining: 10m 45s\n","160:\tlearn: 0.5951576\ttotal: 2m 3s\tremaining: 10m 44s\n","161:\tlearn: 0.5949803\ttotal: 2m 4s\tremaining: 10m 43s\n","162:\tlearn: 0.5948551\ttotal: 2m 5s\tremaining: 10m 42s\n","163:\tlearn: 0.5947114\ttotal: 2m 5s\tremaining: 10m 40s\n","164:\tlearn: 0.5945591\ttotal: 2m 6s\tremaining: 10m 39s\n","165:\tlearn: 0.5944338\ttotal: 2m 6s\tremaining: 10m 37s\n","166:\tlearn: 0.5942658\ttotal: 2m 7s\tremaining: 10m 36s\n","167:\tlearn: 0.5941174\ttotal: 2m 8s\tremaining: 10m 34s\n","168:\tlearn: 0.5939648\ttotal: 2m 9s\tremaining: 10m 34s\n","169:\tlearn: 0.5938026\ttotal: 2m 10s\tremaining: 10m 36s\n","170:\tlearn: 0.5936731\ttotal: 2m 11s\tremaining: 10m 36s\n","171:\tlearn: 0.5935029\ttotal: 2m 12s\tremaining: 10m 37s\n","172:\tlearn: 0.5933704\ttotal: 2m 13s\tremaining: 10m 36s\n","173:\tlearn: 0.5932096\ttotal: 2m 13s\tremaining: 10m 35s\n","174:\tlearn: 0.5930632\ttotal: 2m 14s\tremaining: 10m 34s\n","175:\tlearn: 0.5929227\ttotal: 2m 15s\tremaining: 10m 33s\n","176:\tlearn: 0.5927798\ttotal: 2m 15s\tremaining: 10m 31s\n","177:\tlearn: 0.5926579\ttotal: 2m 16s\tremaining: 10m 30s\n","178:\tlearn: 0.5925431\ttotal: 2m 17s\tremaining: 10m 28s\n","179:\tlearn: 0.5924118\ttotal: 2m 17s\tremaining: 10m 27s\n","180:\tlearn: 0.5922624\ttotal: 2m 18s\tremaining: 10m 26s\n","181:\tlearn: 0.5920957\ttotal: 2m 19s\tremaining: 10m 25s\n","182:\tlearn: 0.5919629\ttotal: 2m 19s\tremaining: 10m 24s\n","183:\tlearn: 0.5917894\ttotal: 2m 20s\tremaining: 10m 22s\n","184:\tlearn: 0.5916450\ttotal: 2m 20s\tremaining: 10m 20s\n","185:\tlearn: 0.5915388\ttotal: 2m 21s\tremaining: 10m 19s\n","186:\tlearn: 0.5914035\ttotal: 2m 22s\tremaining: 10m 18s\n","187:\tlearn: 0.5912578\ttotal: 2m 23s\tremaining: 10m 17s\n","188:\tlearn: 0.5911018\ttotal: 2m 24s\tremaining: 10m 18s\n","189:\tlearn: 0.5909676\ttotal: 2m 25s\tremaining: 10m 20s\n","190:\tlearn: 0.5908321\ttotal: 2m 26s\tremaining: 10m 20s\n","191:\tlearn: 0.5906960\ttotal: 2m 27s\tremaining: 10m 19s\n","192:\tlearn: 0.5905615\ttotal: 2m 27s\tremaining: 10m 17s\n","193:\tlearn: 0.5904096\ttotal: 2m 28s\tremaining: 10m 16s\n","194:\tlearn: 0.5902786\ttotal: 2m 29s\tremaining: 10m 15s\n","195:\tlearn: 0.5901433\ttotal: 2m 29s\tremaining: 10m 14s\n","196:\tlearn: 0.5900053\ttotal: 2m 30s\tremaining: 10m 13s\n","197:\tlearn: 0.5898577\ttotal: 2m 31s\tremaining: 10m 12s\n","198:\tlearn: 0.5897154\ttotal: 2m 31s\tremaining: 10m 11s\n","199:\tlearn: 0.5895698\ttotal: 2m 32s\tremaining: 10m 9s\n","200:\tlearn: 0.5894682\ttotal: 2m 33s\tremaining: 10m 8s\n","201:\tlearn: 0.5893495\ttotal: 2m 33s\tremaining: 10m 7s\n","202:\tlearn: 0.5892292\ttotal: 2m 34s\tremaining: 10m 6s\n","203:\tlearn: 0.5890910\ttotal: 2m 35s\tremaining: 10m 5s\n","204:\tlearn: 0.5889571\ttotal: 2m 35s\tremaining: 10m 4s\n","205:\tlearn: 0.5888189\ttotal: 2m 36s\tremaining: 10m 3s\n","206:\tlearn: 0.5887001\ttotal: 2m 37s\tremaining: 10m 4s\n","207:\tlearn: 0.5885610\ttotal: 2m 38s\tremaining: 10m 4s\n","208:\tlearn: 0.5884118\ttotal: 2m 39s\tremaining: 10m 5s\n","209:\tlearn: 0.5882902\ttotal: 2m 40s\tremaining: 10m 3s\n","210:\tlearn: 0.5881414\ttotal: 2m 41s\tremaining: 10m 2s\n","211:\tlearn: 0.5880099\ttotal: 2m 41s\tremaining: 10m 2s\n","212:\tlearn: 0.5878686\ttotal: 2m 42s\tremaining: 10m\n","213:\tlearn: 0.5877507\ttotal: 2m 43s\tremaining: 9m 59s\n","214:\tlearn: 0.5876039\ttotal: 2m 43s\tremaining: 9m 58s\n","215:\tlearn: 0.5874688\ttotal: 2m 44s\tremaining: 9m 57s\n","216:\tlearn: 0.5873317\ttotal: 2m 45s\tremaining: 9m 56s\n","217:\tlearn: 0.5871732\ttotal: 2m 46s\tremaining: 9m 55s\n","218:\tlearn: 0.5870670\ttotal: 2m 46s\tremaining: 9m 54s\n","219:\tlearn: 0.5869355\ttotal: 2m 47s\tremaining: 9m 53s\n","220:\tlearn: 0.5868077\ttotal: 2m 48s\tremaining: 9m 52s\n","221:\tlearn: 0.5866908\ttotal: 2m 48s\tremaining: 9m 51s\n","222:\tlearn: 0.5865485\ttotal: 2m 49s\tremaining: 9m 50s\n","223:\tlearn: 0.5864097\ttotal: 2m 50s\tremaining: 9m 49s\n","224:\tlearn: 0.5862792\ttotal: 2m 51s\tremaining: 9m 50s\n","225:\tlearn: 0.5861427\ttotal: 2m 52s\tremaining: 9m 51s\n","226:\tlearn: 0.5860018\ttotal: 2m 53s\tremaining: 9m 51s\n","227:\tlearn: 0.5858704\ttotal: 2m 54s\tremaining: 9m 50s\n","228:\tlearn: 0.5857422\ttotal: 2m 54s\tremaining: 9m 48s\n","229:\tlearn: 0.5856299\ttotal: 2m 55s\tremaining: 9m 47s\n","230:\tlearn: 0.5855063\ttotal: 2m 56s\tremaining: 9m 46s\n","231:\tlearn: 0.5853737\ttotal: 2m 56s\tremaining: 9m 45s\n","232:\tlearn: 0.5852626\ttotal: 2m 57s\tremaining: 9m 44s\n","233:\tlearn: 0.5851309\ttotal: 2m 58s\tremaining: 9m 43s\n","234:\tlearn: 0.5849834\ttotal: 2m 58s\tremaining: 9m 42s\n","235:\tlearn: 0.5848596\ttotal: 2m 59s\tremaining: 9m 41s\n","236:\tlearn: 0.5847341\ttotal: 3m\tremaining: 9m 40s\n","237:\tlearn: 0.5846095\ttotal: 3m\tremaining: 9m 38s\n","238:\tlearn: 0.5844966\ttotal: 3m 1s\tremaining: 9m 37s\n","239:\tlearn: 0.5843891\ttotal: 3m 2s\tremaining: 9m 36s\n","240:\tlearn: 0.5842631\ttotal: 3m 2s\tremaining: 9m 35s\n","241:\tlearn: 0.5841475\ttotal: 3m 3s\tremaining: 9m 34s\n","242:\tlearn: 0.5840236\ttotal: 3m 4s\tremaining: 9m 34s\n","243:\tlearn: 0.5839030\ttotal: 3m 5s\tremaining: 9m 34s\n","244:\tlearn: 0.5837847\ttotal: 3m 6s\tremaining: 9m 35s\n","245:\tlearn: 0.5836436\ttotal: 3m 7s\tremaining: 9m 35s\n","246:\tlearn: 0.5835227\ttotal: 3m 8s\tremaining: 9m 33s\n","247:\tlearn: 0.5834200\ttotal: 3m 8s\tremaining: 9m 32s\n","248:\tlearn: 0.5833016\ttotal: 3m 9s\tremaining: 9m 31s\n","249:\tlearn: 0.5831998\ttotal: 3m 10s\tremaining: 9m 30s\n","250:\tlearn: 0.5830777\ttotal: 3m 10s\tremaining: 9m 29s\n","251:\tlearn: 0.5829825\ttotal: 3m 11s\tremaining: 9m 27s\n","252:\tlearn: 0.5828756\ttotal: 3m 12s\tremaining: 9m 26s\n","253:\tlearn: 0.5827617\ttotal: 3m 12s\tremaining: 9m 25s\n","254:\tlearn: 0.5826569\ttotal: 3m 13s\tremaining: 9m 24s\n","255:\tlearn: 0.5825507\ttotal: 3m 13s\tremaining: 9m 23s\n","256:\tlearn: 0.5824258\ttotal: 3m 14s\tremaining: 9m 22s\n","257:\tlearn: 0.5823223\ttotal: 3m 15s\tremaining: 9m 21s\n","258:\tlearn: 0.5822068\ttotal: 3m 15s\tremaining: 9m 20s\n","259:\tlearn: 0.5820957\ttotal: 3m 16s\tremaining: 9m 19s\n","260:\tlearn: 0.5819690\ttotal: 3m 17s\tremaining: 9m 18s\n","261:\tlearn: 0.5818269\ttotal: 3m 18s\tremaining: 9m 18s\n","262:\tlearn: 0.5816999\ttotal: 3m 19s\tremaining: 9m 19s\n","263:\tlearn: 0.5815787\ttotal: 3m 20s\tremaining: 9m 19s\n","264:\tlearn: 0.5814696\ttotal: 3m 21s\tremaining: 9m 18s\n","265:\tlearn: 0.5813459\ttotal: 3m 21s\tremaining: 9m 17s\n","266:\tlearn: 0.5812201\ttotal: 3m 22s\tremaining: 9m 16s\n","267:\tlearn: 0.5811134\ttotal: 3m 23s\tremaining: 9m 15s\n","268:\tlearn: 0.5809791\ttotal: 3m 24s\tremaining: 9m 14s\n","269:\tlearn: 0.5808529\ttotal: 3m 24s\tremaining: 9m 13s\n","270:\tlearn: 0.5807361\ttotal: 3m 25s\tremaining: 9m 11s\n","271:\tlearn: 0.5806454\ttotal: 3m 25s\tremaining: 9m 10s\n","272:\tlearn: 0.5805638\ttotal: 3m 26s\tremaining: 9m 9s\n","273:\tlearn: 0.5804169\ttotal: 3m 27s\tremaining: 9m 8s\n","274:\tlearn: 0.5803062\ttotal: 3m 27s\tremaining: 9m 7s\n","275:\tlearn: 0.5801954\ttotal: 3m 28s\tremaining: 9m 6s\n","276:\tlearn: 0.5800732\ttotal: 3m 29s\tremaining: 9m 5s\n","277:\tlearn: 0.5799368\ttotal: 3m 29s\tremaining: 9m 5s\n","278:\tlearn: 0.5798047\ttotal: 3m 30s\tremaining: 9m 4s\n","279:\tlearn: 0.5797030\ttotal: 3m 31s\tremaining: 9m 3s\n","280:\tlearn: 0.5795722\ttotal: 3m 32s\tremaining: 9m 4s\n","281:\tlearn: 0.5794431\ttotal: 3m 33s\tremaining: 9m 4s\n","282:\tlearn: 0.5793228\ttotal: 3m 34s\tremaining: 9m 4s\n","283:\tlearn: 0.5791932\ttotal: 3m 35s\tremaining: 9m 3s\n","284:\tlearn: 0.5790801\ttotal: 3m 36s\tremaining: 9m 2s\n","285:\tlearn: 0.5789520\ttotal: 3m 36s\tremaining: 9m 1s\n","286:\tlearn: 0.5788213\ttotal: 3m 37s\tremaining: 8m 59s\n","287:\tlearn: 0.5787063\ttotal: 3m 37s\tremaining: 8m 58s\n","288:\tlearn: 0.5786072\ttotal: 3m 38s\tremaining: 8m 57s\n","289:\tlearn: 0.5784875\ttotal: 3m 39s\tremaining: 8m 56s\n","290:\tlearn: 0.5783463\ttotal: 3m 40s\tremaining: 8m 56s\n","291:\tlearn: 0.5782280\ttotal: 3m 40s\tremaining: 8m 55s\n","292:\tlearn: 0.5780962\ttotal: 3m 41s\tremaining: 8m 54s\n","293:\tlearn: 0.5779801\ttotal: 3m 42s\tremaining: 8m 53s\n","294:\tlearn: 0.5778522\ttotal: 3m 42s\tremaining: 8m 52s\n","295:\tlearn: 0.5777278\ttotal: 3m 43s\tremaining: 8m 51s\n","296:\tlearn: 0.5775943\ttotal: 3m 44s\tremaining: 8m 50s\n","297:\tlearn: 0.5774912\ttotal: 3m 44s\tremaining: 8m 49s\n","298:\tlearn: 0.5773601\ttotal: 3m 46s\tremaining: 8m 50s\n","299:\tlearn: 0.5772447\ttotal: 3m 47s\tremaining: 8m 49s\n","300:\tlearn: 0.5771177\ttotal: 3m 48s\tremaining: 8m 50s\n","301:\tlearn: 0.5770180\ttotal: 3m 49s\tremaining: 8m 49s\n","302:\tlearn: 0.5769052\ttotal: 3m 49s\tremaining: 8m 48s\n","303:\tlearn: 0.5767934\ttotal: 3m 50s\tremaining: 8m 47s\n","304:\tlearn: 0.5766581\ttotal: 3m 51s\tremaining: 8m 46s\n","305:\tlearn: 0.5765663\ttotal: 3m 51s\tremaining: 8m 45s\n","306:\tlearn: 0.5764545\ttotal: 3m 52s\tremaining: 8m 44s\n","307:\tlearn: 0.5763762\ttotal: 3m 52s\tremaining: 8m 43s\n","308:\tlearn: 0.5762705\ttotal: 3m 53s\tremaining: 8m 42s\n","309:\tlearn: 0.5761504\ttotal: 3m 54s\tremaining: 8m 41s\n","310:\tlearn: 0.5760380\ttotal: 3m 54s\tremaining: 8m 40s\n","311:\tlearn: 0.5759204\ttotal: 3m 55s\tremaining: 8m 39s\n","312:\tlearn: 0.5758128\ttotal: 3m 56s\tremaining: 8m 38s\n","313:\tlearn: 0.5756985\ttotal: 3m 56s\tremaining: 8m 37s\n","314:\tlearn: 0.5755999\ttotal: 3m 57s\tremaining: 8m 36s\n","315:\tlearn: 0.5754871\ttotal: 3m 58s\tremaining: 8m 35s\n","316:\tlearn: 0.5753742\ttotal: 3m 58s\tremaining: 8m 34s\n","317:\tlearn: 0.5752574\ttotal: 3m 59s\tremaining: 8m 34s\n","318:\tlearn: 0.5751420\ttotal: 4m\tremaining: 8m 34s\n","319:\tlearn: 0.5750354\ttotal: 4m 2s\tremaining: 8m 34s\n","320:\tlearn: 0.5749322\ttotal: 4m 2s\tremaining: 8m 33s\n","321:\tlearn: 0.5747863\ttotal: 4m 3s\tremaining: 8m 32s\n","322:\tlearn: 0.5746738\ttotal: 4m 4s\tremaining: 8m 31s\n","323:\tlearn: 0.5745776\ttotal: 4m 4s\tremaining: 8m 30s\n","324:\tlearn: 0.5744659\ttotal: 4m 5s\tremaining: 8m 29s\n","325:\tlearn: 0.5743652\ttotal: 4m 6s\tremaining: 8m 29s\n","326:\tlearn: 0.5742694\ttotal: 4m 6s\tremaining: 8m 28s\n","327:\tlearn: 0.5741402\ttotal: 4m 7s\tremaining: 8m 27s\n","328:\tlearn: 0.5740327\ttotal: 4m 8s\tremaining: 8m 26s\n","329:\tlearn: 0.5739039\ttotal: 4m 8s\tremaining: 8m 25s\n","330:\tlearn: 0.5737964\ttotal: 4m 9s\tremaining: 8m 24s\n","331:\tlearn: 0.5736695\ttotal: 4m 10s\tremaining: 8m 23s\n","332:\tlearn: 0.5735553\ttotal: 4m 10s\tremaining: 8m 22s\n","333:\tlearn: 0.5734485\ttotal: 4m 11s\tremaining: 8m 21s\n","334:\tlearn: 0.5733342\ttotal: 4m 12s\tremaining: 8m 20s\n","335:\tlearn: 0.5732295\ttotal: 4m 13s\tremaining: 8m 19s\n","336:\tlearn: 0.5731269\ttotal: 4m 14s\tremaining: 8m 19s\n","337:\tlearn: 0.5730247\ttotal: 4m 15s\tremaining: 8m 19s\n","338:\tlearn: 0.5729390\ttotal: 4m 16s\tremaining: 8m 19s\n","339:\tlearn: 0.5728444\ttotal: 4m 16s\tremaining: 8m 18s\n","340:\tlearn: 0.5727410\ttotal: 4m 17s\tremaining: 8m 17s\n","341:\tlearn: 0.5726450\ttotal: 4m 18s\tremaining: 8m 16s\n","342:\tlearn: 0.5725320\ttotal: 4m 18s\tremaining: 8m 15s\n","343:\tlearn: 0.5724101\ttotal: 4m 19s\tremaining: 8m 14s\n","344:\tlearn: 0.5722891\ttotal: 4m 20s\tremaining: 8m 13s\n","345:\tlearn: 0.5721801\ttotal: 4m 20s\tremaining: 8m 13s\n","346:\tlearn: 0.5720424\ttotal: 4m 21s\tremaining: 8m 12s\n","347:\tlearn: 0.5719226\ttotal: 4m 22s\tremaining: 8m 11s\n","348:\tlearn: 0.5718107\ttotal: 4m 22s\tremaining: 8m 10s\n","349:\tlearn: 0.5717135\ttotal: 4m 23s\tremaining: 8m 9s\n","350:\tlearn: 0.5716065\ttotal: 4m 24s\tremaining: 8m 8s\n","351:\tlearn: 0.5714931\ttotal: 4m 24s\tremaining: 8m 7s\n","352:\tlearn: 0.5713903\ttotal: 4m 25s\tremaining: 8m 6s\n","353:\tlearn: 0.5712898\ttotal: 4m 26s\tremaining: 8m 5s\n","354:\tlearn: 0.5711621\ttotal: 4m 27s\tremaining: 8m 6s\n","355:\tlearn: 0.5710527\ttotal: 4m 28s\tremaining: 8m 5s\n","356:\tlearn: 0.5709370\ttotal: 4m 29s\tremaining: 8m 5s\n","357:\tlearn: 0.5708270\ttotal: 4m 30s\tremaining: 8m 4s\n","358:\tlearn: 0.5707074\ttotal: 4m 30s\tremaining: 8m 3s\n","359:\tlearn: 0.5705909\ttotal: 4m 31s\tremaining: 8m 2s\n","360:\tlearn: 0.5704929\ttotal: 4m 32s\tremaining: 8m 2s\n","361:\tlearn: 0.5703753\ttotal: 4m 33s\tremaining: 8m 1s\n","362:\tlearn: 0.5702575\ttotal: 4m 33s\tremaining: 8m\n","363:\tlearn: 0.5701543\ttotal: 4m 34s\tremaining: 7m 59s\n","364:\tlearn: 0.5700376\ttotal: 4m 35s\tremaining: 7m 58s\n","365:\tlearn: 0.5699464\ttotal: 4m 35s\tremaining: 7m 57s\n","366:\tlearn: 0.5698347\ttotal: 4m 36s\tremaining: 7m 56s\n","367:\tlearn: 0.5697218\ttotal: 4m 37s\tremaining: 7m 55s\n","368:\tlearn: 0.5696180\ttotal: 4m 37s\tremaining: 7m 54s\n","369:\tlearn: 0.5695116\ttotal: 4m 38s\tremaining: 7m 54s\n","370:\tlearn: 0.5694027\ttotal: 4m 38s\tremaining: 7m 52s\n","371:\tlearn: 0.5692903\ttotal: 4m 39s\tremaining: 7m 52s\n","372:\tlearn: 0.5691691\ttotal: 4m 40s\tremaining: 7m 51s\n","373:\tlearn: 0.5690618\ttotal: 4m 41s\tremaining: 7m 51s\n","374:\tlearn: 0.5689769\ttotal: 4m 42s\tremaining: 7m 51s\n","375:\tlearn: 0.5688459\ttotal: 4m 43s\tremaining: 7m 51s\n","376:\tlearn: 0.5687527\ttotal: 4m 44s\tremaining: 7m 50s\n","377:\tlearn: 0.5686467\ttotal: 4m 45s\tremaining: 7m 49s\n","378:\tlearn: 0.5685337\ttotal: 4m 45s\tremaining: 7m 48s\n","379:\tlearn: 0.5684204\ttotal: 4m 46s\tremaining: 7m 47s\n","380:\tlearn: 0.5683073\ttotal: 4m 46s\tremaining: 7m 46s\n","381:\tlearn: 0.5681870\ttotal: 4m 47s\tremaining: 7m 45s\n","382:\tlearn: 0.5680654\ttotal: 4m 48s\tremaining: 7m 44s\n","383:\tlearn: 0.5679660\ttotal: 4m 48s\tremaining: 7m 43s\n","384:\tlearn: 0.5678695\ttotal: 4m 49s\tremaining: 7m 42s\n","385:\tlearn: 0.5677556\ttotal: 4m 50s\tremaining: 7m 41s\n","386:\tlearn: 0.5676440\ttotal: 4m 50s\tremaining: 7m 40s\n","387:\tlearn: 0.5675256\ttotal: 4m 51s\tremaining: 7m 39s\n","388:\tlearn: 0.5673910\ttotal: 4m 52s\tremaining: 7m 39s\n","389:\tlearn: 0.5672932\ttotal: 4m 52s\tremaining: 7m 38s\n","390:\tlearn: 0.5671910\ttotal: 4m 53s\tremaining: 7m 37s\n","391:\tlearn: 0.5670681\ttotal: 4m 54s\tremaining: 7m 37s\n","392:\tlearn: 0.5669585\ttotal: 4m 55s\tremaining: 7m 37s\n","393:\tlearn: 0.5668483\ttotal: 4m 57s\tremaining: 7m 36s\n","394:\tlearn: 0.5667576\ttotal: 4m 57s\tremaining: 7m 36s\n","395:\tlearn: 0.5666542\ttotal: 4m 58s\tremaining: 7m 35s\n","396:\tlearn: 0.5665305\ttotal: 4m 59s\tremaining: 7m 34s\n","397:\tlearn: 0.5664246\ttotal: 4m 59s\tremaining: 7m 33s\n","398:\tlearn: 0.5663316\ttotal: 5m\tremaining: 7m 32s\n","399:\tlearn: 0.5662514\ttotal: 5m 1s\tremaining: 7m 31s\n","400:\tlearn: 0.5661469\ttotal: 5m 1s\tremaining: 7m 30s\n","401:\tlearn: 0.5660508\ttotal: 5m 2s\tremaining: 7m 29s\n","402:\tlearn: 0.5659375\ttotal: 5m 2s\tremaining: 7m 28s\n","403:\tlearn: 0.5658430\ttotal: 5m 3s\tremaining: 7m 27s\n","404:\tlearn: 0.5657569\ttotal: 5m 4s\tremaining: 7m 26s\n","405:\tlearn: 0.5656450\ttotal: 5m 4s\tremaining: 7m 26s\n","406:\tlearn: 0.5655554\ttotal: 5m 5s\tremaining: 7m 25s\n","407:\tlearn: 0.5654588\ttotal: 5m 6s\tremaining: 7m 24s\n","408:\tlearn: 0.5653550\ttotal: 5m 6s\tremaining: 7m 23s\n","409:\tlearn: 0.5652521\ttotal: 5m 7s\tremaining: 7m 22s\n","410:\tlearn: 0.5651470\ttotal: 5m 9s\tremaining: 7m 22s\n","411:\tlearn: 0.5650329\ttotal: 5m 10s\tremaining: 7m 22s\n","412:\tlearn: 0.5649315\ttotal: 5m 11s\tremaining: 7m 22s\n","413:\tlearn: 0.5648315\ttotal: 5m 11s\tremaining: 7m 21s\n","414:\tlearn: 0.5647302\ttotal: 5m 12s\tremaining: 7m 20s\n","415:\tlearn: 0.5646246\ttotal: 5m 13s\tremaining: 7m 19s\n","416:\tlearn: 0.5645180\ttotal: 5m 13s\tremaining: 7m 18s\n","417:\tlearn: 0.5644094\ttotal: 5m 14s\tremaining: 7m 17s\n","418:\tlearn: 0.5643064\ttotal: 5m 15s\tremaining: 7m 16s\n","419:\tlearn: 0.5641919\ttotal: 5m 15s\tremaining: 7m 16s\n","420:\tlearn: 0.5640961\ttotal: 5m 16s\tremaining: 7m 15s\n","421:\tlearn: 0.5640027\ttotal: 5m 16s\tremaining: 7m 14s\n","422:\tlearn: 0.5638882\ttotal: 5m 17s\tremaining: 7m 13s\n","423:\tlearn: 0.5637823\ttotal: 5m 18s\tremaining: 7m 12s\n","424:\tlearn: 0.5636846\ttotal: 5m 18s\tremaining: 7m 11s\n","425:\tlearn: 0.5635716\ttotal: 5m 19s\tremaining: 7m 10s\n","426:\tlearn: 0.5634676\ttotal: 5m 20s\tremaining: 7m 9s\n","427:\tlearn: 0.5633929\ttotal: 5m 20s\tremaining: 7m 8s\n","428:\tlearn: 0.5632965\ttotal: 5m 21s\tremaining: 7m 7s\n","429:\tlearn: 0.5631601\ttotal: 5m 22s\tremaining: 7m 7s\n","430:\tlearn: 0.5630515\ttotal: 5m 23s\tremaining: 7m 7s\n","431:\tlearn: 0.5629637\ttotal: 5m 24s\tremaining: 7m 7s\n","432:\tlearn: 0.5628615\ttotal: 5m 25s\tremaining: 7m 6s\n","433:\tlearn: 0.5627459\ttotal: 5m 26s\tremaining: 7m 5s\n","434:\tlearn: 0.5626512\ttotal: 5m 26s\tremaining: 7m 4s\n","435:\tlearn: 0.5625515\ttotal: 5m 27s\tremaining: 7m 3s\n","436:\tlearn: 0.5624573\ttotal: 5m 28s\tremaining: 7m 3s\n","437:\tlearn: 0.5623648\ttotal: 5m 28s\tremaining: 7m 2s\n","438:\tlearn: 0.5622543\ttotal: 5m 29s\tremaining: 7m 1s\n","439:\tlearn: 0.5621646\ttotal: 5m 30s\tremaining: 7m\n","440:\tlearn: 0.5620681\ttotal: 5m 30s\tremaining: 6m 59s\n","441:\tlearn: 0.5619630\ttotal: 5m 31s\tremaining: 6m 58s\n","442:\tlearn: 0.5618723\ttotal: 5m 32s\tremaining: 6m 57s\n","443:\tlearn: 0.5617843\ttotal: 5m 32s\tremaining: 6m 56s\n","444:\tlearn: 0.5616797\ttotal: 5m 33s\tremaining: 6m 55s\n","445:\tlearn: 0.5615660\ttotal: 5m 33s\tremaining: 6m 54s\n","446:\tlearn: 0.5614462\ttotal: 5m 34s\tremaining: 6m 54s\n","447:\tlearn: 0.5613545\ttotal: 5m 35s\tremaining: 6m 53s\n","448:\tlearn: 0.5612337\ttotal: 5m 36s\tremaining: 6m 53s\n","449:\tlearn: 0.5611268\ttotal: 5m 37s\tremaining: 6m 52s\n","450:\tlearn: 0.5610258\ttotal: 5m 38s\tremaining: 6m 52s\n","451:\tlearn: 0.5609424\ttotal: 5m 39s\tremaining: 6m 51s\n","452:\tlearn: 0.5608334\ttotal: 5m 40s\tremaining: 6m 50s\n","453:\tlearn: 0.5607219\ttotal: 5m 40s\tremaining: 6m 49s\n","454:\tlearn: 0.5606177\ttotal: 5m 41s\tremaining: 6m 49s\n","455:\tlearn: 0.5605413\ttotal: 5m 42s\tremaining: 6m 48s\n","456:\tlearn: 0.5604267\ttotal: 5m 42s\tremaining: 6m 47s\n","457:\tlearn: 0.5603171\ttotal: 5m 43s\tremaining: 6m 46s\n","458:\tlearn: 0.5602167\ttotal: 5m 44s\tremaining: 6m 45s\n","459:\tlearn: 0.5601154\ttotal: 5m 44s\tremaining: 6m 44s\n","460:\tlearn: 0.5600268\ttotal: 5m 45s\tremaining: 6m 43s\n","461:\tlearn: 0.5599266\ttotal: 5m 46s\tremaining: 6m 42s\n","462:\tlearn: 0.5598253\ttotal: 5m 46s\tremaining: 6m 42s\n","463:\tlearn: 0.5597198\ttotal: 5m 47s\tremaining: 6m 41s\n","464:\tlearn: 0.5596233\ttotal: 5m 47s\tremaining: 6m 40s\n","465:\tlearn: 0.5595354\ttotal: 5m 48s\tremaining: 6m 39s\n","466:\tlearn: 0.5594346\ttotal: 5m 49s\tremaining: 6m 39s\n","467:\tlearn: 0.5593127\ttotal: 5m 50s\tremaining: 6m 38s\n","468:\tlearn: 0.5592236\ttotal: 5m 51s\tremaining: 6m 38s\n","469:\tlearn: 0.5591147\ttotal: 5m 52s\tremaining: 6m 37s\n","470:\tlearn: 0.5589913\ttotal: 5m 53s\tremaining: 6m 36s\n","471:\tlearn: 0.5588940\ttotal: 5m 54s\tremaining: 6m 36s\n","472:\tlearn: 0.5587916\ttotal: 5m 54s\tremaining: 6m 35s\n","473:\tlearn: 0.5587003\ttotal: 5m 55s\tremaining: 6m 34s\n","474:\tlearn: 0.5586187\ttotal: 5m 56s\tremaining: 6m 33s\n","475:\tlearn: 0.5585094\ttotal: 5m 56s\tremaining: 6m 32s\n","476:\tlearn: 0.5584067\ttotal: 5m 57s\tremaining: 6m 31s\n","477:\tlearn: 0.5583172\ttotal: 5m 57s\tremaining: 6m 30s\n","478:\tlearn: 0.5582156\ttotal: 5m 58s\tremaining: 6m 30s\n","479:\tlearn: 0.5581097\ttotal: 5m 59s\tremaining: 6m 29s\n","480:\tlearn: 0.5580088\ttotal: 5m 59s\tremaining: 6m 28s\n","481:\tlearn: 0.5578962\ttotal: 6m\tremaining: 6m 27s\n","482:\tlearn: 0.5578015\ttotal: 6m 1s\tremaining: 6m 26s\n","483:\tlearn: 0.5577024\ttotal: 6m 1s\tremaining: 6m 25s\n","484:\tlearn: 0.5576085\ttotal: 6m 2s\tremaining: 6m 24s\n","485:\tlearn: 0.5575084\ttotal: 6m 3s\tremaining: 6m 24s\n","486:\tlearn: 0.5574126\ttotal: 6m 4s\tremaining: 6m 23s\n","487:\tlearn: 0.5573252\ttotal: 6m 5s\tremaining: 6m 23s\n","488:\tlearn: 0.5572301\ttotal: 6m 6s\tremaining: 6m 23s\n","489:\tlearn: 0.5571364\ttotal: 6m 7s\tremaining: 6m 22s\n","490:\tlearn: 0.5570417\ttotal: 6m 7s\tremaining: 6m 21s\n","491:\tlearn: 0.5569496\ttotal: 6m 8s\tremaining: 6m 20s\n","492:\tlearn: 0.5568599\ttotal: 6m 9s\tremaining: 6m 19s\n","493:\tlearn: 0.5567559\ttotal: 6m 9s\tremaining: 6m 18s\n","494:\tlearn: 0.5566518\ttotal: 6m 10s\tremaining: 6m 18s\n","495:\tlearn: 0.5565256\ttotal: 6m 11s\tremaining: 6m 17s\n","496:\tlearn: 0.5564253\ttotal: 6m 12s\tremaining: 6m 16s\n","497:\tlearn: 0.5563162\ttotal: 6m 12s\tremaining: 6m 15s\n","498:\tlearn: 0.5562125\ttotal: 6m 13s\tremaining: 6m 14s\n","499:\tlearn: 0.5561130\ttotal: 6m 14s\tremaining: 6m 14s\n","500:\tlearn: 0.5560007\ttotal: 6m 14s\tremaining: 6m 13s\n","501:\tlearn: 0.5558941\ttotal: 6m 15s\tremaining: 6m 12s\n","502:\tlearn: 0.5558076\ttotal: 6m 16s\tremaining: 6m 11s\n","503:\tlearn: 0.5556865\ttotal: 6m 17s\tremaining: 6m 11s\n","504:\tlearn: 0.5555797\ttotal: 6m 18s\tremaining: 6m 11s\n","505:\tlearn: 0.5554803\ttotal: 6m 19s\tremaining: 6m 10s\n","506:\tlearn: 0.5553873\ttotal: 6m 20s\tremaining: 6m 9s\n","507:\tlearn: 0.5552719\ttotal: 6m 21s\tremaining: 6m 9s\n","508:\tlearn: 0.5551663\ttotal: 6m 21s\tremaining: 6m 8s\n","509:\tlearn: 0.5550904\ttotal: 6m 22s\tremaining: 6m 7s\n","510:\tlearn: 0.5549859\ttotal: 6m 23s\tremaining: 6m 6s\n","511:\tlearn: 0.5548864\ttotal: 6m 23s\tremaining: 6m 5s\n","512:\tlearn: 0.5547896\ttotal: 6m 24s\tremaining: 6m 5s\n","513:\tlearn: 0.5546813\ttotal: 6m 25s\tremaining: 6m 4s\n","514:\tlearn: 0.5545752\ttotal: 6m 25s\tremaining: 6m 3s\n","515:\tlearn: 0.5544700\ttotal: 6m 26s\tremaining: 6m 2s\n","516:\tlearn: 0.5543632\ttotal: 6m 27s\tremaining: 6m 1s\n","517:\tlearn: 0.5542669\ttotal: 6m 27s\tremaining: 6m\n","518:\tlearn: 0.5541680\ttotal: 6m 28s\tremaining: 6m\n","519:\tlearn: 0.5540755\ttotal: 6m 29s\tremaining: 5m 59s\n","520:\tlearn: 0.5539726\ttotal: 6m 29s\tremaining: 5m 58s\n","521:\tlearn: 0.5538858\ttotal: 6m 30s\tremaining: 5m 57s\n","522:\tlearn: 0.5538032\ttotal: 6m 31s\tremaining: 5m 57s\n","523:\tlearn: 0.5537110\ttotal: 6m 32s\tremaining: 5m 56s\n","524:\tlearn: 0.5536120\ttotal: 6m 33s\tremaining: 5m 56s\n","525:\tlearn: 0.5535256\ttotal: 6m 34s\tremaining: 5m 55s\n","526:\tlearn: 0.5534321\ttotal: 6m 35s\tremaining: 5m 54s\n","527:\tlearn: 0.5533341\ttotal: 6m 35s\tremaining: 5m 53s\n","528:\tlearn: 0.5532333\ttotal: 6m 36s\tremaining: 5m 52s\n","529:\tlearn: 0.5531330\ttotal: 6m 37s\tremaining: 5m 52s\n","530:\tlearn: 0.5530218\ttotal: 6m 37s\tremaining: 5m 51s\n","531:\tlearn: 0.5529236\ttotal: 6m 38s\tremaining: 5m 50s\n","532:\tlearn: 0.5528182\ttotal: 6m 39s\tremaining: 5m 49s\n","533:\tlearn: 0.5527385\ttotal: 6m 39s\tremaining: 5m 48s\n","534:\tlearn: 0.5526222\ttotal: 6m 40s\tremaining: 5m 48s\n","535:\tlearn: 0.5525309\ttotal: 6m 41s\tremaining: 5m 47s\n","536:\tlearn: 0.5524169\ttotal: 6m 41s\tremaining: 5m 46s\n","537:\tlearn: 0.5523159\ttotal: 6m 42s\tremaining: 5m 45s\n","538:\tlearn: 0.5522169\ttotal: 6m 43s\tremaining: 5m 44s\n","539:\tlearn: 0.5521131\ttotal: 6m 43s\tremaining: 5m 43s\n","540:\tlearn: 0.5520273\ttotal: 6m 44s\tremaining: 5m 43s\n","541:\tlearn: 0.5519221\ttotal: 6m 45s\tremaining: 5m 43s\n","542:\tlearn: 0.5518251\ttotal: 6m 47s\tremaining: 5m 42s\n","543:\tlearn: 0.5517605\ttotal: 6m 47s\tremaining: 5m 41s\n","544:\tlearn: 0.5516751\ttotal: 6m 48s\tremaining: 5m 41s\n","545:\tlearn: 0.5515769\ttotal: 6m 49s\tremaining: 5m 40s\n","546:\tlearn: 0.5514892\ttotal: 6m 49s\tremaining: 5m 39s\n","547:\tlearn: 0.5514054\ttotal: 6m 50s\tremaining: 5m 38s\n","548:\tlearn: 0.5512998\ttotal: 6m 51s\tremaining: 5m 37s\n","549:\tlearn: 0.5511980\ttotal: 6m 51s\tremaining: 5m 36s\n","550:\tlearn: 0.5510926\ttotal: 6m 52s\tremaining: 5m 35s\n","551:\tlearn: 0.5509882\ttotal: 6m 52s\tremaining: 5m 35s\n","552:\tlearn: 0.5508818\ttotal: 6m 53s\tremaining: 5m 34s\n","553:\tlearn: 0.5507856\ttotal: 6m 54s\tremaining: 5m 33s\n","554:\tlearn: 0.5506833\ttotal: 6m 54s\tremaining: 5m 32s\n","555:\tlearn: 0.5505745\ttotal: 6m 55s\tremaining: 5m 31s\n","556:\tlearn: 0.5504731\ttotal: 6m 56s\tremaining: 5m 30s\n","557:\tlearn: 0.5503770\ttotal: 6m 56s\tremaining: 5m 30s\n","558:\tlearn: 0.5503033\ttotal: 6m 57s\tremaining: 5m 29s\n","559:\tlearn: 0.5502136\ttotal: 6m 58s\tremaining: 5m 28s\n","560:\tlearn: 0.5501314\ttotal: 6m 59s\tremaining: 5m 28s\n","561:\tlearn: 0.5500644\ttotal: 7m\tremaining: 5m 27s\n","562:\tlearn: 0.5499830\ttotal: 7m 1s\tremaining: 5m 27s\n","563:\tlearn: 0.5498916\ttotal: 7m 2s\tremaining: 5m 26s\n","564:\tlearn: 0.5498006\ttotal: 7m 2s\tremaining: 5m 25s\n","565:\tlearn: 0.5497076\ttotal: 7m 3s\tremaining: 5m 24s\n","566:\tlearn: 0.5496000\ttotal: 7m 4s\tremaining: 5m 23s\n","567:\tlearn: 0.5495051\ttotal: 7m 4s\tremaining: 5m 23s\n","568:\tlearn: 0.5493981\ttotal: 7m 5s\tremaining: 5m 22s\n","569:\tlearn: 0.5492814\ttotal: 7m 6s\tremaining: 5m 21s\n","570:\tlearn: 0.5491891\ttotal: 7m 6s\tremaining: 5m 20s\n","571:\tlearn: 0.5490972\ttotal: 7m 7s\tremaining: 5m 19s\n","572:\tlearn: 0.5490129\ttotal: 7m 8s\tremaining: 5m 18s\n","573:\tlearn: 0.5489375\ttotal: 7m 8s\tremaining: 5m 18s\n","574:\tlearn: 0.5488394\ttotal: 7m 9s\tremaining: 5m 17s\n","575:\tlearn: 0.5487490\ttotal: 7m 9s\tremaining: 5m 16s\n","576:\tlearn: 0.5486709\ttotal: 7m 10s\tremaining: 5m 15s\n","577:\tlearn: 0.5485712\ttotal: 7m 11s\tremaining: 5m 14s\n","578:\tlearn: 0.5484768\ttotal: 7m 12s\tremaining: 5m 14s\n","579:\tlearn: 0.5483956\ttotal: 7m 13s\tremaining: 5m 13s\n","580:\tlearn: 0.5483107\ttotal: 7m 14s\tremaining: 5m 13s\n","581:\tlearn: 0.5482226\ttotal: 7m 15s\tremaining: 5m 12s\n","582:\tlearn: 0.5481405\ttotal: 7m 16s\tremaining: 5m 12s\n","583:\tlearn: 0.5480574\ttotal: 7m 17s\tremaining: 5m 11s\n","584:\tlearn: 0.5479752\ttotal: 7m 17s\tremaining: 5m 10s\n","585:\tlearn: 0.5478790\ttotal: 7m 18s\tremaining: 5m 9s\n","586:\tlearn: 0.5477901\ttotal: 7m 18s\tremaining: 5m 8s\n","587:\tlearn: 0.5476949\ttotal: 7m 19s\tremaining: 5m 8s\n","588:\tlearn: 0.5475991\ttotal: 7m 20s\tremaining: 5m 7s\n","589:\tlearn: 0.5475054\ttotal: 7m 20s\tremaining: 5m 6s\n","590:\tlearn: 0.5474061\ttotal: 7m 21s\tremaining: 5m 5s\n","591:\tlearn: 0.5472998\ttotal: 7m 22s\tremaining: 5m 4s\n","592:\tlearn: 0.5472178\ttotal: 7m 22s\tremaining: 5m 3s\n","593:\tlearn: 0.5471356\ttotal: 7m 23s\tremaining: 5m 3s\n","594:\tlearn: 0.5470469\ttotal: 7m 24s\tremaining: 5m 2s\n","595:\tlearn: 0.5469455\ttotal: 7m 24s\tremaining: 5m 1s\n","596:\tlearn: 0.5468475\ttotal: 7m 25s\tremaining: 5m\n","597:\tlearn: 0.5467600\ttotal: 7m 26s\tremaining: 5m\n","598:\tlearn: 0.5466888\ttotal: 7m 28s\tremaining: 5m\n","599:\tlearn: 0.5465841\ttotal: 7m 29s\tremaining: 4m 59s\n","600:\tlearn: 0.5464810\ttotal: 7m 29s\tremaining: 4m 58s\n","601:\tlearn: 0.5463966\ttotal: 7m 30s\tremaining: 4m 57s\n","602:\tlearn: 0.5462960\ttotal: 7m 31s\tremaining: 4m 57s\n","603:\tlearn: 0.5461906\ttotal: 7m 31s\tremaining: 4m 56s\n","604:\tlearn: 0.5461025\ttotal: 7m 32s\tremaining: 4m 55s\n","605:\tlearn: 0.5460139\ttotal: 7m 33s\tremaining: 4m 54s\n","606:\tlearn: 0.5459129\ttotal: 7m 33s\tremaining: 4m 53s\n","607:\tlearn: 0.5458118\ttotal: 7m 34s\tremaining: 4m 52s\n","608:\tlearn: 0.5457460\ttotal: 7m 34s\tremaining: 4m 52s\n","609:\tlearn: 0.5456569\ttotal: 7m 35s\tremaining: 4m 51s\n","610:\tlearn: 0.5455816\ttotal: 7m 36s\tremaining: 4m 50s\n","611:\tlearn: 0.5455035\ttotal: 7m 37s\tremaining: 4m 49s\n","612:\tlearn: 0.5454004\ttotal: 7m 37s\tremaining: 4m 48s\n","613:\tlearn: 0.5452925\ttotal: 7m 38s\tremaining: 4m 48s\n","614:\tlearn: 0.5452048\ttotal: 7m 39s\tremaining: 4m 47s\n","615:\tlearn: 0.5451129\ttotal: 7m 40s\tremaining: 4m 46s\n","616:\tlearn: 0.5450194\ttotal: 7m 41s\tremaining: 4m 46s\n","617:\tlearn: 0.5449326\ttotal: 7m 42s\tremaining: 4m 45s\n","618:\tlearn: 0.5448328\ttotal: 7m 43s\tremaining: 4m 45s\n","619:\tlearn: 0.5447364\ttotal: 7m 44s\tremaining: 4m 44s\n","620:\tlearn: 0.5446280\ttotal: 7m 44s\tremaining: 4m 43s\n","621:\tlearn: 0.5445294\ttotal: 7m 45s\tremaining: 4m 42s\n","622:\tlearn: 0.5444394\ttotal: 7m 46s\tremaining: 4m 42s\n","623:\tlearn: 0.5443301\ttotal: 7m 46s\tremaining: 4m 41s\n","624:\tlearn: 0.5442465\ttotal: 7m 47s\tremaining: 4m 40s\n","625:\tlearn: 0.5441482\ttotal: 7m 48s\tremaining: 4m 39s\n","626:\tlearn: 0.5440562\ttotal: 7m 48s\tremaining: 4m 38s\n","627:\tlearn: 0.5439679\ttotal: 7m 49s\tremaining: 4m 38s\n","628:\tlearn: 0.5438877\ttotal: 7m 50s\tremaining: 4m 37s\n","629:\tlearn: 0.5437850\ttotal: 7m 50s\tremaining: 4m 36s\n","630:\tlearn: 0.5436966\ttotal: 7m 51s\tremaining: 4m 35s\n","631:\tlearn: 0.5436190\ttotal: 7m 52s\tremaining: 4m 34s\n","632:\tlearn: 0.5435309\ttotal: 7m 52s\tremaining: 4m 34s\n","633:\tlearn: 0.5434181\ttotal: 7m 53s\tremaining: 4m 33s\n","634:\tlearn: 0.5433282\ttotal: 7m 54s\tremaining: 4m 32s\n","635:\tlearn: 0.5432343\ttotal: 7m 55s\tremaining: 4m 32s\n","636:\tlearn: 0.5431321\ttotal: 7m 56s\tremaining: 4m 31s\n","637:\tlearn: 0.5430448\ttotal: 7m 57s\tremaining: 4m 30s\n","638:\tlearn: 0.5429529\ttotal: 7m 58s\tremaining: 4m 30s\n","639:\tlearn: 0.5428575\ttotal: 7m 58s\tremaining: 4m 29s\n","640:\tlearn: 0.5427607\ttotal: 7m 59s\tremaining: 4m 28s\n","641:\tlearn: 0.5426714\ttotal: 8m\tremaining: 4m 27s\n","642:\tlearn: 0.5425756\ttotal: 8m\tremaining: 4m 26s\n","643:\tlearn: 0.5424863\ttotal: 8m 1s\tremaining: 4m 26s\n","644:\tlearn: 0.5423821\ttotal: 8m 2s\tremaining: 4m 25s\n","645:\tlearn: 0.5423003\ttotal: 8m 2s\tremaining: 4m 24s\n","646:\tlearn: 0.5422076\ttotal: 8m 3s\tremaining: 4m 23s\n","647:\tlearn: 0.5421087\ttotal: 8m 4s\tremaining: 4m 23s\n","648:\tlearn: 0.5420414\ttotal: 8m 4s\tremaining: 4m 22s\n","649:\tlearn: 0.5419507\ttotal: 8m 5s\tremaining: 4m 21s\n","650:\tlearn: 0.5418704\ttotal: 8m 6s\tremaining: 4m 20s\n","651:\tlearn: 0.5417755\ttotal: 8m 6s\tremaining: 4m 19s\n","652:\tlearn: 0.5416838\ttotal: 8m 8s\tremaining: 4m 19s\n","653:\tlearn: 0.5415831\ttotal: 8m 9s\tremaining: 4m 18s\n","654:\tlearn: 0.5414905\ttotal: 8m 10s\tremaining: 4m 18s\n","655:\tlearn: 0.5413927\ttotal: 8m 11s\tremaining: 4m 17s\n","656:\tlearn: 0.5413000\ttotal: 8m 12s\tremaining: 4m 16s\n","657:\tlearn: 0.5412014\ttotal: 8m 12s\tremaining: 4m 16s\n","658:\tlearn: 0.5411277\ttotal: 8m 13s\tremaining: 4m 15s\n","659:\tlearn: 0.5410281\ttotal: 8m 13s\tremaining: 4m 14s\n","660:\tlearn: 0.5409382\ttotal: 8m 14s\tremaining: 4m 13s\n","661:\tlearn: 0.5408415\ttotal: 8m 15s\tremaining: 4m 12s\n","662:\tlearn: 0.5407484\ttotal: 8m 15s\tremaining: 4m 12s\n","663:\tlearn: 0.5406537\ttotal: 8m 16s\tremaining: 4m 11s\n","664:\tlearn: 0.5405638\ttotal: 8m 17s\tremaining: 4m 10s\n","665:\tlearn: 0.5404822\ttotal: 8m 18s\tremaining: 4m 9s\n","666:\tlearn: 0.5404045\ttotal: 8m 18s\tremaining: 4m 8s\n","667:\tlearn: 0.5403115\ttotal: 8m 19s\tremaining: 4m 8s\n","668:\tlearn: 0.5402171\ttotal: 8m 19s\tremaining: 4m 7s\n","669:\tlearn: 0.5401222\ttotal: 8m 20s\tremaining: 4m 6s\n","670:\tlearn: 0.5400140\ttotal: 8m 21s\tremaining: 4m 6s\n","671:\tlearn: 0.5399188\ttotal: 8m 22s\tremaining: 4m 5s\n","672:\tlearn: 0.5398500\ttotal: 8m 23s\tremaining: 4m 4s\n","673:\tlearn: 0.5397609\ttotal: 8m 24s\tremaining: 4m 4s\n","674:\tlearn: 0.5396755\ttotal: 8m 25s\tremaining: 4m 3s\n","675:\tlearn: 0.5395837\ttotal: 8m 25s\tremaining: 4m 2s\n","676:\tlearn: 0.5395016\ttotal: 8m 26s\tremaining: 4m 1s\n","677:\tlearn: 0.5394119\ttotal: 8m 27s\tremaining: 4m\n","678:\tlearn: 0.5393136\ttotal: 8m 27s\tremaining: 4m\n","679:\tlearn: 0.5392056\ttotal: 8m 28s\tremaining: 3m 59s\n","680:\tlearn: 0.5391178\ttotal: 8m 29s\tremaining: 3m 58s\n","681:\tlearn: 0.5390409\ttotal: 8m 29s\tremaining: 3m 57s\n","682:\tlearn: 0.5389622\ttotal: 8m 30s\tremaining: 3m 56s\n","683:\tlearn: 0.5388919\ttotal: 8m 31s\tremaining: 3m 56s\n","684:\tlearn: 0.5387976\ttotal: 8m 31s\tremaining: 3m 55s\n","685:\tlearn: 0.5387030\ttotal: 8m 32s\tremaining: 3m 54s\n","686:\tlearn: 0.5386037\ttotal: 8m 32s\tremaining: 3m 53s\n","687:\tlearn: 0.5385023\ttotal: 8m 33s\tremaining: 3m 52s\n","688:\tlearn: 0.5384120\ttotal: 8m 34s\tremaining: 3m 52s\n","689:\tlearn: 0.5383186\ttotal: 8m 35s\tremaining: 3m 51s\n","690:\tlearn: 0.5382313\ttotal: 8m 36s\tremaining: 3m 51s\n","691:\tlearn: 0.5381428\ttotal: 8m 37s\tremaining: 3m 50s\n","692:\tlearn: 0.5380679\ttotal: 8m 38s\tremaining: 3m 49s\n","693:\tlearn: 0.5379884\ttotal: 8m 39s\tremaining: 3m 48s\n","694:\tlearn: 0.5379034\ttotal: 8m 39s\tremaining: 3m 48s\n","695:\tlearn: 0.5378227\ttotal: 8m 40s\tremaining: 3m 47s\n","696:\tlearn: 0.5377287\ttotal: 8m 41s\tremaining: 3m 46s\n","697:\tlearn: 0.5376230\ttotal: 8m 41s\tremaining: 3m 45s\n","698:\tlearn: 0.5375356\ttotal: 8m 42s\tremaining: 3m 45s\n","699:\tlearn: 0.5374420\ttotal: 8m 43s\tremaining: 3m 44s\n","700:\tlearn: 0.5373517\ttotal: 8m 43s\tremaining: 3m 43s\n","701:\tlearn: 0.5372666\ttotal: 8m 44s\tremaining: 3m 42s\n","702:\tlearn: 0.5371663\ttotal: 8m 45s\tremaining: 3m 41s\n","703:\tlearn: 0.5370734\ttotal: 8m 45s\tremaining: 3m 41s\n","704:\tlearn: 0.5369680\ttotal: 8m 46s\tremaining: 3m 40s\n","705:\tlearn: 0.5368923\ttotal: 8m 47s\tremaining: 3m 39s\n","706:\tlearn: 0.5368027\ttotal: 8m 47s\tremaining: 3m 38s\n","707:\tlearn: 0.5367067\ttotal: 8m 48s\tremaining: 3m 38s\n","708:\tlearn: 0.5366029\ttotal: 8m 49s\tremaining: 3m 37s\n","709:\tlearn: 0.5365031\ttotal: 8m 51s\tremaining: 3m 36s\n","710:\tlearn: 0.5364316\ttotal: 8m 51s\tremaining: 3m 36s\n","711:\tlearn: 0.5363406\ttotal: 8m 52s\tremaining: 3m 35s\n","712:\tlearn: 0.5362463\ttotal: 8m 53s\tremaining: 3m 34s\n","713:\tlearn: 0.5361498\ttotal: 8m 53s\tremaining: 3m 33s\n","714:\tlearn: 0.5360731\ttotal: 8m 54s\tremaining: 3m 33s\n","715:\tlearn: 0.5359854\ttotal: 8m 55s\tremaining: 3m 32s\n","716:\tlearn: 0.5358905\ttotal: 8m 56s\tremaining: 3m 31s\n","717:\tlearn: 0.5357898\ttotal: 8m 56s\tremaining: 3m 30s\n","718:\tlearn: 0.5356885\ttotal: 8m 57s\tremaining: 3m 30s\n","719:\tlearn: 0.5355866\ttotal: 8m 58s\tremaining: 3m 29s\n","720:\tlearn: 0.5354970\ttotal: 8m 58s\tremaining: 3m 28s\n","721:\tlearn: 0.5354118\ttotal: 8m 59s\tremaining: 3m 27s\n","722:\tlearn: 0.5353371\ttotal: 9m\tremaining: 3m 26s\n","723:\tlearn: 0.5352689\ttotal: 9m\tremaining: 3m 26s\n","724:\tlearn: 0.5351677\ttotal: 9m 1s\tremaining: 3m 25s\n","725:\tlearn: 0.5350819\ttotal: 9m 2s\tremaining: 3m 24s\n","726:\tlearn: 0.5350062\ttotal: 9m 3s\tremaining: 3m 24s\n","727:\tlearn: 0.5349026\ttotal: 9m 4s\tremaining: 3m 23s\n","728:\tlearn: 0.5348245\ttotal: 9m 5s\tremaining: 3m 22s\n","729:\tlearn: 0.5347450\ttotal: 9m 6s\tremaining: 3m 22s\n","730:\tlearn: 0.5346676\ttotal: 9m 7s\tremaining: 3m 21s\n","731:\tlearn: 0.5345776\ttotal: 9m 7s\tremaining: 3m 20s\n","732:\tlearn: 0.5344836\ttotal: 9m 8s\tremaining: 3m 19s\n","733:\tlearn: 0.5344081\ttotal: 9m 8s\tremaining: 3m 18s\n","734:\tlearn: 0.5343105\ttotal: 9m 9s\tremaining: 3m 18s\n","735:\tlearn: 0.5342288\ttotal: 9m 10s\tremaining: 3m 17s\n","736:\tlearn: 0.5341378\ttotal: 9m 10s\tremaining: 3m 16s\n","737:\tlearn: 0.5340482\ttotal: 9m 11s\tremaining: 3m 15s\n","738:\tlearn: 0.5339534\ttotal: 9m 12s\tremaining: 3m 14s\n","739:\tlearn: 0.5338755\ttotal: 9m 12s\tremaining: 3m 14s\n","740:\tlearn: 0.5337823\ttotal: 9m 13s\tremaining: 3m 13s\n","741:\tlearn: 0.5336957\ttotal: 9m 14s\tremaining: 3m 12s\n","742:\tlearn: 0.5335898\ttotal: 9m 14s\tremaining: 3m 11s\n","743:\tlearn: 0.5335087\ttotal: 9m 15s\tremaining: 3m 11s\n","744:\tlearn: 0.5334377\ttotal: 9m 16s\tremaining: 3m 10s\n","745:\tlearn: 0.5333631\ttotal: 9m 17s\tremaining: 3m 9s\n","746:\tlearn: 0.5332984\ttotal: 9m 19s\tremaining: 3m 9s\n","747:\tlearn: 0.5332062\ttotal: 9m 19s\tremaining: 3m 8s\n","748:\tlearn: 0.5331137\ttotal: 9m 20s\tremaining: 3m 7s\n","749:\tlearn: 0.5330249\ttotal: 9m 21s\tremaining: 3m 7s\n","750:\tlearn: 0.5329342\ttotal: 9m 21s\tremaining: 3m 6s\n","751:\tlearn: 0.5328454\ttotal: 9m 22s\tremaining: 3m 5s\n","752:\tlearn: 0.5327654\ttotal: 9m 23s\tremaining: 3m 4s\n","753:\tlearn: 0.5326811\ttotal: 9m 23s\tremaining: 3m 4s\n","754:\tlearn: 0.5326071\ttotal: 9m 24s\tremaining: 3m 3s\n","755:\tlearn: 0.5325108\ttotal: 9m 25s\tremaining: 3m 2s\n","756:\tlearn: 0.5324305\ttotal: 9m 25s\tremaining: 3m 1s\n","757:\tlearn: 0.5323396\ttotal: 9m 26s\tremaining: 3m\n","758:\tlearn: 0.5322460\ttotal: 9m 27s\tremaining: 3m\n","759:\tlearn: 0.5321780\ttotal: 9m 27s\tremaining: 2m 59s\n","760:\tlearn: 0.5320883\ttotal: 9m 28s\tremaining: 2m 58s\n","761:\tlearn: 0.5320125\ttotal: 9m 29s\tremaining: 2m 57s\n","762:\tlearn: 0.5319253\ttotal: 9m 30s\tremaining: 2m 57s\n","763:\tlearn: 0.5318366\ttotal: 9m 31s\tremaining: 2m 56s\n","764:\tlearn: 0.5317430\ttotal: 9m 32s\tremaining: 2m 55s\n","765:\tlearn: 0.5316486\ttotal: 9m 33s\tremaining: 2m 55s\n","766:\tlearn: 0.5315716\ttotal: 9m 34s\tremaining: 2m 54s\n","767:\tlearn: 0.5314965\ttotal: 9m 34s\tremaining: 2m 53s\n","768:\tlearn: 0.5314132\ttotal: 9m 35s\tremaining: 2m 52s\n","769:\tlearn: 0.5313296\ttotal: 9m 36s\tremaining: 2m 52s\n","770:\tlearn: 0.5312430\ttotal: 9m 36s\tremaining: 2m 51s\n","771:\tlearn: 0.5311577\ttotal: 9m 37s\tremaining: 2m 50s\n","772:\tlearn: 0.5310752\ttotal: 9m 37s\tremaining: 2m 49s\n","773:\tlearn: 0.5309867\ttotal: 9m 38s\tremaining: 2m 48s\n","774:\tlearn: 0.5309008\ttotal: 9m 39s\tremaining: 2m 48s\n","775:\tlearn: 0.5308175\ttotal: 9m 39s\tremaining: 2m 47s\n","776:\tlearn: 0.5307237\ttotal: 9m 40s\tremaining: 2m 46s\n","777:\tlearn: 0.5306420\ttotal: 9m 41s\tremaining: 2m 45s\n","778:\tlearn: 0.5305323\ttotal: 9m 41s\tremaining: 2m 45s\n","779:\tlearn: 0.5304478\ttotal: 9m 42s\tremaining: 2m 44s\n","780:\tlearn: 0.5303530\ttotal: 9m 43s\tremaining: 2m 43s\n","781:\tlearn: 0.5302595\ttotal: 9m 44s\tremaining: 2m 42s\n","782:\tlearn: 0.5301810\ttotal: 9m 45s\tremaining: 2m 42s\n","783:\tlearn: 0.5300975\ttotal: 9m 46s\tremaining: 2m 41s\n","784:\tlearn: 0.5300040\ttotal: 9m 47s\tremaining: 2m 40s\n","785:\tlearn: 0.5299204\ttotal: 9m 48s\tremaining: 2m 40s\n","786:\tlearn: 0.5298348\ttotal: 9m 49s\tremaining: 2m 39s\n","787:\tlearn: 0.5297581\ttotal: 9m 49s\tremaining: 2m 38s\n","788:\tlearn: 0.5296704\ttotal: 9m 50s\tremaining: 2m 37s\n","789:\tlearn: 0.5295922\ttotal: 9m 50s\tremaining: 2m 37s\n","790:\tlearn: 0.5294953\ttotal: 9m 51s\tremaining: 2m 36s\n","791:\tlearn: 0.5294063\ttotal: 9m 52s\tremaining: 2m 35s\n","792:\tlearn: 0.5293154\ttotal: 9m 52s\tremaining: 2m 34s\n","793:\tlearn: 0.5292217\ttotal: 9m 53s\tremaining: 2m 34s\n","794:\tlearn: 0.5291501\ttotal: 9m 54s\tremaining: 2m 33s\n","795:\tlearn: 0.5290632\ttotal: 9m 54s\tremaining: 2m 32s\n","796:\tlearn: 0.5289865\ttotal: 9m 55s\tremaining: 2m 31s\n","797:\tlearn: 0.5289065\ttotal: 9m 56s\tremaining: 2m 30s\n","798:\tlearn: 0.5288006\ttotal: 9m 56s\tremaining: 2m 30s\n","799:\tlearn: 0.5287146\ttotal: 9m 57s\tremaining: 2m 29s\n","800:\tlearn: 0.5286502\ttotal: 9m 58s\tremaining: 2m 28s\n","801:\tlearn: 0.5285584\ttotal: 10m\tremaining: 2m 28s\n","802:\tlearn: 0.5284639\ttotal: 10m 1s\tremaining: 2m 27s\n","803:\tlearn: 0.5283728\ttotal: 10m 1s\tremaining: 2m 26s\n","804:\tlearn: 0.5282979\ttotal: 10m 2s\tremaining: 2m 25s\n","805:\tlearn: 0.5282075\ttotal: 10m 3s\tremaining: 2m 25s\n","806:\tlearn: 0.5281180\ttotal: 10m 3s\tremaining: 2m 24s\n","807:\tlearn: 0.5280251\ttotal: 10m 4s\tremaining: 2m 23s\n","808:\tlearn: 0.5279416\ttotal: 10m 4s\tremaining: 2m 22s\n","809:\tlearn: 0.5278609\ttotal: 10m 5s\tremaining: 2m 22s\n","810:\tlearn: 0.5277871\ttotal: 10m 6s\tremaining: 2m 21s\n","811:\tlearn: 0.5277033\ttotal: 10m 6s\tremaining: 2m 20s\n","812:\tlearn: 0.5276215\ttotal: 10m 7s\tremaining: 2m 19s\n","813:\tlearn: 0.5275485\ttotal: 10m 7s\tremaining: 2m 18s\n","814:\tlearn: 0.5274675\ttotal: 10m 8s\tremaining: 2m 18s\n","815:\tlearn: 0.5273668\ttotal: 10m 9s\tremaining: 2m 17s\n","816:\tlearn: 0.5272611\ttotal: 10m 10s\tremaining: 2m 16s\n","817:\tlearn: 0.5271852\ttotal: 10m 10s\tremaining: 2m 15s\n","818:\tlearn: 0.5271140\ttotal: 10m 11s\tremaining: 2m 15s\n","819:\tlearn: 0.5270219\ttotal: 10m 12s\tremaining: 2m 14s\n","820:\tlearn: 0.5269252\ttotal: 10m 13s\tremaining: 2m 13s\n","821:\tlearn: 0.5268422\ttotal: 10m 15s\tremaining: 2m 13s\n","822:\tlearn: 0.5267542\ttotal: 10m 15s\tremaining: 2m 12s\n","823:\tlearn: 0.5266848\ttotal: 10m 16s\tremaining: 2m 11s\n","824:\tlearn: 0.5265822\ttotal: 10m 17s\tremaining: 2m 10s\n","825:\tlearn: 0.5264996\ttotal: 10m 17s\tremaining: 2m 10s\n","826:\tlearn: 0.5264269\ttotal: 10m 18s\tremaining: 2m 9s\n","827:\tlearn: 0.5263472\ttotal: 10m 18s\tremaining: 2m 8s\n","828:\tlearn: 0.5262651\ttotal: 10m 19s\tremaining: 2m 7s\n","829:\tlearn: 0.5261803\ttotal: 10m 20s\tremaining: 2m 7s\n","830:\tlearn: 0.5260835\ttotal: 10m 20s\tremaining: 2m 6s\n","831:\tlearn: 0.5259977\ttotal: 10m 21s\tremaining: 2m 5s\n","832:\tlearn: 0.5259104\ttotal: 10m 22s\tremaining: 2m 4s\n","833:\tlearn: 0.5258312\ttotal: 10m 22s\tremaining: 2m 3s\n","834:\tlearn: 0.5257528\ttotal: 10m 23s\tremaining: 2m 3s\n","835:\tlearn: 0.5256707\ttotal: 10m 24s\tremaining: 2m 2s\n","836:\tlearn: 0.5255559\ttotal: 10m 24s\tremaining: 2m 1s\n","837:\tlearn: 0.5254901\ttotal: 10m 25s\tremaining: 2m\n","838:\tlearn: 0.5254148\ttotal: 10m 26s\tremaining: 2m\n","839:\tlearn: 0.5253572\ttotal: 10m 28s\tremaining: 1m 59s\n","840:\tlearn: 0.5252668\ttotal: 10m 29s\tremaining: 1m 58s\n","841:\tlearn: 0.5251882\ttotal: 10m 29s\tremaining: 1m 58s\n","842:\tlearn: 0.5251051\ttotal: 10m 30s\tremaining: 1m 57s\n","843:\tlearn: 0.5250202\ttotal: 10m 30s\tremaining: 1m 56s\n","844:\tlearn: 0.5249209\ttotal: 10m 31s\tremaining: 1m 55s\n","845:\tlearn: 0.5248372\ttotal: 10m 32s\tremaining: 1m 55s\n","846:\tlearn: 0.5247312\ttotal: 10m 33s\tremaining: 1m 54s\n","847:\tlearn: 0.5246589\ttotal: 10m 33s\tremaining: 1m 53s\n","848:\tlearn: 0.5245636\ttotal: 10m 34s\tremaining: 1m 52s\n","849:\tlearn: 0.5244830\ttotal: 10m 35s\tremaining: 1m 52s\n","850:\tlearn: 0.5243984\ttotal: 10m 35s\tremaining: 1m 51s\n","851:\tlearn: 0.5243012\ttotal: 10m 36s\tremaining: 1m 50s\n","852:\tlearn: 0.5242199\ttotal: 10m 37s\tremaining: 1m 49s\n","853:\tlearn: 0.5241394\ttotal: 10m 37s\tremaining: 1m 49s\n","854:\tlearn: 0.5240437\ttotal: 10m 38s\tremaining: 1m 48s\n","855:\tlearn: 0.5239526\ttotal: 10m 39s\tremaining: 1m 47s\n","856:\tlearn: 0.5238724\ttotal: 10m 40s\tremaining: 1m 46s\n","857:\tlearn: 0.5237901\ttotal: 10m 41s\tremaining: 1m 46s\n","858:\tlearn: 0.5237015\ttotal: 10m 43s\tremaining: 1m 45s\n","859:\tlearn: 0.5236085\ttotal: 10m 43s\tremaining: 1m 44s\n","860:\tlearn: 0.5235319\ttotal: 10m 44s\tremaining: 1m 44s\n","861:\tlearn: 0.5234425\ttotal: 10m 44s\tremaining: 1m 43s\n","862:\tlearn: 0.5233737\ttotal: 10m 45s\tremaining: 1m 42s\n","863:\tlearn: 0.5232901\ttotal: 10m 46s\tremaining: 1m 41s\n","864:\tlearn: 0.5232142\ttotal: 10m 46s\tremaining: 1m 40s\n","865:\tlearn: 0.5231357\ttotal: 10m 47s\tremaining: 1m 40s\n","866:\tlearn: 0.5230484\ttotal: 10m 48s\tremaining: 1m 39s\n","867:\tlearn: 0.5229720\ttotal: 10m 49s\tremaining: 1m 38s\n","868:\tlearn: 0.5228973\ttotal: 10m 49s\tremaining: 1m 37s\n","869:\tlearn: 0.5228124\ttotal: 10m 50s\tremaining: 1m 37s\n","870:\tlearn: 0.5227363\ttotal: 10m 51s\tremaining: 1m 36s\n","871:\tlearn: 0.5226519\ttotal: 10m 51s\tremaining: 1m 35s\n","872:\tlearn: 0.5225640\ttotal: 10m 52s\tremaining: 1m 34s\n","873:\tlearn: 0.5224843\ttotal: 10m 53s\tremaining: 1m 34s\n","874:\tlearn: 0.5224025\ttotal: 10m 54s\tremaining: 1m 33s\n","875:\tlearn: 0.5223362\ttotal: 10m 55s\tremaining: 1m 32s\n","876:\tlearn: 0.5222659\ttotal: 10m 56s\tremaining: 1m 32s\n","877:\tlearn: 0.5221946\ttotal: 10m 56s\tremaining: 1m 31s\n","878:\tlearn: 0.5220964\ttotal: 10m 57s\tremaining: 1m 30s\n","879:\tlearn: 0.5220219\ttotal: 10m 58s\tremaining: 1m 29s\n","880:\tlearn: 0.5219140\ttotal: 10m 59s\tremaining: 1m 29s\n","881:\tlearn: 0.5218404\ttotal: 10m 59s\tremaining: 1m 28s\n","882:\tlearn: 0.5217717\ttotal: 11m\tremaining: 1m 27s\n","883:\tlearn: 0.5216811\ttotal: 11m 1s\tremaining: 1m 26s\n","884:\tlearn: 0.5215948\ttotal: 11m 1s\tremaining: 1m 25s\n","885:\tlearn: 0.5214933\ttotal: 11m 2s\tremaining: 1m 25s\n","886:\tlearn: 0.5214249\ttotal: 11m 3s\tremaining: 1m 24s\n","887:\tlearn: 0.5213434\ttotal: 11m 3s\tremaining: 1m 23s\n","888:\tlearn: 0.5212523\ttotal: 11m 4s\tremaining: 1m 22s\n","889:\tlearn: 0.5211537\ttotal: 11m 5s\tremaining: 1m 22s\n","890:\tlearn: 0.5210802\ttotal: 11m 5s\tremaining: 1m 21s\n","891:\tlearn: 0.5210106\ttotal: 11m 6s\tremaining: 1m 20s\n","892:\tlearn: 0.5209278\ttotal: 11m 7s\tremaining: 1m 20s\n","893:\tlearn: 0.5208504\ttotal: 11m 8s\tremaining: 1m 19s\n","894:\tlearn: 0.5207559\ttotal: 11m 10s\tremaining: 1m 18s\n","895:\tlearn: 0.5206823\ttotal: 11m 10s\tremaining: 1m 17s\n","896:\tlearn: 0.5205995\ttotal: 11m 11s\tremaining: 1m 17s\n","897:\tlearn: 0.5205068\ttotal: 11m 11s\tremaining: 1m 16s\n","898:\tlearn: 0.5204289\ttotal: 11m 12s\tremaining: 1m 15s\n","899:\tlearn: 0.5203559\ttotal: 11m 13s\tremaining: 1m 14s\n","900:\tlearn: 0.5202862\ttotal: 11m 13s\tremaining: 1m 14s\n","901:\tlearn: 0.5202098\ttotal: 11m 14s\tremaining: 1m 13s\n","902:\tlearn: 0.5201358\ttotal: 11m 15s\tremaining: 1m 12s\n","903:\tlearn: 0.5200630\ttotal: 11m 15s\tremaining: 1m 11s\n","904:\tlearn: 0.5199986\ttotal: 11m 16s\tremaining: 1m 11s\n","905:\tlearn: 0.5199255\ttotal: 11m 17s\tremaining: 1m 10s\n","906:\tlearn: 0.5198313\ttotal: 11m 17s\tremaining: 1m 9s\n","907:\tlearn: 0.5197477\ttotal: 11m 18s\tremaining: 1m 8s\n","908:\tlearn: 0.5196680\ttotal: 11m 19s\tremaining: 1m 7s\n","909:\tlearn: 0.5195788\ttotal: 11m 19s\tremaining: 1m 7s\n","910:\tlearn: 0.5195122\ttotal: 11m 20s\tremaining: 1m 6s\n","911:\tlearn: 0.5194292\ttotal: 11m 21s\tremaining: 1m 5s\n","912:\tlearn: 0.5193467\ttotal: 11m 23s\tremaining: 1m 5s\n","913:\tlearn: 0.5192507\ttotal: 11m 24s\tremaining: 1m 4s\n","914:\tlearn: 0.5191935\ttotal: 11m 24s\tremaining: 1m 3s\n","915:\tlearn: 0.5191136\ttotal: 11m 25s\tremaining: 1m 2s\n","916:\tlearn: 0.5190247\ttotal: 11m 25s\tremaining: 1m 2s\n","917:\tlearn: 0.5189445\ttotal: 11m 26s\tremaining: 1m 1s\n","918:\tlearn: 0.5188563\ttotal: 11m 27s\tremaining: 1m\n","919:\tlearn: 0.5187773\ttotal: 11m 27s\tremaining: 59.8s\n","920:\tlearn: 0.5186973\ttotal: 11m 28s\tremaining: 59.1s\n","921:\tlearn: 0.5186213\ttotal: 11m 29s\tremaining: 58.3s\n","922:\tlearn: 0.5185347\ttotal: 11m 29s\tremaining: 57.5s\n","923:\tlearn: 0.5184560\ttotal: 11m 30s\tremaining: 56.8s\n","924:\tlearn: 0.5183644\ttotal: 11m 31s\tremaining: 56s\n","925:\tlearn: 0.5183052\ttotal: 11m 31s\tremaining: 55.3s\n","926:\tlearn: 0.5182345\ttotal: 11m 32s\tremaining: 54.5s\n","927:\tlearn: 0.5181498\ttotal: 11m 33s\tremaining: 53.8s\n","928:\tlearn: 0.5180712\ttotal: 11m 33s\tremaining: 53s\n","929:\tlearn: 0.5180007\ttotal: 11m 35s\tremaining: 52.3s\n","930:\tlearn: 0.5179325\ttotal: 11m 36s\tremaining: 51.6s\n","931:\tlearn: 0.5178331\ttotal: 11m 37s\tremaining: 50.9s\n","932:\tlearn: 0.5177565\ttotal: 11m 38s\tremaining: 50.1s\n","933:\tlearn: 0.5176702\ttotal: 11m 38s\tremaining: 49.4s\n","934:\tlearn: 0.5175896\ttotal: 11m 39s\tremaining: 48.6s\n","935:\tlearn: 0.5175178\ttotal: 11m 40s\tremaining: 47.9s\n","936:\tlearn: 0.5174547\ttotal: 11m 40s\tremaining: 47.1s\n","937:\tlearn: 0.5173866\ttotal: 11m 41s\tremaining: 46.4s\n","938:\tlearn: 0.5173136\ttotal: 11m 42s\tremaining: 45.6s\n","939:\tlearn: 0.5172383\ttotal: 11m 42s\tremaining: 44.9s\n","940:\tlearn: 0.5171749\ttotal: 11m 43s\tremaining: 44.1s\n","941:\tlearn: 0.5170934\ttotal: 11m 44s\tremaining: 43.4s\n","942:\tlearn: 0.5170304\ttotal: 11m 44s\tremaining: 42.6s\n","943:\tlearn: 0.5169343\ttotal: 11m 45s\tremaining: 41.9s\n","944:\tlearn: 0.5168730\ttotal: 11m 46s\tremaining: 41.1s\n","945:\tlearn: 0.5167897\ttotal: 11m 46s\tremaining: 40.4s\n","946:\tlearn: 0.5166961\ttotal: 11m 47s\tremaining: 39.6s\n","947:\tlearn: 0.5166240\ttotal: 11m 48s\tremaining: 38.9s\n","948:\tlearn: 0.5165457\ttotal: 11m 50s\tremaining: 38.2s\n","949:\tlearn: 0.5164784\ttotal: 11m 51s\tremaining: 37.4s\n","950:\tlearn: 0.5164009\ttotal: 11m 52s\tremaining: 36.7s\n","951:\tlearn: 0.5163088\ttotal: 11m 52s\tremaining: 35.9s\n","952:\tlearn: 0.5162248\ttotal: 11m 53s\tremaining: 35.2s\n","953:\tlearn: 0.5161417\ttotal: 11m 54s\tremaining: 34.4s\n","954:\tlearn: 0.5160599\ttotal: 11m 54s\tremaining: 33.7s\n","955:\tlearn: 0.5159953\ttotal: 11m 55s\tremaining: 32.9s\n","956:\tlearn: 0.5159224\ttotal: 11m 55s\tremaining: 32.2s\n","957:\tlearn: 0.5158500\ttotal: 11m 56s\tremaining: 31.4s\n","958:\tlearn: 0.5157769\ttotal: 11m 57s\tremaining: 30.7s\n","959:\tlearn: 0.5157025\ttotal: 11m 57s\tremaining: 29.9s\n","960:\tlearn: 0.5156152\ttotal: 11m 58s\tremaining: 29.2s\n","961:\tlearn: 0.5155523\ttotal: 11m 59s\tremaining: 28.4s\n","962:\tlearn: 0.5154811\ttotal: 11m 59s\tremaining: 27.7s\n","963:\tlearn: 0.5153685\ttotal: 12m\tremaining: 26.9s\n","964:\tlearn: 0.5152983\ttotal: 12m 1s\tremaining: 26.2s\n","965:\tlearn: 0.5152378\ttotal: 12m 1s\tremaining: 25.4s\n","966:\tlearn: 0.5151542\ttotal: 12m 2s\tremaining: 24.7s\n","967:\tlearn: 0.5150680\ttotal: 12m 4s\tremaining: 23.9s\n","968:\tlearn: 0.5149957\ttotal: 12m 5s\tremaining: 23.2s\n","969:\tlearn: 0.5149171\ttotal: 12m 6s\tremaining: 22.5s\n","970:\tlearn: 0.5148328\ttotal: 12m 6s\tremaining: 21.7s\n","971:\tlearn: 0.5147642\ttotal: 12m 7s\tremaining: 21s\n","972:\tlearn: 0.5146611\ttotal: 12m 8s\tremaining: 20.2s\n","973:\tlearn: 0.5145796\ttotal: 12m 8s\tremaining: 19.5s\n","974:\tlearn: 0.5145072\ttotal: 12m 9s\tremaining: 18.7s\n","975:\tlearn: 0.5144266\ttotal: 12m 10s\tremaining: 18s\n","976:\tlearn: 0.5143701\ttotal: 12m 10s\tremaining: 17.2s\n","977:\tlearn: 0.5142842\ttotal: 12m 11s\tremaining: 16.4s\n","978:\tlearn: 0.5142154\ttotal: 12m 12s\tremaining: 15.7s\n","979:\tlearn: 0.5141468\ttotal: 12m 12s\tremaining: 15s\n","980:\tlearn: 0.5140619\ttotal: 12m 13s\tremaining: 14.2s\n","981:\tlearn: 0.5139887\ttotal: 12m 14s\tremaining: 13.5s\n","982:\tlearn: 0.5139202\ttotal: 12m 14s\tremaining: 12.7s\n","983:\tlearn: 0.5138380\ttotal: 12m 15s\tremaining: 12s\n","984:\tlearn: 0.5137509\ttotal: 12m 16s\tremaining: 11.2s\n","985:\tlearn: 0.5136684\ttotal: 12m 17s\tremaining: 10.5s\n","986:\tlearn: 0.5135950\ttotal: 12m 18s\tremaining: 9.73s\n","987:\tlearn: 0.5135224\ttotal: 12m 19s\tremaining: 8.98s\n","988:\tlearn: 0.5134499\ttotal: 12m 20s\tremaining: 8.23s\n","989:\tlearn: 0.5133603\ttotal: 12m 21s\tremaining: 7.49s\n","990:\tlearn: 0.5132763\ttotal: 12m 21s\tremaining: 6.74s\n","991:\tlearn: 0.5131948\ttotal: 12m 22s\tremaining: 5.99s\n","992:\tlearn: 0.5131190\ttotal: 12m 23s\tremaining: 5.24s\n","993:\tlearn: 0.5130297\ttotal: 12m 23s\tremaining: 4.49s\n","994:\tlearn: 0.5129635\ttotal: 12m 24s\tremaining: 3.74s\n","995:\tlearn: 0.5128939\ttotal: 12m 25s\tremaining: 2.99s\n","996:\tlearn: 0.5128225\ttotal: 12m 25s\tremaining: 2.24s\n","997:\tlearn: 0.5127574\ttotal: 12m 26s\tremaining: 1.5s\n","998:\tlearn: 0.5126809\ttotal: 12m 27s\tremaining: 748ms\n","999:\tlearn: 0.5126071\ttotal: 12m 27s\tremaining: 0us\n","train: 0.7592408896954792\n","test: 0.6546236769448879\n","test conf matrix: \n"," [[628516 239498]\n"," [ 13269  18717]]\n"]}]},{"cell_type":"code","source":["def objective_lgbm(trial):\n","    max_depth = trial.suggest_int(\"max_depth\", 2, 15)\n","    learning_rate = trial.suggest_float(\"learning_rate\", 1e-5, 1, log=True)\n","    n_estimators = trial.suggest_int(\"n_estimators\", 10, 700)\n","\n","    score = cross_val_score(LGBMClassifier(max_depth=max_depth, learning_rate=learning_rate, n_estimators=n_estimators),\n","                            x_train_feat_sel, y_train, cv=3, scoring='roc_auc', n_jobs=-1).mean()\n","    return score\n","\n","\n","study_lgbm = optuna.create_study(direction=\"maximize\")\n","study_lgbm.optimize(objective_lgbm, n_trials=50)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SbsTB_Ix2zBV","executionInfo":{"status":"ok","timestamp":1707664229958,"user_tz":-240,"elapsed":17022183,"user":{"displayName":"Евгений Малов","userId":"06257165098392198337"}},"outputId":"98af68f3-7627-4f3c-8ced-db0441640375"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[I 2024-02-11 10:26:47,626] A new study created in memory with name: no-name-4f3fce99-0124-4813-86ba-cb74de625dd6\n","[I 2024-02-11 10:30:21,104] Trial 0 finished with value: 0.7173433665390375 and parameters: {'max_depth': 5, 'learning_rate': 0.04047951114746578, 'n_estimators': 230}. Best is trial 0 with value: 0.7173433665390375.\n","[I 2024-02-11 10:37:03,507] Trial 1 finished with value: 0.7046452041991218 and parameters: {'max_depth': 5, 'learning_rate': 0.2862559105055916, 'n_estimators': 567}. Best is trial 0 with value: 0.7173433665390375.\n","[I 2024-02-11 10:41:49,243] Trial 2 finished with value: 0.6602050169385131 and parameters: {'max_depth': 7, 'learning_rate': 2.809964106315185e-05, 'n_estimators': 261}. Best is trial 0 with value: 0.7173433665390375.\n","[I 2024-02-11 10:44:38,010] Trial 3 finished with value: 0.6403566502768295 and parameters: {'max_depth': 2, 'learning_rate': 0.001202914166804647, 'n_estimators': 319}. Best is trial 0 with value: 0.7173433665390375.\n","[I 2024-02-11 10:48:53,862] Trial 4 finished with value: 0.6890123695727097 and parameters: {'max_depth': 14, 'learning_rate': 0.5624670553143717, 'n_estimators': 617}. Best is trial 0 with value: 0.7173433665390375.\n","[I 2024-02-11 11:00:04,213] Trial 5 finished with value: 0.7080070825913064 and parameters: {'max_depth': 7, 'learning_rate': 0.005399864699449981, 'n_estimators': 615}. Best is trial 0 with value: 0.7173433665390375.\n","[I 2024-02-11 11:00:36,681] Trial 6 finished with value: 0.6865316693074549 and parameters: {'max_depth': 15, 'learning_rate': 0.1040963002196327, 'n_estimators': 10}. Best is trial 0 with value: 0.7173433665390375.\n","[I 2024-02-11 11:04:51,321] Trial 7 finished with value: 0.6790833107628113 and parameters: {'max_depth': 15, 'learning_rate': 0.7076832112597181, 'n_estimators': 630}. Best is trial 0 with value: 0.7173433665390375.\n","[I 2024-02-11 11:06:57,924] Trial 8 finished with value: 0.6236534637885204 and parameters: {'max_depth': 2, 'learning_rate': 0.00012664134332606686, 'n_estimators': 233}. Best is trial 0 with value: 0.7173433665390375.\n","[I 2024-02-11 11:12:05,895] Trial 9 finished with value: 0.6654405625217156 and parameters: {'max_depth': 8, 'learning_rate': 0.0001962815718492085, 'n_estimators': 277}. Best is trial 0 with value: 0.7173433665390375.\n","[I 2024-02-11 11:13:41,508] Trial 10 finished with value: 0.6962957520918555 and parameters: {'max_depth': 11, 'learning_rate': 0.025121747918485458, 'n_estimators': 68}. Best is trial 0 with value: 0.7173433665390375.\n","[I 2024-02-11 11:22:14,113] Trial 11 finished with value: 0.715209924720591 and parameters: {'max_depth': 6, 'learning_rate': 0.011900801232732556, 'n_estimators': 503}. Best is trial 0 with value: 0.7173433665390375.\n","[I 2024-02-11 11:29:01,648] Trial 12 finished with value: 0.715173251007287 and parameters: {'max_depth': 5, 'learning_rate': 0.015275595326726944, 'n_estimators': 454}. Best is trial 0 with value: 0.7173433665390375.\n","[I 2024-02-11 11:34:25,438] Trial 13 finished with value: 0.7227222804948935 and parameters: {'max_depth': 5, 'learning_rate': 0.06754653617684293, 'n_estimators': 420}. Best is trial 13 with value: 0.7227222804948935.\n","[I 2024-02-11 11:39:15,943] Trial 14 finished with value: 0.7219629818592633 and parameters: {'max_depth': 10, 'learning_rate': 0.06370244576744034, 'n_estimators': 407}. Best is trial 13 with value: 0.7227222804948935.\n","[I 2024-02-11 11:47:12,919] Trial 15 finished with value: 0.6811417453388219 and parameters: {'max_depth': 11, 'learning_rate': 0.0016218035899799106, 'n_estimators': 405}. Best is trial 13 with value: 0.7227222804948935.\n","[I 2024-02-11 11:51:14,266] Trial 16 finished with value: 0.7201278790135719 and parameters: {'max_depth': 10, 'learning_rate': 0.11217864583642795, 'n_estimators': 376}. Best is trial 13 with value: 0.7227222804948935.\n","[I 2024-02-11 11:53:28,751] Trial 17 finished with value: 0.7199018061104412 and parameters: {'max_depth': 9, 'learning_rate': 0.11190181172808386, 'n_estimators': 141}. Best is trial 13 with value: 0.7227222804948935.\n","[I 2024-02-11 12:02:35,427] Trial 18 finished with value: 0.6716445034634844 and parameters: {'max_depth': 13, 'learning_rate': 0.0005233109279615553, 'n_estimators': 476}. Best is trial 13 with value: 0.7227222804948935.\n","[I 2024-02-11 12:09:17,344] Trial 19 finished with value: 0.6944746716630545 and parameters: {'max_depth': 4, 'learning_rate': 0.004785003575341191, 'n_estimators': 525}. Best is trial 13 with value: 0.7227222804948935.\n","[I 2024-02-11 12:15:05,008] Trial 20 finished with value: 0.7002956932869323 and parameters: {'max_depth': 12, 'learning_rate': 0.23091412754145174, 'n_estimators': 685}. Best is trial 13 with value: 0.7227222804948935.\n","[I 2024-02-11 12:19:20,359] Trial 21 finished with value: 0.7210558404684595 and parameters: {'max_depth': 10, 'learning_rate': 0.08649816779572429, 'n_estimators': 376}. Best is trial 13 with value: 0.7227222804948935.\n","[I 2024-02-11 12:25:33,226] Trial 22 finished with value: 0.7218260130533679 and parameters: {'max_depth': 9, 'learning_rate': 0.03702759528741574, 'n_estimators': 421}. Best is trial 13 with value: 0.7227222804948935.\n","[I 2024-02-11 12:30:59,228] Trial 23 finished with value: 0.7221742305310167 and parameters: {'max_depth': 9, 'learning_rate': 0.054616418075821634, 'n_estimators': 430}. Best is trial 13 with value: 0.7227222804948935.\n","[I 2024-02-11 12:37:14,446] Trial 24 finished with value: 0.7079360952391275 and parameters: {'max_depth': 8, 'learning_rate': 0.01005236934259581, 'n_estimators': 324}. Best is trial 13 with value: 0.7227222804948935.\n","[I 2024-02-11 12:41:03,438] Trial 25 finished with value: 0.7213483325621537 and parameters: {'max_depth': 3, 'learning_rate': 0.2823621762994778, 'n_estimators': 438}. Best is trial 13 with value: 0.7227222804948935.\n","[I 2024-02-11 12:47:05,786] Trial 26 finished with value: 0.722517050798663 and parameters: {'max_depth': 7, 'learning_rate': 0.05659017303453137, 'n_estimators': 520}. Best is trial 13 with value: 0.7227222804948935.\n","[I 2024-02-11 12:55:13,102] Trial 27 finished with value: 0.7217397099447226 and parameters: {'max_depth': 7, 'learning_rate': 0.02595676527814225, 'n_estimators': 547}. Best is trial 13 with value: 0.7227222804948935.\n","[I 2024-02-11 12:59:20,891] Trial 28 finished with value: 0.6605784754696193 and parameters: {'max_depth': 6, 'learning_rate': 0.8507555733245443, 'n_estimators': 482}. Best is trial 13 with value: 0.7227222804948935.\n","[I 2024-02-11 13:01:31,328] Trial 29 finished with value: 0.7101983901150665 and parameters: {'max_depth': 4, 'learning_rate': 0.04413019749427319, 'n_estimators': 154}. Best is trial 13 with value: 0.7227222804948935.\n","[I 2024-02-11 13:07:53,754] Trial 30 finished with value: 0.6831404036016018 and parameters: {'max_depth': 6, 'learning_rate': 0.0022454464501913524, 'n_estimators': 338}. Best is trial 13 with value: 0.7227222804948935.\n","[I 2024-02-11 13:12:46,763] Trial 31 finished with value: 0.7218288400932823 and parameters: {'max_depth': 10, 'learning_rate': 0.06616263277248585, 'n_estimators': 402}. Best is trial 13 with value: 0.7227222804948935.\n","[I 2024-02-11 13:17:46,726] Trial 32 finished with value: 0.7077626498321004 and parameters: {'max_depth': 8, 'learning_rate': 0.22032931212274803, 'n_estimators': 568}. Best is trial 13 with value: 0.7227222804948935.\n","[I 2024-02-11 13:26:24,771] Trial 33 finished with value: 0.708416118437407 and parameters: {'max_depth': 9, 'learning_rate': 0.007436850741483919, 'n_estimators': 451}. Best is trial 13 with value: 0.7227222804948935.\n","[I 2024-02-11 13:31:42,773] Trial 34 finished with value: 0.7165649994772204 and parameters: {'max_depth': 7, 'learning_rate': 0.022085701523067054, 'n_estimators': 296}. Best is trial 13 with value: 0.7227222804948935.\n","[I 2024-02-11 13:36:31,050] Trial 35 finished with value: 0.7214401648331576 and parameters: {'max_depth': 11, 'learning_rate': 0.05659774440103681, 'n_estimators': 358}. Best is trial 13 with value: 0.7227222804948935.\n","[I 2024-02-11 13:41:11,475] Trial 36 finished with value: 0.7118194468171374 and parameters: {'max_depth': 12, 'learning_rate': 0.16985690122785185, 'n_estimators': 516}. Best is trial 13 with value: 0.7227222804948935.\n","[I 2024-02-11 13:46:46,733] Trial 37 finished with value: 0.681311287577773 and parameters: {'max_depth': 6, 'learning_rate': 0.44480037211453555, 'n_estimators': 600}. Best is trial 13 with value: 0.7227222804948935.\n","[I 2024-02-11 13:56:14,440] Trial 38 finished with value: 0.6618246550523635 and parameters: {'max_depth': 5, 'learning_rate': 1.6269525945195307e-05, 'n_estimators': 574}. Best is trial 13 with value: 0.7227222804948935.\n","[I 2024-02-11 14:03:00,695] Trial 39 finished with value: 0.7012967374710556 and parameters: {'max_depth': 4, 'learning_rate': 0.4412323008402239, 'n_estimators': 684}. Best is trial 13 with value: 0.7227222804948935.\n","[I 2024-02-11 14:11:58,251] Trial 40 finished with value: 0.6994373759580675 and parameters: {'max_depth': 7, 'learning_rate': 0.00413784693223566, 'n_estimators': 491}. Best is trial 13 with value: 0.7227222804948935.\n","[I 2024-02-11 14:16:19,378] Trial 41 finished with value: 0.7212308511604357 and parameters: {'max_depth': 9, 'learning_rate': 0.08778691604415921, 'n_estimators': 399}. Best is trial 13 with value: 0.7227222804948935.\n","[I 2024-02-11 14:21:16,243] Trial 42 finished with value: 0.7217122234629909 and parameters: {'max_depth': 10, 'learning_rate': 0.06250257892380018, 'n_estimators': 407}. Best is trial 13 with value: 0.7227222804948935.\n","[I 2024-02-11 14:27:53,749] Trial 43 finished with value: 0.72194949525641 and parameters: {'max_depth': 10, 'learning_rate': 0.03574280884575201, 'n_estimators': 455}. Best is trial 13 with value: 0.7227222804948935.\n","[I 2024-02-11 14:35:44,224] Trial 44 finished with value: 0.7193086638628134 and parameters: {'max_depth': 8, 'learning_rate': 0.019066956889574327, 'n_estimators': 451}. Best is trial 13 with value: 0.7227222804948935.\n","[I 2024-02-11 14:43:02,290] Trial 45 finished with value: 0.7222275432909852 and parameters: {'max_depth': 12, 'learning_rate': 0.03426882645827746, 'n_estimators': 539}. Best is trial 13 with value: 0.7227222804948935.\n","[I 2024-02-11 14:53:13,667] Trial 46 finished with value: 0.7117518239504514 and parameters: {'max_depth': 14, 'learning_rate': 0.007769235155342161, 'n_estimators': 542}. Best is trial 13 with value: 0.7227222804948935.\n","[I 2024-02-11 14:58:54,938] Trial 47 finished with value: 0.7182156132860129 and parameters: {'max_depth': 12, 'learning_rate': 0.11615878649838421, 'n_estimators': 622}. Best is trial 13 with value: 0.7227222804948935.\n","[I 2024-02-11 15:04:38,134] Trial 48 finished with value: 0.712320628209912 and parameters: {'max_depth': 13, 'learning_rate': 0.15964546631658352, 'n_estimators': 651}. Best is trial 13 with value: 0.7227222804948935.\n","[I 2024-02-11 15:10:29,182] Trial 49 finished with value: 0.6721248490315394 and parameters: {'max_depth': 11, 'learning_rate': 0.0008852510992007599, 'n_estimators': 299}. Best is trial 13 with value: 0.7227222804948935.\n"]}]},{"cell_type":"code","source":["study_lgbm.best_params"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lgpiGaqT2zFZ","executionInfo":{"status":"ok","timestamp":1707664242457,"user_tz":-240,"elapsed":329,"user":{"displayName":"Евгений Малов","userId":"06257165098392198337"}},"outputId":"0cda2224-b8f2-40a0-8192-4fc4c25d6fec"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'max_depth': 5, 'learning_rate': 0.06754653617684293, 'n_estimators': 420}"]},"metadata":{},"execution_count":11}]},{"cell_type":"markdown","source":["{'max_depth': 10, 'learning_rate': 0.035530338682115685, 'n_estimators': 614}. Best is trial 11 with value: 0.7229"],"metadata":{"id":"SONiS2HY3myL"}},{"cell_type":"code","source":["opt_model_lgbm = LGBMClassifier(**study_lgbm.best_params)\n","opt_model_lgbm.fit(x_train_feat_sel, y_train)\n","\n","pred_train = opt_model_lgbm.predict(x_train_feat_sel)\n","pred_test = opt_model_lgbm.predict(x_test_feat_sel)\n","\n","print(f'train: {roc_auc_score(y_train, pred_train)}')\n","print(f'test: {roc_auc_score(y_test, pred_test)}')\n","print(f'test conf matrix: \\n {confusion_matrix(y_test, pred_test)}')"],"metadata":{"id":"d-B2WmMP3Fib","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1707664506905,"user_tz":-240,"elapsed":250654,"user":{"displayName":"Евгений Малов","userId":"06257165098392198337"}},"outputId":"a8431f2a-d4e5-4ec9-c2e0-2622d884e2f7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 74456, number of negative: 2025544\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.813150 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 12750\n","[LightGBM] [Info] Number of data points in the train set: 2100000, number of used features: 50\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.035455 -> initscore=-3.303385\n","[LightGBM] [Info] Start training from score -3.303385\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","train: 0.5003477184436372\n","test: 0.5001476779756614\n","test conf matrix: \n"," [[867999     15]\n"," [ 31976     10]]\n"]}]},{"cell_type":"code","source":["# с балансировкой\n","opt_model_lgbm = LGBMClassifier(max_depth=5, learning_rate=0.06754653617684293, n_estimators=420, class_weight='balanced')\n","opt_model_lgbm.fit(x_train_feat_sel, y_train)\n","\n","pred_train = opt_model_lgbm.predict(x_train_feat_sel)\n","pred_test = opt_model_lgbm.predict(x_test_feat_sel)\n","\n","print(f'train: {roc_auc_score(y_train, pred_train)}')\n","print(f'test: {roc_auc_score(y_test, pred_test)}')\n","print(f'test conf matrix: \\n {confusion_matrix(y_test, pred_test)}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZiOZbZ3QZ0Su","executionInfo":{"status":"ok","timestamp":1708011698465,"user_tz":-240,"elapsed":321540,"user":{"displayName":"Евгений Малов","userId":"06257165098392198337"}},"outputId":"c5ac6ee9-118e-4cc4-a18e-f811781a07c1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 74456, number of negative: 2025544\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 1.328313 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 12750\n","[LightGBM] [Info] Number of data points in the train set: 2100000, number of used features: 50\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n","[LightGBM] [Info] Start training from score -0.000000\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","train: 0.6942078394547144\n","test: 0.6652948860074752\n","test conf matrix: \n"," [[585277 282737]\n"," [ 10993  20993]]\n"]}]},{"cell_type":"code","source":["opt_model_catb = CatBoostClassifier(max_depth = 7, learning_rate =  0.19107171151392033, n_estimators = 136, l2_leaf_reg = 4)\n","opt_model_catb.fit(x_train_feat_sel, y_train)\n","\n","pred_train = opt_model_catb.predict(x_train_feat_sel)\n","pred_test = opt_model_catb.predict(x_test_feat_sel)\n","\n","print(f'train: {roc_auc_score(y_train, pred_train)}')\n","print(f'test: {roc_auc_score(y_test, pred_test)}')\n","print(f'test conf matrix: \\n {confusion_matrix(y_test, pred_test)}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"78LRjJq8vMnd","executionInfo":{"status":"ok","timestamp":1707664791985,"user_tz":-240,"elapsed":133053,"user":{"displayName":"Евгений Малов","userId":"06257165098392198337"}},"outputId":"ac362b53-a581-477d-d435-a9c92ef85611"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0:\tlearn: 0.4478266\ttotal: 822ms\tremaining: 1m 50s\n","1:\tlearn: 0.3141861\ttotal: 1.34s\tremaining: 1m 29s\n","2:\tlearn: 0.2429194\ttotal: 1.91s\tremaining: 1m 24s\n","3:\tlearn: 0.2028646\ttotal: 2.51s\tremaining: 1m 22s\n","4:\tlearn: 0.1807790\ttotal: 3.05s\tremaining: 1m 19s\n","5:\tlearn: 0.1681337\ttotal: 3.56s\tremaining: 1m 17s\n","6:\tlearn: 0.1595936\ttotal: 4.24s\tremaining: 1m 18s\n","7:\tlearn: 0.1550436\ttotal: 4.81s\tremaining: 1m 17s\n","8:\tlearn: 0.1516302\ttotal: 5.38s\tremaining: 1m 15s\n","9:\tlearn: 0.1494762\ttotal: 5.86s\tremaining: 1m 13s\n","10:\tlearn: 0.1480799\ttotal: 6.38s\tremaining: 1m 12s\n","11:\tlearn: 0.1471039\ttotal: 6.93s\tremaining: 1m 11s\n","12:\tlearn: 0.1464747\ttotal: 7.49s\tremaining: 1m 10s\n","13:\tlearn: 0.1460053\ttotal: 8.26s\tremaining: 1m 11s\n","14:\tlearn: 0.1455668\ttotal: 8.91s\tremaining: 1m 11s\n","15:\tlearn: 0.1451941\ttotal: 9.69s\tremaining: 1m 12s\n","16:\tlearn: 0.1449197\ttotal: 10.5s\tremaining: 1m 13s\n","17:\tlearn: 0.1447011\ttotal: 11.6s\tremaining: 1m 16s\n","18:\tlearn: 0.1445055\ttotal: 12.6s\tremaining: 1m 17s\n","19:\tlearn: 0.1443355\ttotal: 13.8s\tremaining: 1m 20s\n","20:\tlearn: 0.1442182\ttotal: 14.3s\tremaining: 1m 18s\n","21:\tlearn: 0.1441031\ttotal: 14.8s\tremaining: 1m 16s\n","22:\tlearn: 0.1439754\ttotal: 15.3s\tremaining: 1m 15s\n","23:\tlearn: 0.1438521\ttotal: 15.9s\tremaining: 1m 13s\n","24:\tlearn: 0.1437430\ttotal: 16.5s\tremaining: 1m 13s\n","25:\tlearn: 0.1436545\ttotal: 17s\tremaining: 1m 11s\n","26:\tlearn: 0.1435631\ttotal: 17.5s\tremaining: 1m 10s\n","27:\tlearn: 0.1434876\ttotal: 18.1s\tremaining: 1m 9s\n","28:\tlearn: 0.1434141\ttotal: 18.7s\tremaining: 1m 9s\n","29:\tlearn: 0.1433598\ttotal: 19.2s\tremaining: 1m 7s\n","30:\tlearn: 0.1432789\ttotal: 19.8s\tremaining: 1m 7s\n","31:\tlearn: 0.1432013\ttotal: 20.4s\tremaining: 1m 6s\n","32:\tlearn: 0.1431258\ttotal: 21s\tremaining: 1m 5s\n","33:\tlearn: 0.1430732\ttotal: 21.5s\tremaining: 1m 4s\n","34:\tlearn: 0.1430174\ttotal: 22s\tremaining: 1m 3s\n","35:\tlearn: 0.1429626\ttotal: 22.5s\tremaining: 1m 2s\n","36:\tlearn: 0.1428963\ttotal: 23s\tremaining: 1m 1s\n","37:\tlearn: 0.1428312\ttotal: 23.6s\tremaining: 1m\n","38:\tlearn: 0.1427825\ttotal: 24.4s\tremaining: 1m\n","39:\tlearn: 0.1427246\ttotal: 25.3s\tremaining: 1m\n","40:\tlearn: 0.1426858\ttotal: 25.9s\tremaining: 59.9s\n","41:\tlearn: 0.1426343\ttotal: 26.4s\tremaining: 59.1s\n","42:\tlearn: 0.1425937\ttotal: 26.9s\tremaining: 58.2s\n","43:\tlearn: 0.1425528\ttotal: 27.4s\tremaining: 57.3s\n","44:\tlearn: 0.1425085\ttotal: 27.9s\tremaining: 56.5s\n","45:\tlearn: 0.1424735\ttotal: 28.5s\tremaining: 55.7s\n","46:\tlearn: 0.1424331\ttotal: 29s\tremaining: 55s\n","47:\tlearn: 0.1423915\ttotal: 29.6s\tremaining: 54.3s\n","48:\tlearn: 0.1423537\ttotal: 30.2s\tremaining: 53.5s\n","49:\tlearn: 0.1423146\ttotal: 30.6s\tremaining: 52.7s\n","50:\tlearn: 0.1422731\ttotal: 31.2s\tremaining: 51.9s\n","51:\tlearn: 0.1422306\ttotal: 31.7s\tremaining: 51.2s\n","52:\tlearn: 0.1422017\ttotal: 32.1s\tremaining: 50.3s\n","53:\tlearn: 0.1421594\ttotal: 32.7s\tremaining: 49.6s\n","54:\tlearn: 0.1421271\ttotal: 33.1s\tremaining: 48.8s\n","55:\tlearn: 0.1420977\ttotal: 33.7s\tremaining: 48.2s\n","56:\tlearn: 0.1420670\ttotal: 34.2s\tremaining: 47.4s\n","57:\tlearn: 0.1420279\ttotal: 34.7s\tremaining: 46.7s\n","58:\tlearn: 0.1419928\ttotal: 35.3s\tremaining: 46s\n","59:\tlearn: 0.1419669\ttotal: 35.9s\tremaining: 45.5s\n","60:\tlearn: 0.1419368\ttotal: 36.6s\tremaining: 45s\n","61:\tlearn: 0.1418975\ttotal: 37.3s\tremaining: 44.5s\n","62:\tlearn: 0.1418734\ttotal: 37.7s\tremaining: 43.7s\n","63:\tlearn: 0.1418295\ttotal: 38.3s\tremaining: 43.1s\n","64:\tlearn: 0.1418031\ttotal: 38.7s\tremaining: 42.3s\n","65:\tlearn: 0.1417574\ttotal: 39.2s\tremaining: 41.6s\n","66:\tlearn: 0.1417275\ttotal: 39.7s\tremaining: 40.9s\n","67:\tlearn: 0.1417010\ttotal: 40.3s\tremaining: 40.3s\n","68:\tlearn: 0.1416691\ttotal: 40.8s\tremaining: 39.6s\n","69:\tlearn: 0.1416397\ttotal: 41.2s\tremaining: 38.8s\n","70:\tlearn: 0.1416136\ttotal: 41.6s\tremaining: 38.1s\n","71:\tlearn: 0.1415790\ttotal: 42.1s\tremaining: 37.5s\n","72:\tlearn: 0.1415488\ttotal: 42.7s\tremaining: 36.9s\n","73:\tlearn: 0.1415142\ttotal: 43.3s\tremaining: 36.3s\n","74:\tlearn: 0.1414834\ttotal: 43.7s\tremaining: 35.6s\n","75:\tlearn: 0.1414330\ttotal: 44.4s\tremaining: 35s\n","76:\tlearn: 0.1414063\ttotal: 44.9s\tremaining: 34.4s\n","77:\tlearn: 0.1413836\ttotal: 45.3s\tremaining: 33.7s\n","78:\tlearn: 0.1413603\ttotal: 45.8s\tremaining: 33s\n","79:\tlearn: 0.1413254\ttotal: 46.3s\tremaining: 32.4s\n","80:\tlearn: 0.1412937\ttotal: 46.9s\tremaining: 31.8s\n","81:\tlearn: 0.1412636\ttotal: 47.4s\tremaining: 31.2s\n","82:\tlearn: 0.1412429\ttotal: 48.1s\tremaining: 30.7s\n","83:\tlearn: 0.1412139\ttotal: 48.8s\tremaining: 30.2s\n","84:\tlearn: 0.1411908\ttotal: 49.3s\tremaining: 29.6s\n","85:\tlearn: 0.1411639\ttotal: 49.8s\tremaining: 29s\n","86:\tlearn: 0.1411389\ttotal: 50.2s\tremaining: 28.3s\n","87:\tlearn: 0.1411170\ttotal: 50.6s\tremaining: 27.6s\n","88:\tlearn: 0.1410699\ttotal: 51.2s\tremaining: 27s\n","89:\tlearn: 0.1410400\ttotal: 51.8s\tremaining: 26.5s\n","90:\tlearn: 0.1410118\ttotal: 52.3s\tremaining: 25.9s\n","91:\tlearn: 0.1409744\ttotal: 52.9s\tremaining: 25.3s\n","92:\tlearn: 0.1409514\ttotal: 53.3s\tremaining: 24.6s\n","93:\tlearn: 0.1409173\ttotal: 53.9s\tremaining: 24.1s\n","94:\tlearn: 0.1408904\ttotal: 54.3s\tremaining: 23.4s\n","95:\tlearn: 0.1408622\ttotal: 54.7s\tremaining: 22.8s\n","96:\tlearn: 0.1408329\ttotal: 55.3s\tremaining: 22.2s\n","97:\tlearn: 0.1408072\ttotal: 55.8s\tremaining: 21.6s\n","98:\tlearn: 0.1407824\ttotal: 56.3s\tremaining: 21s\n","99:\tlearn: 0.1407563\ttotal: 57.2s\tremaining: 20.6s\n","100:\tlearn: 0.1407332\ttotal: 57.7s\tremaining: 20s\n","101:\tlearn: 0.1407128\ttotal: 58.2s\tremaining: 19.4s\n","102:\tlearn: 0.1406854\ttotal: 58.7s\tremaining: 18.8s\n","103:\tlearn: 0.1406508\ttotal: 59.5s\tremaining: 18.3s\n","104:\tlearn: 0.1406276\ttotal: 1m\tremaining: 17.8s\n","105:\tlearn: 0.1406102\ttotal: 1m\tremaining: 17.2s\n","106:\tlearn: 0.1405814\ttotal: 1m 1s\tremaining: 16.6s\n","107:\tlearn: 0.1405576\ttotal: 1m 1s\tremaining: 16.1s\n","108:\tlearn: 0.1405275\ttotal: 1m 2s\tremaining: 15.5s\n","109:\tlearn: 0.1405012\ttotal: 1m 2s\tremaining: 14.9s\n","110:\tlearn: 0.1404821\ttotal: 1m 3s\tremaining: 14.3s\n","111:\tlearn: 0.1404532\ttotal: 1m 3s\tremaining: 13.7s\n","112:\tlearn: 0.1404290\ttotal: 1m 4s\tremaining: 13.1s\n","113:\tlearn: 0.1404124\ttotal: 1m 4s\tremaining: 12.5s\n","114:\tlearn: 0.1403893\ttotal: 1m 5s\tremaining: 11.9s\n","115:\tlearn: 0.1403635\ttotal: 1m 5s\tremaining: 11.3s\n","116:\tlearn: 0.1403399\ttotal: 1m 6s\tremaining: 10.8s\n","117:\tlearn: 0.1403114\ttotal: 1m 6s\tremaining: 10.2s\n","118:\tlearn: 0.1402859\ttotal: 1m 7s\tremaining: 9.59s\n","119:\tlearn: 0.1402604\ttotal: 1m 7s\tremaining: 9s\n","120:\tlearn: 0.1402342\ttotal: 1m 8s\tremaining: 8.44s\n","121:\tlearn: 0.1402174\ttotal: 1m 8s\tremaining: 7.86s\n","122:\tlearn: 0.1401889\ttotal: 1m 8s\tremaining: 7.29s\n","123:\tlearn: 0.1401647\ttotal: 1m 9s\tremaining: 6.72s\n","124:\tlearn: 0.1401378\ttotal: 1m 9s\tremaining: 6.15s\n","125:\tlearn: 0.1401217\ttotal: 1m 10s\tremaining: 5.59s\n","126:\tlearn: 0.1400983\ttotal: 1m 10s\tremaining: 5.03s\n","127:\tlearn: 0.1400804\ttotal: 1m 11s\tremaining: 4.47s\n","128:\tlearn: 0.1400507\ttotal: 1m 12s\tremaining: 3.93s\n","129:\tlearn: 0.1400196\ttotal: 1m 12s\tremaining: 3.37s\n","130:\tlearn: 0.1399961\ttotal: 1m 13s\tremaining: 2.8s\n","131:\tlearn: 0.1399816\ttotal: 1m 13s\tremaining: 2.24s\n","132:\tlearn: 0.1399622\ttotal: 1m 14s\tremaining: 1.68s\n","133:\tlearn: 0.1399406\ttotal: 1m 14s\tremaining: 1.12s\n","134:\tlearn: 0.1399215\ttotal: 1m 15s\tremaining: 558ms\n","135:\tlearn: 0.1398954\ttotal: 1m 15s\tremaining: 0us\n","train: 0.5003074261904945\n","test: 0.500073550974043\n","test conf matrix: \n"," [[868006      8]\n"," [ 31981      5]]\n"]}]},{"cell_type":"code","source":["# с балансировкой\n","classes = np.unique(y_train)\n","weights = compute_class_weight(class_weight='balanced', classes=classes, y=y_train['flag'])\n","class_weights = dict(zip(classes, weights))\n","\n","opt_model_catb = CatBoostClassifier(max_depth = 7, learning_rate =  0.19107171151392033, n_estimators = 136, l2_leaf_reg = 4, class_weights=class_weights)\n","opt_model_catb.fit(x_train_feat_sel, y_train)\n","\n","pred_train = opt_model_catb.predict(x_train_feat_sel)\n","pred_test = opt_model_catb.predict(x_test_feat_sel)\n","\n","print(f'train: {roc_auc_score(y_train, pred_train)}')\n","print(f'test: {roc_auc_score(y_test, pred_test)}')\n","print(f'test conf matrix: \\n {confusion_matrix(y_test, pred_test)}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IW7FRtZrb1Pl","executionInfo":{"status":"ok","timestamp":1708012132869,"user_tz":-240,"elapsed":38240,"user":{"displayName":"Евгений Малов","userId":"06257165098392198337"}},"outputId":"dd86f4ef-2440-4018-e5f3-d2d47e3f1588"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0:\tlearn: 0.6795174\ttotal: 1.04s\tremaining: 2m 20s\n","1:\tlearn: 0.6690053\ttotal: 2.59s\tremaining: 2m 53s\n","2:\tlearn: 0.6620686\ttotal: 3.9s\tremaining: 2m 53s\n","3:\tlearn: 0.6561042\ttotal: 5.19s\tremaining: 2m 51s\n","4:\tlearn: 0.6515308\ttotal: 6.32s\tremaining: 2m 45s\n","5:\tlearn: 0.6481029\ttotal: 7.32s\tremaining: 2m 38s\n","6:\tlearn: 0.6449347\ttotal: 8.33s\tremaining: 2m 33s\n","7:\tlearn: 0.6423794\ttotal: 9.3s\tremaining: 2m 28s\n","8:\tlearn: 0.6403765\ttotal: 10.4s\tremaining: 2m 26s\n","9:\tlearn: 0.6386144\ttotal: 11.6s\tremaining: 2m 25s\n","10:\tlearn: 0.6369531\ttotal: 12.5s\tremaining: 2m 21s\n","11:\tlearn: 0.6356664\ttotal: 13.2s\tremaining: 2m 16s\n","12:\tlearn: 0.6343993\ttotal: 14.1s\tremaining: 2m 13s\n","13:\tlearn: 0.6334161\ttotal: 14.9s\tremaining: 2m 10s\n","14:\tlearn: 0.6323426\ttotal: 16.3s\tremaining: 2m 11s\n","15:\tlearn: 0.6314776\ttotal: 17.6s\tremaining: 2m 11s\n","16:\tlearn: 0.6307389\ttotal: 18.8s\tremaining: 2m 11s\n","17:\tlearn: 0.6295785\ttotal: 19.6s\tremaining: 2m 8s\n","18:\tlearn: 0.6287574\ttotal: 20.5s\tremaining: 2m 5s\n","19:\tlearn: 0.6280880\ttotal: 21.3s\tremaining: 2m 3s\n","20:\tlearn: 0.6274923\ttotal: 22.1s\tremaining: 2m\n","21:\tlearn: 0.6268129\ttotal: 23s\tremaining: 1m 58s\n","22:\tlearn: 0.6261924\ttotal: 23.7s\tremaining: 1m 56s\n","23:\tlearn: 0.6255954\ttotal: 24.5s\tremaining: 1m 54s\n","24:\tlearn: 0.6252037\ttotal: 25.3s\tremaining: 1m 52s\n","25:\tlearn: 0.6247303\ttotal: 26.1s\tremaining: 1m 50s\n","26:\tlearn: 0.6242541\ttotal: 26.9s\tremaining: 1m 48s\n","27:\tlearn: 0.6238237\ttotal: 27.7s\tremaining: 1m 46s\n","28:\tlearn: 0.6233189\ttotal: 28.4s\tremaining: 1m 44s\n","29:\tlearn: 0.6228462\ttotal: 29.5s\tremaining: 1m 44s\n","30:\tlearn: 0.6223703\ttotal: 30.9s\tremaining: 1m 44s\n","31:\tlearn: 0.6220210\ttotal: 32.2s\tremaining: 1m 44s\n","32:\tlearn: 0.6216028\ttotal: 33.1s\tremaining: 1m 43s\n","33:\tlearn: 0.6212530\ttotal: 34s\tremaining: 1m 41s\n","34:\tlearn: 0.6209480\ttotal: 34.8s\tremaining: 1m 40s\n","35:\tlearn: 0.6204595\ttotal: 35.6s\tremaining: 1m 38s\n","36:\tlearn: 0.6200632\ttotal: 36.3s\tremaining: 1m 37s\n","37:\tlearn: 0.6197828\ttotal: 37s\tremaining: 1m 35s\n","38:\tlearn: 0.6195066\ttotal: 37.7s\tremaining: 1m 33s\n","39:\tlearn: 0.6191530\ttotal: 38.6s\tremaining: 1m 32s\n","40:\tlearn: 0.6186594\ttotal: 39.4s\tremaining: 1m 31s\n","41:\tlearn: 0.6183344\ttotal: 40.2s\tremaining: 1m 29s\n","42:\tlearn: 0.6181033\ttotal: 40.9s\tremaining: 1m 28s\n","43:\tlearn: 0.6178374\ttotal: 41.6s\tremaining: 1m 27s\n","44:\tlearn: 0.6175802\ttotal: 42.4s\tremaining: 1m 25s\n","45:\tlearn: 0.6172805\ttotal: 43.7s\tremaining: 1m 25s\n","46:\tlearn: 0.6170339\ttotal: 44.9s\tremaining: 1m 25s\n","47:\tlearn: 0.6167654\ttotal: 46.2s\tremaining: 1m 24s\n","48:\tlearn: 0.6164519\ttotal: 47.3s\tremaining: 1m 23s\n","49:\tlearn: 0.6161165\ttotal: 48s\tremaining: 1m 22s\n","50:\tlearn: 0.6157374\ttotal: 48.9s\tremaining: 1m 21s\n","51:\tlearn: 0.6155274\ttotal: 49.6s\tremaining: 1m 20s\n","52:\tlearn: 0.6151887\ttotal: 50.5s\tremaining: 1m 19s\n","53:\tlearn: 0.6149177\ttotal: 51.3s\tremaining: 1m 17s\n","54:\tlearn: 0.6146808\ttotal: 52.1s\tremaining: 1m 16s\n","55:\tlearn: 0.6144296\ttotal: 53s\tremaining: 1m 15s\n","56:\tlearn: 0.6141951\ttotal: 53.8s\tremaining: 1m 14s\n","57:\tlearn: 0.6139493\ttotal: 54.5s\tremaining: 1m 13s\n","58:\tlearn: 0.6137304\ttotal: 55.2s\tremaining: 1m 12s\n","59:\tlearn: 0.6134173\ttotal: 56.1s\tremaining: 1m 11s\n","60:\tlearn: 0.6132097\ttotal: 57.7s\tremaining: 1m 10s\n","61:\tlearn: 0.6130334\ttotal: 59.4s\tremaining: 1m 10s\n","62:\tlearn: 0.6128233\ttotal: 1m\tremaining: 1m 10s\n","63:\tlearn: 0.6126208\ttotal: 1m 1s\tremaining: 1m 9s\n","64:\tlearn: 0.6124317\ttotal: 1m 2s\tremaining: 1m 7s\n","65:\tlearn: 0.6121742\ttotal: 1m 2s\tremaining: 1m 6s\n","66:\tlearn: 0.6119703\ttotal: 1m 3s\tremaining: 1m 5s\n","67:\tlearn: 0.6117074\ttotal: 1m 4s\tremaining: 1m 4s\n","68:\tlearn: 0.6115077\ttotal: 1m 5s\tremaining: 1m 3s\n","69:\tlearn: 0.6112747\ttotal: 1m 5s\tremaining: 1m 2s\n","70:\tlearn: 0.6110441\ttotal: 1m 6s\tremaining: 1m\n","71:\tlearn: 0.6108292\ttotal: 1m 7s\tremaining: 59.9s\n","72:\tlearn: 0.6106024\ttotal: 1m 8s\tremaining: 58.8s\n","73:\tlearn: 0.6103452\ttotal: 1m 8s\tremaining: 57.8s\n","74:\tlearn: 0.6101420\ttotal: 1m 9s\tremaining: 56.6s\n","75:\tlearn: 0.6098558\ttotal: 1m 10s\tremaining: 55.8s\n","76:\tlearn: 0.6096291\ttotal: 1m 11s\tremaining: 55.1s\n","77:\tlearn: 0.6094114\ttotal: 1m 13s\tremaining: 54.3s\n","78:\tlearn: 0.6091851\ttotal: 1m 14s\tremaining: 53.5s\n","79:\tlearn: 0.6089477\ttotal: 1m 14s\tremaining: 52.5s\n","80:\tlearn: 0.6087201\ttotal: 1m 15s\tremaining: 51.3s\n","81:\tlearn: 0.6085025\ttotal: 1m 16s\tremaining: 50.3s\n","82:\tlearn: 0.6082358\ttotal: 1m 17s\tremaining: 49.2s\n","83:\tlearn: 0.6080515\ttotal: 1m 17s\tremaining: 48.1s\n","84:\tlearn: 0.6078056\ttotal: 1m 18s\tremaining: 47s\n","85:\tlearn: 0.6075512\ttotal: 1m 19s\tremaining: 46.1s\n","86:\tlearn: 0.6073632\ttotal: 1m 20s\tremaining: 45.1s\n","87:\tlearn: 0.6071242\ttotal: 1m 20s\tremaining: 44.1s\n","88:\tlearn: 0.6068947\ttotal: 1m 21s\tremaining: 43.1s\n","89:\tlearn: 0.6067236\ttotal: 1m 22s\tremaining: 42s\n","90:\tlearn: 0.6064810\ttotal: 1m 22s\tremaining: 41s\n","91:\tlearn: 0.6062272\ttotal: 1m 23s\tremaining: 40.1s\n","92:\tlearn: 0.6059896\ttotal: 1m 24s\tremaining: 39.2s\n","93:\tlearn: 0.6057492\ttotal: 1m 26s\tremaining: 38.4s\n","94:\tlearn: 0.6055352\ttotal: 1m 27s\tremaining: 37.7s\n","95:\tlearn: 0.6052353\ttotal: 1m 28s\tremaining: 36.8s\n","96:\tlearn: 0.6050181\ttotal: 1m 29s\tremaining: 35.9s\n","97:\tlearn: 0.6048075\ttotal: 1m 30s\tremaining: 34.9s\n","98:\tlearn: 0.6046142\ttotal: 1m 30s\tremaining: 33.9s\n","99:\tlearn: 0.6043952\ttotal: 1m 31s\tremaining: 32.9s\n","100:\tlearn: 0.6041729\ttotal: 1m 32s\tremaining: 31.9s\n","101:\tlearn: 0.6040035\ttotal: 1m 32s\tremaining: 30.9s\n","102:\tlearn: 0.6037330\ttotal: 1m 33s\tremaining: 30s\n","103:\tlearn: 0.6034852\ttotal: 1m 34s\tremaining: 29.1s\n","104:\tlearn: 0.6032777\ttotal: 1m 35s\tremaining: 28.1s\n","105:\tlearn: 0.6030951\ttotal: 1m 35s\tremaining: 27.1s\n","106:\tlearn: 0.6028848\ttotal: 1m 36s\tremaining: 26.2s\n","107:\tlearn: 0.6026684\ttotal: 1m 37s\tremaining: 25.2s\n","108:\tlearn: 0.6024816\ttotal: 1m 38s\tremaining: 24.3s\n","109:\tlearn: 0.6022745\ttotal: 1m 40s\tremaining: 23.7s\n","110:\tlearn: 0.6020732\ttotal: 1m 42s\tremaining: 23s\n","111:\tlearn: 0.6018677\ttotal: 1m 43s\tremaining: 22.1s\n","112:\tlearn: 0.6016514\ttotal: 1m 43s\tremaining: 21.1s\n","113:\tlearn: 0.6013978\ttotal: 1m 44s\tremaining: 20.2s\n","114:\tlearn: 0.6012050\ttotal: 1m 45s\tremaining: 19.2s\n","115:\tlearn: 0.6009918\ttotal: 1m 46s\tremaining: 18.3s\n","116:\tlearn: 0.6007666\ttotal: 1m 47s\tremaining: 17.4s\n","117:\tlearn: 0.6005931\ttotal: 1m 47s\tremaining: 16.4s\n","118:\tlearn: 0.6003714\ttotal: 1m 48s\tremaining: 15.5s\n","119:\tlearn: 0.6001779\ttotal: 1m 49s\tremaining: 14.6s\n","120:\tlearn: 0.6000178\ttotal: 1m 49s\tremaining: 13.6s\n","121:\tlearn: 0.5998143\ttotal: 1m 50s\tremaining: 12.7s\n","122:\tlearn: 0.5996068\ttotal: 1m 51s\tremaining: 11.8s\n","123:\tlearn: 0.5994245\ttotal: 1m 52s\tremaining: 10.9s\n","124:\tlearn: 0.5992401\ttotal: 1m 53s\tremaining: 9.99s\n","125:\tlearn: 0.5990397\ttotal: 1m 54s\tremaining: 9.11s\n","126:\tlearn: 0.5988365\ttotal: 1m 55s\tremaining: 8.2s\n","127:\tlearn: 0.5986417\ttotal: 1m 56s\tremaining: 7.29s\n","128:\tlearn: 0.5984701\ttotal: 1m 57s\tremaining: 6.36s\n","129:\tlearn: 0.5982644\ttotal: 1m 57s\tremaining: 5.44s\n","130:\tlearn: 0.5980754\ttotal: 1m 58s\tremaining: 4.53s\n","131:\tlearn: 0.5979286\ttotal: 1m 59s\tremaining: 3.61s\n","132:\tlearn: 0.5977562\ttotal: 1m 59s\tremaining: 2.71s\n","133:\tlearn: 0.5975374\ttotal: 2m\tremaining: 1.8s\n","134:\tlearn: 0.5973460\ttotal: 2m 1s\tremaining: 901ms\n","135:\tlearn: 0.5971676\ttotal: 2m 2s\tremaining: 0us\n","train: 0.680683501333115\n","test: 0.6639809544654137\n","test conf matrix: \n"," [[574502 293512]\n"," [ 10680  21306]]\n"]}]},{"cell_type":"code","source":["y_train.value_counts()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Oub3YSa4vMsT","executionInfo":{"status":"ok","timestamp":1707666551658,"user_tz":-240,"elapsed":7,"user":{"displayName":"Евгений Малов","userId":"06257165098392198337"}},"outputId":"f2b3f093-9cd4-4c1a-cf7b-1b5364ae6fd9"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["flag\n","0       2025544\n","1         74456\n","dtype: int64"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":["y_test.value_counts()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aaRySbcLvMwQ","executionInfo":{"status":"ok","timestamp":1707666573624,"user_tz":-240,"elapsed":9,"user":{"displayName":"Евгений Малов","userId":"06257165098392198337"}},"outputId":"76187ea2-11a7-48e7-b8eb-be9c4066b272"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["flag\n","0       868014\n","1        31986\n","dtype: int64"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","source":["estimators = [\n","    ('lgbm', opt_model_lgbm),\n","    ('cb', opt_model_catb)\n","    ]\n","\n","reg = StackingClassifier(\n","    estimators=estimators,\n","    final_estimator=GradientBoostingClassifier(learning_rate = 0.02, n_estimators = 100, random_state=42))\n","\n","reg.fit(x_train_feat_sel, y_train)\n","pred_train = reg.predict(x_train_feat_sel)\n","pred_test = reg.predict(x_test_feat_sel)\n","\n","print(f'train: {roc_auc_score(y_train, pred_train)}')\n","print(f'test: {roc_auc_score(y_test, pred_test)}')\n","print(f'test conf matrix: \\n {confusion_matrix(y_test, pred_test)}')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"X_MDnnK0vM7u","executionInfo":{"status":"ok","timestamp":1707670202206,"user_tz":-240,"elapsed":1752929,"user":{"displayName":"Евгений Малов","userId":"06257165098392198337"}},"outputId":"2246eb6a-6754-4d46-8f47-f5428e2800e8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 74456, number of negative: 2025544\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 1.336492 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 12750\n","[LightGBM] [Info] Number of data points in the train set: 2100000, number of used features: 50\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.035455 -> initscore=-3.303385\n","[LightGBM] [Info] Start training from score -3.303385\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","0:\tlearn: 0.4478266\ttotal: 621ms\tremaining: 1m 23s\n","1:\tlearn: 0.3141861\ttotal: 1.14s\tremaining: 1m 16s\n","2:\tlearn: 0.2429194\ttotal: 1.71s\tremaining: 1m 15s\n","3:\tlearn: 0.2028646\ttotal: 2.29s\tremaining: 1m 15s\n","4:\tlearn: 0.1807790\ttotal: 2.84s\tremaining: 1m 14s\n","5:\tlearn: 0.1681337\ttotal: 3.34s\tremaining: 1m 12s\n","6:\tlearn: 0.1595936\ttotal: 4.02s\tremaining: 1m 14s\n","7:\tlearn: 0.1550436\ttotal: 4.68s\tremaining: 1m 14s\n","8:\tlearn: 0.1516302\ttotal: 5.54s\tremaining: 1m 18s\n","9:\tlearn: 0.1494762\ttotal: 6.23s\tremaining: 1m 18s\n","10:\tlearn: 0.1480799\ttotal: 6.74s\tremaining: 1m 16s\n","11:\tlearn: 0.1471039\ttotal: 7.29s\tremaining: 1m 15s\n","12:\tlearn: 0.1464747\ttotal: 7.83s\tremaining: 1m 14s\n","13:\tlearn: 0.1460053\ttotal: 8.43s\tremaining: 1m 13s\n","14:\tlearn: 0.1455668\ttotal: 8.95s\tremaining: 1m 12s\n","15:\tlearn: 0.1451941\ttotal: 9.52s\tremaining: 1m 11s\n","16:\tlearn: 0.1449197\ttotal: 10.1s\tremaining: 1m 10s\n","17:\tlearn: 0.1447011\ttotal: 10.6s\tremaining: 1m 9s\n","18:\tlearn: 0.1445055\ttotal: 11.1s\tremaining: 1m 8s\n","19:\tlearn: 0.1443355\ttotal: 11.7s\tremaining: 1m 8s\n","20:\tlearn: 0.1442182\ttotal: 12.2s\tremaining: 1m 6s\n","21:\tlearn: 0.1441031\ttotal: 12.7s\tremaining: 1m 5s\n","22:\tlearn: 0.1439754\ttotal: 13.3s\tremaining: 1m 5s\n","23:\tlearn: 0.1438521\ttotal: 13.8s\tremaining: 1m 4s\n","24:\tlearn: 0.1437430\ttotal: 14.4s\tremaining: 1m 4s\n","25:\tlearn: 0.1436545\ttotal: 14.9s\tremaining: 1m 3s\n","26:\tlearn: 0.1435631\ttotal: 15.4s\tremaining: 1m 2s\n","27:\tlearn: 0.1434876\ttotal: 16s\tremaining: 1m 1s\n","28:\tlearn: 0.1434141\ttotal: 16.8s\tremaining: 1m 2s\n","29:\tlearn: 0.1433598\ttotal: 17.6s\tremaining: 1m 2s\n","30:\tlearn: 0.1432789\ttotal: 18.7s\tremaining: 1m 3s\n","31:\tlearn: 0.1432013\ttotal: 19.2s\tremaining: 1m 2s\n","32:\tlearn: 0.1431258\ttotal: 19.8s\tremaining: 1m 1s\n","33:\tlearn: 0.1430732\ttotal: 20.3s\tremaining: 1m\n","34:\tlearn: 0.1430174\ttotal: 20.8s\tremaining: 1m\n","35:\tlearn: 0.1429626\ttotal: 21.3s\tremaining: 59.3s\n","36:\tlearn: 0.1428963\ttotal: 21.8s\tremaining: 58.3s\n","37:\tlearn: 0.1428312\ttotal: 22.4s\tremaining: 57.8s\n","38:\tlearn: 0.1427825\ttotal: 23s\tremaining: 57.2s\n","39:\tlearn: 0.1427246\ttotal: 23.6s\tremaining: 56.5s\n","40:\tlearn: 0.1426858\ttotal: 24s\tremaining: 55.7s\n","41:\tlearn: 0.1426343\ttotal: 24.6s\tremaining: 55.1s\n","42:\tlearn: 0.1425937\ttotal: 25.1s\tremaining: 54.3s\n","43:\tlearn: 0.1425528\ttotal: 25.6s\tremaining: 53.5s\n","44:\tlearn: 0.1425085\ttotal: 26.1s\tremaining: 52.8s\n","45:\tlearn: 0.1424735\ttotal: 26.7s\tremaining: 52.2s\n","46:\tlearn: 0.1424331\ttotal: 27.2s\tremaining: 51.5s\n","47:\tlearn: 0.1423915\ttotal: 27.8s\tremaining: 50.9s\n","48:\tlearn: 0.1423537\ttotal: 28.5s\tremaining: 50.6s\n","49:\tlearn: 0.1423146\ttotal: 29.3s\tremaining: 50.4s\n","50:\tlearn: 0.1422731\ttotal: 29.9s\tremaining: 49.9s\n","51:\tlearn: 0.1422306\ttotal: 30.5s\tremaining: 49.2s\n","52:\tlearn: 0.1422017\ttotal: 30.9s\tremaining: 48.4s\n","53:\tlearn: 0.1421594\ttotal: 31.4s\tremaining: 47.7s\n","54:\tlearn: 0.1421271\ttotal: 31.9s\tremaining: 47s\n","55:\tlearn: 0.1420977\ttotal: 32.5s\tremaining: 46.4s\n","56:\tlearn: 0.1420670\ttotal: 33s\tremaining: 45.7s\n","57:\tlearn: 0.1420279\ttotal: 33.5s\tremaining: 45s\n","58:\tlearn: 0.1419928\ttotal: 34s\tremaining: 44.4s\n","59:\tlearn: 0.1419669\ttotal: 34.5s\tremaining: 43.7s\n","60:\tlearn: 0.1419368\ttotal: 35s\tremaining: 43s\n","61:\tlearn: 0.1418975\ttotal: 35.4s\tremaining: 42.3s\n","62:\tlearn: 0.1418734\ttotal: 35.9s\tremaining: 41.6s\n","63:\tlearn: 0.1418295\ttotal: 36.4s\tremaining: 41s\n","64:\tlearn: 0.1418031\ttotal: 36.9s\tremaining: 40.3s\n","65:\tlearn: 0.1417574\ttotal: 37.4s\tremaining: 39.6s\n","66:\tlearn: 0.1417275\ttotal: 37.9s\tremaining: 39s\n","67:\tlearn: 0.1417010\ttotal: 38.4s\tremaining: 38.4s\n","68:\tlearn: 0.1416691\ttotal: 38.9s\tremaining: 37.8s\n","69:\tlearn: 0.1416397\ttotal: 39.3s\tremaining: 37s\n","70:\tlearn: 0.1416136\ttotal: 39.8s\tremaining: 36.4s\n","71:\tlearn: 0.1415790\ttotal: 40.6s\tremaining: 36.1s\n","72:\tlearn: 0.1415488\ttotal: 41.4s\tremaining: 35.8s\n","73:\tlearn: 0.1415142\ttotal: 42s\tremaining: 35.2s\n","74:\tlearn: 0.1414834\ttotal: 42.4s\tremaining: 34.5s\n","75:\tlearn: 0.1414330\ttotal: 43.1s\tremaining: 34s\n","76:\tlearn: 0.1414063\ttotal: 43.6s\tremaining: 33.4s\n","77:\tlearn: 0.1413836\ttotal: 44s\tremaining: 32.7s\n","78:\tlearn: 0.1413603\ttotal: 44.4s\tremaining: 32.1s\n","79:\tlearn: 0.1413254\ttotal: 45s\tremaining: 31.5s\n","80:\tlearn: 0.1412937\ttotal: 45.5s\tremaining: 30.9s\n","81:\tlearn: 0.1412636\ttotal: 46s\tremaining: 30.3s\n","82:\tlearn: 0.1412429\ttotal: 46.5s\tremaining: 29.7s\n","83:\tlearn: 0.1412139\ttotal: 46.9s\tremaining: 29s\n","84:\tlearn: 0.1411908\ttotal: 47.3s\tremaining: 28.4s\n","85:\tlearn: 0.1411639\ttotal: 47.9s\tremaining: 27.8s\n","86:\tlearn: 0.1411389\ttotal: 48.3s\tremaining: 27.2s\n","87:\tlearn: 0.1411170\ttotal: 48.7s\tremaining: 26.6s\n","88:\tlearn: 0.1410699\ttotal: 49.3s\tremaining: 26s\n","89:\tlearn: 0.1410400\ttotal: 49.8s\tremaining: 25.5s\n","90:\tlearn: 0.1410118\ttotal: 50.4s\tremaining: 24.9s\n","91:\tlearn: 0.1409744\ttotal: 50.9s\tremaining: 24.3s\n","92:\tlearn: 0.1409514\ttotal: 51.4s\tremaining: 23.7s\n","93:\tlearn: 0.1409173\ttotal: 52.2s\tremaining: 23.3s\n","94:\tlearn: 0.1408904\ttotal: 52.8s\tremaining: 22.8s\n","95:\tlearn: 0.1408622\ttotal: 53.4s\tremaining: 22.2s\n","96:\tlearn: 0.1408329\ttotal: 54s\tremaining: 21.7s\n","97:\tlearn: 0.1408072\ttotal: 54.4s\tremaining: 21.1s\n","98:\tlearn: 0.1407824\ttotal: 55s\tremaining: 20.5s\n","99:\tlearn: 0.1407563\ttotal: 55.5s\tremaining: 20s\n","100:\tlearn: 0.1407332\ttotal: 56s\tremaining: 19.4s\n","101:\tlearn: 0.1407128\ttotal: 56.5s\tremaining: 18.8s\n","102:\tlearn: 0.1406854\ttotal: 57s\tremaining: 18.3s\n","103:\tlearn: 0.1406508\ttotal: 57.6s\tremaining: 17.7s\n","104:\tlearn: 0.1406276\ttotal: 58.1s\tremaining: 17.1s\n","105:\tlearn: 0.1406102\ttotal: 58.5s\tremaining: 16.6s\n","106:\tlearn: 0.1405814\ttotal: 59.1s\tremaining: 16s\n","107:\tlearn: 0.1405576\ttotal: 59.6s\tremaining: 15.5s\n","108:\tlearn: 0.1405275\ttotal: 1m\tremaining: 14.9s\n","109:\tlearn: 0.1405012\ttotal: 1m\tremaining: 14.3s\n","110:\tlearn: 0.1404821\ttotal: 1m\tremaining: 13.7s\n","111:\tlearn: 0.1404532\ttotal: 1m 1s\tremaining: 13.2s\n","112:\tlearn: 0.1404290\ttotal: 1m 1s\tremaining: 12.6s\n","113:\tlearn: 0.1404124\ttotal: 1m 2s\tremaining: 12s\n","114:\tlearn: 0.1403893\ttotal: 1m 2s\tremaining: 11.5s\n","115:\tlearn: 0.1403635\ttotal: 1m 3s\tremaining: 10.9s\n","116:\tlearn: 0.1403399\ttotal: 1m 4s\tremaining: 10.5s\n","117:\tlearn: 0.1403114\ttotal: 1m 4s\tremaining: 9.91s\n","118:\tlearn: 0.1402859\ttotal: 1m 5s\tremaining: 9.34s\n","119:\tlearn: 0.1402604\ttotal: 1m 5s\tremaining: 8.78s\n","120:\tlearn: 0.1402342\ttotal: 1m 6s\tremaining: 8.23s\n","121:\tlearn: 0.1402174\ttotal: 1m 6s\tremaining: 7.67s\n","122:\tlearn: 0.1401889\ttotal: 1m 7s\tremaining: 7.11s\n","123:\tlearn: 0.1401647\ttotal: 1m 7s\tremaining: 6.56s\n","124:\tlearn: 0.1401378\ttotal: 1m 8s\tremaining: 6.01s\n","125:\tlearn: 0.1401217\ttotal: 1m 8s\tremaining: 5.45s\n","126:\tlearn: 0.1400983\ttotal: 1m 9s\tremaining: 4.9s\n","127:\tlearn: 0.1400804\ttotal: 1m 9s\tremaining: 4.35s\n","128:\tlearn: 0.1400507\ttotal: 1m 10s\tremaining: 3.81s\n","129:\tlearn: 0.1400196\ttotal: 1m 10s\tremaining: 3.26s\n","130:\tlearn: 0.1399961\ttotal: 1m 11s\tremaining: 2.72s\n","131:\tlearn: 0.1399816\ttotal: 1m 11s\tremaining: 2.17s\n","132:\tlearn: 0.1399622\ttotal: 1m 12s\tremaining: 1.62s\n","133:\tlearn: 0.1399406\ttotal: 1m 12s\tremaining: 1.08s\n","134:\tlearn: 0.1399215\ttotal: 1m 13s\tremaining: 541ms\n","135:\tlearn: 0.1398954\ttotal: 1m 13s\tremaining: 0us\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 59565, number of negative: 1620435\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.725110 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 12750\n","[LightGBM] [Info] Number of data points in the train set: 1680000, number of used features: 50\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.035455 -> initscore=-3.303382\n","[LightGBM] [Info] Start training from score -3.303382\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 59565, number of negative: 1620435\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.683491 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 12750\n","[LightGBM] [Info] Number of data points in the train set: 1680000, number of used features: 50\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.035455 -> initscore=-3.303382\n","[LightGBM] [Info] Start training from score -3.303382\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 59565, number of negative: 1620435\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.696170 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 12750\n","[LightGBM] [Info] Number of data points in the train set: 1680000, number of used features: 50\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.035455 -> initscore=-3.303382\n","[LightGBM] [Info] Start training from score -3.303382\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 59565, number of negative: 1620435\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.689377 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 12750\n","[LightGBM] [Info] Number of data points in the train set: 1680000, number of used features: 50\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.035455 -> initscore=-3.303382\n","[LightGBM] [Info] Start training from score -3.303382\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 59564, number of negative: 1620436\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 1.067688 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 12750\n","[LightGBM] [Info] Number of data points in the train set: 1680000, number of used features: 50\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.035455 -> initscore=-3.303399\n","[LightGBM] [Info] Start training from score -3.303399\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","0:\tlearn: 0.4484393\ttotal: 455ms\tremaining: 1m 1s\n","1:\tlearn: 0.3162553\ttotal: 928ms\tremaining: 1m 2s\n","2:\tlearn: 0.2437473\ttotal: 1.64s\tremaining: 1m 12s\n","3:\tlearn: 0.2041865\ttotal: 2.36s\tremaining: 1m 17s\n","4:\tlearn: 0.1815066\ttotal: 2.82s\tremaining: 1m 14s\n","5:\tlearn: 0.1678772\ttotal: 3.29s\tremaining: 1m 11s\n","6:\tlearn: 0.1598412\ttotal: 3.75s\tremaining: 1m 9s\n","7:\tlearn: 0.1548667\ttotal: 4.17s\tremaining: 1m 6s\n","8:\tlearn: 0.1519444\ttotal: 4.6s\tremaining: 1m 4s\n","9:\tlearn: 0.1497663\ttotal: 5.01s\tremaining: 1m 3s\n","10:\tlearn: 0.1483569\ttotal: 5.46s\tremaining: 1m 2s\n","11:\tlearn: 0.1473755\ttotal: 5.95s\tremaining: 1m 1s\n","12:\tlearn: 0.1465741\ttotal: 6.38s\tremaining: 1m\n","13:\tlearn: 0.1459536\ttotal: 6.84s\tremaining: 59.6s\n","14:\tlearn: 0.1454944\ttotal: 7.32s\tremaining: 59s\n","15:\tlearn: 0.1451992\ttotal: 7.71s\tremaining: 57.8s\n","16:\tlearn: 0.1449387\ttotal: 8.15s\tremaining: 57s\n","17:\tlearn: 0.1446859\ttotal: 8.61s\tremaining: 56.5s\n","18:\tlearn: 0.1444995\ttotal: 9.08s\tremaining: 55.9s\n","19:\tlearn: 0.1443319\ttotal: 9.51s\tremaining: 55.1s\n","20:\tlearn: 0.1441896\ttotal: 9.97s\tremaining: 54.6s\n","21:\tlearn: 0.1440606\ttotal: 10.4s\tremaining: 54.1s\n","22:\tlearn: 0.1439250\ttotal: 10.9s\tremaining: 53.6s\n","23:\tlearn: 0.1437828\ttotal: 11.4s\tremaining: 53.2s\n","24:\tlearn: 0.1436910\ttotal: 11.9s\tremaining: 52.7s\n","25:\tlearn: 0.1435998\ttotal: 12.3s\tremaining: 52s\n","26:\tlearn: 0.1435021\ttotal: 12.9s\tremaining: 52.1s\n","27:\tlearn: 0.1434176\ttotal: 13.6s\tremaining: 52.3s\n","28:\tlearn: 0.1433311\ttotal: 14.2s\tremaining: 52.3s\n","29:\tlearn: 0.1432627\ttotal: 14.6s\tremaining: 51.7s\n","30:\tlearn: 0.1431858\ttotal: 15.1s\tremaining: 51s\n","31:\tlearn: 0.1431222\ttotal: 15.5s\tremaining: 50.3s\n","32:\tlearn: 0.1430560\ttotal: 16s\tremaining: 49.9s\n","33:\tlearn: 0.1429883\ttotal: 16.4s\tremaining: 49.3s\n","34:\tlearn: 0.1429306\ttotal: 16.9s\tremaining: 48.9s\n","35:\tlearn: 0.1428706\ttotal: 17.3s\tremaining: 48.1s\n","36:\tlearn: 0.1428099\ttotal: 17.7s\tremaining: 47.5s\n","37:\tlearn: 0.1427543\ttotal: 18.2s\tremaining: 46.9s\n","38:\tlearn: 0.1427027\ttotal: 18.6s\tremaining: 46.2s\n","39:\tlearn: 0.1426536\ttotal: 19.1s\tremaining: 45.7s\n","40:\tlearn: 0.1426023\ttotal: 19.4s\tremaining: 45s\n","41:\tlearn: 0.1425622\ttotal: 19.8s\tremaining: 44.4s\n","42:\tlearn: 0.1425051\ttotal: 20.2s\tremaining: 43.8s\n","43:\tlearn: 0.1424551\ttotal: 20.7s\tremaining: 43.3s\n","44:\tlearn: 0.1423993\ttotal: 21.2s\tremaining: 42.8s\n","45:\tlearn: 0.1423553\ttotal: 21.6s\tremaining: 42.2s\n","46:\tlearn: 0.1423204\ttotal: 21.9s\tremaining: 41.5s\n","47:\tlearn: 0.1422712\ttotal: 22.3s\tremaining: 40.9s\n","48:\tlearn: 0.1422286\ttotal: 22.8s\tremaining: 40.5s\n","49:\tlearn: 0.1421937\ttotal: 23.2s\tremaining: 39.9s\n","50:\tlearn: 0.1421636\ttotal: 23.5s\tremaining: 39.2s\n","51:\tlearn: 0.1421253\ttotal: 23.9s\tremaining: 38.6s\n","52:\tlearn: 0.1420751\ttotal: 24.4s\tremaining: 38.3s\n","53:\tlearn: 0.1420465\ttotal: 25s\tremaining: 38s\n","54:\tlearn: 0.1420069\ttotal: 25.8s\tremaining: 37.9s\n","55:\tlearn: 0.1419721\ttotal: 26.1s\tremaining: 37.4s\n","56:\tlearn: 0.1419334\ttotal: 26.5s\tremaining: 36.7s\n","57:\tlearn: 0.1418998\ttotal: 26.9s\tremaining: 36.2s\n","58:\tlearn: 0.1418614\ttotal: 27.3s\tremaining: 35.7s\n","59:\tlearn: 0.1418322\ttotal: 27.7s\tremaining: 35.1s\n","60:\tlearn: 0.1417994\ttotal: 28.1s\tremaining: 34.6s\n","61:\tlearn: 0.1417560\ttotal: 28.6s\tremaining: 34.1s\n","62:\tlearn: 0.1417205\ttotal: 29.1s\tremaining: 33.7s\n","63:\tlearn: 0.1416898\ttotal: 29.5s\tremaining: 33.2s\n","64:\tlearn: 0.1416528\ttotal: 29.8s\tremaining: 32.6s\n","65:\tlearn: 0.1416239\ttotal: 30.2s\tremaining: 32.1s\n","66:\tlearn: 0.1415892\ttotal: 30.6s\tremaining: 31.5s\n","67:\tlearn: 0.1415594\ttotal: 30.9s\tremaining: 30.9s\n","68:\tlearn: 0.1415283\ttotal: 31.3s\tremaining: 30.4s\n","69:\tlearn: 0.1415021\ttotal: 31.7s\tremaining: 29.9s\n","70:\tlearn: 0.1414687\ttotal: 32.1s\tremaining: 29.4s\n","71:\tlearn: 0.1414235\ttotal: 32.6s\tremaining: 29s\n","72:\tlearn: 0.1413948\ttotal: 33s\tremaining: 28.5s\n","73:\tlearn: 0.1413632\ttotal: 33.3s\tremaining: 27.9s\n","74:\tlearn: 0.1413265\ttotal: 33.7s\tremaining: 27.4s\n","75:\tlearn: 0.1412849\ttotal: 34.2s\tremaining: 27s\n","76:\tlearn: 0.1412534\ttotal: 34.6s\tremaining: 26.5s\n","77:\tlearn: 0.1412164\ttotal: 35s\tremaining: 26s\n","78:\tlearn: 0.1411923\ttotal: 35.3s\tremaining: 25.5s\n","79:\tlearn: 0.1411611\ttotal: 35.7s\tremaining: 25s\n","80:\tlearn: 0.1411315\ttotal: 36.2s\tremaining: 24.6s\n","81:\tlearn: 0.1410965\ttotal: 36.8s\tremaining: 24.2s\n","82:\tlearn: 0.1410611\ttotal: 37.5s\tremaining: 23.9s\n","83:\tlearn: 0.1410215\ttotal: 37.9s\tremaining: 23.5s\n","84:\tlearn: 0.1409969\ttotal: 38.3s\tremaining: 23s\n","85:\tlearn: 0.1409672\ttotal: 38.7s\tremaining: 22.5s\n","86:\tlearn: 0.1409328\ttotal: 39.2s\tremaining: 22.1s\n","87:\tlearn: 0.1409050\ttotal: 39.5s\tremaining: 21.6s\n","88:\tlearn: 0.1408782\ttotal: 39.9s\tremaining: 21.1s\n","89:\tlearn: 0.1408434\ttotal: 40.2s\tremaining: 20.6s\n","90:\tlearn: 0.1408000\ttotal: 40.6s\tremaining: 20.1s\n","91:\tlearn: 0.1407666\ttotal: 41s\tremaining: 19.6s\n","92:\tlearn: 0.1407285\ttotal: 41.5s\tremaining: 19.2s\n","93:\tlearn: 0.1406962\ttotal: 41.9s\tremaining: 18.7s\n","94:\tlearn: 0.1406642\ttotal: 42.3s\tremaining: 18.3s\n","95:\tlearn: 0.1406282\ttotal: 42.7s\tremaining: 17.8s\n","96:\tlearn: 0.1405947\ttotal: 43.2s\tremaining: 17.4s\n","97:\tlearn: 0.1405616\ttotal: 43.6s\tremaining: 16.9s\n","98:\tlearn: 0.1405386\ttotal: 44s\tremaining: 16.4s\n","99:\tlearn: 0.1404905\ttotal: 44.4s\tremaining: 16s\n","100:\tlearn: 0.1404655\ttotal: 44.8s\tremaining: 15.5s\n","101:\tlearn: 0.1404362\ttotal: 45.2s\tremaining: 15.1s\n","102:\tlearn: 0.1404143\ttotal: 45.5s\tremaining: 14.6s\n","103:\tlearn: 0.1403902\ttotal: 45.9s\tremaining: 14.1s\n","104:\tlearn: 0.1403587\ttotal: 46.3s\tremaining: 13.7s\n","105:\tlearn: 0.1403182\ttotal: 46.8s\tremaining: 13.2s\n","106:\tlearn: 0.1402874\ttotal: 47.2s\tremaining: 12.8s\n","107:\tlearn: 0.1402632\ttotal: 47.6s\tremaining: 12.3s\n","108:\tlearn: 0.1402370\ttotal: 48.2s\tremaining: 11.9s\n","109:\tlearn: 0.1402090\ttotal: 48.9s\tremaining: 11.6s\n","110:\tlearn: 0.1401694\ttotal: 49.4s\tremaining: 11.1s\n","111:\tlearn: 0.1401478\ttotal: 49.8s\tremaining: 10.7s\n","112:\tlearn: 0.1401163\ttotal: 50.2s\tremaining: 10.2s\n","113:\tlearn: 0.1400807\ttotal: 50.7s\tremaining: 9.78s\n","114:\tlearn: 0.1400523\ttotal: 51.1s\tremaining: 9.33s\n","115:\tlearn: 0.1400117\ttotal: 51.6s\tremaining: 8.9s\n","116:\tlearn: 0.1399781\ttotal: 52s\tremaining: 8.45s\n","117:\tlearn: 0.1399557\ttotal: 52.3s\tremaining: 7.98s\n","118:\tlearn: 0.1399240\ttotal: 52.7s\tremaining: 7.53s\n","119:\tlearn: 0.1398946\ttotal: 53.2s\tremaining: 7.09s\n","120:\tlearn: 0.1398687\ttotal: 53.6s\tremaining: 6.64s\n","121:\tlearn: 0.1398411\ttotal: 54s\tremaining: 6.2s\n","122:\tlearn: 0.1398136\ttotal: 54.3s\tremaining: 5.74s\n","123:\tlearn: 0.1397818\ttotal: 54.8s\tremaining: 5.3s\n","124:\tlearn: 0.1397553\ttotal: 55.2s\tremaining: 4.86s\n","125:\tlearn: 0.1397317\ttotal: 55.6s\tremaining: 4.41s\n","126:\tlearn: 0.1397069\ttotal: 55.9s\tremaining: 3.96s\n","127:\tlearn: 0.1396816\ttotal: 56.3s\tremaining: 3.52s\n","128:\tlearn: 0.1396546\ttotal: 56.6s\tremaining: 3.07s\n","129:\tlearn: 0.1396264\ttotal: 57.1s\tremaining: 2.63s\n","130:\tlearn: 0.1396058\ttotal: 57.4s\tremaining: 2.19s\n","131:\tlearn: 0.1395834\ttotal: 57.8s\tremaining: 1.75s\n","132:\tlearn: 0.1395562\ttotal: 58.2s\tremaining: 1.31s\n","133:\tlearn: 0.1395305\ttotal: 58.6s\tremaining: 874ms\n","134:\tlearn: 0.1395080\ttotal: 58.9s\tremaining: 436ms\n","135:\tlearn: 0.1394733\ttotal: 59.4s\tremaining: 0us\n","0:\tlearn: 0.4482988\ttotal: 431ms\tremaining: 58.2s\n","1:\tlearn: 0.3162781\ttotal: 837ms\tremaining: 56.1s\n","2:\tlearn: 0.2438226\ttotal: 1.31s\tremaining: 58s\n","3:\tlearn: 0.2042503\ttotal: 1.78s\tremaining: 58.8s\n","4:\tlearn: 0.1814227\ttotal: 2.19s\tremaining: 57.3s\n","5:\tlearn: 0.1677880\ttotal: 2.66s\tremaining: 57.7s\n","6:\tlearn: 0.1598623\ttotal: 3.08s\tremaining: 56.8s\n","7:\tlearn: 0.1550787\ttotal: 3.5s\tremaining: 55.9s\n","8:\tlearn: 0.1522280\ttotal: 3.92s\tremaining: 55.4s\n","9:\tlearn: 0.1499415\ttotal: 4.35s\tremaining: 54.8s\n","10:\tlearn: 0.1484633\ttotal: 4.77s\tremaining: 54.2s\n","11:\tlearn: 0.1474061\ttotal: 5.19s\tremaining: 53.6s\n","12:\tlearn: 0.1466639\ttotal: 5.61s\tremaining: 53.1s\n","13:\tlearn: 0.1460206\ttotal: 6.13s\tremaining: 53.4s\n","14:\tlearn: 0.1455700\ttotal: 6.56s\tremaining: 52.9s\n","15:\tlearn: 0.1452076\ttotal: 7.03s\tremaining: 52.7s\n","16:\tlearn: 0.1449541\ttotal: 7.48s\tremaining: 52.4s\n","17:\tlearn: 0.1447624\ttotal: 7.87s\tremaining: 51.6s\n","18:\tlearn: 0.1445637\ttotal: 8.4s\tremaining: 51.7s\n","19:\tlearn: 0.1443787\ttotal: 8.88s\tremaining: 51.5s\n","20:\tlearn: 0.1442191\ttotal: 9.34s\tremaining: 51.1s\n","21:\tlearn: 0.1440872\ttotal: 10s\tremaining: 52s\n","22:\tlearn: 0.1439626\ttotal: 10.7s\tremaining: 52.6s\n","23:\tlearn: 0.1438583\ttotal: 11.3s\tremaining: 52.5s\n","24:\tlearn: 0.1437521\ttotal: 11.7s\tremaining: 52.1s\n","25:\tlearn: 0.1436583\ttotal: 12.2s\tremaining: 51.6s\n","26:\tlearn: 0.1435649\ttotal: 12.7s\tremaining: 51.3s\n","27:\tlearn: 0.1434677\ttotal: 13.1s\tremaining: 50.5s\n","28:\tlearn: 0.1433948\ttotal: 13.5s\tremaining: 49.8s\n","29:\tlearn: 0.1433014\ttotal: 14s\tremaining: 49.4s\n","30:\tlearn: 0.1432312\ttotal: 14.4s\tremaining: 48.8s\n","31:\tlearn: 0.1431720\ttotal: 14.8s\tremaining: 48.2s\n","32:\tlearn: 0.1430994\ttotal: 15.3s\tremaining: 47.8s\n","33:\tlearn: 0.1430245\ttotal: 15.7s\tremaining: 47.2s\n","34:\tlearn: 0.1429705\ttotal: 16.2s\tremaining: 46.7s\n","35:\tlearn: 0.1429110\ttotal: 16.6s\tremaining: 46s\n","36:\tlearn: 0.1428468\ttotal: 17.1s\tremaining: 45.8s\n","37:\tlearn: 0.1427908\ttotal: 17.5s\tremaining: 45s\n","38:\tlearn: 0.1427273\ttotal: 17.9s\tremaining: 44.6s\n","39:\tlearn: 0.1426704\ttotal: 18.4s\tremaining: 44.2s\n","40:\tlearn: 0.1426190\ttotal: 18.8s\tremaining: 43.6s\n","41:\tlearn: 0.1425731\ttotal: 19.2s\tremaining: 42.9s\n","42:\tlearn: 0.1425271\ttotal: 19.6s\tremaining: 42.3s\n","43:\tlearn: 0.1424795\ttotal: 20s\tremaining: 41.9s\n","44:\tlearn: 0.1424461\ttotal: 20.4s\tremaining: 41.2s\n","45:\tlearn: 0.1424017\ttotal: 20.8s\tremaining: 40.6s\n","46:\tlearn: 0.1423651\ttotal: 21.3s\tremaining: 40.3s\n","47:\tlearn: 0.1423195\ttotal: 21.9s\tremaining: 40.1s\n","48:\tlearn: 0.1422702\ttotal: 22.5s\tremaining: 40s\n","49:\tlearn: 0.1422130\ttotal: 23.1s\tremaining: 39.8s\n","50:\tlearn: 0.1421751\ttotal: 23.6s\tremaining: 39.3s\n","51:\tlearn: 0.1421298\ttotal: 24s\tremaining: 38.8s\n","52:\tlearn: 0.1420892\ttotal: 24.4s\tremaining: 38.2s\n","53:\tlearn: 0.1420344\ttotal: 24.9s\tremaining: 37.7s\n","54:\tlearn: 0.1420025\ttotal: 25.3s\tremaining: 37.3s\n","55:\tlearn: 0.1419575\ttotal: 25.7s\tremaining: 36.7s\n","56:\tlearn: 0.1419210\ttotal: 26.1s\tremaining: 36.2s\n","57:\tlearn: 0.1418848\ttotal: 26.5s\tremaining: 35.6s\n","58:\tlearn: 0.1418575\ttotal: 26.9s\tremaining: 35.1s\n","59:\tlearn: 0.1418225\ttotal: 27.3s\tremaining: 34.6s\n","60:\tlearn: 0.1417922\ttotal: 27.7s\tremaining: 34.1s\n","61:\tlearn: 0.1417579\ttotal: 28.1s\tremaining: 33.5s\n","62:\tlearn: 0.1417224\ttotal: 28.4s\tremaining: 33s\n","63:\tlearn: 0.1416887\ttotal: 28.9s\tremaining: 32.5s\n","64:\tlearn: 0.1416546\ttotal: 29.2s\tremaining: 31.9s\n","65:\tlearn: 0.1416266\ttotal: 29.6s\tremaining: 31.4s\n","66:\tlearn: 0.1415865\ttotal: 30s\tremaining: 30.9s\n","67:\tlearn: 0.1415485\ttotal: 30.4s\tremaining: 30.4s\n","68:\tlearn: 0.1415182\ttotal: 30.8s\tremaining: 29.9s\n","69:\tlearn: 0.1414750\ttotal: 31.3s\tremaining: 29.5s\n","70:\tlearn: 0.1414341\ttotal: 31.8s\tremaining: 29.1s\n","71:\tlearn: 0.1414044\ttotal: 32.2s\tremaining: 28.6s\n","72:\tlearn: 0.1413690\ttotal: 32.6s\tremaining: 28.1s\n","73:\tlearn: 0.1413230\ttotal: 33.1s\tremaining: 27.7s\n","74:\tlearn: 0.1412899\ttotal: 33.7s\tremaining: 27.4s\n","75:\tlearn: 0.1412515\ttotal: 34.4s\tremaining: 27.2s\n","76:\tlearn: 0.1412250\ttotal: 34.8s\tremaining: 26.7s\n","77:\tlearn: 0.1411911\ttotal: 35.2s\tremaining: 26.2s\n","78:\tlearn: 0.1411495\ttotal: 35.6s\tremaining: 25.7s\n","79:\tlearn: 0.1411178\ttotal: 36s\tremaining: 25.2s\n","80:\tlearn: 0.1410863\ttotal: 36.3s\tremaining: 24.7s\n","81:\tlearn: 0.1410542\ttotal: 36.7s\tremaining: 24.2s\n","82:\tlearn: 0.1410236\ttotal: 37.2s\tremaining: 23.7s\n","83:\tlearn: 0.1409927\ttotal: 37.5s\tremaining: 23.2s\n","84:\tlearn: 0.1409574\ttotal: 37.9s\tremaining: 22.7s\n","85:\tlearn: 0.1409276\ttotal: 38.3s\tremaining: 22.3s\n","86:\tlearn: 0.1408952\ttotal: 38.7s\tremaining: 21.8s\n","87:\tlearn: 0.1408646\ttotal: 39.1s\tremaining: 21.3s\n","88:\tlearn: 0.1408335\ttotal: 39.4s\tremaining: 20.8s\n","89:\tlearn: 0.1408057\ttotal: 39.9s\tremaining: 20.4s\n","90:\tlearn: 0.1407707\ttotal: 40.3s\tremaining: 19.9s\n","91:\tlearn: 0.1407463\ttotal: 40.6s\tremaining: 19.4s\n","92:\tlearn: 0.1407180\ttotal: 40.9s\tremaining: 18.9s\n","93:\tlearn: 0.1406896\ttotal: 41.4s\tremaining: 18.5s\n","94:\tlearn: 0.1406626\ttotal: 41.7s\tremaining: 18s\n","95:\tlearn: 0.1406287\ttotal: 42.1s\tremaining: 17.5s\n","96:\tlearn: 0.1405936\ttotal: 42.6s\tremaining: 17.1s\n","97:\tlearn: 0.1405638\ttotal: 42.9s\tremaining: 16.6s\n","98:\tlearn: 0.1405459\ttotal: 43.2s\tremaining: 16.2s\n","99:\tlearn: 0.1405175\ttotal: 43.7s\tremaining: 15.7s\n","100:\tlearn: 0.1404985\ttotal: 44s\tremaining: 15.2s\n","101:\tlearn: 0.1404753\ttotal: 44.4s\tremaining: 14.8s\n","102:\tlearn: 0.1404442\ttotal: 44.9s\tremaining: 14.4s\n","103:\tlearn: 0.1404188\ttotal: 45.5s\tremaining: 14s\n","104:\tlearn: 0.1403795\ttotal: 46.2s\tremaining: 13.6s\n","105:\tlearn: 0.1403501\ttotal: 46.6s\tremaining: 13.2s\n","106:\tlearn: 0.1403276\ttotal: 46.9s\tremaining: 12.7s\n","107:\tlearn: 0.1402943\ttotal: 47.4s\tremaining: 12.3s\n","108:\tlearn: 0.1402735\ttotal: 47.7s\tremaining: 11.8s\n","109:\tlearn: 0.1402414\ttotal: 48.2s\tremaining: 11.4s\n","110:\tlearn: 0.1402172\ttotal: 48.6s\tremaining: 11s\n","111:\tlearn: 0.1401998\ttotal: 49s\tremaining: 10.5s\n","112:\tlearn: 0.1401685\ttotal: 49.3s\tremaining: 10s\n","113:\tlearn: 0.1401328\ttotal: 49.7s\tremaining: 9.6s\n","114:\tlearn: 0.1401071\ttotal: 50.1s\tremaining: 9.15s\n","115:\tlearn: 0.1400769\ttotal: 50.5s\tremaining: 8.71s\n","116:\tlearn: 0.1400520\ttotal: 50.8s\tremaining: 8.26s\n","117:\tlearn: 0.1400218\ttotal: 51.2s\tremaining: 7.81s\n","118:\tlearn: 0.1399945\ttotal: 51.6s\tremaining: 7.37s\n","119:\tlearn: 0.1399699\ttotal: 51.9s\tremaining: 6.92s\n","120:\tlearn: 0.1399426\ttotal: 52.3s\tremaining: 6.48s\n","121:\tlearn: 0.1399183\ttotal: 52.7s\tremaining: 6.05s\n","122:\tlearn: 0.1398927\ttotal: 53.1s\tremaining: 5.62s\n","123:\tlearn: 0.1398678\ttotal: 53.5s\tremaining: 5.17s\n","124:\tlearn: 0.1398466\ttotal: 53.9s\tremaining: 4.74s\n","125:\tlearn: 0.1398174\ttotal: 54.3s\tremaining: 4.31s\n","126:\tlearn: 0.1397877\ttotal: 54.7s\tremaining: 3.88s\n","127:\tlearn: 0.1397597\ttotal: 55.1s\tremaining: 3.44s\n","128:\tlearn: 0.1397312\ttotal: 55.4s\tremaining: 3.01s\n","129:\tlearn: 0.1397101\ttotal: 55.8s\tremaining: 2.58s\n","130:\tlearn: 0.1396932\ttotal: 56.2s\tremaining: 2.15s\n","131:\tlearn: 0.1396722\ttotal: 56.7s\tremaining: 1.72s\n","132:\tlearn: 0.1396473\ttotal: 57.3s\tremaining: 1.29s\n","133:\tlearn: 0.1396280\ttotal: 57.8s\tremaining: 863ms\n","134:\tlearn: 0.1395997\ttotal: 58.2s\tremaining: 431ms\n","135:\tlearn: 0.1395709\ttotal: 58.6s\tremaining: 0us\n","0:\tlearn: 0.4483066\ttotal: 434ms\tremaining: 58.6s\n","1:\tlearn: 0.3154815\ttotal: 857ms\tremaining: 57.4s\n","2:\tlearn: 0.2425999\ttotal: 1.3s\tremaining: 57.8s\n","3:\tlearn: 0.2045120\ttotal: 1.72s\tremaining: 56.9s\n","4:\tlearn: 0.1822177\ttotal: 2.14s\tremaining: 56s\n","5:\tlearn: 0.1686288\ttotal: 2.59s\tremaining: 56.1s\n","6:\tlearn: 0.1600056\ttotal: 2.98s\tremaining: 54.9s\n","7:\tlearn: 0.1549994\ttotal: 3.38s\tremaining: 54.2s\n","8:\tlearn: 0.1519830\ttotal: 3.83s\tremaining: 54.1s\n","9:\tlearn: 0.1498327\ttotal: 4.28s\tremaining: 54s\n","10:\tlearn: 0.1484150\ttotal: 4.74s\tremaining: 53.8s\n","11:\tlearn: 0.1474187\ttotal: 5.24s\tremaining: 54.1s\n","12:\tlearn: 0.1466325\ttotal: 5.66s\tremaining: 53.6s\n","13:\tlearn: 0.1460318\ttotal: 6.17s\tremaining: 53.8s\n","14:\tlearn: 0.1455908\ttotal: 6.6s\tremaining: 53.3s\n","15:\tlearn: 0.1452236\ttotal: 7.07s\tremaining: 53s\n","16:\tlearn: 0.1449771\ttotal: 7.52s\tremaining: 52.6s\n","17:\tlearn: 0.1447440\ttotal: 8.07s\tremaining: 52.9s\n","18:\tlearn: 0.1445808\ttotal: 8.77s\tremaining: 54s\n","19:\tlearn: 0.1443588\ttotal: 9.49s\tremaining: 55.1s\n","20:\tlearn: 0.1442504\ttotal: 9.92s\tremaining: 54.3s\n","21:\tlearn: 0.1441295\ttotal: 10.4s\tremaining: 53.7s\n","22:\tlearn: 0.1439741\ttotal: 10.8s\tremaining: 53.1s\n","23:\tlearn: 0.1438540\ttotal: 11.3s\tremaining: 52.6s\n","24:\tlearn: 0.1437410\ttotal: 11.7s\tremaining: 52.2s\n","25:\tlearn: 0.1436481\ttotal: 12.2s\tremaining: 51.6s\n","26:\tlearn: 0.1435492\ttotal: 12.7s\tremaining: 51.1s\n","27:\tlearn: 0.1434454\ttotal: 13.1s\tremaining: 50.4s\n","28:\tlearn: 0.1433486\ttotal: 13.5s\tremaining: 49.8s\n","29:\tlearn: 0.1432642\ttotal: 14s\tremaining: 49.4s\n","30:\tlearn: 0.1431928\ttotal: 14.4s\tremaining: 48.8s\n","31:\tlearn: 0.1431257\ttotal: 14.8s\tremaining: 48.2s\n","32:\tlearn: 0.1430493\ttotal: 15.3s\tremaining: 47.6s\n","33:\tlearn: 0.1429931\ttotal: 15.8s\tremaining: 47.4s\n","34:\tlearn: 0.1429338\ttotal: 16.2s\tremaining: 46.7s\n","35:\tlearn: 0.1428669\ttotal: 16.7s\tremaining: 46.3s\n","36:\tlearn: 0.1428009\ttotal: 17.1s\tremaining: 45.8s\n","37:\tlearn: 0.1427405\ttotal: 17.6s\tremaining: 45.3s\n","38:\tlearn: 0.1426872\ttotal: 18s\tremaining: 44.8s\n","39:\tlearn: 0.1426278\ttotal: 18.4s\tremaining: 44.3s\n","40:\tlearn: 0.1425802\ttotal: 18.9s\tremaining: 43.8s\n","41:\tlearn: 0.1425333\ttotal: 19.4s\tremaining: 43.4s\n","42:\tlearn: 0.1424795\ttotal: 20s\tremaining: 43.2s\n","43:\tlearn: 0.1424374\ttotal: 20.6s\tremaining: 43.1s\n","44:\tlearn: 0.1423952\ttotal: 21.3s\tremaining: 43s\n","45:\tlearn: 0.1423538\ttotal: 21.6s\tremaining: 42.3s\n","46:\tlearn: 0.1423126\ttotal: 22s\tremaining: 41.7s\n","47:\tlearn: 0.1422600\ttotal: 22.4s\tremaining: 41.1s\n","48:\tlearn: 0.1422130\ttotal: 22.9s\tremaining: 40.6s\n","49:\tlearn: 0.1421704\ttotal: 23.3s\tremaining: 40s\n","50:\tlearn: 0.1421231\ttotal: 23.7s\tremaining: 39.5s\n","51:\tlearn: 0.1420908\ttotal: 24.1s\tremaining: 38.9s\n","52:\tlearn: 0.1420561\ttotal: 24.4s\tremaining: 38.2s\n","53:\tlearn: 0.1420202\ttotal: 24.8s\tremaining: 37.7s\n","54:\tlearn: 0.1419939\ttotal: 25.2s\tremaining: 37s\n","55:\tlearn: 0.1419596\ttotal: 25.6s\tremaining: 36.5s\n","56:\tlearn: 0.1419296\ttotal: 25.9s\tremaining: 35.9s\n","57:\tlearn: 0.1418973\ttotal: 26.3s\tremaining: 35.4s\n","58:\tlearn: 0.1418621\ttotal: 26.7s\tremaining: 34.9s\n","59:\tlearn: 0.1418171\ttotal: 27.2s\tremaining: 34.4s\n","60:\tlearn: 0.1417726\ttotal: 27.6s\tremaining: 33.9s\n","61:\tlearn: 0.1417385\ttotal: 27.9s\tremaining: 33.4s\n","62:\tlearn: 0.1417132\ttotal: 28.3s\tremaining: 32.8s\n","63:\tlearn: 0.1416675\ttotal: 28.7s\tremaining: 32.3s\n","64:\tlearn: 0.1416360\ttotal: 29.1s\tremaining: 31.8s\n","65:\tlearn: 0.1416050\ttotal: 29.5s\tremaining: 31.3s\n","66:\tlearn: 0.1415718\ttotal: 29.9s\tremaining: 30.8s\n","67:\tlearn: 0.1415351\ttotal: 30.3s\tremaining: 30.3s\n","68:\tlearn: 0.1415029\ttotal: 30.7s\tremaining: 29.8s\n","69:\tlearn: 0.1414717\ttotal: 31.1s\tremaining: 29.3s\n","70:\tlearn: 0.1414211\ttotal: 31.8s\tremaining: 29.1s\n","71:\tlearn: 0.1413946\ttotal: 32.4s\tremaining: 28.8s\n","72:\tlearn: 0.1413598\ttotal: 33s\tremaining: 28.4s\n","73:\tlearn: 0.1413343\ttotal: 33.3s\tremaining: 27.9s\n","74:\tlearn: 0.1413070\ttotal: 33.7s\tremaining: 27.4s\n","75:\tlearn: 0.1412701\ttotal: 34.1s\tremaining: 26.9s\n","76:\tlearn: 0.1412356\ttotal: 34.5s\tremaining: 26.4s\n","77:\tlearn: 0.1412040\ttotal: 34.8s\tremaining: 25.9s\n","78:\tlearn: 0.1411758\ttotal: 35.2s\tremaining: 25.4s\n","79:\tlearn: 0.1411495\ttotal: 35.6s\tremaining: 24.9s\n","80:\tlearn: 0.1411146\ttotal: 36s\tremaining: 24.4s\n","81:\tlearn: 0.1410798\ttotal: 36.4s\tremaining: 24s\n","82:\tlearn: 0.1410594\ttotal: 36.7s\tremaining: 23.5s\n","83:\tlearn: 0.1410309\ttotal: 37.1s\tremaining: 22.9s\n","84:\tlearn: 0.1410051\ttotal: 37.4s\tremaining: 22.4s\n","85:\tlearn: 0.1409766\ttotal: 37.8s\tremaining: 22s\n","86:\tlearn: 0.1409419\ttotal: 38.2s\tremaining: 21.5s\n","87:\tlearn: 0.1409060\ttotal: 38.6s\tremaining: 21.1s\n","88:\tlearn: 0.1408767\ttotal: 39s\tremaining: 20.6s\n","89:\tlearn: 0.1408524\ttotal: 39.3s\tremaining: 20.1s\n","90:\tlearn: 0.1408179\ttotal: 39.8s\tremaining: 19.7s\n","91:\tlearn: 0.1407900\ttotal: 40.2s\tremaining: 19.2s\n","92:\tlearn: 0.1407656\ttotal: 40.5s\tremaining: 18.7s\n","93:\tlearn: 0.1407293\ttotal: 40.9s\tremaining: 18.3s\n","94:\tlearn: 0.1407034\ttotal: 41.3s\tremaining: 17.8s\n","95:\tlearn: 0.1406758\ttotal: 41.7s\tremaining: 17.4s\n","96:\tlearn: 0.1406509\ttotal: 42.1s\tremaining: 16.9s\n","97:\tlearn: 0.1406239\ttotal: 42.5s\tremaining: 16.5s\n","98:\tlearn: 0.1406030\ttotal: 42.8s\tremaining: 16s\n","99:\tlearn: 0.1405746\ttotal: 43.3s\tremaining: 15.6s\n","100:\tlearn: 0.1405375\ttotal: 44s\tremaining: 15.2s\n","101:\tlearn: 0.1405085\ttotal: 44.6s\tremaining: 14.9s\n","102:\tlearn: 0.1404780\ttotal: 45.1s\tremaining: 14.4s\n","103:\tlearn: 0.1404501\ttotal: 45.4s\tremaining: 14s\n","104:\tlearn: 0.1404253\ttotal: 45.8s\tremaining: 13.5s\n","105:\tlearn: 0.1403919\ttotal: 46.3s\tremaining: 13.1s\n","106:\tlearn: 0.1403629\ttotal: 46.6s\tremaining: 12.6s\n","107:\tlearn: 0.1403340\ttotal: 47s\tremaining: 12.2s\n","108:\tlearn: 0.1403037\ttotal: 47.4s\tremaining: 11.8s\n","109:\tlearn: 0.1402662\ttotal: 47.9s\tremaining: 11.3s\n","110:\tlearn: 0.1402413\ttotal: 48.3s\tremaining: 10.9s\n","111:\tlearn: 0.1402103\ttotal: 48.6s\tremaining: 10.4s\n","112:\tlearn: 0.1401801\ttotal: 49s\tremaining: 9.97s\n","113:\tlearn: 0.1401551\ttotal: 49.4s\tremaining: 9.53s\n","114:\tlearn: 0.1401274\ttotal: 49.8s\tremaining: 9.09s\n","115:\tlearn: 0.1401033\ttotal: 50.2s\tremaining: 8.65s\n","116:\tlearn: 0.1400770\ttotal: 50.6s\tremaining: 8.21s\n","117:\tlearn: 0.1400516\ttotal: 50.9s\tremaining: 7.77s\n","118:\tlearn: 0.1400349\ttotal: 51.3s\tremaining: 7.33s\n","119:\tlearn: 0.1400106\ttotal: 51.7s\tremaining: 6.9s\n","120:\tlearn: 0.1399866\ttotal: 52.1s\tremaining: 6.46s\n","121:\tlearn: 0.1399587\ttotal: 52.5s\tremaining: 6.03s\n","122:\tlearn: 0.1399294\ttotal: 53s\tremaining: 5.6s\n","123:\tlearn: 0.1399052\ttotal: 53.3s\tremaining: 5.16s\n","124:\tlearn: 0.1398727\ttotal: 53.7s\tremaining: 4.73s\n","125:\tlearn: 0.1398422\ttotal: 54.1s\tremaining: 4.29s\n","126:\tlearn: 0.1398073\ttotal: 54.6s\tremaining: 3.87s\n","127:\tlearn: 0.1397814\ttotal: 55s\tremaining: 3.44s\n","128:\tlearn: 0.1397638\ttotal: 55.6s\tremaining: 3.02s\n","129:\tlearn: 0.1397459\ttotal: 56.2s\tremaining: 2.59s\n","130:\tlearn: 0.1397213\ttotal: 56.6s\tremaining: 2.16s\n","131:\tlearn: 0.1396871\ttotal: 57s\tremaining: 1.73s\n","132:\tlearn: 0.1396652\ttotal: 57.4s\tremaining: 1.29s\n","133:\tlearn: 0.1396413\ttotal: 57.8s\tremaining: 863ms\n","134:\tlearn: 0.1396163\ttotal: 58.2s\tremaining: 431ms\n","135:\tlearn: 0.1395970\ttotal: 58.6s\tremaining: 0us\n","0:\tlearn: 0.4483962\ttotal: 431ms\tremaining: 58.1s\n","1:\tlearn: 0.3154886\ttotal: 858ms\tremaining: 57.5s\n","2:\tlearn: 0.2425809\ttotal: 1.3s\tremaining: 57.5s\n","3:\tlearn: 0.2044999\ttotal: 1.72s\tremaining: 56.8s\n","4:\tlearn: 0.1822082\ttotal: 2.13s\tremaining: 55.9s\n","5:\tlearn: 0.1686565\ttotal: 2.6s\tremaining: 56.3s\n","6:\tlearn: 0.1600286\ttotal: 3s\tremaining: 55.2s\n","7:\tlearn: 0.1547440\ttotal: 3.46s\tremaining: 55.3s\n","8:\tlearn: 0.1517789\ttotal: 3.91s\tremaining: 55.1s\n","9:\tlearn: 0.1496936\ttotal: 4.38s\tremaining: 55.1s\n","10:\tlearn: 0.1483527\ttotal: 4.83s\tremaining: 54.9s\n","11:\tlearn: 0.1473673\ttotal: 5.27s\tremaining: 54.4s\n","12:\tlearn: 0.1466664\ttotal: 5.73s\tremaining: 54.3s\n","13:\tlearn: 0.1460921\ttotal: 6.4s\tremaining: 55.8s\n","14:\tlearn: 0.1457317\ttotal: 7.07s\tremaining: 57s\n","15:\tlearn: 0.1454075\ttotal: 7.73s\tremaining: 58s\n","16:\tlearn: 0.1451137\ttotal: 8.16s\tremaining: 57.1s\n","17:\tlearn: 0.1448908\ttotal: 8.58s\tremaining: 56.2s\n","18:\tlearn: 0.1446973\ttotal: 9.04s\tremaining: 55.7s\n","19:\tlearn: 0.1445380\ttotal: 9.45s\tremaining: 54.8s\n","20:\tlearn: 0.1443874\ttotal: 9.84s\tremaining: 53.9s\n","21:\tlearn: 0.1442693\ttotal: 10.3s\tremaining: 53.1s\n","22:\tlearn: 0.1441324\ttotal: 10.7s\tremaining: 52.7s\n","23:\tlearn: 0.1439974\ttotal: 11.1s\tremaining: 52s\n","24:\tlearn: 0.1438756\ttotal: 11.6s\tremaining: 51.5s\n","25:\tlearn: 0.1437768\ttotal: 12s\tremaining: 51s\n","26:\tlearn: 0.1436592\ttotal: 12.5s\tremaining: 50.4s\n","27:\tlearn: 0.1435620\ttotal: 13s\tremaining: 50s\n","28:\tlearn: 0.1434857\ttotal: 13.4s\tremaining: 49.3s\n","29:\tlearn: 0.1434057\ttotal: 13.7s\tremaining: 48.5s\n","30:\tlearn: 0.1433015\ttotal: 14.2s\tremaining: 48.1s\n","31:\tlearn: 0.1432246\ttotal: 14.7s\tremaining: 47.8s\n","32:\tlearn: 0.1431487\ttotal: 15.1s\tremaining: 47.3s\n","33:\tlearn: 0.1430862\ttotal: 15.6s\tremaining: 46.8s\n","34:\tlearn: 0.1430211\ttotal: 16.1s\tremaining: 46.4s\n","35:\tlearn: 0.1429560\ttotal: 16.5s\tremaining: 45.9s\n","36:\tlearn: 0.1429076\ttotal: 16.9s\tremaining: 45.2s\n","37:\tlearn: 0.1428575\ttotal: 17.3s\tremaining: 44.7s\n","38:\tlearn: 0.1427987\ttotal: 17.9s\tremaining: 44.5s\n","39:\tlearn: 0.1427427\ttotal: 18.6s\tremaining: 44.7s\n","40:\tlearn: 0.1426978\ttotal: 19.3s\tremaining: 44.7s\n","41:\tlearn: 0.1426462\ttotal: 19.7s\tremaining: 44.1s\n","42:\tlearn: 0.1425933\ttotal: 20.1s\tremaining: 43.4s\n","43:\tlearn: 0.1425463\ttotal: 20.5s\tremaining: 42.9s\n","44:\tlearn: 0.1425078\ttotal: 20.9s\tremaining: 42.4s\n","45:\tlearn: 0.1424656\ttotal: 21.3s\tremaining: 41.8s\n","46:\tlearn: 0.1424110\ttotal: 21.8s\tremaining: 41.3s\n","47:\tlearn: 0.1423686\ttotal: 22.3s\tremaining: 40.8s\n","48:\tlearn: 0.1423114\ttotal: 22.7s\tremaining: 40.3s\n","49:\tlearn: 0.1422648\ttotal: 23.2s\tremaining: 39.9s\n","50:\tlearn: 0.1422191\ttotal: 23.6s\tremaining: 39.4s\n","51:\tlearn: 0.1421835\ttotal: 24s\tremaining: 38.8s\n","52:\tlearn: 0.1421361\ttotal: 24.4s\tremaining: 38.2s\n","53:\tlearn: 0.1420958\ttotal: 24.8s\tremaining: 37.6s\n","54:\tlearn: 0.1420637\ttotal: 25.1s\tremaining: 37s\n","55:\tlearn: 0.1420293\ttotal: 25.5s\tremaining: 36.4s\n","56:\tlearn: 0.1419908\ttotal: 25.9s\tremaining: 35.9s\n","57:\tlearn: 0.1419494\ttotal: 26.4s\tremaining: 35.5s\n","58:\tlearn: 0.1419228\ttotal: 26.8s\tremaining: 34.9s\n","59:\tlearn: 0.1418876\ttotal: 27.3s\tremaining: 34.5s\n","60:\tlearn: 0.1418507\ttotal: 27.6s\tremaining: 34s\n","61:\tlearn: 0.1418289\ttotal: 28s\tremaining: 33.4s\n","62:\tlearn: 0.1417872\ttotal: 28.5s\tremaining: 33s\n","63:\tlearn: 0.1417345\ttotal: 28.9s\tremaining: 32.5s\n","64:\tlearn: 0.1416915\ttotal: 29.4s\tremaining: 32.2s\n","65:\tlearn: 0.1416585\ttotal: 30s\tremaining: 31.8s\n","66:\tlearn: 0.1416275\ttotal: 30.6s\tremaining: 31.5s\n","67:\tlearn: 0.1415939\ttotal: 31.1s\tremaining: 31.1s\n","68:\tlearn: 0.1415615\ttotal: 31.5s\tremaining: 30.6s\n","69:\tlearn: 0.1415282\ttotal: 31.9s\tremaining: 30.1s\n","70:\tlearn: 0.1414888\ttotal: 32.3s\tremaining: 29.6s\n","71:\tlearn: 0.1414623\ttotal: 32.7s\tremaining: 29.1s\n","72:\tlearn: 0.1414281\ttotal: 33.1s\tremaining: 28.6s\n","73:\tlearn: 0.1414005\ttotal: 33.6s\tremaining: 28.1s\n","74:\tlearn: 0.1413700\ttotal: 33.9s\tremaining: 27.6s\n","75:\tlearn: 0.1413321\ttotal: 34.4s\tremaining: 27.1s\n","76:\tlearn: 0.1412981\ttotal: 34.8s\tremaining: 26.7s\n","77:\tlearn: 0.1412696\ttotal: 35.2s\tremaining: 26.2s\n","78:\tlearn: 0.1412312\ttotal: 35.6s\tremaining: 25.7s\n","79:\tlearn: 0.1412018\ttotal: 35.9s\tremaining: 25.1s\n","80:\tlearn: 0.1411635\ttotal: 36.4s\tremaining: 24.7s\n","81:\tlearn: 0.1411404\ttotal: 36.8s\tremaining: 24.2s\n","82:\tlearn: 0.1411156\ttotal: 37.1s\tremaining: 23.7s\n","83:\tlearn: 0.1410846\ttotal: 37.5s\tremaining: 23.2s\n","84:\tlearn: 0.1410469\ttotal: 37.8s\tremaining: 22.7s\n","85:\tlearn: 0.1410181\ttotal: 38.2s\tremaining: 22.2s\n","86:\tlearn: 0.1409744\ttotal: 38.5s\tremaining: 21.7s\n","87:\tlearn: 0.1409464\ttotal: 38.9s\tremaining: 21.2s\n","88:\tlearn: 0.1409195\ttotal: 39.3s\tremaining: 20.8s\n","89:\tlearn: 0.1408906\ttotal: 39.7s\tremaining: 20.3s\n","90:\tlearn: 0.1408652\ttotal: 40.1s\tremaining: 19.8s\n","91:\tlearn: 0.1408237\ttotal: 40.6s\tremaining: 19.4s\n","92:\tlearn: 0.1407891\ttotal: 41.1s\tremaining: 19s\n","93:\tlearn: 0.1407548\ttotal: 41.7s\tremaining: 18.6s\n","94:\tlearn: 0.1407283\ttotal: 42.2s\tremaining: 18.2s\n","95:\tlearn: 0.1406990\ttotal: 42.8s\tremaining: 17.8s\n","96:\tlearn: 0.1406635\ttotal: 43.3s\tremaining: 17.4s\n","97:\tlearn: 0.1406327\ttotal: 43.7s\tremaining: 16.9s\n","98:\tlearn: 0.1406064\ttotal: 44.1s\tremaining: 16.5s\n","99:\tlearn: 0.1405717\ttotal: 44.4s\tremaining: 16s\n","100:\tlearn: 0.1405434\ttotal: 44.8s\tremaining: 15.5s\n","101:\tlearn: 0.1405143\ttotal: 45.3s\tremaining: 15.1s\n","102:\tlearn: 0.1404835\ttotal: 45.7s\tremaining: 14.6s\n","103:\tlearn: 0.1404519\ttotal: 46.1s\tremaining: 14.2s\n","104:\tlearn: 0.1404231\ttotal: 46.5s\tremaining: 13.7s\n","105:\tlearn: 0.1404019\ttotal: 46.8s\tremaining: 13.3s\n","106:\tlearn: 0.1403574\ttotal: 47.3s\tremaining: 12.8s\n","107:\tlearn: 0.1403350\ttotal: 47.6s\tremaining: 12.3s\n","108:\tlearn: 0.1403070\ttotal: 48s\tremaining: 11.9s\n","109:\tlearn: 0.1402797\ttotal: 48.4s\tremaining: 11.4s\n","110:\tlearn: 0.1402573\ttotal: 48.7s\tremaining: 11s\n","111:\tlearn: 0.1402284\ttotal: 49.1s\tremaining: 10.5s\n","112:\tlearn: 0.1402064\ttotal: 49.6s\tremaining: 10.1s\n","113:\tlearn: 0.1401855\ttotal: 50s\tremaining: 9.64s\n","114:\tlearn: 0.1401661\ttotal: 50.3s\tremaining: 9.19s\n","115:\tlearn: 0.1401369\ttotal: 50.7s\tremaining: 8.74s\n","116:\tlearn: 0.1401188\ttotal: 51.1s\tremaining: 8.29s\n","117:\tlearn: 0.1400865\ttotal: 51.4s\tremaining: 7.84s\n","118:\tlearn: 0.1400600\ttotal: 51.8s\tremaining: 7.4s\n","119:\tlearn: 0.1400338\ttotal: 52.2s\tremaining: 6.96s\n","120:\tlearn: 0.1400076\ttotal: 52.5s\tremaining: 6.51s\n","121:\tlearn: 0.1399844\ttotal: 53s\tremaining: 6.09s\n","122:\tlearn: 0.1399647\ttotal: 53.6s\tremaining: 5.67s\n","123:\tlearn: 0.1399445\ttotal: 54.2s\tremaining: 5.24s\n","124:\tlearn: 0.1399238\ttotal: 54.6s\tremaining: 4.8s\n","125:\tlearn: 0.1399048\ttotal: 55s\tremaining: 4.36s\n","126:\tlearn: 0.1398736\ttotal: 55.4s\tremaining: 3.92s\n","127:\tlearn: 0.1398501\ttotal: 55.7s\tremaining: 3.48s\n","128:\tlearn: 0.1398215\ttotal: 56.1s\tremaining: 3.04s\n","129:\tlearn: 0.1397870\ttotal: 56.5s\tremaining: 2.61s\n","130:\tlearn: 0.1397669\ttotal: 56.9s\tremaining: 2.17s\n","131:\tlearn: 0.1397354\ttotal: 57.3s\tremaining: 1.74s\n","132:\tlearn: 0.1397113\ttotal: 57.7s\tremaining: 1.3s\n","133:\tlearn: 0.1396873\ttotal: 58.1s\tremaining: 867ms\n","134:\tlearn: 0.1396522\ttotal: 58.5s\tremaining: 434ms\n","135:\tlearn: 0.1396314\ttotal: 58.9s\tremaining: 0us\n","0:\tlearn: 0.4483993\ttotal: 449ms\tremaining: 1m\n","1:\tlearn: 0.3163294\ttotal: 846ms\tremaining: 56.7s\n","2:\tlearn: 0.2437138\ttotal: 1.31s\tremaining: 58.1s\n","3:\tlearn: 0.2041900\ttotal: 1.79s\tremaining: 59.2s\n","4:\tlearn: 0.1813391\ttotal: 2.25s\tremaining: 59s\n","5:\tlearn: 0.1677174\ttotal: 2.72s\tremaining: 59s\n","6:\tlearn: 0.1599318\ttotal: 3.14s\tremaining: 58s\n","7:\tlearn: 0.1548984\ttotal: 3.55s\tremaining: 56.9s\n","8:\tlearn: 0.1515627\ttotal: 4.29s\tremaining: 1m\n","9:\tlearn: 0.1493658\ttotal: 4.96s\tremaining: 1m 2s\n","10:\tlearn: 0.1480471\ttotal: 5.46s\tremaining: 1m 2s\n","11:\tlearn: 0.1471003\ttotal: 5.87s\tremaining: 1m\n","12:\tlearn: 0.1463661\ttotal: 6.33s\tremaining: 59.9s\n","13:\tlearn: 0.1458558\ttotal: 6.75s\tremaining: 58.8s\n","14:\tlearn: 0.1455022\ttotal: 7.22s\tremaining: 58.3s\n","15:\tlearn: 0.1451884\ttotal: 7.7s\tremaining: 57.8s\n","16:\tlearn: 0.1449340\ttotal: 8.13s\tremaining: 56.9s\n","17:\tlearn: 0.1447191\ttotal: 8.62s\tremaining: 56.5s\n","18:\tlearn: 0.1444885\ttotal: 9.08s\tremaining: 55.9s\n","19:\tlearn: 0.1443678\ttotal: 9.45s\tremaining: 54.8s\n","20:\tlearn: 0.1441899\ttotal: 9.91s\tremaining: 54.3s\n","21:\tlearn: 0.1440361\ttotal: 10.4s\tremaining: 53.8s\n","22:\tlearn: 0.1439140\ttotal: 10.9s\tremaining: 53.3s\n","23:\tlearn: 0.1437990\ttotal: 11.3s\tremaining: 52.8s\n","24:\tlearn: 0.1436878\ttotal: 11.8s\tremaining: 52.3s\n","25:\tlearn: 0.1435879\ttotal: 12.2s\tremaining: 51.7s\n","26:\tlearn: 0.1434944\ttotal: 12.6s\tremaining: 50.9s\n","27:\tlearn: 0.1434217\ttotal: 13.1s\tremaining: 50.4s\n","28:\tlearn: 0.1433473\ttotal: 13.5s\tremaining: 49.9s\n","29:\tlearn: 0.1432593\ttotal: 14s\tremaining: 49.4s\n","30:\tlearn: 0.1431957\ttotal: 14.5s\tremaining: 49s\n","31:\tlearn: 0.1431367\ttotal: 14.9s\tremaining: 48.4s\n","32:\tlearn: 0.1430494\ttotal: 15.4s\tremaining: 48.1s\n","33:\tlearn: 0.1429854\ttotal: 16.1s\tremaining: 48.4s\n","34:\tlearn: 0.1429307\ttotal: 16.8s\tremaining: 48.4s\n","35:\tlearn: 0.1428748\ttotal: 17.2s\tremaining: 47.8s\n","36:\tlearn: 0.1428132\ttotal: 17.6s\tremaining: 47.2s\n","37:\tlearn: 0.1427620\ttotal: 18s\tremaining: 46.5s\n","38:\tlearn: 0.1426936\ttotal: 18.5s\tremaining: 46s\n","39:\tlearn: 0.1426380\ttotal: 18.8s\tremaining: 45.2s\n","40:\tlearn: 0.1425809\ttotal: 19.4s\tremaining: 44.9s\n","41:\tlearn: 0.1425282\ttotal: 19.8s\tremaining: 44.4s\n","42:\tlearn: 0.1424720\ttotal: 20.3s\tremaining: 43.9s\n","43:\tlearn: 0.1424270\ttotal: 20.7s\tremaining: 43.3s\n","44:\tlearn: 0.1423878\ttotal: 21.1s\tremaining: 42.7s\n","45:\tlearn: 0.1423271\ttotal: 21.6s\tremaining: 42.2s\n","46:\tlearn: 0.1422813\ttotal: 22s\tremaining: 41.6s\n","47:\tlearn: 0.1422432\ttotal: 22.4s\tremaining: 41.1s\n","48:\tlearn: 0.1421998\ttotal: 22.8s\tremaining: 40.5s\n","49:\tlearn: 0.1421660\ttotal: 23.3s\tremaining: 40s\n","50:\tlearn: 0.1421260\ttotal: 23.7s\tremaining: 39.4s\n","51:\tlearn: 0.1420797\ttotal: 24.1s\tremaining: 38.9s\n","52:\tlearn: 0.1420469\ttotal: 24.5s\tremaining: 38.3s\n","53:\tlearn: 0.1420038\ttotal: 24.9s\tremaining: 37.8s\n","54:\tlearn: 0.1419607\ttotal: 25.4s\tremaining: 37.3s\n","55:\tlearn: 0.1419202\ttotal: 25.7s\tremaining: 36.8s\n","56:\tlearn: 0.1418865\ttotal: 26.2s\tremaining: 36.3s\n","57:\tlearn: 0.1418373\ttotal: 26.6s\tremaining: 35.8s\n","58:\tlearn: 0.1418077\ttotal: 27s\tremaining: 35.3s\n","59:\tlearn: 0.1417767\ttotal: 27.7s\tremaining: 35s\n","60:\tlearn: 0.1417372\ttotal: 28.3s\tremaining: 34.8s\n","61:\tlearn: 0.1417105\ttotal: 28.8s\tremaining: 34.4s\n","62:\tlearn: 0.1416693\ttotal: 29.3s\tremaining: 33.9s\n","63:\tlearn: 0.1416297\ttotal: 29.6s\tremaining: 33.3s\n","64:\tlearn: 0.1415948\ttotal: 30s\tremaining: 32.7s\n","65:\tlearn: 0.1415606\ttotal: 30.3s\tremaining: 32.2s\n","66:\tlearn: 0.1415313\ttotal: 30.7s\tremaining: 31.6s\n","67:\tlearn: 0.1415050\ttotal: 31.1s\tremaining: 31.1s\n","68:\tlearn: 0.1414757\ttotal: 31.5s\tremaining: 30.6s\n","69:\tlearn: 0.1414407\ttotal: 31.9s\tremaining: 30s\n","70:\tlearn: 0.1414097\ttotal: 32.2s\tremaining: 29.5s\n","71:\tlearn: 0.1413719\ttotal: 32.7s\tremaining: 29.1s\n","72:\tlearn: 0.1413351\ttotal: 33s\tremaining: 28.5s\n","73:\tlearn: 0.1413054\ttotal: 33.5s\tremaining: 28s\n","74:\tlearn: 0.1412705\ttotal: 33.9s\tremaining: 27.6s\n","75:\tlearn: 0.1412445\ttotal: 34.3s\tremaining: 27.1s\n","76:\tlearn: 0.1412058\ttotal: 34.6s\tremaining: 26.5s\n","77:\tlearn: 0.1411780\ttotal: 34.9s\tremaining: 26s\n","78:\tlearn: 0.1411500\ttotal: 35.3s\tremaining: 25.4s\n","79:\tlearn: 0.1411246\ttotal: 35.6s\tremaining: 24.9s\n","80:\tlearn: 0.1410973\ttotal: 35.9s\tremaining: 24.4s\n","81:\tlearn: 0.1410655\ttotal: 36.4s\tremaining: 24s\n","82:\tlearn: 0.1410297\ttotal: 36.8s\tremaining: 23.5s\n","83:\tlearn: 0.1410039\ttotal: 37.1s\tremaining: 23s\n","84:\tlearn: 0.1409627\ttotal: 37.5s\tremaining: 22.5s\n","85:\tlearn: 0.1409381\ttotal: 37.9s\tremaining: 22s\n","86:\tlearn: 0.1409098\ttotal: 38.4s\tremaining: 21.6s\n","87:\tlearn: 0.1408797\ttotal: 38.8s\tremaining: 21.2s\n","88:\tlearn: 0.1408543\ttotal: 39.3s\tremaining: 20.8s\n","89:\tlearn: 0.1408177\ttotal: 39.9s\tremaining: 20.4s\n","90:\tlearn: 0.1407864\ttotal: 40.4s\tremaining: 20s\n","91:\tlearn: 0.1407599\ttotal: 40.7s\tremaining: 19.5s\n","92:\tlearn: 0.1407234\ttotal: 41.1s\tremaining: 19s\n","93:\tlearn: 0.1406766\ttotal: 41.6s\tremaining: 18.6s\n","94:\tlearn: 0.1406486\ttotal: 42s\tremaining: 18.1s\n","95:\tlearn: 0.1406239\ttotal: 42.4s\tremaining: 17.7s\n","96:\tlearn: 0.1405944\ttotal: 42.7s\tremaining: 17.2s\n","97:\tlearn: 0.1405659\ttotal: 43.2s\tremaining: 16.8s\n","98:\tlearn: 0.1405441\ttotal: 43.6s\tremaining: 16.3s\n","99:\tlearn: 0.1405109\ttotal: 44s\tremaining: 15.9s\n","100:\tlearn: 0.1404747\ttotal: 44.5s\tremaining: 15.4s\n","101:\tlearn: 0.1404508\ttotal: 44.8s\tremaining: 14.9s\n","102:\tlearn: 0.1404189\ttotal: 45.2s\tremaining: 14.5s\n","103:\tlearn: 0.1403899\ttotal: 45.7s\tremaining: 14s\n","104:\tlearn: 0.1403657\ttotal: 46s\tremaining: 13.6s\n","105:\tlearn: 0.1403378\ttotal: 46.4s\tremaining: 13.1s\n","106:\tlearn: 0.1403207\ttotal: 46.7s\tremaining: 12.7s\n","107:\tlearn: 0.1402901\ttotal: 47.2s\tremaining: 12.2s\n","108:\tlearn: 0.1402668\ttotal: 47.6s\tremaining: 11.8s\n","109:\tlearn: 0.1402418\ttotal: 48s\tremaining: 11.3s\n","110:\tlearn: 0.1402117\ttotal: 48.4s\tremaining: 10.9s\n","111:\tlearn: 0.1401800\ttotal: 48.8s\tremaining: 10.5s\n","112:\tlearn: 0.1401485\ttotal: 49.3s\tremaining: 10s\n","113:\tlearn: 0.1401252\ttotal: 49.6s\tremaining: 9.57s\n","114:\tlearn: 0.1400892\ttotal: 50.1s\tremaining: 9.14s\n","115:\tlearn: 0.1400682\ttotal: 50.5s\tremaining: 8.7s\n","116:\tlearn: 0.1400424\ttotal: 51s\tremaining: 8.29s\n","117:\tlearn: 0.1400115\ttotal: 51.6s\tremaining: 7.88s\n","118:\tlearn: 0.1399808\ttotal: 52.2s\tremaining: 7.46s\n","119:\tlearn: 0.1399610\ttotal: 52.6s\tremaining: 7.01s\n","120:\tlearn: 0.1399387\ttotal: 53s\tremaining: 6.57s\n","121:\tlearn: 0.1399107\ttotal: 53.4s\tremaining: 6.13s\n","122:\tlearn: 0.1398853\ttotal: 53.8s\tremaining: 5.68s\n","123:\tlearn: 0.1398572\ttotal: 54.2s\tremaining: 5.24s\n","124:\tlearn: 0.1398211\ttotal: 54.6s\tremaining: 4.81s\n","125:\tlearn: 0.1398006\ttotal: 55s\tremaining: 4.37s\n","126:\tlearn: 0.1397699\ttotal: 55.5s\tremaining: 3.93s\n","127:\tlearn: 0.1397492\ttotal: 55.8s\tremaining: 3.49s\n","128:\tlearn: 0.1397270\ttotal: 56.2s\tremaining: 3.05s\n","129:\tlearn: 0.1396973\ttotal: 56.6s\tremaining: 2.61s\n","130:\tlearn: 0.1396655\ttotal: 57.1s\tremaining: 2.18s\n","131:\tlearn: 0.1396388\ttotal: 57.4s\tremaining: 1.74s\n","132:\tlearn: 0.1396129\ttotal: 57.8s\tremaining: 1.3s\n","133:\tlearn: 0.1395935\ttotal: 58.1s\tremaining: 867ms\n","134:\tlearn: 0.1395666\ttotal: 58.5s\tremaining: 433ms\n","135:\tlearn: 0.1395447\ttotal: 58.8s\tremaining: 0us\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","train: 0.5\n","test: 0.5\n","test conf matrix: \n"," [[868014      0]\n"," [ 31986      0]]\n"]}]},{"cell_type":"code","source":["# с балансировкой\n","estimators = [\n","    ('lgbm', opt_model_lgbm),\n","    ('cb', opt_model_catb)\n","    ]\n","\n","reg = StackingClassifier(\n","    estimators=estimators,\n","    final_estimator=RandomForestClassifier(random_state=1, class_weight='balanced'))\n","\n","reg.fit(x_train_feat_sel, y_train)\n","pred_train = reg.predict(x_train_feat_sel)\n","pred_test = reg.predict(x_test_feat_sel)\n","\n","print(f'train: {roc_auc_score(y_train, pred_train)}')\n","print(f'test: {roc_auc_score(y_test, pred_test)}')\n","print(f'test conf matrix: \\n {confusion_matrix(y_test, pred_test)}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Tl0MbCCqdty4","executionInfo":{"status":"ok","timestamp":1708016075328,"user_tz":-240,"elapsed":1223702,"user":{"displayName":"Евгений Малов","userId":"06257165098392198337"}},"outputId":"a0cfbd9b-a12f-4fb1-c2ac-7d33c3e4a096"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 74456, number of negative: 2025544\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 2.244711 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 12750\n","[LightGBM] [Info] Number of data points in the train set: 2100000, number of used features: 50\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n","[LightGBM] [Info] Start training from score -0.000000\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","0:\tlearn: 0.6795174\ttotal: 965ms\tremaining: 2m 10s\n","1:\tlearn: 0.6690053\ttotal: 1.9s\tremaining: 2m 7s\n","2:\tlearn: 0.6620686\ttotal: 2.69s\tremaining: 1m 59s\n","3:\tlearn: 0.6561042\ttotal: 3.56s\tremaining: 1m 57s\n","4:\tlearn: 0.6515308\ttotal: 4.86s\tremaining: 2m 7s\n","5:\tlearn: 0.6481029\ttotal: 6.3s\tremaining: 2m 16s\n","6:\tlearn: 0.6449347\ttotal: 7.4s\tremaining: 2m 16s\n","7:\tlearn: 0.6423794\ttotal: 8.19s\tremaining: 2m 11s\n","8:\tlearn: 0.6403765\ttotal: 8.96s\tremaining: 2m 6s\n","9:\tlearn: 0.6386144\ttotal: 9.73s\tremaining: 2m 2s\n","10:\tlearn: 0.6369531\ttotal: 10.5s\tremaining: 1m 59s\n","11:\tlearn: 0.6356664\ttotal: 11.2s\tremaining: 1m 56s\n","12:\tlearn: 0.6343993\ttotal: 12.1s\tremaining: 1m 54s\n","13:\tlearn: 0.6334161\ttotal: 13s\tremaining: 1m 53s\n","14:\tlearn: 0.6323426\ttotal: 13.8s\tremaining: 1m 51s\n","15:\tlearn: 0.6314776\ttotal: 14.6s\tremaining: 1m 49s\n","16:\tlearn: 0.6307389\ttotal: 15.3s\tremaining: 1m 47s\n","17:\tlearn: 0.6295785\ttotal: 16.1s\tremaining: 1m 45s\n","18:\tlearn: 0.6287574\ttotal: 17s\tremaining: 1m 44s\n","19:\tlearn: 0.6280880\ttotal: 18.4s\tremaining: 1m 46s\n","20:\tlearn: 0.6274923\ttotal: 19.8s\tremaining: 1m 48s\n","21:\tlearn: 0.6268129\ttotal: 21s\tremaining: 1m 48s\n","22:\tlearn: 0.6261924\ttotal: 21.8s\tremaining: 1m 46s\n","23:\tlearn: 0.6255954\ttotal: 22.6s\tremaining: 1m 45s\n","24:\tlearn: 0.6252037\ttotal: 23.4s\tremaining: 1m 43s\n","25:\tlearn: 0.6247303\ttotal: 24.2s\tremaining: 1m 42s\n","26:\tlearn: 0.6242541\ttotal: 25s\tremaining: 1m 40s\n","27:\tlearn: 0.6238237\ttotal: 25.8s\tremaining: 1m 39s\n","28:\tlearn: 0.6233189\ttotal: 26.5s\tremaining: 1m 37s\n","29:\tlearn: 0.6228462\ttotal: 27.3s\tremaining: 1m 36s\n","30:\tlearn: 0.6223703\ttotal: 28.1s\tremaining: 1m 35s\n","31:\tlearn: 0.6220210\ttotal: 28.9s\tremaining: 1m 33s\n","32:\tlearn: 0.6216028\ttotal: 29.6s\tremaining: 1m 32s\n","33:\tlearn: 0.6212530\ttotal: 30.4s\tremaining: 1m 31s\n","34:\tlearn: 0.6209480\ttotal: 31.7s\tremaining: 1m 31s\n","35:\tlearn: 0.6204595\ttotal: 33.1s\tremaining: 1m 31s\n","36:\tlearn: 0.6200632\ttotal: 34.2s\tremaining: 1m 31s\n","37:\tlearn: 0.6197828\ttotal: 34.9s\tremaining: 1m 30s\n","38:\tlearn: 0.6195066\ttotal: 35.6s\tremaining: 1m 28s\n","39:\tlearn: 0.6191530\ttotal: 36.5s\tremaining: 1m 27s\n","40:\tlearn: 0.6186594\ttotal: 37.3s\tremaining: 1m 26s\n","41:\tlearn: 0.6183344\ttotal: 38.1s\tremaining: 1m 25s\n","42:\tlearn: 0.6181033\ttotal: 38.8s\tremaining: 1m 23s\n","43:\tlearn: 0.6178374\ttotal: 39.5s\tremaining: 1m 22s\n","44:\tlearn: 0.6175802\ttotal: 40.3s\tremaining: 1m 21s\n","45:\tlearn: 0.6172805\ttotal: 41.2s\tremaining: 1m 20s\n","46:\tlearn: 0.6170339\ttotal: 41.9s\tremaining: 1m 19s\n","47:\tlearn: 0.6167654\ttotal: 42.6s\tremaining: 1m 18s\n","48:\tlearn: 0.6164519\ttotal: 43.6s\tremaining: 1m 17s\n","49:\tlearn: 0.6161165\ttotal: 44.6s\tremaining: 1m 16s\n","50:\tlearn: 0.6157374\ttotal: 46.1s\tremaining: 1m 16s\n","51:\tlearn: 0.6155274\ttotal: 47.3s\tremaining: 1m 16s\n","52:\tlearn: 0.6151887\ttotal: 48.3s\tremaining: 1m 15s\n","53:\tlearn: 0.6149177\ttotal: 49.1s\tremaining: 1m 14s\n","54:\tlearn: 0.6146808\ttotal: 50s\tremaining: 1m 13s\n","55:\tlearn: 0.6144296\ttotal: 50.8s\tremaining: 1m 12s\n","56:\tlearn: 0.6141951\ttotal: 51.6s\tremaining: 1m 11s\n","57:\tlearn: 0.6139493\ttotal: 52.3s\tremaining: 1m 10s\n","58:\tlearn: 0.6137304\ttotal: 53.1s\tremaining: 1m 9s\n","59:\tlearn: 0.6134173\ttotal: 54s\tremaining: 1m 8s\n","60:\tlearn: 0.6132097\ttotal: 54.7s\tremaining: 1m 7s\n","61:\tlearn: 0.6130334\ttotal: 55.4s\tremaining: 1m 6s\n","62:\tlearn: 0.6128233\ttotal: 56.2s\tremaining: 1m 5s\n","63:\tlearn: 0.6126208\ttotal: 57s\tremaining: 1m 4s\n","64:\tlearn: 0.6124317\ttotal: 57.7s\tremaining: 1m 3s\n","65:\tlearn: 0.6121742\ttotal: 58.9s\tremaining: 1m 2s\n","66:\tlearn: 0.6119703\ttotal: 1m\tremaining: 1m 1s\n","67:\tlearn: 0.6117074\ttotal: 1m 1s\tremaining: 1m 1s\n","68:\tlearn: 0.6115077\ttotal: 1m 2s\tremaining: 1m\n","69:\tlearn: 0.6112747\ttotal: 1m 2s\tremaining: 59.3s\n","70:\tlearn: 0.6110441\ttotal: 1m 3s\tremaining: 58.3s\n","71:\tlearn: 0.6108292\ttotal: 1m 4s\tremaining: 57.3s\n","72:\tlearn: 0.6106024\ttotal: 1m 5s\tremaining: 56.3s\n","73:\tlearn: 0.6103452\ttotal: 1m 6s\tremaining: 55.4s\n","74:\tlearn: 0.6101420\ttotal: 1m 6s\tremaining: 54.3s\n","75:\tlearn: 0.6098558\ttotal: 1m 7s\tremaining: 53.4s\n","76:\tlearn: 0.6096291\ttotal: 1m 8s\tremaining: 52.4s\n","77:\tlearn: 0.6094114\ttotal: 1m 9s\tremaining: 51.4s\n","78:\tlearn: 0.6091851\ttotal: 1m 9s\tremaining: 50.4s\n","79:\tlearn: 0.6089477\ttotal: 1m 10s\tremaining: 49.4s\n","80:\tlearn: 0.6087201\ttotal: 1m 11s\tremaining: 48.4s\n","81:\tlearn: 0.6085025\ttotal: 1m 12s\tremaining: 47.8s\n","82:\tlearn: 0.6082358\ttotal: 1m 13s\tremaining: 47s\n","83:\tlearn: 0.6080515\ttotal: 1m 14s\tremaining: 46.3s\n","84:\tlearn: 0.6078056\ttotal: 1m 15s\tremaining: 45.3s\n","85:\tlearn: 0.6075512\ttotal: 1m 16s\tremaining: 44.4s\n","86:\tlearn: 0.6073632\ttotal: 1m 17s\tremaining: 43.4s\n","87:\tlearn: 0.6071242\ttotal: 1m 17s\tremaining: 42.5s\n","88:\tlearn: 0.6068947\ttotal: 1m 18s\tremaining: 41.5s\n","89:\tlearn: 0.6067236\ttotal: 1m 19s\tremaining: 40.6s\n","90:\tlearn: 0.6064810\ttotal: 1m 20s\tremaining: 39.6s\n","91:\tlearn: 0.6062272\ttotal: 1m 20s\tremaining: 38.7s\n","92:\tlearn: 0.6059896\ttotal: 1m 21s\tremaining: 37.8s\n","93:\tlearn: 0.6057492\ttotal: 1m 22s\tremaining: 36.8s\n","94:\tlearn: 0.6055352\ttotal: 1m 23s\tremaining: 35.9s\n","95:\tlearn: 0.6052353\ttotal: 1m 24s\tremaining: 35s\n","96:\tlearn: 0.6050181\ttotal: 1m 25s\tremaining: 34.2s\n","97:\tlearn: 0.6048075\ttotal: 1m 26s\tremaining: 33.5s\n","98:\tlearn: 0.6046142\ttotal: 1m 27s\tremaining: 32.7s\n","99:\tlearn: 0.6043952\ttotal: 1m 28s\tremaining: 31.9s\n","100:\tlearn: 0.6041729\ttotal: 1m 29s\tremaining: 30.9s\n","101:\tlearn: 0.6040035\ttotal: 1m 29s\tremaining: 30s\n","102:\tlearn: 0.6037330\ttotal: 1m 30s\tremaining: 29.1s\n","103:\tlearn: 0.6034852\ttotal: 1m 31s\tremaining: 28.2s\n","104:\tlearn: 0.6032777\ttotal: 1m 32s\tremaining: 27.3s\n","105:\tlearn: 0.6030951\ttotal: 1m 33s\tremaining: 26.3s\n","106:\tlearn: 0.6028848\ttotal: 1m 33s\tremaining: 25.4s\n","107:\tlearn: 0.6026684\ttotal: 1m 34s\tremaining: 24.5s\n","108:\tlearn: 0.6024816\ttotal: 1m 35s\tremaining: 23.6s\n","109:\tlearn: 0.6022745\ttotal: 1m 36s\tremaining: 22.7s\n","110:\tlearn: 0.6020732\ttotal: 1m 36s\tremaining: 21.8s\n","111:\tlearn: 0.6018677\ttotal: 1m 37s\tremaining: 20.9s\n","112:\tlearn: 0.6016514\ttotal: 1m 38s\tremaining: 20s\n","113:\tlearn: 0.6013978\ttotal: 1m 39s\tremaining: 19.3s\n","114:\tlearn: 0.6012050\ttotal: 1m 41s\tremaining: 18.5s\n","115:\tlearn: 0.6009918\ttotal: 1m 42s\tremaining: 17.6s\n","116:\tlearn: 0.6007666\ttotal: 1m 42s\tremaining: 16.7s\n","117:\tlearn: 0.6005931\ttotal: 1m 43s\tremaining: 15.8s\n","118:\tlearn: 0.6003714\ttotal: 1m 44s\tremaining: 14.9s\n","119:\tlearn: 0.6001779\ttotal: 1m 45s\tremaining: 14s\n","120:\tlearn: 0.6000178\ttotal: 1m 45s\tremaining: 13.1s\n","121:\tlearn: 0.5998143\ttotal: 1m 46s\tremaining: 12.2s\n","122:\tlearn: 0.5996068\ttotal: 1m 47s\tremaining: 11.3s\n","123:\tlearn: 0.5994245\ttotal: 1m 48s\tremaining: 10.5s\n","124:\tlearn: 0.5992401\ttotal: 1m 48s\tremaining: 9.57s\n","125:\tlearn: 0.5990397\ttotal: 1m 49s\tremaining: 8.69s\n","126:\tlearn: 0.5988365\ttotal: 1m 50s\tremaining: 7.81s\n","127:\tlearn: 0.5986417\ttotal: 1m 51s\tremaining: 6.94s\n","128:\tlearn: 0.5984701\ttotal: 1m 51s\tremaining: 6.06s\n","129:\tlearn: 0.5982644\ttotal: 1m 52s\tremaining: 5.21s\n","130:\tlearn: 0.5980754\ttotal: 1m 54s\tremaining: 4.36s\n","131:\tlearn: 0.5979286\ttotal: 1m 55s\tremaining: 3.49s\n","132:\tlearn: 0.5977562\ttotal: 1m 55s\tremaining: 2.61s\n","133:\tlearn: 0.5975374\ttotal: 1m 56s\tremaining: 1.74s\n","134:\tlearn: 0.5973460\ttotal: 1m 57s\tremaining: 871ms\n","135:\tlearn: 0.5971676\ttotal: 1m 58s\tremaining: 0us\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 59565, number of negative: 1620435\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 1.023932 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 12750\n","[LightGBM] [Info] Number of data points in the train set: 1680000, number of used features: 50\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n","[LightGBM] [Info] Start training from score 0.000000\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 59565, number of negative: 1620435\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 1.024216 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 12750\n","[LightGBM] [Info] Number of data points in the train set: 1680000, number of used features: 50\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n","[LightGBM] [Info] Start training from score 0.000000\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 59565, number of negative: 1620435\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 1.018899 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 12750\n","[LightGBM] [Info] Number of data points in the train set: 1680000, number of used features: 50\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n","[LightGBM] [Info] Start training from score 0.000000\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 59565, number of negative: 1620435\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 1.031716 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 12750\n","[LightGBM] [Info] Number of data points in the train set: 1680000, number of used features: 50\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n","[LightGBM] [Info] Start training from score 0.000000\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 59564, number of negative: 1620436\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 1.018623 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 12750\n","[LightGBM] [Info] Number of data points in the train set: 1680000, number of used features: 50\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n","[LightGBM] [Info] Start training from score -0.000000\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","0:\tlearn: 0.6795780\ttotal: 759ms\tremaining: 1m 42s\n","1:\tlearn: 0.6690960\ttotal: 1.47s\tremaining: 1m 38s\n","2:\tlearn: 0.6619266\ttotal: 2.44s\tremaining: 1m 48s\n","3:\tlearn: 0.6557394\ttotal: 3.61s\tremaining: 1m 59s\n","4:\tlearn: 0.6512337\ttotal: 4.79s\tremaining: 2m 5s\n","5:\tlearn: 0.6479172\ttotal: 5.55s\tremaining: 2m\n","6:\tlearn: 0.6450367\ttotal: 6.17s\tremaining: 1m 53s\n","7:\tlearn: 0.6425819\ttotal: 6.76s\tremaining: 1m 48s\n","8:\tlearn: 0.6402213\ttotal: 7.44s\tremaining: 1m 44s\n","9:\tlearn: 0.6383505\ttotal: 8.11s\tremaining: 1m 42s\n","10:\tlearn: 0.6368727\ttotal: 8.79s\tremaining: 1m 39s\n","11:\tlearn: 0.6353543\ttotal: 9.44s\tremaining: 1m 37s\n","12:\tlearn: 0.6340272\ttotal: 10.1s\tremaining: 1m 35s\n","13:\tlearn: 0.6330079\ttotal: 10.7s\tremaining: 1m 33s\n","14:\tlearn: 0.6320460\ttotal: 11.4s\tremaining: 1m 31s\n","15:\tlearn: 0.6309128\ttotal: 12.1s\tremaining: 1m 31s\n","16:\tlearn: 0.6300786\ttotal: 12.8s\tremaining: 1m 29s\n","17:\tlearn: 0.6292904\ttotal: 13.5s\tremaining: 1m 28s\n","18:\tlearn: 0.6285192\ttotal: 14.1s\tremaining: 1m 26s\n","19:\tlearn: 0.6278255\ttotal: 14.7s\tremaining: 1m 25s\n","20:\tlearn: 0.6270209\ttotal: 15.6s\tremaining: 1m 25s\n","21:\tlearn: 0.6263503\ttotal: 16.8s\tremaining: 1m 27s\n","22:\tlearn: 0.6256814\ttotal: 17.8s\tremaining: 1m 27s\n","23:\tlearn: 0.6250333\ttotal: 18.8s\tremaining: 1m 27s\n","24:\tlearn: 0.6245720\ttotal: 19.5s\tremaining: 1m 26s\n","25:\tlearn: 0.6240489\ttotal: 20.2s\tremaining: 1m 25s\n","26:\tlearn: 0.6234696\ttotal: 20.8s\tremaining: 1m 23s\n","27:\tlearn: 0.6229997\ttotal: 21.3s\tremaining: 1m 22s\n","28:\tlearn: 0.6224877\ttotal: 21.9s\tremaining: 1m 20s\n","29:\tlearn: 0.6220852\ttotal: 22.6s\tremaining: 1m 19s\n","30:\tlearn: 0.6216636\ttotal: 23.2s\tremaining: 1m 18s\n","31:\tlearn: 0.6212733\ttotal: 23.8s\tremaining: 1m 17s\n","32:\tlearn: 0.6209134\ttotal: 24.4s\tremaining: 1m 16s\n","33:\tlearn: 0.6204932\ttotal: 25s\tremaining: 1m 14s\n","34:\tlearn: 0.6201229\ttotal: 25.5s\tremaining: 1m 13s\n","35:\tlearn: 0.6197425\ttotal: 26.1s\tremaining: 1m 12s\n","36:\tlearn: 0.6193511\ttotal: 26.7s\tremaining: 1m 11s\n","37:\tlearn: 0.6188815\ttotal: 27.4s\tremaining: 1m 10s\n","38:\tlearn: 0.6184293\ttotal: 28s\tremaining: 1m 9s\n","39:\tlearn: 0.6180955\ttotal: 28.7s\tremaining: 1m 8s\n","40:\tlearn: 0.6178149\ttotal: 29.7s\tremaining: 1m 8s\n","41:\tlearn: 0.6175141\ttotal: 30.8s\tremaining: 1m 8s\n","42:\tlearn: 0.6171747\ttotal: 31.9s\tremaining: 1m 9s\n","43:\tlearn: 0.6168760\ttotal: 32.6s\tremaining: 1m 8s\n","44:\tlearn: 0.6165210\ttotal: 33.3s\tremaining: 1m 7s\n","45:\tlearn: 0.6162354\ttotal: 33.9s\tremaining: 1m 6s\n","46:\tlearn: 0.6158932\ttotal: 34.6s\tremaining: 1m 5s\n","47:\tlearn: 0.6156173\ttotal: 35.1s\tremaining: 1m 4s\n","48:\tlearn: 0.6152785\ttotal: 35.8s\tremaining: 1m 3s\n","49:\tlearn: 0.6149083\ttotal: 36.5s\tremaining: 1m 2s\n","50:\tlearn: 0.6146533\ttotal: 37.2s\tremaining: 1m 1s\n","51:\tlearn: 0.6143687\ttotal: 37.8s\tremaining: 1m 1s\n","52:\tlearn: 0.6140915\ttotal: 38.4s\tremaining: 1m\n","53:\tlearn: 0.6137632\ttotal: 39s\tremaining: 59.2s\n","54:\tlearn: 0.6135144\ttotal: 39.6s\tremaining: 58.3s\n","55:\tlearn: 0.6132756\ttotal: 40.2s\tremaining: 57.4s\n","56:\tlearn: 0.6129844\ttotal: 40.8s\tremaining: 56.6s\n","57:\tlearn: 0.6127783\ttotal: 41.4s\tremaining: 55.7s\n","58:\tlearn: 0.6125031\ttotal: 42s\tremaining: 54.8s\n","59:\tlearn: 0.6122249\ttotal: 43s\tremaining: 54.4s\n","60:\tlearn: 0.6119955\ttotal: 44.1s\tremaining: 54.2s\n","61:\tlearn: 0.6117962\ttotal: 44.9s\tremaining: 53.6s\n","62:\tlearn: 0.6114950\ttotal: 45.9s\tremaining: 53.2s\n","63:\tlearn: 0.6112792\ttotal: 46.5s\tremaining: 52.3s\n","64:\tlearn: 0.6110114\ttotal: 47.1s\tremaining: 51.4s\n","65:\tlearn: 0.6108176\ttotal: 47.6s\tremaining: 50.5s\n","66:\tlearn: 0.6105581\ttotal: 48.2s\tremaining: 49.7s\n","67:\tlearn: 0.6103599\ttotal: 48.8s\tremaining: 48.8s\n","68:\tlearn: 0.6101630\ttotal: 49.4s\tremaining: 48s\n","69:\tlearn: 0.6099532\ttotal: 50s\tremaining: 47.1s\n","70:\tlearn: 0.6097026\ttotal: 50.6s\tremaining: 46.3s\n","71:\tlearn: 0.6094391\ttotal: 51.3s\tremaining: 45.6s\n","72:\tlearn: 0.6092344\ttotal: 51.9s\tremaining: 44.8s\n","73:\tlearn: 0.6089362\ttotal: 52.6s\tremaining: 44.1s\n","74:\tlearn: 0.6087068\ttotal: 53.1s\tremaining: 43.2s\n","75:\tlearn: 0.6084412\ttotal: 53.7s\tremaining: 42.4s\n","76:\tlearn: 0.6081626\ttotal: 54.4s\tremaining: 41.7s\n","77:\tlearn: 0.6079041\ttotal: 55s\tremaining: 40.9s\n","78:\tlearn: 0.6076272\ttotal: 55.6s\tremaining: 40.1s\n","79:\tlearn: 0.6073201\ttotal: 56.8s\tremaining: 39.7s\n","80:\tlearn: 0.6070554\ttotal: 57.8s\tremaining: 39.2s\n","81:\tlearn: 0.6067113\ttotal: 59s\tremaining: 38.8s\n","82:\tlearn: 0.6064180\ttotal: 59.6s\tremaining: 38.1s\n","83:\tlearn: 0.6061447\ttotal: 1m\tremaining: 37.3s\n","84:\tlearn: 0.6058914\ttotal: 1m\tremaining: 36.5s\n","85:\tlearn: 0.6056180\ttotal: 1m 1s\tremaining: 35.7s\n","86:\tlearn: 0.6053441\ttotal: 1m 1s\tremaining: 34.9s\n","87:\tlearn: 0.6050802\ttotal: 1m 2s\tremaining: 34.1s\n","88:\tlearn: 0.6048182\ttotal: 1m 2s\tremaining: 33.3s\n","89:\tlearn: 0.6045455\ttotal: 1m 3s\tremaining: 32.5s\n","90:\tlearn: 0.6042777\ttotal: 1m 4s\tremaining: 31.8s\n","91:\tlearn: 0.6039838\ttotal: 1m 4s\tremaining: 31s\n","92:\tlearn: 0.6037196\ttotal: 1m 5s\tremaining: 30.3s\n","93:\tlearn: 0.6034288\ttotal: 1m 6s\tremaining: 29.6s\n","94:\tlearn: 0.6032154\ttotal: 1m 6s\tremaining: 28.8s\n","95:\tlearn: 0.6029337\ttotal: 1m 7s\tremaining: 28s\n","96:\tlearn: 0.6026820\ttotal: 1m 7s\tremaining: 27.3s\n","97:\tlearn: 0.6024324\ttotal: 1m 8s\tremaining: 26.5s\n","98:\tlearn: 0.6021545\ttotal: 1m 9s\tremaining: 25.9s\n","99:\tlearn: 0.6019003\ttotal: 1m 10s\tremaining: 25.2s\n","100:\tlearn: 0.6016363\ttotal: 1m 11s\tremaining: 24.6s\n","101:\tlearn: 0.6013930\ttotal: 1m 12s\tremaining: 24s\n","102:\tlearn: 0.6011716\ttotal: 1m 12s\tremaining: 23.4s\n","103:\tlearn: 0.6009112\ttotal: 1m 13s\tremaining: 22.6s\n","104:\tlearn: 0.6005781\ttotal: 1m 14s\tremaining: 21.9s\n","105:\tlearn: 0.6003302\ttotal: 1m 14s\tremaining: 21.2s\n","106:\tlearn: 0.6000823\ttotal: 1m 15s\tremaining: 20.4s\n","107:\tlearn: 0.5998551\ttotal: 1m 15s\tremaining: 19.7s\n","108:\tlearn: 0.5996317\ttotal: 1m 16s\tremaining: 18.9s\n","109:\tlearn: 0.5993081\ttotal: 1m 17s\tremaining: 18.2s\n","110:\tlearn: 0.5990656\ttotal: 1m 17s\tremaining: 17.5s\n","111:\tlearn: 0.5988204\ttotal: 1m 18s\tremaining: 16.8s\n","112:\tlearn: 0.5985550\ttotal: 1m 18s\tremaining: 16.1s\n","113:\tlearn: 0.5983209\ttotal: 1m 19s\tremaining: 15.4s\n","114:\tlearn: 0.5980435\ttotal: 1m 20s\tremaining: 14.7s\n","115:\tlearn: 0.5977550\ttotal: 1m 20s\tremaining: 14s\n","116:\tlearn: 0.5975144\ttotal: 1m 21s\tremaining: 13.2s\n","117:\tlearn: 0.5972903\ttotal: 1m 22s\tremaining: 12.5s\n","118:\tlearn: 0.5970752\ttotal: 1m 22s\tremaining: 11.8s\n","119:\tlearn: 0.5968815\ttotal: 1m 23s\tremaining: 11.2s\n","120:\tlearn: 0.5966861\ttotal: 1m 24s\tremaining: 10.5s\n","121:\tlearn: 0.5964823\ttotal: 1m 25s\tremaining: 9.83s\n","122:\tlearn: 0.5962619\ttotal: 1m 26s\tremaining: 9.13s\n","123:\tlearn: 0.5960382\ttotal: 1m 27s\tremaining: 8.43s\n","124:\tlearn: 0.5957646\ttotal: 1m 27s\tremaining: 7.72s\n","125:\tlearn: 0.5955395\ttotal: 1m 28s\tremaining: 7.01s\n","126:\tlearn: 0.5953211\ttotal: 1m 28s\tremaining: 6.3s\n","127:\tlearn: 0.5950934\ttotal: 1m 29s\tremaining: 5.59s\n","128:\tlearn: 0.5948298\ttotal: 1m 30s\tremaining: 4.89s\n","129:\tlearn: 0.5946276\ttotal: 1m 30s\tremaining: 4.18s\n","130:\tlearn: 0.5943866\ttotal: 1m 31s\tremaining: 3.48s\n","131:\tlearn: 0.5941712\ttotal: 1m 31s\tremaining: 2.78s\n","132:\tlearn: 0.5939367\ttotal: 1m 32s\tremaining: 2.08s\n","133:\tlearn: 0.5937210\ttotal: 1m 32s\tremaining: 1.39s\n","134:\tlearn: 0.5934644\ttotal: 1m 33s\tremaining: 693ms\n","135:\tlearn: 0.5932139\ttotal: 1m 34s\tremaining: 0us\n","0:\tlearn: 0.6796188\ttotal: 1.19s\tremaining: 2m 41s\n","1:\tlearn: 0.6692777\ttotal: 1.91s\tremaining: 2m 7s\n","2:\tlearn: 0.6618244\ttotal: 2.56s\tremaining: 1m 53s\n","3:\tlearn: 0.6564981\ttotal: 3.24s\tremaining: 1m 46s\n","4:\tlearn: 0.6522099\ttotal: 3.91s\tremaining: 1m 42s\n","5:\tlearn: 0.6485831\ttotal: 4.56s\tremaining: 1m 38s\n","6:\tlearn: 0.6459271\ttotal: 5.15s\tremaining: 1m 34s\n","7:\tlearn: 0.6432931\ttotal: 5.81s\tremaining: 1m 32s\n","8:\tlearn: 0.6411646\ttotal: 6.45s\tremaining: 1m 31s\n","9:\tlearn: 0.6391466\ttotal: 7.08s\tremaining: 1m 29s\n","10:\tlearn: 0.6374778\ttotal: 7.8s\tremaining: 1m 28s\n","11:\tlearn: 0.6361199\ttotal: 8.5s\tremaining: 1m 27s\n","12:\tlearn: 0.6349405\ttotal: 9.13s\tremaining: 1m 26s\n","13:\tlearn: 0.6338829\ttotal: 9.87s\tremaining: 1m 25s\n","14:\tlearn: 0.6329369\ttotal: 10.5s\tremaining: 1m 24s\n","15:\tlearn: 0.6318692\ttotal: 11.2s\tremaining: 1m 23s\n","16:\tlearn: 0.6308955\ttotal: 12.3s\tremaining: 1m 26s\n","17:\tlearn: 0.6298847\ttotal: 13.4s\tremaining: 1m 28s\n","18:\tlearn: 0.6291192\ttotal: 14.5s\tremaining: 1m 29s\n","19:\tlearn: 0.6283180\ttotal: 15.2s\tremaining: 1m 28s\n","20:\tlearn: 0.6276258\ttotal: 15.9s\tremaining: 1m 27s\n","21:\tlearn: 0.6270111\ttotal: 16.6s\tremaining: 1m 26s\n","22:\tlearn: 0.6264347\ttotal: 17.2s\tremaining: 1m 24s\n","23:\tlearn: 0.6259572\ttotal: 17.9s\tremaining: 1m 23s\n","24:\tlearn: 0.6253707\ttotal: 18.5s\tremaining: 1m 22s\n","25:\tlearn: 0.6247669\ttotal: 19.1s\tremaining: 1m 21s\n","26:\tlearn: 0.6242589\ttotal: 19.7s\tremaining: 1m 19s\n","27:\tlearn: 0.6237673\ttotal: 20.4s\tremaining: 1m 18s\n","28:\tlearn: 0.6233169\ttotal: 21s\tremaining: 1m 17s\n","29:\tlearn: 0.6228300\ttotal: 21.6s\tremaining: 1m 16s\n","30:\tlearn: 0.6224181\ttotal: 22.2s\tremaining: 1m 15s\n","31:\tlearn: 0.6218262\ttotal: 22.8s\tremaining: 1m 14s\n","32:\tlearn: 0.6213991\ttotal: 23.4s\tremaining: 1m 13s\n","33:\tlearn: 0.6208828\ttotal: 24.1s\tremaining: 1m 12s\n","34:\tlearn: 0.6204122\ttotal: 25.2s\tremaining: 1m 12s\n","35:\tlearn: 0.6201028\ttotal: 26.4s\tremaining: 1m 13s\n","36:\tlearn: 0.6197635\ttotal: 27.6s\tremaining: 1m 13s\n","37:\tlearn: 0.6194419\ttotal: 28.4s\tremaining: 1m 13s\n","38:\tlearn: 0.6189982\ttotal: 29.1s\tremaining: 1m 12s\n","39:\tlearn: 0.6186632\ttotal: 29.6s\tremaining: 1m 11s\n","40:\tlearn: 0.6183839\ttotal: 30.2s\tremaining: 1m 9s\n","41:\tlearn: 0.6180547\ttotal: 30.9s\tremaining: 1m 9s\n","42:\tlearn: 0.6177261\ttotal: 31.5s\tremaining: 1m 8s\n","43:\tlearn: 0.6173280\ttotal: 32.1s\tremaining: 1m 7s\n","44:\tlearn: 0.6170480\ttotal: 32.8s\tremaining: 1m 6s\n","45:\tlearn: 0.6166714\ttotal: 33.4s\tremaining: 1m 5s\n","46:\tlearn: 0.6163833\ttotal: 34.1s\tremaining: 1m 4s\n","47:\tlearn: 0.6161211\ttotal: 34.6s\tremaining: 1m 3s\n","48:\tlearn: 0.6158108\ttotal: 35.3s\tremaining: 1m 2s\n","49:\tlearn: 0.6154606\ttotal: 36s\tremaining: 1m 1s\n","50:\tlearn: 0.6151504\ttotal: 36.5s\tremaining: 1m\n","51:\tlearn: 0.6148661\ttotal: 37.1s\tremaining: 60s\n","52:\tlearn: 0.6146387\ttotal: 37.7s\tremaining: 59s\n","53:\tlearn: 0.6143611\ttotal: 38.4s\tremaining: 58.3s\n","54:\tlearn: 0.6141158\ttotal: 39.4s\tremaining: 58s\n","55:\tlearn: 0.6137557\ttotal: 40.4s\tremaining: 57.7s\n","56:\tlearn: 0.6135116\ttotal: 41.4s\tremaining: 57.4s\n","57:\tlearn: 0.6132948\ttotal: 42.1s\tremaining: 56.6s\n","58:\tlearn: 0.6130591\ttotal: 42.6s\tremaining: 55.6s\n","59:\tlearn: 0.6127765\ttotal: 43.1s\tremaining: 54.7s\n","60:\tlearn: 0.6125982\ttotal: 43.8s\tremaining: 53.8s\n","61:\tlearn: 0.6123947\ttotal: 44.4s\tremaining: 53s\n","62:\tlearn: 0.6120843\ttotal: 45.1s\tremaining: 52.2s\n","63:\tlearn: 0.6118509\ttotal: 45.7s\tremaining: 51.4s\n","64:\tlearn: 0.6115518\ttotal: 46.3s\tremaining: 50.6s\n","65:\tlearn: 0.6113079\ttotal: 46.9s\tremaining: 49.8s\n","66:\tlearn: 0.6110544\ttotal: 47.5s\tremaining: 49s\n","67:\tlearn: 0.6108147\ttotal: 48.1s\tremaining: 48.1s\n","68:\tlearn: 0.6105949\ttotal: 48.8s\tremaining: 47.4s\n","69:\tlearn: 0.6103548\ttotal: 49.3s\tremaining: 46.5s\n","70:\tlearn: 0.6101030\ttotal: 49.9s\tremaining: 45.7s\n","71:\tlearn: 0.6098870\ttotal: 50.4s\tremaining: 44.8s\n","72:\tlearn: 0.6096254\ttotal: 51.2s\tremaining: 44.1s\n","73:\tlearn: 0.6094174\ttotal: 51.8s\tremaining: 43.4s\n","74:\tlearn: 0.6091169\ttotal: 53s\tremaining: 43.1s\n","75:\tlearn: 0.6088447\ttotal: 54s\tremaining: 42.7s\n","76:\tlearn: 0.6085714\ttotal: 55s\tremaining: 42.1s\n","77:\tlearn: 0.6083152\ttotal: 55.6s\tremaining: 41.4s\n","78:\tlearn: 0.6080886\ttotal: 56.2s\tremaining: 40.5s\n","79:\tlearn: 0.6078093\ttotal: 56.9s\tremaining: 39.8s\n","80:\tlearn: 0.6075220\ttotal: 57.4s\tremaining: 39s\n","81:\tlearn: 0.6071965\ttotal: 58.1s\tremaining: 38.3s\n","82:\tlearn: 0.6069021\ttotal: 58.7s\tremaining: 37.5s\n","83:\tlearn: 0.6066000\ttotal: 59.3s\tremaining: 36.7s\n","84:\tlearn: 0.6062976\ttotal: 59.9s\tremaining: 35.9s\n","85:\tlearn: 0.6060429\ttotal: 1m\tremaining: 35.1s\n","86:\tlearn: 0.6057445\ttotal: 1m 1s\tremaining: 34.4s\n","87:\tlearn: 0.6054639\ttotal: 1m 1s\tremaining: 33.6s\n","88:\tlearn: 0.6051253\ttotal: 1m 2s\tremaining: 32.9s\n","89:\tlearn: 0.6048764\ttotal: 1m 2s\tremaining: 32.2s\n","90:\tlearn: 0.6046223\ttotal: 1m 3s\tremaining: 31.4s\n","91:\tlearn: 0.6043588\ttotal: 1m 4s\tremaining: 30.7s\n","92:\tlearn: 0.6040611\ttotal: 1m 4s\tremaining: 30s\n","93:\tlearn: 0.6037885\ttotal: 1m 5s\tremaining: 29.3s\n","94:\tlearn: 0.6035346\ttotal: 1m 6s\tremaining: 28.8s\n","95:\tlearn: 0.6032940\ttotal: 1m 7s\tremaining: 28.2s\n","96:\tlearn: 0.6030264\ttotal: 1m 8s\tremaining: 27.6s\n","97:\tlearn: 0.6027661\ttotal: 1m 9s\tremaining: 26.9s\n","98:\tlearn: 0.6024442\ttotal: 1m 9s\tremaining: 26.1s\n","99:\tlearn: 0.6022017\ttotal: 1m 10s\tremaining: 25.4s\n","100:\tlearn: 0.6019529\ttotal: 1m 11s\tremaining: 24.6s\n","101:\tlearn: 0.6017114\ttotal: 1m 11s\tremaining: 23.9s\n","102:\tlearn: 0.6014109\ttotal: 1m 12s\tremaining: 23.2s\n","103:\tlearn: 0.6011725\ttotal: 1m 12s\tremaining: 22.4s\n","104:\tlearn: 0.6009099\ttotal: 1m 13s\tremaining: 21.7s\n","105:\tlearn: 0.6006065\ttotal: 1m 14s\tremaining: 21s\n","106:\tlearn: 0.6003988\ttotal: 1m 14s\tremaining: 20.3s\n","107:\tlearn: 0.6001229\ttotal: 1m 15s\tremaining: 19.6s\n","108:\tlearn: 0.5998717\ttotal: 1m 16s\tremaining: 18.9s\n","109:\tlearn: 0.5996204\ttotal: 1m 16s\tremaining: 18.1s\n","110:\tlearn: 0.5993957\ttotal: 1m 17s\tremaining: 17.4s\n","111:\tlearn: 0.5991861\ttotal: 1m 17s\tremaining: 16.7s\n","112:\tlearn: 0.5989429\ttotal: 1m 18s\tremaining: 16s\n","113:\tlearn: 0.5987281\ttotal: 1m 19s\tremaining: 15.4s\n","114:\tlearn: 0.5984734\ttotal: 1m 20s\tremaining: 14.7s\n","115:\tlearn: 0.5982595\ttotal: 1m 21s\tremaining: 14.1s\n","116:\tlearn: 0.5980520\ttotal: 1m 22s\tremaining: 13.4s\n","117:\tlearn: 0.5977691\ttotal: 1m 23s\tremaining: 12.7s\n","118:\tlearn: 0.5975440\ttotal: 1m 23s\tremaining: 12s\n","119:\tlearn: 0.5972956\ttotal: 1m 24s\tremaining: 11.2s\n","120:\tlearn: 0.5970644\ttotal: 1m 24s\tremaining: 10.5s\n","121:\tlearn: 0.5968167\ttotal: 1m 25s\tremaining: 9.82s\n","122:\tlearn: 0.5965816\ttotal: 1m 26s\tremaining: 9.11s\n","123:\tlearn: 0.5963676\ttotal: 1m 26s\tremaining: 8.4s\n","124:\tlearn: 0.5961496\ttotal: 1m 27s\tremaining: 7.69s\n","125:\tlearn: 0.5959133\ttotal: 1m 28s\tremaining: 6.98s\n","126:\tlearn: 0.5956836\ttotal: 1m 28s\tremaining: 6.28s\n","127:\tlearn: 0.5954671\ttotal: 1m 29s\tremaining: 5.57s\n","128:\tlearn: 0.5952393\ttotal: 1m 29s\tremaining: 4.87s\n","129:\tlearn: 0.5950485\ttotal: 1m 30s\tremaining: 4.17s\n","130:\tlearn: 0.5948540\ttotal: 1m 30s\tremaining: 3.47s\n","131:\tlearn: 0.5946163\ttotal: 1m 31s\tremaining: 2.78s\n","132:\tlearn: 0.5943898\ttotal: 1m 32s\tremaining: 2.08s\n","133:\tlearn: 0.5941843\ttotal: 1m 33s\tremaining: 1.4s\n","134:\tlearn: 0.5939774\ttotal: 1m 34s\tremaining: 701ms\n","135:\tlearn: 0.5937514\ttotal: 1m 35s\tremaining: 0us\n","0:\tlearn: 0.6793648\ttotal: 767ms\tremaining: 1m 43s\n","1:\tlearn: 0.6691253\ttotal: 1.46s\tremaining: 1m 37s\n","2:\tlearn: 0.6617886\ttotal: 2.18s\tremaining: 1m 36s\n","3:\tlearn: 0.6562167\ttotal: 2.84s\tremaining: 1m 33s\n","4:\tlearn: 0.6522933\ttotal: 3.49s\tremaining: 1m 31s\n","5:\tlearn: 0.6484580\ttotal: 4.17s\tremaining: 1m 30s\n","6:\tlearn: 0.6456033\ttotal: 4.83s\tremaining: 1m 29s\n","7:\tlearn: 0.6430768\ttotal: 5.52s\tremaining: 1m 28s\n","8:\tlearn: 0.6410653\ttotal: 6.17s\tremaining: 1m 27s\n","9:\tlearn: 0.6392325\ttotal: 6.91s\tremaining: 1m 27s\n","10:\tlearn: 0.6373194\ttotal: 7.96s\tremaining: 1m 30s\n","11:\tlearn: 0.6359361\ttotal: 8.96s\tremaining: 1m 32s\n","12:\tlearn: 0.6345420\ttotal: 10s\tremaining: 1m 34s\n","13:\tlearn: 0.6333616\ttotal: 10.8s\tremaining: 1m 34s\n","14:\tlearn: 0.6324990\ttotal: 11.5s\tremaining: 1m 32s\n","15:\tlearn: 0.6314852\ttotal: 12.2s\tremaining: 1m 31s\n","16:\tlearn: 0.6303804\ttotal: 12.8s\tremaining: 1m 29s\n","17:\tlearn: 0.6296118\ttotal: 13.5s\tremaining: 1m 28s\n","18:\tlearn: 0.6287545\ttotal: 14.2s\tremaining: 1m 27s\n","19:\tlearn: 0.6280812\ttotal: 14.8s\tremaining: 1m 25s\n","20:\tlearn: 0.6274288\ttotal: 15.4s\tremaining: 1m 24s\n","21:\tlearn: 0.6266116\ttotal: 16.1s\tremaining: 1m 23s\n","22:\tlearn: 0.6259797\ttotal: 16.7s\tremaining: 1m 21s\n","23:\tlearn: 0.6252456\ttotal: 17.3s\tremaining: 1m 20s\n","24:\tlearn: 0.6246415\ttotal: 18s\tremaining: 1m 19s\n","25:\tlearn: 0.6241214\ttotal: 18.6s\tremaining: 1m 18s\n","26:\tlearn: 0.6236228\ttotal: 19.3s\tremaining: 1m 17s\n","27:\tlearn: 0.6231341\ttotal: 19.9s\tremaining: 1m 16s\n","28:\tlearn: 0.6225665\ttotal: 20.8s\tremaining: 1m 16s\n","29:\tlearn: 0.6221453\ttotal: 21.8s\tremaining: 1m 17s\n","30:\tlearn: 0.6217239\ttotal: 22.8s\tremaining: 1m 17s\n","31:\tlearn: 0.6213579\ttotal: 23.9s\tremaining: 1m 17s\n","32:\tlearn: 0.6207843\ttotal: 24.6s\tremaining: 1m 16s\n","33:\tlearn: 0.6204684\ttotal: 25.2s\tremaining: 1m 15s\n","34:\tlearn: 0.6200810\ttotal: 25.8s\tremaining: 1m 14s\n","35:\tlearn: 0.6197245\ttotal: 26.4s\tremaining: 1m 13s\n","36:\tlearn: 0.6193529\ttotal: 27s\tremaining: 1m 12s\n","37:\tlearn: 0.6190185\ttotal: 27.6s\tremaining: 1m 11s\n","38:\tlearn: 0.6185446\ttotal: 28.3s\tremaining: 1m 10s\n","39:\tlearn: 0.6181804\ttotal: 28.9s\tremaining: 1m 9s\n","40:\tlearn: 0.6177865\ttotal: 29.6s\tremaining: 1m 8s\n","41:\tlearn: 0.6174604\ttotal: 30.3s\tremaining: 1m 7s\n","42:\tlearn: 0.6171442\ttotal: 30.9s\tremaining: 1m 6s\n","43:\tlearn: 0.6168424\ttotal: 31.5s\tremaining: 1m 5s\n","44:\tlearn: 0.6165004\ttotal: 32.2s\tremaining: 1m 5s\n","45:\tlearn: 0.6162453\ttotal: 32.8s\tremaining: 1m 4s\n","46:\tlearn: 0.6159725\ttotal: 33.4s\tremaining: 1m 3s\n","47:\tlearn: 0.6156476\ttotal: 34.2s\tremaining: 1m 2s\n","48:\tlearn: 0.6153601\ttotal: 35.3s\tremaining: 1m 2s\n","49:\tlearn: 0.6151143\ttotal: 36.4s\tremaining: 1m 2s\n","50:\tlearn: 0.6148238\ttotal: 37.3s\tremaining: 1m 2s\n","51:\tlearn: 0.6145163\ttotal: 38s\tremaining: 1m 1s\n","52:\tlearn: 0.6142591\ttotal: 38.6s\tremaining: 1m\n","53:\tlearn: 0.6139950\ttotal: 39.1s\tremaining: 59.4s\n","54:\tlearn: 0.6137510\ttotal: 39.7s\tremaining: 58.5s\n","55:\tlearn: 0.6134750\ttotal: 40.4s\tremaining: 57.8s\n","56:\tlearn: 0.6131601\ttotal: 41s\tremaining: 56.8s\n","57:\tlearn: 0.6129044\ttotal: 41.6s\tremaining: 55.9s\n","58:\tlearn: 0.6126548\ttotal: 42.2s\tremaining: 55.1s\n","59:\tlearn: 0.6124395\ttotal: 42.9s\tremaining: 54.3s\n","60:\tlearn: 0.6122015\ttotal: 43.5s\tremaining: 53.5s\n","61:\tlearn: 0.6119554\ttotal: 44.1s\tremaining: 52.7s\n","62:\tlearn: 0.6117235\ttotal: 44.7s\tremaining: 51.8s\n","63:\tlearn: 0.6113968\ttotal: 45.3s\tremaining: 51s\n","64:\tlearn: 0.6111267\ttotal: 45.9s\tremaining: 50.1s\n","65:\tlearn: 0.6109027\ttotal: 46.5s\tremaining: 49.3s\n","66:\tlearn: 0.6106802\ttotal: 47.2s\tremaining: 48.6s\n","67:\tlearn: 0.6104046\ttotal: 48.3s\tremaining: 48.3s\n","68:\tlearn: 0.6101133\ttotal: 49.4s\tremaining: 48s\n","69:\tlearn: 0.6098776\ttotal: 50.5s\tremaining: 47.6s\n","70:\tlearn: 0.6095703\ttotal: 51.4s\tremaining: 47s\n","71:\tlearn: 0.6093033\ttotal: 51.9s\tremaining: 46.1s\n","72:\tlearn: 0.6090678\ttotal: 52.5s\tremaining: 45.3s\n","73:\tlearn: 0.6088020\ttotal: 53.1s\tremaining: 44.5s\n","74:\tlearn: 0.6085448\ttotal: 53.8s\tremaining: 43.8s\n","75:\tlearn: 0.6082869\ttotal: 54.4s\tremaining: 43s\n","76:\tlearn: 0.6080121\ttotal: 55s\tremaining: 42.1s\n","77:\tlearn: 0.6077691\ttotal: 55.5s\tremaining: 41.3s\n","78:\tlearn: 0.6074834\ttotal: 56.2s\tremaining: 40.6s\n","79:\tlearn: 0.6072354\ttotal: 56.9s\tremaining: 39.8s\n","80:\tlearn: 0.6069815\ttotal: 57.4s\tremaining: 39s\n","81:\tlearn: 0.6067074\ttotal: 58s\tremaining: 38.2s\n","82:\tlearn: 0.6064592\ttotal: 58.6s\tremaining: 37.4s\n","83:\tlearn: 0.6061408\ttotal: 59.3s\tremaining: 36.7s\n","84:\tlearn: 0.6058593\ttotal: 59.9s\tremaining: 35.9s\n","85:\tlearn: 0.6055693\ttotal: 1m\tremaining: 35.2s\n","86:\tlearn: 0.6053117\ttotal: 1m 1s\tremaining: 34.5s\n","87:\tlearn: 0.6050456\ttotal: 1m 2s\tremaining: 34s\n","88:\tlearn: 0.6047974\ttotal: 1m 3s\tremaining: 33.4s\n","89:\tlearn: 0.6044812\ttotal: 1m 4s\tremaining: 32.9s\n","90:\tlearn: 0.6042550\ttotal: 1m 4s\tremaining: 32.1s\n","91:\tlearn: 0.6039890\ttotal: 1m 5s\tremaining: 31.4s\n","92:\tlearn: 0.6037636\ttotal: 1m 6s\tremaining: 30.6s\n","93:\tlearn: 0.6035369\ttotal: 1m 6s\tremaining: 29.8s\n","94:\tlearn: 0.6032420\ttotal: 1m 7s\tremaining: 29s\n","95:\tlearn: 0.6029781\ttotal: 1m 7s\tremaining: 28.3s\n","96:\tlearn: 0.6027380\ttotal: 1m 8s\tremaining: 27.5s\n","97:\tlearn: 0.6024612\ttotal: 1m 9s\tremaining: 26.8s\n","98:\tlearn: 0.6022135\ttotal: 1m 9s\tremaining: 26s\n","99:\tlearn: 0.6020128\ttotal: 1m 10s\tremaining: 25.3s\n","100:\tlearn: 0.6017432\ttotal: 1m 10s\tremaining: 24.5s\n","101:\tlearn: 0.6014693\ttotal: 1m 11s\tremaining: 23.8s\n","102:\tlearn: 0.6011973\ttotal: 1m 11s\tremaining: 23.1s\n","103:\tlearn: 0.6009192\ttotal: 1m 12s\tremaining: 22.4s\n","104:\tlearn: 0.6006405\ttotal: 1m 13s\tremaining: 21.6s\n","105:\tlearn: 0.6004144\ttotal: 1m 13s\tremaining: 20.9s\n","106:\tlearn: 0.6001687\ttotal: 1m 14s\tremaining: 20.2s\n","107:\tlearn: 0.5999068\ttotal: 1m 15s\tremaining: 19.7s\n","108:\tlearn: 0.5996591\ttotal: 1m 16s\tremaining: 19s\n","109:\tlearn: 0.5993816\ttotal: 1m 18s\tremaining: 18.4s\n","110:\tlearn: 0.5991693\ttotal: 1m 18s\tremaining: 17.7s\n","111:\tlearn: 0.5989197\ttotal: 1m 19s\tremaining: 17s\n","112:\tlearn: 0.5986691\ttotal: 1m 19s\tremaining: 16.3s\n","113:\tlearn: 0.5984310\ttotal: 1m 20s\tremaining: 15.5s\n","114:\tlearn: 0.5982210\ttotal: 1m 21s\tremaining: 14.8s\n","115:\tlearn: 0.5979851\ttotal: 1m 21s\tremaining: 14.1s\n","116:\tlearn: 0.5977270\ttotal: 1m 22s\tremaining: 13.4s\n","117:\tlearn: 0.5974925\ttotal: 1m 22s\tremaining: 12.7s\n","118:\tlearn: 0.5972508\ttotal: 1m 23s\tremaining: 11.9s\n","119:\tlearn: 0.5970305\ttotal: 1m 24s\tremaining: 11.2s\n","120:\tlearn: 0.5968361\ttotal: 1m 24s\tremaining: 10.5s\n","121:\tlearn: 0.5966052\ttotal: 1m 25s\tremaining: 9.79s\n","122:\tlearn: 0.5964186\ttotal: 1m 25s\tremaining: 9.07s\n","123:\tlearn: 0.5962043\ttotal: 1m 26s\tremaining: 8.37s\n","124:\tlearn: 0.5959758\ttotal: 1m 27s\tremaining: 7.66s\n","125:\tlearn: 0.5957405\ttotal: 1m 27s\tremaining: 6.95s\n","126:\tlearn: 0.5955118\ttotal: 1m 28s\tremaining: 6.26s\n","127:\tlearn: 0.5952869\ttotal: 1m 29s\tremaining: 5.59s\n","128:\tlearn: 0.5950670\ttotal: 1m 30s\tremaining: 4.9s\n","129:\tlearn: 0.5948280\ttotal: 1m 31s\tremaining: 4.21s\n","130:\tlearn: 0.5945533\ttotal: 1m 32s\tremaining: 3.51s\n","131:\tlearn: 0.5942937\ttotal: 1m 32s\tremaining: 2.81s\n","132:\tlearn: 0.5940154\ttotal: 1m 33s\tremaining: 2.11s\n","133:\tlearn: 0.5937759\ttotal: 1m 34s\tremaining: 1.41s\n","134:\tlearn: 0.5935809\ttotal: 1m 34s\tremaining: 701ms\n","135:\tlearn: 0.5933547\ttotal: 1m 35s\tremaining: 0us\n","0:\tlearn: 0.6795623\ttotal: 747ms\tremaining: 1m 40s\n","1:\tlearn: 0.6693587\ttotal: 1.6s\tremaining: 1m 47s\n","2:\tlearn: 0.6620511\ttotal: 2.77s\tremaining: 2m 2s\n","3:\tlearn: 0.6563447\ttotal: 3.9s\tremaining: 2m 8s\n","4:\tlearn: 0.6523320\ttotal: 4.91s\tremaining: 2m 8s\n","5:\tlearn: 0.6487035\ttotal: 5.52s\tremaining: 1m 59s\n","6:\tlearn: 0.6457511\ttotal: 6.2s\tremaining: 1m 54s\n","7:\tlearn: 0.6432071\ttotal: 6.83s\tremaining: 1m 49s\n","8:\tlearn: 0.6413854\ttotal: 7.49s\tremaining: 1m 45s\n","9:\tlearn: 0.6394269\ttotal: 8.14s\tremaining: 1m 42s\n","10:\tlearn: 0.6377391\ttotal: 8.77s\tremaining: 1m 39s\n","11:\tlearn: 0.6362703\ttotal: 9.37s\tremaining: 1m 36s\n","12:\tlearn: 0.6350097\ttotal: 10s\tremaining: 1m 34s\n","13:\tlearn: 0.6336737\ttotal: 10.7s\tremaining: 1m 32s\n","14:\tlearn: 0.6327114\ttotal: 11.4s\tremaining: 1m 31s\n","15:\tlearn: 0.6316790\ttotal: 12.1s\tremaining: 1m 30s\n","16:\tlearn: 0.6308012\ttotal: 12.7s\tremaining: 1m 29s\n","17:\tlearn: 0.6300660\ttotal: 13.5s\tremaining: 1m 28s\n","18:\tlearn: 0.6292610\ttotal: 14s\tremaining: 1m 26s\n","19:\tlearn: 0.6285082\ttotal: 14.7s\tremaining: 1m 25s\n","20:\tlearn: 0.6277543\ttotal: 15.6s\tremaining: 1m 25s\n","21:\tlearn: 0.6271334\ttotal: 16.6s\tremaining: 1m 26s\n","22:\tlearn: 0.6265126\ttotal: 17.9s\tremaining: 1m 27s\n","23:\tlearn: 0.6258913\ttotal: 18.7s\tremaining: 1m 27s\n","24:\tlearn: 0.6253524\ttotal: 19.4s\tremaining: 1m 26s\n","25:\tlearn: 0.6248580\ttotal: 20.2s\tremaining: 1m 25s\n","26:\tlearn: 0.6243476\ttotal: 20.9s\tremaining: 1m 24s\n","27:\tlearn: 0.6238543\ttotal: 21.5s\tremaining: 1m 22s\n","28:\tlearn: 0.6232834\ttotal: 22.1s\tremaining: 1m 21s\n","29:\tlearn: 0.6227980\ttotal: 22.7s\tremaining: 1m 20s\n","30:\tlearn: 0.6223953\ttotal: 23.3s\tremaining: 1m 18s\n","31:\tlearn: 0.6218164\ttotal: 23.9s\tremaining: 1m 17s\n","32:\tlearn: 0.6213936\ttotal: 24.5s\tremaining: 1m 16s\n","33:\tlearn: 0.6208626\ttotal: 25.1s\tremaining: 1m 15s\n","34:\tlearn: 0.6204946\ttotal: 25.7s\tremaining: 1m 14s\n","35:\tlearn: 0.6201079\ttotal: 26.3s\tremaining: 1m 12s\n","36:\tlearn: 0.6197962\ttotal: 26.9s\tremaining: 1m 11s\n","37:\tlearn: 0.6193858\ttotal: 27.5s\tremaining: 1m 11s\n","38:\tlearn: 0.6188998\ttotal: 28.2s\tremaining: 1m 10s\n","39:\tlearn: 0.6186030\ttotal: 29.1s\tremaining: 1m 9s\n","40:\tlearn: 0.6182124\ttotal: 30.1s\tremaining: 1m 9s\n","41:\tlearn: 0.6178456\ttotal: 31.1s\tremaining: 1m 9s\n","42:\tlearn: 0.6175823\ttotal: 32.1s\tremaining: 1m 9s\n","43:\tlearn: 0.6171733\ttotal: 32.8s\tremaining: 1m 8s\n","44:\tlearn: 0.6168112\ttotal: 33.3s\tremaining: 1m 7s\n","45:\tlearn: 0.6164996\ttotal: 34s\tremaining: 1m 6s\n","46:\tlearn: 0.6162464\ttotal: 34.6s\tremaining: 1m 5s\n","47:\tlearn: 0.6159609\ttotal: 35.2s\tremaining: 1m 4s\n","48:\tlearn: 0.6156718\ttotal: 35.8s\tremaining: 1m 3s\n","49:\tlearn: 0.6153834\ttotal: 36.4s\tremaining: 1m 2s\n","50:\tlearn: 0.6150259\ttotal: 37s\tremaining: 1m 1s\n","51:\tlearn: 0.6147860\ttotal: 37.7s\tremaining: 1m\n","52:\tlearn: 0.6144898\ttotal: 38.3s\tremaining: 60s\n","53:\tlearn: 0.6142166\ttotal: 38.9s\tremaining: 59s\n","54:\tlearn: 0.6139083\ttotal: 39.4s\tremaining: 58.1s\n","55:\tlearn: 0.6135960\ttotal: 40.1s\tremaining: 57.2s\n","56:\tlearn: 0.6133472\ttotal: 40.7s\tremaining: 56.4s\n","57:\tlearn: 0.6131438\ttotal: 41.2s\tremaining: 55.5s\n","58:\tlearn: 0.6128987\ttotal: 41.8s\tremaining: 54.6s\n","59:\tlearn: 0.6126589\ttotal: 42.9s\tremaining: 54.3s\n","60:\tlearn: 0.6124501\ttotal: 44s\tremaining: 54.1s\n","61:\tlearn: 0.6122677\ttotal: 45s\tremaining: 53.7s\n","62:\tlearn: 0.6120416\ttotal: 45.7s\tremaining: 53s\n","63:\tlearn: 0.6118400\ttotal: 46.4s\tremaining: 52.2s\n","64:\tlearn: 0.6115985\ttotal: 47s\tremaining: 51.4s\n","65:\tlearn: 0.6113554\ttotal: 47.6s\tremaining: 50.5s\n","66:\tlearn: 0.6110126\ttotal: 48.3s\tremaining: 49.8s\n","67:\tlearn: 0.6107833\ttotal: 48.9s\tremaining: 48.9s\n","68:\tlearn: 0.6105592\ttotal: 49.5s\tremaining: 48.1s\n","69:\tlearn: 0.6103278\ttotal: 50.1s\tremaining: 47.3s\n","70:\tlearn: 0.6101278\ttotal: 50.7s\tremaining: 46.4s\n","71:\tlearn: 0.6098709\ttotal: 51.4s\tremaining: 45.7s\n","72:\tlearn: 0.6095733\ttotal: 52.1s\tremaining: 44.9s\n","73:\tlearn: 0.6092918\ttotal: 52.7s\tremaining: 44.2s\n","74:\tlearn: 0.6090499\ttotal: 53.3s\tremaining: 43.4s\n","75:\tlearn: 0.6088079\ttotal: 54s\tremaining: 42.6s\n","76:\tlearn: 0.6085785\ttotal: 54.6s\tremaining: 41.8s\n","77:\tlearn: 0.6082346\ttotal: 55.3s\tremaining: 41.1s\n","78:\tlearn: 0.6080087\ttotal: 56.4s\tremaining: 40.7s\n","79:\tlearn: 0.6077508\ttotal: 57.4s\tremaining: 40.2s\n","80:\tlearn: 0.6075175\ttotal: 58.4s\tremaining: 39.7s\n","81:\tlearn: 0.6072933\ttotal: 59.2s\tremaining: 39s\n","82:\tlearn: 0.6070121\ttotal: 59.8s\tremaining: 38.2s\n","83:\tlearn: 0.6067632\ttotal: 1m\tremaining: 37.4s\n","84:\tlearn: 0.6064615\ttotal: 1m 1s\tremaining: 36.7s\n","85:\tlearn: 0.6061738\ttotal: 1m 1s\tremaining: 35.9s\n","86:\tlearn: 0.6059493\ttotal: 1m 2s\tremaining: 35s\n","87:\tlearn: 0.6056899\ttotal: 1m 2s\tremaining: 34.2s\n","88:\tlearn: 0.6054405\ttotal: 1m 3s\tremaining: 33.4s\n","89:\tlearn: 0.6051838\ttotal: 1m 3s\tremaining: 32.6s\n","90:\tlearn: 0.6048389\ttotal: 1m 4s\tremaining: 31.9s\n","91:\tlearn: 0.6045217\ttotal: 1m 5s\tremaining: 31.3s\n","92:\tlearn: 0.6042745\ttotal: 1m 5s\tremaining: 30.5s\n","93:\tlearn: 0.6040219\ttotal: 1m 6s\tremaining: 29.7s\n","94:\tlearn: 0.6037611\ttotal: 1m 7s\tremaining: 29s\n","95:\tlearn: 0.6034646\ttotal: 1m 7s\tremaining: 28.2s\n","96:\tlearn: 0.6032053\ttotal: 1m 8s\tremaining: 27.5s\n","97:\tlearn: 0.6029417\ttotal: 1m 9s\tremaining: 26.9s\n","98:\tlearn: 0.6026341\ttotal: 1m 10s\tremaining: 26.3s\n","99:\tlearn: 0.6023927\ttotal: 1m 11s\tremaining: 25.7s\n","100:\tlearn: 0.6021293\ttotal: 1m 12s\tremaining: 25.1s\n","101:\tlearn: 0.6018520\ttotal: 1m 13s\tremaining: 24.4s\n","102:\tlearn: 0.6015657\ttotal: 1m 13s\tremaining: 23.6s\n","103:\tlearn: 0.6012823\ttotal: 1m 14s\tremaining: 22.9s\n","104:\tlearn: 0.6009679\ttotal: 1m 15s\tremaining: 22.2s\n","105:\tlearn: 0.6007706\ttotal: 1m 15s\tremaining: 21.4s\n","106:\tlearn: 0.6005068\ttotal: 1m 16s\tremaining: 20.7s\n","107:\tlearn: 0.6002169\ttotal: 1m 16s\tremaining: 19.9s\n","108:\tlearn: 0.5999462\ttotal: 1m 17s\tremaining: 19.2s\n","109:\tlearn: 0.5996896\ttotal: 1m 18s\tremaining: 18.5s\n","110:\tlearn: 0.5994834\ttotal: 1m 18s\tremaining: 17.7s\n","111:\tlearn: 0.5992211\ttotal: 1m 19s\tremaining: 17s\n","112:\tlearn: 0.5989800\ttotal: 1m 19s\tremaining: 16.3s\n","113:\tlearn: 0.5987718\ttotal: 1m 20s\tremaining: 15.5s\n","114:\tlearn: 0.5985375\ttotal: 1m 21s\tremaining: 14.8s\n","115:\tlearn: 0.5982823\ttotal: 1m 21s\tremaining: 14.1s\n","116:\tlearn: 0.5980446\ttotal: 1m 22s\tremaining: 13.4s\n","117:\tlearn: 0.5978070\ttotal: 1m 23s\tremaining: 12.7s\n","118:\tlearn: 0.5975782\ttotal: 1m 24s\tremaining: 12s\n","119:\tlearn: 0.5973363\ttotal: 1m 25s\tremaining: 11.4s\n","120:\tlearn: 0.5971079\ttotal: 1m 26s\tremaining: 10.7s\n","121:\tlearn: 0.5968883\ttotal: 1m 26s\tremaining: 9.95s\n","122:\tlearn: 0.5966712\ttotal: 1m 27s\tremaining: 9.22s\n","123:\tlearn: 0.5964056\ttotal: 1m 27s\tremaining: 8.51s\n","124:\tlearn: 0.5961793\ttotal: 1m 28s\tremaining: 7.79s\n","125:\tlearn: 0.5959233\ttotal: 1m 29s\tremaining: 7.08s\n","126:\tlearn: 0.5957031\ttotal: 1m 29s\tremaining: 6.36s\n","127:\tlearn: 0.5954640\ttotal: 1m 30s\tremaining: 5.65s\n","128:\tlearn: 0.5952482\ttotal: 1m 31s\tremaining: 4.94s\n","129:\tlearn: 0.5950099\ttotal: 1m 31s\tremaining: 4.24s\n","130:\tlearn: 0.5948185\ttotal: 1m 32s\tremaining: 3.52s\n","131:\tlearn: 0.5945892\ttotal: 1m 32s\tremaining: 2.81s\n","132:\tlearn: 0.5943866\ttotal: 1m 33s\tremaining: 2.11s\n","133:\tlearn: 0.5941774\ttotal: 1m 34s\tremaining: 1.4s\n","134:\tlearn: 0.5939858\ttotal: 1m 34s\tremaining: 701ms\n","135:\tlearn: 0.5937263\ttotal: 1m 35s\tremaining: 0us\n","0:\tlearn: 0.6794504\ttotal: 751ms\tremaining: 1m 41s\n","1:\tlearn: 0.6691771\ttotal: 1.45s\tremaining: 1m 37s\n","2:\tlearn: 0.6618153\ttotal: 2.14s\tremaining: 1m 34s\n","3:\tlearn: 0.6564579\ttotal: 2.81s\tremaining: 1m 32s\n","4:\tlearn: 0.6516976\ttotal: 3.44s\tremaining: 1m 30s\n","5:\tlearn: 0.6481436\ttotal: 4.08s\tremaining: 1m 28s\n","6:\tlearn: 0.6452729\ttotal: 4.76s\tremaining: 1m 27s\n","7:\tlearn: 0.6428403\ttotal: 5.41s\tremaining: 1m 26s\n","8:\tlearn: 0.6409559\ttotal: 6.02s\tremaining: 1m 25s\n","9:\tlearn: 0.6388240\ttotal: 6.71s\tremaining: 1m 24s\n","10:\tlearn: 0.6369990\ttotal: 7.4s\tremaining: 1m 24s\n","11:\tlearn: 0.6355619\ttotal: 8.06s\tremaining: 1m 23s\n","12:\tlearn: 0.6342898\ttotal: 8.72s\tremaining: 1m 22s\n","13:\tlearn: 0.6331461\ttotal: 9.4s\tremaining: 1m 21s\n","14:\tlearn: 0.6322583\ttotal: 10.5s\tremaining: 1m 24s\n","15:\tlearn: 0.6313559\ttotal: 11.6s\tremaining: 1m 26s\n","16:\tlearn: 0.6305239\ttotal: 12.7s\tremaining: 1m 28s\n","17:\tlearn: 0.6295517\ttotal: 13.4s\tremaining: 1m 27s\n","18:\tlearn: 0.6287388\ttotal: 14s\tremaining: 1m 26s\n","19:\tlearn: 0.6280987\ttotal: 14.6s\tremaining: 1m 24s\n","20:\tlearn: 0.6274693\ttotal: 15.2s\tremaining: 1m 23s\n","21:\tlearn: 0.6266956\ttotal: 15.8s\tremaining: 1m 22s\n","22:\tlearn: 0.6261687\ttotal: 16.5s\tremaining: 1m 21s\n","23:\tlearn: 0.6253927\ttotal: 17.2s\tremaining: 1m 20s\n","24:\tlearn: 0.6248181\ttotal: 17.9s\tremaining: 1m 19s\n","25:\tlearn: 0.6242302\ttotal: 18.5s\tremaining: 1m 18s\n","26:\tlearn: 0.6237195\ttotal: 19.1s\tremaining: 1m 17s\n","27:\tlearn: 0.6230954\ttotal: 19.8s\tremaining: 1m 16s\n","28:\tlearn: 0.6225975\ttotal: 20.4s\tremaining: 1m 15s\n","29:\tlearn: 0.6221050\ttotal: 21s\tremaining: 1m 14s\n","30:\tlearn: 0.6216284\ttotal: 21.6s\tremaining: 1m 13s\n","31:\tlearn: 0.6211974\ttotal: 22.2s\tremaining: 1m 12s\n","32:\tlearn: 0.6208199\ttotal: 22.8s\tremaining: 1m 11s\n","33:\tlearn: 0.6203931\ttotal: 23.8s\tremaining: 1m 11s\n","34:\tlearn: 0.6200227\ttotal: 24.8s\tremaining: 1m 11s\n","35:\tlearn: 0.6196265\ttotal: 25.8s\tremaining: 1m 11s\n","36:\tlearn: 0.6192552\ttotal: 26.9s\tremaining: 1m 11s\n","37:\tlearn: 0.6189276\ttotal: 27.5s\tremaining: 1m 10s\n","38:\tlearn: 0.6185321\ttotal: 28.1s\tremaining: 1m 9s\n","39:\tlearn: 0.6181955\ttotal: 28.7s\tremaining: 1m 8s\n","40:\tlearn: 0.6177267\ttotal: 29.4s\tremaining: 1m 8s\n","41:\tlearn: 0.6174484\ttotal: 30s\tremaining: 1m 7s\n","42:\tlearn: 0.6171140\ttotal: 30.7s\tremaining: 1m 6s\n","43:\tlearn: 0.6167579\ttotal: 31.3s\tremaining: 1m 5s\n","44:\tlearn: 0.6164433\ttotal: 31.9s\tremaining: 1m 4s\n","45:\tlearn: 0.6161299\ttotal: 32.5s\tremaining: 1m 3s\n","46:\tlearn: 0.6158084\ttotal: 33.1s\tremaining: 1m 2s\n","47:\tlearn: 0.6155454\ttotal: 33.8s\tremaining: 1m 1s\n","48:\tlearn: 0.6151314\ttotal: 34.4s\tremaining: 1m 1s\n","49:\tlearn: 0.6147780\ttotal: 35s\tremaining: 1m\n","50:\tlearn: 0.6144732\ttotal: 35.6s\tremaining: 59.4s\n","51:\tlearn: 0.6142449\ttotal: 36.2s\tremaining: 58.5s\n","52:\tlearn: 0.6138964\ttotal: 37s\tremaining: 58s\n","53:\tlearn: 0.6135739\ttotal: 38.2s\tremaining: 58s\n","54:\tlearn: 0.6133185\ttotal: 39.1s\tremaining: 57.7s\n","55:\tlearn: 0.6130812\ttotal: 40.1s\tremaining: 57.3s\n","56:\tlearn: 0.6127734\ttotal: 40.9s\tremaining: 56.6s\n","57:\tlearn: 0.6125162\ttotal: 41.5s\tremaining: 55.8s\n","58:\tlearn: 0.6123036\ttotal: 42.1s\tremaining: 54.9s\n","59:\tlearn: 0.6120581\ttotal: 42.7s\tremaining: 54s\n","60:\tlearn: 0.6118212\ttotal: 43.3s\tremaining: 53.2s\n","61:\tlearn: 0.6116086\ttotal: 43.8s\tremaining: 52.3s\n","62:\tlearn: 0.6112772\ttotal: 44.5s\tremaining: 51.5s\n","63:\tlearn: 0.6110051\ttotal: 45.2s\tremaining: 50.8s\n","64:\tlearn: 0.6107319\ttotal: 45.8s\tremaining: 50s\n","65:\tlearn: 0.6105329\ttotal: 46.4s\tremaining: 49.3s\n","66:\tlearn: 0.6103109\ttotal: 47s\tremaining: 48.4s\n","67:\tlearn: 0.6100534\ttotal: 47.6s\tremaining: 47.6s\n","68:\tlearn: 0.6098013\ttotal: 48.3s\tremaining: 46.9s\n","69:\tlearn: 0.6095347\ttotal: 49s\tremaining: 46.2s\n","70:\tlearn: 0.6092996\ttotal: 49.6s\tremaining: 45.4s\n","71:\tlearn: 0.6090781\ttotal: 50.2s\tremaining: 44.6s\n","72:\tlearn: 0.6088570\ttotal: 51.2s\tremaining: 44.2s\n","73:\tlearn: 0.6086616\ttotal: 52.2s\tremaining: 43.7s\n","74:\tlearn: 0.6084183\ttotal: 53.1s\tremaining: 43.2s\n","75:\tlearn: 0.6081173\ttotal: 54.1s\tremaining: 42.7s\n","76:\tlearn: 0.6079025\ttotal: 54.8s\tremaining: 42s\n","77:\tlearn: 0.6076265\ttotal: 55.4s\tremaining: 41.2s\n","78:\tlearn: 0.6073653\ttotal: 56.1s\tremaining: 40.5s\n","79:\tlearn: 0.6071172\ttotal: 56.8s\tremaining: 39.7s\n","80:\tlearn: 0.6068729\ttotal: 57.3s\tremaining: 38.9s\n","81:\tlearn: 0.6066182\ttotal: 57.9s\tremaining: 38.1s\n","82:\tlearn: 0.6063034\ttotal: 58.6s\tremaining: 37.4s\n","83:\tlearn: 0.6060447\ttotal: 59.2s\tremaining: 36.6s\n","84:\tlearn: 0.6057663\ttotal: 59.7s\tremaining: 35.8s\n","85:\tlearn: 0.6054991\ttotal: 1m\tremaining: 35s\n","86:\tlearn: 0.6052502\ttotal: 1m\tremaining: 34.2s\n","87:\tlearn: 0.6049661\ttotal: 1m 1s\tremaining: 33.5s\n","88:\tlearn: 0.6047002\ttotal: 1m 2s\tremaining: 32.8s\n","89:\tlearn: 0.6044343\ttotal: 1m 2s\tremaining: 32s\n","90:\tlearn: 0.6041388\ttotal: 1m 3s\tremaining: 31.3s\n","91:\tlearn: 0.6038885\ttotal: 1m 4s\tremaining: 30.6s\n","92:\tlearn: 0.6036059\ttotal: 1m 5s\tremaining: 30.1s\n","93:\tlearn: 0.6033277\ttotal: 1m 6s\tremaining: 29.6s\n","94:\tlearn: 0.6030713\ttotal: 1m 7s\tremaining: 29s\n","95:\tlearn: 0.6028113\ttotal: 1m 7s\tremaining: 28.2s\n","96:\tlearn: 0.6025408\ttotal: 1m 8s\tremaining: 27.5s\n","97:\tlearn: 0.6023120\ttotal: 1m 9s\tremaining: 26.8s\n","98:\tlearn: 0.6020691\ttotal: 1m 9s\tremaining: 26.1s\n","99:\tlearn: 0.6018090\ttotal: 1m 10s\tremaining: 25.3s\n","100:\tlearn: 0.6015780\ttotal: 1m 10s\tremaining: 24.6s\n","101:\tlearn: 0.6012801\ttotal: 1m 11s\tremaining: 23.8s\n","102:\tlearn: 0.6010012\ttotal: 1m 12s\tremaining: 23.1s\n","103:\tlearn: 0.6007568\ttotal: 1m 12s\tremaining: 22.4s\n","104:\tlearn: 0.6004556\ttotal: 1m 13s\tremaining: 21.7s\n","105:\tlearn: 0.6002060\ttotal: 1m 13s\tremaining: 20.9s\n","106:\tlearn: 0.5999276\ttotal: 1m 14s\tremaining: 20.2s\n","107:\tlearn: 0.5996853\ttotal: 1m 15s\tremaining: 19.5s\n","108:\tlearn: 0.5994281\ttotal: 1m 15s\tremaining: 18.8s\n","109:\tlearn: 0.5991901\ttotal: 1m 16s\tremaining: 18s\n","110:\tlearn: 0.5989533\ttotal: 1m 16s\tremaining: 17.3s\n","111:\tlearn: 0.5987239\ttotal: 1m 17s\tremaining: 16.7s\n","112:\tlearn: 0.5985510\ttotal: 1m 18s\tremaining: 16s\n","113:\tlearn: 0.5983380\ttotal: 1m 19s\tremaining: 15.4s\n","114:\tlearn: 0.5981072\ttotal: 1m 20s\tremaining: 14.8s\n","115:\tlearn: 0.5978662\ttotal: 1m 21s\tremaining: 14s\n","116:\tlearn: 0.5976236\ttotal: 1m 21s\tremaining: 13.3s\n","117:\tlearn: 0.5974076\ttotal: 1m 22s\tremaining: 12.6s\n","118:\tlearn: 0.5971289\ttotal: 1m 23s\tremaining: 11.9s\n","119:\tlearn: 0.5968837\ttotal: 1m 23s\tremaining: 11.2s\n","120:\tlearn: 0.5966493\ttotal: 1m 24s\tremaining: 10.4s\n","121:\tlearn: 0.5964073\ttotal: 1m 24s\tremaining: 9.74s\n","122:\tlearn: 0.5961675\ttotal: 1m 25s\tremaining: 9.03s\n","123:\tlearn: 0.5959362\ttotal: 1m 26s\tremaining: 8.33s\n","124:\tlearn: 0.5956968\ttotal: 1m 26s\tremaining: 7.63s\n","125:\tlearn: 0.5954511\ttotal: 1m 27s\tremaining: 6.93s\n","126:\tlearn: 0.5951983\ttotal: 1m 27s\tremaining: 6.24s\n","127:\tlearn: 0.5949642\ttotal: 1m 28s\tremaining: 5.54s\n","128:\tlearn: 0.5947197\ttotal: 1m 29s\tremaining: 4.85s\n","129:\tlearn: 0.5945186\ttotal: 1m 29s\tremaining: 4.15s\n","130:\tlearn: 0.5942985\ttotal: 1m 30s\tremaining: 3.45s\n","131:\tlearn: 0.5940166\ttotal: 1m 31s\tremaining: 2.78s\n","132:\tlearn: 0.5938131\ttotal: 1m 32s\tremaining: 2.09s\n","133:\tlearn: 0.5936016\ttotal: 1m 33s\tremaining: 1.4s\n","134:\tlearn: 0.5933799\ttotal: 1m 34s\tremaining: 699ms\n","135:\tlearn: 0.5931256\ttotal: 1m 35s\tremaining: 0us\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","train: 0.5016356798501505\n","test: 0.5010013988179738\n","test conf matrix: \n"," [[867093    921]\n"," [ 31888     98]]\n"]}]},{"cell_type":"markdown","source":["XGB Trial 48 finished with value: 0.7247609613978563 and parameters: {'max_depth': 8, 'learning_rate': 0.019440445008201374, 'n_estimators': 650}. Best is trial 48 with value: 0.7247609613978563."],"metadata":{"id":"szcLdOAuA_-K"}},{"cell_type":"code","source":["opt_model_xgb = XGBClassifier(max_depth=8, learning_rate=0.019440445008201374, n_estimators=650)\n","opt_model_xgb.fit(x_train_feat_sel, y_train)\n","\n","pred_train = opt_model_xgb.predict(x_train_feat_sel)\n","pred_test = opt_model_xgb.predict(x_test_feat_sel)\n","\n","print(f'train: {roc_auc_score(y_train, pred_train)}')\n","print(f'test: {roc_auc_score(y_test, pred_test)}')\n","print(f'test conf matrix: \\n {confusion_matrix(y_test, pred_test)}')"],"metadata":{"id":"a-uMJkS9vNE-","executionInfo":{"status":"ok","timestamp":1707737153242,"user_tz":-240,"elapsed":560266,"user":{"displayName":"Евгений Малов","userId":"06257165098392198337"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"ba68a9a2-9b03-43cd-ce2d-01232c3acadc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["train: 0.5011140117951506\n","test: 0.5001656139248932\n","test conf matrix: \n"," [[868003     11]\n"," [ 31975     11]]\n"]}]},{"cell_type":"markdown","source":["##Старое: обучение на 222 признаках"],"metadata":{"id":"9hYaTqmSKFHp"}},{"cell_type":"code","source":["x_train = pd.read_parquet(path + '/min_x_train.parquet').drop('id', axis=1)\n","x_test = pd.read_parquet(path + '/min_x_test.parquet').drop('id', axis=1)\n","y_train = pd.read_parquet(path + '/min_y_train.parquet').drop('id', axis=1)\n","y_test = pd.read_parquet(path + '/min_y_test.parquet').drop('id', axis=1)"],"metadata":{"id":"EFLij3pyVSg7","executionInfo":{"status":"ok","timestamp":1708683141035,"user_tz":-240,"elapsed":32012,"user":{"displayName":"Евгений Малов","userId":"06257165098392198337"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["x_train.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MEQy9KreAYAn","executionInfo":{"status":"ok","timestamp":1707405901847,"user_tz":-240,"elapsed":369,"user":{"displayName":"Евгений Малов","userId":"06257165098392198337"}},"outputId":"3db9b3cc-a02e-4df4-8828-5256502d9124"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(2100000, 220)"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["x_test.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"S3Rfis_-AYlr","executionInfo":{"status":"ok","timestamp":1707405904888,"user_tz":-240,"elapsed":345,"user":{"displayName":"Евгений Малов","userId":"06257165098392198337"}},"outputId":"46fdc02d-8dbb-4aae-bacc-956be75f3575"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(900000, 220)"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["model_log_reg = LogisticRegression()\n","model_log_reg.fit(x_train, y_train)\n","\n","pred_train = model_log_reg.predict(x_train)\n","pred_test = model_log_reg.predict(x_test)\n","\n","print(f'train: {roc_auc_score(y_train, pred_train)}')\n","print(f'test: {roc_auc_score(y_test, pred_test)}')\n","print(f'test conf matrix: \\n {confusion_matrix(y_test, pred_test)}')"],"metadata":{"id":"r-IgSOzruDeZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1707406098989,"user_tz":-240,"elapsed":118780,"user":{"displayName":"Евгений Малов","userId":"06257165098392198337"}},"outputId":"f59c9d94-1d4e-4431-a173-4fa6d1a91db1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["train: 0.5006086981473608\n","test: 0.5004318297530267\n","test conf matrix: \n"," [[867841    173]\n"," [ 31952     34]]\n"]}]},{"cell_type":"code","source":["model_lgbm = LGBMClassifier()\n","model_lgbm.fit(x_train, y_train)\n","\n","pred_train = model_lgbm.predict(x_train)\n","pred_test = model_lgbm.predict(x_test)\n","\n","print(f'train: {roc_auc_score(y_train, pred_train)}')\n","print(f'test: {roc_auc_score(y_test, pred_test)}')\n","print(f'test conf matrix: \\n {confusion_matrix(y_test, pred_test)}')"],"metadata":{"id":"wZBH6apVvRNq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1707406369646,"user_tz":-240,"elapsed":178597,"user":{"displayName":"Евгений Малов","userId":"06257165098392198337"}},"outputId":"bcff0847-13c7-49fd-928b-2555780b86fa"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[LightGBM] [Info] Number of positive: 74456, number of negative: 2025544\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 5.665577 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 3878\n","[LightGBM] [Info] Number of data points in the train set: 2100000, number of used features: 219\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.035455 -> initscore=-3.303385\n","[LightGBM] [Info] Start training from score -3.303385\n","train: 0.5000791034226854\n","test: 0.5000457434616374\n","test conf matrix: \n"," [[868012      2]\n"," [ 31983      3]]\n"]}]},{"cell_type":"code","source":["# с балансировкой классов\n","model_lgbm = LGBMClassifier(class_weight='balanced')\n","model_lgbm.fit(x_train, y_train)\n","\n","pred_train = model_lgbm.predict(x_train)\n","pred_test = model_lgbm.predict(x_test)\n","\n","print(f'train: {roc_auc_score(y_train, pred_train)}')\n","print(f'test: {roc_auc_score(y_test, pred_test)}')\n","print(f'test conf matrix: \\n {confusion_matrix(y_test, pred_test)}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QhINBAbSGr0v","executionInfo":{"status":"ok","timestamp":1708683611086,"user_tz":-240,"elapsed":183414,"user":{"displayName":"Евгений Малов","userId":"06257165098392198337"}},"outputId":"f9b2a2e3-779f-49b9-c3e7-379858815424"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["[LightGBM] [Info] Number of positive: 74456, number of negative: 2025544\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 6.811692 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 3878\n","[LightGBM] [Info] Number of data points in the train set: 2100000, number of used features: 219\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n","[LightGBM] [Info] Start training from score -0.000000\n","train: 0.6877738625212068\n","test: 0.6796169973913594\n","test conf matrix: \n"," [[572474 295540]\n"," [  9605  22381]]\n"]}]},{"cell_type":"code","source":["model_xbm = XGBClassifier()\n","model_xbm.fit(x_train, y_train)\n","\n","pred_train = model_xbm.predict(x_train)\n","pred_test = model_xbm.predict(x_test)\n","\n","print(f'train: {roc_auc_score(y_train, pred_train)}')\n","print(f'test: {roc_auc_score(y_test, pred_test)}')\n","print(f'test conf matrix: \\n {confusion_matrix(y_test, pred_test)}')"],"metadata":{"id":"mycqwVHavRRm","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1707406537316,"user_tz":-240,"elapsed":161700,"user":{"displayName":"Евгений Малов","userId":"06257165098392198337"}},"outputId":"06397da1-a849-4b2e-ff7e-b9d09faa4e8f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["train: 0.5024124523946121\n","test: 0.5007152696808949\n","test conf matrix: \n"," [[867926     88]\n"," [ 31937     49]]\n"]}]},{"cell_type":"code","source":["y_train.value_counts()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4oFTCGk_is3R","executionInfo":{"status":"ok","timestamp":1708684687227,"user_tz":-240,"elapsed":315,"user":{"displayName":"Евгений Малов","userId":"06257165098392198337"}},"outputId":"61a3dfae-9763-444a-c26a-9102474db62b"},"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["flag\n","0       2025544\n","1         74456\n","dtype: int64"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["2025544/74456"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zGjPOxSJjhyN","executionInfo":{"status":"ok","timestamp":1708684901248,"user_tz":-240,"elapsed":289,"user":{"displayName":"Евгений Малов","userId":"06257165098392198337"}},"outputId":"1eb6ae0f-9bf5-4720-b92a-32c9c36d33c8"},"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["27.204577199957022"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["# с балансировкой классов\n","model_xbm = XGBClassifier(scale_pos_weight=27)\n","model_xbm.fit(x_train, y_train)\n","\n","pred_train = model_xbm.predict(x_train)\n","pred_test = model_xbm.predict(x_test)\n","\n","print(f'train: {roc_auc_score(y_train, pred_train)}')\n","print(f'test: {roc_auc_score(y_test, pred_test)}')\n","print(f'test conf matrix: \\n {confusion_matrix(y_test, pred_test)}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rcar6ToIIgIA","executionInfo":{"status":"ok","timestamp":1708685096488,"user_tz":-240,"elapsed":161523,"user":{"displayName":"Евгений Малов","userId":"06257165098392198337"}},"outputId":"f4fecfa9-0338-4d63-8afb-7eb7bf9bd9aa"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["train: 0.7121864315800754\n","test: 0.6766989042557745\n","test conf matrix: \n"," [[600787 267227]\n"," [ 10835  21151]]\n"]}]},{"cell_type":"code","source":["model_catb = CatBoostClassifier()\n","model_catb.fit(x_train, y_train)\n","\n","pred_train = model_catb.predict(x_train)\n","pred_test = model_catb.predict(x_test)\n","\n","print(f'train: {roc_auc_score(y_train, pred_train)}')\n","print(f'test: {roc_auc_score(y_test, pred_test)}')\n","print(f'test conf matrix: \\n {confusion_matrix(y_test, pred_test)}')"],"metadata":{"id":"P1TJfk5YFWrV","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1707408121563,"user_tz":-240,"elapsed":178613,"user":{"displayName":"Евгений Малов","userId":"06257165098392198337"}},"outputId":"f5af858b-7abb-46c9-f85a-0d23f8cbd463"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Learning rate set to 0.270098\n","0:\tlearn: 0.3741723\ttotal: 1.3s\tremaining: 21m 40s\n","1:\tlearn: 0.2473445\ttotal: 2.29s\tremaining: 19m 3s\n","2:\tlearn: 0.1934488\ttotal: 3.67s\tremaining: 20m 18s\n","3:\tlearn: 0.1691090\ttotal: 5.09s\tremaining: 21m 8s\n","4:\tlearn: 0.1575900\ttotal: 6.74s\tremaining: 22m 21s\n","5:\tlearn: 0.1520792\ttotal: 9.21s\tremaining: 25m 25s\n","6:\tlearn: 0.1488467\ttotal: 11.7s\tremaining: 27m 45s\n","7:\tlearn: 0.1472151\ttotal: 13.3s\tremaining: 27m 24s\n","8:\tlearn: 0.1462331\ttotal: 14.7s\tremaining: 26m 58s\n","9:\tlearn: 0.1454603\ttotal: 16.3s\tremaining: 26m 52s\n","10:\tlearn: 0.1448576\ttotal: 18s\tremaining: 26m 57s\n","11:\tlearn: 0.1444927\ttotal: 19.6s\tremaining: 26m 51s\n","12:\tlearn: 0.1439314\ttotal: 21.4s\tremaining: 27m 6s\n","13:\tlearn: 0.1437106\ttotal: 24.3s\tremaining: 28m 32s\n","14:\tlearn: 0.1434507\ttotal: 26.3s\tremaining: 28m 45s\n","15:\tlearn: 0.1432514\ttotal: 28.1s\tremaining: 28m 46s\n","16:\tlearn: 0.1431429\ttotal: 29.3s\tremaining: 28m 13s\n","17:\tlearn: 0.1430065\ttotal: 30.6s\tremaining: 27m 48s\n","18:\tlearn: 0.1428924\ttotal: 32.1s\tremaining: 27m 36s\n","19:\tlearn: 0.1427020\ttotal: 33.7s\tremaining: 27m 33s\n","20:\tlearn: 0.1425464\ttotal: 35.1s\tremaining: 27m 17s\n","21:\tlearn: 0.1424226\ttotal: 37.3s\tremaining: 27m 38s\n","22:\tlearn: 0.1423175\ttotal: 39.4s\tremaining: 27m 55s\n","23:\tlearn: 0.1421502\ttotal: 41.2s\tremaining: 27m 56s\n","24:\tlearn: 0.1420666\ttotal: 42.5s\tremaining: 27m 36s\n","25:\tlearn: 0.1420021\ttotal: 43.8s\tremaining: 27m 19s\n","26:\tlearn: 0.1418798\ttotal: 45.4s\tremaining: 27m 17s\n","27:\tlearn: 0.1417438\ttotal: 47.3s\tremaining: 27m 22s\n","28:\tlearn: 0.1416623\ttotal: 48.7s\tremaining: 27m 10s\n","29:\tlearn: 0.1416007\ttotal: 50.5s\tremaining: 27m 13s\n","30:\tlearn: 0.1414989\ttotal: 53.6s\tremaining: 27m 55s\n","31:\tlearn: 0.1414176\ttotal: 55s\tremaining: 27m 44s\n","32:\tlearn: 0.1413550\ttotal: 56.7s\tremaining: 27m 40s\n","33:\tlearn: 0.1412881\ttotal: 58.5s\tremaining: 27m 42s\n","34:\tlearn: 0.1412192\ttotal: 1m\tremaining: 27m 49s\n","35:\tlearn: 0.1411894\ttotal: 1m 1s\tremaining: 27m 38s\n","36:\tlearn: 0.1411453\ttotal: 1m 3s\tremaining: 27m 23s\n","37:\tlearn: 0.1411064\ttotal: 1m 5s\tremaining: 27m 35s\n","38:\tlearn: 0.1410556\ttotal: 1m 7s\tremaining: 27m 48s\n","39:\tlearn: 0.1410224\ttotal: 1m 8s\tremaining: 27m 32s\n","40:\tlearn: 0.1409853\ttotal: 1m 10s\tremaining: 27m 21s\n","41:\tlearn: 0.1409189\ttotal: 1m 11s\tremaining: 27m 15s\n","42:\tlearn: 0.1408448\ttotal: 1m 13s\tremaining: 27m 12s\n","43:\tlearn: 0.1407476\ttotal: 1m 15s\tremaining: 27m 10s\n","44:\tlearn: 0.1407139\ttotal: 1m 16s\tremaining: 27m 4s\n","45:\tlearn: 0.1406647\ttotal: 1m 18s\tremaining: 27m 9s\n","46:\tlearn: 0.1406116\ttotal: 1m 20s\tremaining: 27m 21s\n","47:\tlearn: 0.1405687\ttotal: 1m 22s\tremaining: 27m 21s\n","48:\tlearn: 0.1405303\ttotal: 1m 24s\tremaining: 27m 17s\n","49:\tlearn: 0.1404914\ttotal: 1m 26s\tremaining: 27m 19s\n","50:\tlearn: 0.1404501\ttotal: 1m 27s\tremaining: 27m 14s\n","51:\tlearn: 0.1404141\ttotal: 1m 29s\tremaining: 27m 3s\n","52:\tlearn: 0.1403733\ttotal: 1m 30s\tremaining: 26m 55s\n","53:\tlearn: 0.1403260\ttotal: 1m 32s\tremaining: 26m 56s\n","54:\tlearn: 0.1402857\ttotal: 1m 34s\tremaining: 27m 10s\n","55:\tlearn: 0.1402357\ttotal: 1m 36s\tremaining: 27m 13s\n","56:\tlearn: 0.1401952\ttotal: 1m 38s\tremaining: 27m 11s\n","57:\tlearn: 0.1401682\ttotal: 1m 39s\tremaining: 27m 4s\n","58:\tlearn: 0.1401199\ttotal: 1m 41s\tremaining: 26m 59s\n","59:\tlearn: 0.1400765\ttotal: 1m 43s\tremaining: 26m 59s\n","60:\tlearn: 0.1400356\ttotal: 1m 45s\tremaining: 26m 57s\n","61:\tlearn: 0.1400159\ttotal: 1m 47s\tremaining: 26m 59s\n","62:\tlearn: 0.1399767\ttotal: 1m 49s\tremaining: 27m 10s\n","63:\tlearn: 0.1399589\ttotal: 1m 50s\tremaining: 27m\n","64:\tlearn: 0.1399318\ttotal: 1m 51s\tremaining: 26m 50s\n","65:\tlearn: 0.1399140\ttotal: 1m 53s\tremaining: 26m 44s\n","66:\tlearn: 0.1398989\ttotal: 1m 54s\tremaining: 26m 37s\n","67:\tlearn: 0.1398887\ttotal: 1m 55s\tremaining: 26m 26s\n","68:\tlearn: 0.1398715\ttotal: 1m 56s\tremaining: 26m 18s\n","69:\tlearn: 0.1398455\ttotal: 1m 58s\tremaining: 26m 12s\n","70:\tlearn: 0.1398324\ttotal: 1m 59s\tremaining: 26m 2s\n","71:\tlearn: 0.1398054\ttotal: 2m 1s\tremaining: 26m 4s\n","72:\tlearn: 0.1397957\ttotal: 2m 3s\tremaining: 26m 5s\n","73:\tlearn: 0.1397608\ttotal: 2m 4s\tremaining: 26m 4s\n","74:\tlearn: 0.1397328\ttotal: 2m 6s\tremaining: 26m 2s\n","75:\tlearn: 0.1397185\ttotal: 2m 7s\tremaining: 25m 53s\n","76:\tlearn: 0.1396932\ttotal: 2m 9s\tremaining: 25m 50s\n","77:\tlearn: 0.1396694\ttotal: 2m 11s\tremaining: 25m 49s\n","78:\tlearn: 0.1396344\ttotal: 2m 12s\tremaining: 25m 44s\n","79:\tlearn: 0.1396104\ttotal: 2m 13s\tremaining: 25m 39s\n","80:\tlearn: 0.1395724\ttotal: 2m 16s\tremaining: 25m 49s\n","81:\tlearn: 0.1395495\ttotal: 2m 18s\tremaining: 25m 48s\n","82:\tlearn: 0.1395311\ttotal: 2m 19s\tremaining: 25m 42s\n","83:\tlearn: 0.1395225\ttotal: 2m 20s\tremaining: 25m 35s\n","84:\tlearn: 0.1395076\ttotal: 2m 21s\tremaining: 25m 27s\n","85:\tlearn: 0.1394651\ttotal: 2m 23s\tremaining: 25m 26s\n","86:\tlearn: 0.1394445\ttotal: 2m 25s\tremaining: 25m 23s\n","87:\tlearn: 0.1394275\ttotal: 2m 26s\tremaining: 25m 19s\n","88:\tlearn: 0.1393977\ttotal: 2m 28s\tremaining: 25m 23s\n","89:\tlearn: 0.1393613\ttotal: 2m 31s\tremaining: 25m 31s\n","90:\tlearn: 0.1393418\ttotal: 2m 32s\tremaining: 25m 28s\n","91:\tlearn: 0.1393258\ttotal: 2m 34s\tremaining: 25m 21s\n","92:\tlearn: 0.1392972\ttotal: 2m 35s\tremaining: 25m 17s\n","93:\tlearn: 0.1392604\ttotal: 2m 37s\tremaining: 25m 17s\n","94:\tlearn: 0.1392234\ttotal: 2m 39s\tremaining: 25m 16s\n","95:\tlearn: 0.1391975\ttotal: 2m 40s\tremaining: 25m 14s\n","96:\tlearn: 0.1391786\ttotal: 2m 42s\tremaining: 25m 9s\n","97:\tlearn: 0.1391667\ttotal: 2m 44s\tremaining: 25m 11s\n","98:\tlearn: 0.1391451\ttotal: 2m 46s\tremaining: 25m 14s\n","99:\tlearn: 0.1391315\ttotal: 2m 47s\tremaining: 25m 10s\n","100:\tlearn: 0.1391303\ttotal: 2m 48s\tremaining: 25m 3s\n","101:\tlearn: 0.1391210\ttotal: 2m 50s\tremaining: 24m 58s\n","102:\tlearn: 0.1390992\ttotal: 2m 51s\tremaining: 24m 57s\n","103:\tlearn: 0.1390832\ttotal: 2m 53s\tremaining: 24m 53s\n","104:\tlearn: 0.1390513\ttotal: 2m 55s\tremaining: 24m 54s\n","105:\tlearn: 0.1390338\ttotal: 2m 57s\tremaining: 24m 59s\n","106:\tlearn: 0.1390123\ttotal: 3m\tremaining: 25m 6s\n","107:\tlearn: 0.1389933\ttotal: 3m 1s\tremaining: 25m 2s\n","108:\tlearn: 0.1389888\ttotal: 3m 2s\tremaining: 24m 55s\n","109:\tlearn: 0.1389703\ttotal: 3m 4s\tremaining: 24m 49s\n","110:\tlearn: 0.1389684\ttotal: 3m 5s\tremaining: 24m 42s\n","111:\tlearn: 0.1389406\ttotal: 3m 6s\tremaining: 24m 38s\n","112:\tlearn: 0.1389282\ttotal: 3m 7s\tremaining: 24m 35s\n","113:\tlearn: 0.1389019\ttotal: 3m 9s\tremaining: 24m 32s\n","114:\tlearn: 0.1388738\ttotal: 3m 11s\tremaining: 24m 33s\n","115:\tlearn: 0.1388620\ttotal: 3m 13s\tremaining: 24m 37s\n","116:\tlearn: 0.1388489\ttotal: 3m 15s\tremaining: 24m 35s\n","117:\tlearn: 0.1388284\ttotal: 3m 16s\tremaining: 24m 31s\n","118:\tlearn: 0.1388072\ttotal: 3m 18s\tremaining: 24m 30s\n","119:\tlearn: 0.1387896\ttotal: 3m 19s\tremaining: 24m 26s\n","120:\tlearn: 0.1387874\ttotal: 3m 20s\tremaining: 24m 19s\n","121:\tlearn: 0.1387703\ttotal: 3m 22s\tremaining: 24m 20s\n","122:\tlearn: 0.1387530\ttotal: 3m 24s\tremaining: 24m 18s\n","123:\tlearn: 0.1387416\ttotal: 3m 26s\tremaining: 24m 17s\n","124:\tlearn: 0.1387353\ttotal: 3m 28s\tremaining: 24m 18s\n","125:\tlearn: 0.1387167\ttotal: 3m 29s\tremaining: 24m 16s\n","126:\tlearn: 0.1386973\ttotal: 3m 31s\tremaining: 24m 12s\n","127:\tlearn: 0.1386834\ttotal: 3m 32s\tremaining: 24m 8s\n","128:\tlearn: 0.1386618\ttotal: 3m 34s\tremaining: 24m 9s\n","129:\tlearn: 0.1386361\ttotal: 3m 36s\tremaining: 24m 9s\n","130:\tlearn: 0.1386100\ttotal: 3m 38s\tremaining: 24m 10s\n","131:\tlearn: 0.1385862\ttotal: 3m 41s\tremaining: 24m 14s\n","132:\tlearn: 0.1385848\ttotal: 3m 42s\tremaining: 24m 10s\n","133:\tlearn: 0.1385785\ttotal: 3m 43s\tremaining: 24m 5s\n","134:\tlearn: 0.1385653\ttotal: 3m 44s\tremaining: 24m\n","135:\tlearn: 0.1385414\ttotal: 3m 45s\tremaining: 23m 55s\n","136:\tlearn: 0.1385281\ttotal: 3m 47s\tremaining: 23m 53s\n","137:\tlearn: 0.1385168\ttotal: 3m 49s\tremaining: 23m 50s\n","138:\tlearn: 0.1385160\ttotal: 3m 50s\tremaining: 23m 45s\n","139:\tlearn: 0.1384999\ttotal: 3m 51s\tremaining: 23m 42s\n","140:\tlearn: 0.1384826\ttotal: 3m 53s\tremaining: 23m 43s\n","141:\tlearn: 0.1384694\ttotal: 3m 56s\tremaining: 23m 46s\n","142:\tlearn: 0.1384561\ttotal: 3m 57s\tremaining: 23m 45s\n","143:\tlearn: 0.1384426\ttotal: 3m 59s\tremaining: 23m 40s\n","144:\tlearn: 0.1384252\ttotal: 4m\tremaining: 23m 38s\n","145:\tlearn: 0.1384083\ttotal: 4m 2s\tremaining: 23m 36s\n","146:\tlearn: 0.1383942\ttotal: 4m 3s\tremaining: 23m 34s\n","147:\tlearn: 0.1383857\ttotal: 4m 5s\tremaining: 23m 34s\n","148:\tlearn: 0.1383765\ttotal: 4m 8s\tremaining: 23m 40s\n","149:\tlearn: 0.1383660\ttotal: 4m 12s\tremaining: 23m 48s\n","150:\tlearn: 0.1383542\ttotal: 4m 14s\tremaining: 23m 49s\n","151:\tlearn: 0.1383408\ttotal: 4m 17s\tremaining: 23m 56s\n","152:\tlearn: 0.1383256\ttotal: 4m 19s\tremaining: 23m 59s\n","153:\tlearn: 0.1383206\ttotal: 4m 21s\tremaining: 23m 59s\n","154:\tlearn: 0.1383118\ttotal: 4m 24s\tremaining: 24m 1s\n","155:\tlearn: 0.1383028\ttotal: 4m 25s\tremaining: 23m 57s\n","156:\tlearn: 0.1382895\ttotal: 4m 26s\tremaining: 23m 53s\n","157:\tlearn: 0.1382715\ttotal: 4m 28s\tremaining: 23m 48s\n","158:\tlearn: 0.1382628\ttotal: 4m 29s\tremaining: 23m 44s\n","159:\tlearn: 0.1382529\ttotal: 4m 30s\tremaining: 23m 40s\n","160:\tlearn: 0.1382364\ttotal: 4m 32s\tremaining: 23m 38s\n","161:\tlearn: 0.1382283\ttotal: 4m 33s\tremaining: 23m 33s\n","162:\tlearn: 0.1382167\ttotal: 4m 34s\tremaining: 23m 30s\n","163:\tlearn: 0.1381928\ttotal: 4m 36s\tremaining: 23m 30s\n","164:\tlearn: 0.1381809\ttotal: 4m 39s\tremaining: 23m 32s\n","165:\tlearn: 0.1381690\ttotal: 4m 40s\tremaining: 23m 29s\n","166:\tlearn: 0.1381449\ttotal: 4m 42s\tremaining: 23m 26s\n","167:\tlearn: 0.1381250\ttotal: 4m 43s\tremaining: 23m 25s\n","168:\tlearn: 0.1381180\ttotal: 4m 44s\tremaining: 23m 19s\n","169:\tlearn: 0.1381056\ttotal: 4m 45s\tremaining: 23m 16s\n","170:\tlearn: 0.1381000\ttotal: 4m 47s\tremaining: 23m 11s\n","171:\tlearn: 0.1380873\ttotal: 4m 48s\tremaining: 23m 8s\n","172:\tlearn: 0.1380658\ttotal: 4m 50s\tremaining: 23m 9s\n","173:\tlearn: 0.1380559\ttotal: 4m 52s\tremaining: 23m 9s\n","174:\tlearn: 0.1380476\ttotal: 4m 53s\tremaining: 23m 5s\n","175:\tlearn: 0.1380374\ttotal: 4m 54s\tremaining: 23m 1s\n","176:\tlearn: 0.1380221\ttotal: 4m 56s\tremaining: 22m 58s\n","177:\tlearn: 0.1380107\ttotal: 4m 57s\tremaining: 22m 55s\n","178:\tlearn: 0.1379936\ttotal: 4m 59s\tremaining: 22m 54s\n","179:\tlearn: 0.1379834\ttotal: 5m\tremaining: 22m 51s\n","180:\tlearn: 0.1379700\ttotal: 5m 2s\tremaining: 22m 48s\n","181:\tlearn: 0.1379493\ttotal: 5m 4s\tremaining: 22m 50s\n","182:\tlearn: 0.1379325\ttotal: 5m 7s\tremaining: 22m 51s\n","183:\tlearn: 0.1379144\ttotal: 5m 8s\tremaining: 22m 49s\n","184:\tlearn: 0.1379052\ttotal: 5m 10s\tremaining: 22m 46s\n","185:\tlearn: 0.1378872\ttotal: 5m 11s\tremaining: 22m 44s\n","186:\tlearn: 0.1378754\ttotal: 5m 13s\tremaining: 22m 41s\n","187:\tlearn: 0.1378592\ttotal: 5m 14s\tremaining: 22m 39s\n","188:\tlearn: 0.1378333\ttotal: 5m 16s\tremaining: 22m 37s\n","189:\tlearn: 0.1378212\ttotal: 5m 18s\tremaining: 22m 38s\n","190:\tlearn: 0.1378117\ttotal: 5m 20s\tremaining: 22m 39s\n","191:\tlearn: 0.1377980\ttotal: 5m 22s\tremaining: 22m 36s\n","192:\tlearn: 0.1377904\ttotal: 5m 23s\tremaining: 22m 33s\n","193:\tlearn: 0.1377866\ttotal: 5m 24s\tremaining: 22m 29s\n","194:\tlearn: 0.1377646\ttotal: 5m 26s\tremaining: 22m 28s\n","195:\tlearn: 0.1377567\ttotal: 5m 27s\tremaining: 22m 25s\n","196:\tlearn: 0.1377515\ttotal: 5m 29s\tremaining: 22m 22s\n","197:\tlearn: 0.1377401\ttotal: 5m 30s\tremaining: 22m 19s\n","198:\tlearn: 0.1377390\ttotal: 5m 32s\tremaining: 22m 18s\n","199:\tlearn: 0.1377153\ttotal: 5m 34s\tremaining: 22m 19s\n","200:\tlearn: 0.1377014\ttotal: 5m 36s\tremaining: 22m 16s\n","201:\tlearn: 0.1376873\ttotal: 5m 37s\tremaining: 22m 14s\n","202:\tlearn: 0.1376677\ttotal: 5m 39s\tremaining: 22m 12s\n","203:\tlearn: 0.1376599\ttotal: 5m 41s\tremaining: 22m 10s\n","204:\tlearn: 0.1376371\ttotal: 5m 42s\tremaining: 22m 9s\n","205:\tlearn: 0.1376250\ttotal: 5m 44s\tremaining: 22m 7s\n","206:\tlearn: 0.1376159\ttotal: 5m 46s\tremaining: 22m 6s\n","207:\tlearn: 0.1376064\ttotal: 5m 48s\tremaining: 22m 6s\n","208:\tlearn: 0.1376006\ttotal: 5m 49s\tremaining: 22m 3s\n","209:\tlearn: 0.1375897\ttotal: 5m 51s\tremaining: 22m 2s\n","210:\tlearn: 0.1375784\ttotal: 5m 53s\tremaining: 22m 1s\n","211:\tlearn: 0.1375557\ttotal: 5m 55s\tremaining: 21m 59s\n","212:\tlearn: 0.1375475\ttotal: 5m 56s\tremaining: 21m 57s\n","213:\tlearn: 0.1375388\ttotal: 5m 57s\tremaining: 21m 53s\n","214:\tlearn: 0.1375359\ttotal: 5m 59s\tremaining: 21m 51s\n","215:\tlearn: 0.1375264\ttotal: 6m 1s\tremaining: 21m 50s\n","216:\tlearn: 0.1375095\ttotal: 6m 3s\tremaining: 21m 50s\n","217:\tlearn: 0.1375025\ttotal: 6m 4s\tremaining: 21m 47s\n","218:\tlearn: 0.1374950\ttotal: 6m 5s\tremaining: 21m 45s\n","219:\tlearn: 0.1374904\ttotal: 6m 6s\tremaining: 21m 41s\n","220:\tlearn: 0.1374858\ttotal: 6m 8s\tremaining: 21m 37s\n","221:\tlearn: 0.1374722\ttotal: 6m 9s\tremaining: 21m 35s\n","222:\tlearn: 0.1374601\ttotal: 6m 10s\tremaining: 21m 32s\n","223:\tlearn: 0.1374497\ttotal: 6m 12s\tremaining: 21m 30s\n","224:\tlearn: 0.1374406\ttotal: 6m 14s\tremaining: 21m 29s\n","225:\tlearn: 0.1374384\ttotal: 6m 16s\tremaining: 21m 28s\n","226:\tlearn: 0.1374341\ttotal: 6m 17s\tremaining: 21m 24s\n","227:\tlearn: 0.1374242\ttotal: 6m 18s\tremaining: 21m 21s\n","228:\tlearn: 0.1374095\ttotal: 6m 19s\tremaining: 21m 18s\n","229:\tlearn: 0.1373889\ttotal: 6m 21s\tremaining: 21m 16s\n","230:\tlearn: 0.1373807\ttotal: 6m 22s\tremaining: 21m 12s\n","231:\tlearn: 0.1373745\ttotal: 6m 23s\tremaining: 21m 9s\n","232:\tlearn: 0.1373684\ttotal: 6m 24s\tremaining: 21m 5s\n","233:\tlearn: 0.1373606\ttotal: 6m 26s\tremaining: 21m 3s\n","234:\tlearn: 0.1373463\ttotal: 6m 28s\tremaining: 21m 4s\n","235:\tlearn: 0.1373397\ttotal: 6m 30s\tremaining: 21m 4s\n","236:\tlearn: 0.1373251\ttotal: 6m 32s\tremaining: 21m 2s\n","237:\tlearn: 0.1373127\ttotal: 6m 34s\tremaining: 21m 1s\n","238:\tlearn: 0.1373041\ttotal: 6m 35s\tremaining: 20m 57s\n","239:\tlearn: 0.1372859\ttotal: 6m 36s\tremaining: 20m 56s\n","240:\tlearn: 0.1372833\ttotal: 6m 37s\tremaining: 20m 53s\n","241:\tlearn: 0.1372785\ttotal: 6m 39s\tremaining: 20m 49s\n","242:\tlearn: 0.1372708\ttotal: 6m 40s\tremaining: 20m 47s\n","243:\tlearn: 0.1372700\ttotal: 6m 42s\tremaining: 20m 47s\n","244:\tlearn: 0.1372595\ttotal: 6m 44s\tremaining: 20m 47s\n","245:\tlearn: 0.1372527\ttotal: 6m 45s\tremaining: 20m 43s\n","246:\tlearn: 0.1372410\ttotal: 6m 47s\tremaining: 20m 41s\n","247:\tlearn: 0.1372131\ttotal: 6m 49s\tremaining: 20m 40s\n","248:\tlearn: 0.1372052\ttotal: 6m 50s\tremaining: 20m 37s\n","249:\tlearn: 0.1371922\ttotal: 6m 51s\tremaining: 20m 35s\n","250:\tlearn: 0.1371837\ttotal: 6m 52s\tremaining: 20m 32s\n","251:\tlearn: 0.1371765\ttotal: 6m 54s\tremaining: 20m 30s\n","252:\tlearn: 0.1371690\ttotal: 6m 56s\tremaining: 20m 29s\n","253:\tlearn: 0.1371468\ttotal: 6m 59s\tremaining: 20m 31s\n","254:\tlearn: 0.1371342\ttotal: 7m\tremaining: 20m 29s\n","255:\tlearn: 0.1371248\ttotal: 7m 2s\tremaining: 20m 26s\n","256:\tlearn: 0.1371176\ttotal: 7m 3s\tremaining: 20m 24s\n","257:\tlearn: 0.1371094\ttotal: 7m 4s\tremaining: 20m 21s\n","258:\tlearn: 0.1370909\ttotal: 7m 6s\tremaining: 20m 19s\n","259:\tlearn: 0.1370756\ttotal: 7m 7s\tremaining: 20m 17s\n","260:\tlearn: 0.1370618\ttotal: 7m 10s\tremaining: 20m 17s\n","261:\tlearn: 0.1370584\ttotal: 7m 11s\tremaining: 20m 16s\n","262:\tlearn: 0.1370527\ttotal: 7m 13s\tremaining: 20m 14s\n","263:\tlearn: 0.1370435\ttotal: 7m 14s\tremaining: 20m 12s\n","264:\tlearn: 0.1370341\ttotal: 7m 16s\tremaining: 20m 9s\n","265:\tlearn: 0.1370246\ttotal: 7m 17s\tremaining: 20m 7s\n","266:\tlearn: 0.1370033\ttotal: 7m 19s\tremaining: 20m 5s\n","267:\tlearn: 0.1369972\ttotal: 7m 20s\tremaining: 20m 2s\n","268:\tlearn: 0.1369869\ttotal: 7m 21s\tremaining: 20m\n","269:\tlearn: 0.1369801\ttotal: 7m 23s\tremaining: 19m 59s\n","270:\tlearn: 0.1369730\ttotal: 7m 25s\tremaining: 19m 58s\n","271:\tlearn: 0.1369691\ttotal: 7m 27s\tremaining: 19m 57s\n","272:\tlearn: 0.1369596\ttotal: 7m 28s\tremaining: 19m 54s\n","273:\tlearn: 0.1369499\ttotal: 7m 30s\tremaining: 19m 52s\n","274:\tlearn: 0.1369436\ttotal: 7m 31s\tremaining: 19m 50s\n","275:\tlearn: 0.1369379\ttotal: 7m 32s\tremaining: 19m 47s\n","276:\tlearn: 0.1369353\ttotal: 7m 33s\tremaining: 19m 44s\n","277:\tlearn: 0.1369317\ttotal: 7m 34s\tremaining: 19m 41s\n","278:\tlearn: 0.1369227\ttotal: 7m 36s\tremaining: 19m 38s\n","279:\tlearn: 0.1369139\ttotal: 7m 37s\tremaining: 19m 36s\n","280:\tlearn: 0.1369053\ttotal: 7m 39s\tremaining: 19m 36s\n","281:\tlearn: 0.1368886\ttotal: 7m 41s\tremaining: 19m 35s\n","282:\tlearn: 0.1368798\ttotal: 7m 43s\tremaining: 19m 33s\n","283:\tlearn: 0.1368667\ttotal: 7m 44s\tremaining: 19m 31s\n","284:\tlearn: 0.1368539\ttotal: 7m 46s\tremaining: 19m 29s\n","285:\tlearn: 0.1368416\ttotal: 7m 47s\tremaining: 19m 27s\n","286:\tlearn: 0.1368343\ttotal: 7m 48s\tremaining: 19m 24s\n","287:\tlearn: 0.1368307\ttotal: 7m 49s\tremaining: 19m 21s\n","288:\tlearn: 0.1368247\ttotal: 7m 51s\tremaining: 19m 18s\n","289:\tlearn: 0.1368173\ttotal: 7m 53s\tremaining: 19m 18s\n","290:\tlearn: 0.1368057\ttotal: 7m 55s\tremaining: 19m 18s\n","291:\tlearn: 0.1367957\ttotal: 7m 56s\tremaining: 19m 16s\n","292:\tlearn: 0.1367881\ttotal: 7m 58s\tremaining: 19m 13s\n","293:\tlearn: 0.1367803\ttotal: 7m 59s\tremaining: 19m 11s\n","294:\tlearn: 0.1367741\ttotal: 8m\tremaining: 19m 9s\n","295:\tlearn: 0.1367621\ttotal: 8m 2s\tremaining: 19m 7s\n","296:\tlearn: 0.1367571\ttotal: 8m 3s\tremaining: 19m 5s\n","297:\tlearn: 0.1367471\ttotal: 8m 5s\tremaining: 19m 3s\n","298:\tlearn: 0.1367307\ttotal: 8m 7s\tremaining: 19m 3s\n","299:\tlearn: 0.1367183\ttotal: 8m 9s\tremaining: 19m 2s\n","300:\tlearn: 0.1367084\ttotal: 8m 11s\tremaining: 19m\n","301:\tlearn: 0.1367064\ttotal: 8m 12s\tremaining: 18m 57s\n","302:\tlearn: 0.1367011\ttotal: 8m 13s\tremaining: 18m 55s\n","303:\tlearn: 0.1366913\ttotal: 8m 14s\tremaining: 18m 53s\n","304:\tlearn: 0.1366768\ttotal: 8m 16s\tremaining: 18m 51s\n","305:\tlearn: 0.1366692\ttotal: 8m 18s\tremaining: 18m 49s\n","306:\tlearn: 0.1366540\ttotal: 8m 19s\tremaining: 18m 47s\n","307:\tlearn: 0.1366503\ttotal: 8m 21s\tremaining: 18m 47s\n","308:\tlearn: 0.1366433\ttotal: 8m 23s\tremaining: 18m 46s\n","309:\tlearn: 0.1366298\ttotal: 8m 25s\tremaining: 18m 44s\n","310:\tlearn: 0.1366222\ttotal: 8m 26s\tremaining: 18m 41s\n","311:\tlearn: 0.1366142\ttotal: 8m 27s\tremaining: 18m 39s\n","312:\tlearn: 0.1366125\ttotal: 8m 28s\tremaining: 18m 36s\n","313:\tlearn: 0.1366045\ttotal: 8m 30s\tremaining: 18m 34s\n","314:\tlearn: 0.1365983\ttotal: 8m 31s\tremaining: 18m 32s\n","315:\tlearn: 0.1365870\ttotal: 8m 32s\tremaining: 18m 29s\n","316:\tlearn: 0.1365778\ttotal: 8m 34s\tremaining: 18m 28s\n","317:\tlearn: 0.1365673\ttotal: 8m 36s\tremaining: 18m 28s\n","318:\tlearn: 0.1365526\ttotal: 8m 38s\tremaining: 18m 26s\n","319:\tlearn: 0.1365379\ttotal: 8m 39s\tremaining: 18m 24s\n","320:\tlearn: 0.1365312\ttotal: 8m 41s\tremaining: 18m 22s\n","321:\tlearn: 0.1365244\ttotal: 8m 42s\tremaining: 18m 19s\n","322:\tlearn: 0.1365206\ttotal: 8m 43s\tremaining: 18m 17s\n","323:\tlearn: 0.1365196\ttotal: 8m 44s\tremaining: 18m 14s\n","324:\tlearn: 0.1365141\ttotal: 8m 45s\tremaining: 18m 12s\n","325:\tlearn: 0.1365016\ttotal: 8m 47s\tremaining: 18m 10s\n","326:\tlearn: 0.1364942\ttotal: 8m 49s\tremaining: 18m 10s\n","327:\tlearn: 0.1364841\ttotal: 8m 51s\tremaining: 18m 9s\n","328:\tlearn: 0.1364694\ttotal: 8m 54s\tremaining: 18m 9s\n","329:\tlearn: 0.1364625\ttotal: 8m 55s\tremaining: 18m 6s\n","330:\tlearn: 0.1364564\ttotal: 8m 56s\tremaining: 18m 4s\n","331:\tlearn: 0.1364522\ttotal: 8m 57s\tremaining: 18m 1s\n","332:\tlearn: 0.1364422\ttotal: 8m 59s\tremaining: 17m 59s\n","333:\tlearn: 0.1364410\ttotal: 9m\tremaining: 17m 56s\n","334:\tlearn: 0.1364361\ttotal: 9m 1s\tremaining: 17m 54s\n","335:\tlearn: 0.1364296\ttotal: 9m 3s\tremaining: 17m 53s\n","336:\tlearn: 0.1364190\ttotal: 9m 5s\tremaining: 17m 53s\n","337:\tlearn: 0.1364089\ttotal: 9m 7s\tremaining: 17m 51s\n","338:\tlearn: 0.1363954\ttotal: 9m 8s\tremaining: 17m 48s\n","339:\tlearn: 0.1363867\ttotal: 9m 9s\tremaining: 17m 46s\n","340:\tlearn: 0.1363756\ttotal: 9m 10s\tremaining: 17m 44s\n","341:\tlearn: 0.1363652\ttotal: 9m 12s\tremaining: 17m 42s\n","342:\tlearn: 0.1363531\ttotal: 9m 13s\tremaining: 17m 40s\n","343:\tlearn: 0.1363363\ttotal: 9m 15s\tremaining: 17m 38s\n","344:\tlearn: 0.1363314\ttotal: 9m 16s\tremaining: 17m 37s\n","345:\tlearn: 0.1363133\ttotal: 9m 19s\tremaining: 17m 37s\n","346:\tlearn: 0.1363119\ttotal: 9m 20s\tremaining: 17m 34s\n","347:\tlearn: 0.1363054\ttotal: 9m 21s\tremaining: 17m 32s\n","348:\tlearn: 0.1362950\ttotal: 9m 23s\tremaining: 17m 30s\n","349:\tlearn: 0.1362908\ttotal: 9m 24s\tremaining: 17m 27s\n","350:\tlearn: 0.1362827\ttotal: 9m 25s\tremaining: 17m 25s\n","351:\tlearn: 0.1362686\ttotal: 9m 26s\tremaining: 17m 23s\n","352:\tlearn: 0.1362657\ttotal: 9m 27s\tremaining: 17m 20s\n","353:\tlearn: 0.1362502\ttotal: 9m 29s\tremaining: 17m 20s\n","354:\tlearn: 0.1362438\ttotal: 9m 32s\tremaining: 17m 19s\n","355:\tlearn: 0.1362363\ttotal: 9m 33s\tremaining: 17m 17s\n","356:\tlearn: 0.1362276\ttotal: 9m 35s\tremaining: 17m 15s\n","357:\tlearn: 0.1362238\ttotal: 9m 36s\tremaining: 17m 13s\n","358:\tlearn: 0.1362192\ttotal: 9m 37s\tremaining: 17m 10s\n","359:\tlearn: 0.1362173\ttotal: 9m 38s\tremaining: 17m 8s\n","360:\tlearn: 0.1362117\ttotal: 9m 39s\tremaining: 17m 5s\n","361:\tlearn: 0.1362054\ttotal: 9m 40s\tremaining: 17m 3s\n","362:\tlearn: 0.1361921\ttotal: 9m 42s\tremaining: 17m 2s\n","363:\tlearn: 0.1361831\ttotal: 9m 43s\tremaining: 17m\n","364:\tlearn: 0.1361738\ttotal: 9m 46s\tremaining: 17m\n","365:\tlearn: 0.1361696\ttotal: 9m 48s\tremaining: 16m 59s\n","366:\tlearn: 0.1361642\ttotal: 9m 49s\tremaining: 16m 56s\n","367:\tlearn: 0.1361613\ttotal: 9m 50s\tremaining: 16m 54s\n","368:\tlearn: 0.1361552\ttotal: 9m 51s\tremaining: 16m 52s\n","369:\tlearn: 0.1361529\ttotal: 9m 52s\tremaining: 16m 49s\n","370:\tlearn: 0.1361487\ttotal: 9m 54s\tremaining: 16m 47s\n","371:\tlearn: 0.1361441\ttotal: 9m 55s\tremaining: 16m 44s\n","372:\tlearn: 0.1361344\ttotal: 9m 56s\tremaining: 16m 43s\n","373:\tlearn: 0.1361228\ttotal: 9m 59s\tremaining: 16m 42s\n","374:\tlearn: 0.1361147\ttotal: 10m 1s\tremaining: 16m 42s\n","375:\tlearn: 0.1361044\ttotal: 10m 2s\tremaining: 16m 40s\n","376:\tlearn: 0.1360958\ttotal: 10m 4s\tremaining: 16m 38s\n","377:\tlearn: 0.1360829\ttotal: 10m 5s\tremaining: 16m 37s\n","378:\tlearn: 0.1360753\ttotal: 10m 7s\tremaining: 16m 34s\n","379:\tlearn: 0.1360605\ttotal: 10m 8s\tremaining: 16m 33s\n","380:\tlearn: 0.1360516\ttotal: 10m 9s\tremaining: 16m 30s\n","381:\tlearn: 0.1360455\ttotal: 10m 11s\tremaining: 16m 28s\n","382:\tlearn: 0.1360439\ttotal: 10m 12s\tremaining: 16m 27s\n","383:\tlearn: 0.1360353\ttotal: 10m 15s\tremaining: 16m 26s\n","384:\tlearn: 0.1360248\ttotal: 10m 16s\tremaining: 16m 24s\n","385:\tlearn: 0.1360149\ttotal: 10m 17s\tremaining: 16m 22s\n","386:\tlearn: 0.1360038\ttotal: 10m 19s\tremaining: 16m 20s\n","387:\tlearn: 0.1360024\ttotal: 10m 20s\tremaining: 16m 18s\n","388:\tlearn: 0.1359923\ttotal: 10m 21s\tremaining: 16m 15s\n","389:\tlearn: 0.1359807\ttotal: 10m 22s\tremaining: 16m 13s\n","390:\tlearn: 0.1359635\ttotal: 10m 24s\tremaining: 16m 12s\n","391:\tlearn: 0.1359577\ttotal: 10m 26s\tremaining: 16m 11s\n","392:\tlearn: 0.1359471\ttotal: 10m 28s\tremaining: 16m 11s\n","393:\tlearn: 0.1359385\ttotal: 10m 30s\tremaining: 16m 9s\n","394:\tlearn: 0.1359331\ttotal: 10m 31s\tremaining: 16m 6s\n","395:\tlearn: 0.1359322\ttotal: 10m 32s\tremaining: 16m 4s\n","396:\tlearn: 0.1359254\ttotal: 10m 33s\tremaining: 16m 2s\n","397:\tlearn: 0.1359134\ttotal: 10m 35s\tremaining: 16m\n","398:\tlearn: 0.1359067\ttotal: 10m 36s\tremaining: 15m 58s\n","399:\tlearn: 0.1358997\ttotal: 10m 37s\tremaining: 15m 56s\n","400:\tlearn: 0.1358964\ttotal: 10m 39s\tremaining: 15m 54s\n","401:\tlearn: 0.1358901\ttotal: 10m 41s\tremaining: 15m 53s\n","402:\tlearn: 0.1358818\ttotal: 10m 43s\tremaining: 15m 52s\n","403:\tlearn: 0.1358753\ttotal: 10m 44s\tremaining: 15m 50s\n","404:\tlearn: 0.1358656\ttotal: 10m 45s\tremaining: 15m 48s\n","405:\tlearn: 0.1358551\ttotal: 10m 47s\tremaining: 15m 47s\n","406:\tlearn: 0.1358482\ttotal: 10m 48s\tremaining: 15m 45s\n","407:\tlearn: 0.1358411\ttotal: 10m 50s\tremaining: 15m 43s\n","408:\tlearn: 0.1358369\ttotal: 10m 51s\tremaining: 15m 41s\n","409:\tlearn: 0.1358250\ttotal: 10m 53s\tremaining: 15m 40s\n","410:\tlearn: 0.1358175\ttotal: 10m 56s\tremaining: 15m 40s\n","411:\tlearn: 0.1358144\ttotal: 10m 57s\tremaining: 15m 37s\n","412:\tlearn: 0.1358037\ttotal: 10m 58s\tremaining: 15m 35s\n","413:\tlearn: 0.1357892\ttotal: 10m 59s\tremaining: 15m 34s\n","414:\tlearn: 0.1357834\ttotal: 11m 1s\tremaining: 15m 32s\n","415:\tlearn: 0.1357740\ttotal: 11m 2s\tremaining: 15m 30s\n","416:\tlearn: 0.1357676\ttotal: 11m 4s\tremaining: 15m 28s\n","417:\tlearn: 0.1357599\ttotal: 11m 5s\tremaining: 15m 26s\n","418:\tlearn: 0.1357545\ttotal: 11m 7s\tremaining: 15m 24s\n","419:\tlearn: 0.1357432\ttotal: 11m 9s\tremaining: 15m 24s\n","420:\tlearn: 0.1357301\ttotal: 11m 11s\tremaining: 15m 23s\n","421:\tlearn: 0.1357243\ttotal: 11m 12s\tremaining: 15m 21s\n","422:\tlearn: 0.1357106\ttotal: 11m 14s\tremaining: 15m 20s\n","423:\tlearn: 0.1357069\ttotal: 11m 15s\tremaining: 15m 17s\n","424:\tlearn: 0.1356941\ttotal: 11m 17s\tremaining: 15m 16s\n","425:\tlearn: 0.1356903\ttotal: 11m 18s\tremaining: 15m 14s\n","426:\tlearn: 0.1356817\ttotal: 11m 19s\tremaining: 15m 12s\n","427:\tlearn: 0.1356771\ttotal: 11m 21s\tremaining: 15m 11s\n","428:\tlearn: 0.1356723\ttotal: 11m 23s\tremaining: 15m 10s\n","429:\tlearn: 0.1356598\ttotal: 11m 25s\tremaining: 15m 8s\n","430:\tlearn: 0.1356568\ttotal: 11m 26s\tremaining: 15m 5s\n","431:\tlearn: 0.1356549\ttotal: 11m 27s\tremaining: 15m 3s\n","432:\tlearn: 0.1356492\ttotal: 11m 28s\tremaining: 15m 1s\n","433:\tlearn: 0.1356442\ttotal: 11m 29s\tremaining: 14m 58s\n","434:\tlearn: 0.1356361\ttotal: 11m 30s\tremaining: 14m 56s\n","435:\tlearn: 0.1356216\ttotal: 11m 32s\tremaining: 14m 55s\n","436:\tlearn: 0.1356153\ttotal: 11m 33s\tremaining: 14m 53s\n","437:\tlearn: 0.1356089\ttotal: 11m 35s\tremaining: 14m 53s\n","438:\tlearn: 0.1355965\ttotal: 11m 38s\tremaining: 14m 51s\n","439:\tlearn: 0.1355950\ttotal: 11m 39s\tremaining: 14m 50s\n","440:\tlearn: 0.1355832\ttotal: 11m 41s\tremaining: 14m 48s\n","441:\tlearn: 0.1355754\ttotal: 11m 42s\tremaining: 14m 46s\n","442:\tlearn: 0.1355678\ttotal: 11m 43s\tremaining: 14m 44s\n","443:\tlearn: 0.1355528\ttotal: 11m 44s\tremaining: 14m 42s\n","444:\tlearn: 0.1355404\ttotal: 11m 46s\tremaining: 14m 40s\n","445:\tlearn: 0.1355350\ttotal: 11m 47s\tremaining: 14m 39s\n","446:\tlearn: 0.1355302\ttotal: 11m 49s\tremaining: 14m 37s\n","447:\tlearn: 0.1355244\ttotal: 11m 51s\tremaining: 14m 36s\n","448:\tlearn: 0.1355219\ttotal: 11m 52s\tremaining: 14m 33s\n","449:\tlearn: 0.1355109\ttotal: 11m 53s\tremaining: 14m 32s\n","450:\tlearn: 0.1355010\ttotal: 11m 54s\tremaining: 14m 30s\n","451:\tlearn: 0.1354939\ttotal: 11m 56s\tremaining: 14m 28s\n","452:\tlearn: 0.1354863\ttotal: 11m 57s\tremaining: 14m 26s\n","453:\tlearn: 0.1354767\ttotal: 11m 58s\tremaining: 14m 24s\n","454:\tlearn: 0.1354640\ttotal: 12m\tremaining: 14m 23s\n","455:\tlearn: 0.1354587\ttotal: 12m 2s\tremaining: 14m 22s\n","456:\tlearn: 0.1354512\ttotal: 12m 4s\tremaining: 14m 21s\n","457:\tlearn: 0.1354399\ttotal: 12m 5s\tremaining: 14m 19s\n","458:\tlearn: 0.1354362\ttotal: 12m 7s\tremaining: 14m 16s\n","459:\tlearn: 0.1354265\ttotal: 12m 8s\tremaining: 14m 15s\n","460:\tlearn: 0.1354227\ttotal: 12m 9s\tremaining: 14m 13s\n","461:\tlearn: 0.1354164\ttotal: 12m 11s\tremaining: 14m 11s\n","462:\tlearn: 0.1354067\ttotal: 12m 12s\tremaining: 14m 9s\n","463:\tlearn: 0.1354053\ttotal: 12m 13s\tremaining: 14m 7s\n","464:\tlearn: 0.1353926\ttotal: 12m 15s\tremaining: 14m 5s\n","465:\tlearn: 0.1353854\ttotal: 12m 17s\tremaining: 14m 5s\n","466:\tlearn: 0.1353791\ttotal: 12m 19s\tremaining: 14m 3s\n","467:\tlearn: 0.1353759\ttotal: 12m 20s\tremaining: 14m 1s\n","468:\tlearn: 0.1353657\ttotal: 12m 22s\tremaining: 14m\n","469:\tlearn: 0.1353581\ttotal: 12m 23s\tremaining: 13m 58s\n","470:\tlearn: 0.1353497\ttotal: 12m 24s\tremaining: 13m 56s\n","471:\tlearn: 0.1353434\ttotal: 12m 26s\tremaining: 13m 54s\n","472:\tlearn: 0.1353395\ttotal: 12m 27s\tremaining: 13m 52s\n","473:\tlearn: 0.1353278\ttotal: 12m 29s\tremaining: 13m 51s\n","474:\tlearn: 0.1353267\ttotal: 12m 31s\tremaining: 13m 50s\n","475:\tlearn: 0.1353186\ttotal: 12m 33s\tremaining: 13m 49s\n","476:\tlearn: 0.1353079\ttotal: 12m 34s\tremaining: 13m 47s\n","477:\tlearn: 0.1353056\ttotal: 12m 35s\tremaining: 13m 45s\n","478:\tlearn: 0.1352941\ttotal: 12m 37s\tremaining: 13m 43s\n","479:\tlearn: 0.1352862\ttotal: 12m 38s\tremaining: 13m 42s\n","480:\tlearn: 0.1352716\ttotal: 12m 40s\tremaining: 13m 40s\n","481:\tlearn: 0.1352696\ttotal: 12m 41s\tremaining: 13m 38s\n","482:\tlearn: 0.1352669\ttotal: 12m 42s\tremaining: 13m 36s\n","483:\tlearn: 0.1352593\ttotal: 12m 45s\tremaining: 13m 35s\n","484:\tlearn: 0.1352542\ttotal: 12m 46s\tremaining: 13m 33s\n","485:\tlearn: 0.1352442\ttotal: 12m 47s\tremaining: 13m 31s\n","486:\tlearn: 0.1352361\ttotal: 12m 49s\tremaining: 13m 30s\n","487:\tlearn: 0.1352208\ttotal: 12m 50s\tremaining: 13m 28s\n","488:\tlearn: 0.1352166\ttotal: 12m 51s\tremaining: 13m 26s\n","489:\tlearn: 0.1352064\ttotal: 12m 53s\tremaining: 13m 24s\n","490:\tlearn: 0.1351930\ttotal: 12m 54s\tremaining: 13m 23s\n","491:\tlearn: 0.1351919\ttotal: 12m 55s\tremaining: 13m 20s\n","492:\tlearn: 0.1351853\ttotal: 12m 57s\tremaining: 13m 19s\n","493:\tlearn: 0.1351799\ttotal: 12m 59s\tremaining: 13m 18s\n","494:\tlearn: 0.1351725\ttotal: 13m 1s\tremaining: 13m 17s\n","495:\tlearn: 0.1351709\ttotal: 13m 2s\tremaining: 13m 15s\n","496:\tlearn: 0.1351631\ttotal: 13m 3s\tremaining: 13m 13s\n","497:\tlearn: 0.1351520\ttotal: 13m 5s\tremaining: 13m 11s\n","498:\tlearn: 0.1351459\ttotal: 13m 6s\tremaining: 13m 9s\n","499:\tlearn: 0.1351354\ttotal: 13m 8s\tremaining: 13m 8s\n","500:\tlearn: 0.1351206\ttotal: 13m 9s\tremaining: 13m 6s\n","501:\tlearn: 0.1351132\ttotal: 13m 11s\tremaining: 13m 5s\n","502:\tlearn: 0.1351079\ttotal: 13m 14s\tremaining: 13m 4s\n","503:\tlearn: 0.1351003\ttotal: 13m 15s\tremaining: 13m 2s\n","504:\tlearn: 0.1350970\ttotal: 13m 16s\tremaining: 13m\n","505:\tlearn: 0.1350917\ttotal: 13m 17s\tremaining: 12m 58s\n","506:\tlearn: 0.1350776\ttotal: 13m 19s\tremaining: 12m 57s\n","507:\tlearn: 0.1350703\ttotal: 13m 20s\tremaining: 12m 55s\n","508:\tlearn: 0.1350672\ttotal: 13m 21s\tremaining: 12m 52s\n","509:\tlearn: 0.1350590\ttotal: 13m 22s\tremaining: 12m 51s\n","510:\tlearn: 0.1350563\ttotal: 13m 23s\tremaining: 12m 49s\n","511:\tlearn: 0.1350532\ttotal: 13m 25s\tremaining: 12m 48s\n","512:\tlearn: 0.1350409\ttotal: 13m 27s\tremaining: 12m 46s\n","513:\tlearn: 0.1350292\ttotal: 13m 29s\tremaining: 12m 45s\n","514:\tlearn: 0.1350253\ttotal: 13m 30s\tremaining: 12m 43s\n","515:\tlearn: 0.1350228\ttotal: 13m 31s\tremaining: 12m 41s\n","516:\tlearn: 0.1350193\ttotal: 13m 32s\tremaining: 12m 39s\n","517:\tlearn: 0.1350126\ttotal: 13m 33s\tremaining: 12m 37s\n","518:\tlearn: 0.1350069\ttotal: 13m 35s\tremaining: 12m 35s\n","519:\tlearn: 0.1350046\ttotal: 13m 36s\tremaining: 12m 33s\n","520:\tlearn: 0.1349946\ttotal: 13m 38s\tremaining: 12m 32s\n","521:\tlearn: 0.1349899\ttotal: 13m 40s\tremaining: 12m 31s\n","522:\tlearn: 0.1349857\ttotal: 13m 42s\tremaining: 12m 29s\n","523:\tlearn: 0.1349799\ttotal: 13m 43s\tremaining: 12m 27s\n","524:\tlearn: 0.1349739\ttotal: 13m 44s\tremaining: 12m 25s\n","525:\tlearn: 0.1349646\ttotal: 13m 45s\tremaining: 12m 24s\n","526:\tlearn: 0.1349597\ttotal: 13m 47s\tremaining: 12m 22s\n","527:\tlearn: 0.1349579\ttotal: 13m 48s\tremaining: 12m 20s\n","528:\tlearn: 0.1349534\ttotal: 13m 49s\tremaining: 12m 18s\n","529:\tlearn: 0.1349480\ttotal: 13m 50s\tremaining: 12m 16s\n","530:\tlearn: 0.1349362\ttotal: 13m 53s\tremaining: 12m 16s\n","531:\tlearn: 0.1349238\ttotal: 13m 55s\tremaining: 12m 14s\n","532:\tlearn: 0.1349130\ttotal: 13m 57s\tremaining: 12m 13s\n","533:\tlearn: 0.1349027\ttotal: 13m 58s\tremaining: 12m 11s\n","534:\tlearn: 0.1348999\ttotal: 13m 59s\tremaining: 12m 9s\n","535:\tlearn: 0.1348889\ttotal: 14m 1s\tremaining: 12m 8s\n","536:\tlearn: 0.1348872\ttotal: 14m 2s\tremaining: 12m 6s\n","537:\tlearn: 0.1348759\ttotal: 14m 4s\tremaining: 12m 5s\n","538:\tlearn: 0.1348742\ttotal: 14m 6s\tremaining: 12m 4s\n","539:\tlearn: 0.1348646\ttotal: 14m 8s\tremaining: 12m 2s\n","540:\tlearn: 0.1348563\ttotal: 14m 9s\tremaining: 12m 1s\n","541:\tlearn: 0.1348488\ttotal: 14m 11s\tremaining: 11m 59s\n","542:\tlearn: 0.1348423\ttotal: 14m 13s\tremaining: 11m 57s\n","543:\tlearn: 0.1348335\ttotal: 14m 14s\tremaining: 11m 56s\n","544:\tlearn: 0.1348283\ttotal: 14m 15s\tremaining: 11m 54s\n","545:\tlearn: 0.1348208\ttotal: 14m 17s\tremaining: 11m 52s\n","546:\tlearn: 0.1348144\ttotal: 14m 18s\tremaining: 11m 51s\n","547:\tlearn: 0.1348075\ttotal: 14m 20s\tremaining: 11m 50s\n","548:\tlearn: 0.1348051\ttotal: 14m 22s\tremaining: 11m 48s\n","549:\tlearn: 0.1347946\ttotal: 14m 23s\tremaining: 11m 46s\n","550:\tlearn: 0.1347857\ttotal: 14m 25s\tremaining: 11m 45s\n","551:\tlearn: 0.1347690\ttotal: 14m 26s\tremaining: 11m 43s\n","552:\tlearn: 0.1347675\ttotal: 14m 28s\tremaining: 11m 41s\n","553:\tlearn: 0.1347624\ttotal: 14m 29s\tremaining: 11m 39s\n","554:\tlearn: 0.1347555\ttotal: 14m 31s\tremaining: 11m 38s\n","555:\tlearn: 0.1347388\ttotal: 14m 33s\tremaining: 11m 37s\n","556:\tlearn: 0.1347351\ttotal: 14m 35s\tremaining: 11m 35s\n","557:\tlearn: 0.1347334\ttotal: 14m 36s\tremaining: 11m 34s\n","558:\tlearn: 0.1347270\ttotal: 14m 37s\tremaining: 11m 32s\n","559:\tlearn: 0.1347190\ttotal: 14m 39s\tremaining: 11m 30s\n","560:\tlearn: 0.1347136\ttotal: 14m 40s\tremaining: 11m 29s\n","561:\tlearn: 0.1347119\ttotal: 14m 41s\tremaining: 11m 27s\n","562:\tlearn: 0.1347020\ttotal: 14m 43s\tremaining: 11m 25s\n","563:\tlearn: 0.1346973\ttotal: 14m 44s\tremaining: 11m 23s\n","564:\tlearn: 0.1346959\ttotal: 14m 45s\tremaining: 11m 21s\n","565:\tlearn: 0.1346850\ttotal: 14m 47s\tremaining: 11m 20s\n","566:\tlearn: 0.1346809\ttotal: 14m 49s\tremaining: 11m 19s\n","567:\tlearn: 0.1346734\ttotal: 14m 50s\tremaining: 11m 17s\n","568:\tlearn: 0.1346706\ttotal: 14m 52s\tremaining: 11m 15s\n","569:\tlearn: 0.1346639\ttotal: 14m 53s\tremaining: 11m 14s\n","570:\tlearn: 0.1346616\ttotal: 14m 54s\tremaining: 11m 12s\n","571:\tlearn: 0.1346544\ttotal: 14m 55s\tremaining: 11m 10s\n","572:\tlearn: 0.1346522\ttotal: 14m 56s\tremaining: 11m 8s\n","573:\tlearn: 0.1346501\ttotal: 14m 58s\tremaining: 11m 6s\n","574:\tlearn: 0.1346373\ttotal: 14m 59s\tremaining: 11m 5s\n","575:\tlearn: 0.1346288\ttotal: 15m 2s\tremaining: 11m 4s\n","576:\tlearn: 0.1346246\ttotal: 15m 3s\tremaining: 11m 2s\n","577:\tlearn: 0.1346152\ttotal: 15m 5s\tremaining: 11m\n","578:\tlearn: 0.1346036\ttotal: 15m 6s\tremaining: 10m 59s\n","579:\tlearn: 0.1345934\ttotal: 15m 8s\tremaining: 10m 58s\n","580:\tlearn: 0.1345902\ttotal: 15m 10s\tremaining: 10m 56s\n","581:\tlearn: 0.1345881\ttotal: 15m 11s\tremaining: 10m 54s\n","582:\tlearn: 0.1345853\ttotal: 15m 13s\tremaining: 10m 53s\n","583:\tlearn: 0.1345718\ttotal: 15m 16s\tremaining: 10m 53s\n","584:\tlearn: 0.1345625\ttotal: 15m 19s\tremaining: 10m 51s\n","585:\tlearn: 0.1345586\ttotal: 15m 20s\tremaining: 10m 50s\n","586:\tlearn: 0.1345469\ttotal: 15m 22s\tremaining: 10m 48s\n","587:\tlearn: 0.1345322\ttotal: 15m 23s\tremaining: 10m 47s\n","588:\tlearn: 0.1345222\ttotal: 15m 25s\tremaining: 10m 45s\n","589:\tlearn: 0.1345132\ttotal: 15m 26s\tremaining: 10m 43s\n","590:\tlearn: 0.1345045\ttotal: 15m 27s\tremaining: 10m 42s\n","591:\tlearn: 0.1345017\ttotal: 15m 28s\tremaining: 10m 40s\n","592:\tlearn: 0.1344940\ttotal: 15m 31s\tremaining: 10m 39s\n","593:\tlearn: 0.1344827\ttotal: 15m 33s\tremaining: 10m 38s\n","594:\tlearn: 0.1344751\ttotal: 15m 34s\tremaining: 10m 36s\n","595:\tlearn: 0.1344730\ttotal: 15m 35s\tremaining: 10m 34s\n","596:\tlearn: 0.1344709\ttotal: 15m 37s\tremaining: 10m 32s\n","597:\tlearn: 0.1344681\ttotal: 15m 38s\tremaining: 10m 31s\n","598:\tlearn: 0.1344590\ttotal: 15m 40s\tremaining: 10m 29s\n","599:\tlearn: 0.1344502\ttotal: 15m 41s\tremaining: 10m 27s\n","600:\tlearn: 0.1344430\ttotal: 15m 42s\tremaining: 10m 26s\n","601:\tlearn: 0.1344302\ttotal: 15m 45s\tremaining: 10m 24s\n","602:\tlearn: 0.1344240\ttotal: 15m 47s\tremaining: 10m 23s\n","603:\tlearn: 0.1344183\ttotal: 15m 48s\tremaining: 10m 21s\n","604:\tlearn: 0.1344087\ttotal: 15m 50s\tremaining: 10m 20s\n","605:\tlearn: 0.1344025\ttotal: 15m 51s\tremaining: 10m 18s\n","606:\tlearn: 0.1343960\ttotal: 15m 52s\tremaining: 10m 16s\n","607:\tlearn: 0.1343832\ttotal: 15m 54s\tremaining: 10m 15s\n","608:\tlearn: 0.1343748\ttotal: 15m 55s\tremaining: 10m 13s\n","609:\tlearn: 0.1343659\ttotal: 15m 58s\tremaining: 10m 12s\n","610:\tlearn: 0.1343533\ttotal: 16m\tremaining: 10m 11s\n","611:\tlearn: 0.1343493\ttotal: 16m 2s\tremaining: 10m 10s\n","612:\tlearn: 0.1343392\ttotal: 16m 3s\tremaining: 10m 8s\n","613:\tlearn: 0.1343349\ttotal: 16m 5s\tremaining: 10m 6s\n","614:\tlearn: 0.1343330\ttotal: 16m 6s\tremaining: 10m 4s\n","615:\tlearn: 0.1343282\ttotal: 16m 7s\tremaining: 10m 3s\n","616:\tlearn: 0.1343205\ttotal: 16m 8s\tremaining: 10m 1s\n","617:\tlearn: 0.1343188\ttotal: 16m 9s\tremaining: 9m 59s\n","618:\tlearn: 0.1343128\ttotal: 16m 11s\tremaining: 9m 57s\n","619:\tlearn: 0.1343043\ttotal: 16m 13s\tremaining: 9m 56s\n","620:\tlearn: 0.1342964\ttotal: 16m 15s\tremaining: 9m 55s\n","621:\tlearn: 0.1342909\ttotal: 16m 16s\tremaining: 9m 53s\n","622:\tlearn: 0.1342816\ttotal: 16m 18s\tremaining: 9m 52s\n","623:\tlearn: 0.1342620\ttotal: 16m 19s\tremaining: 9m 50s\n","624:\tlearn: 0.1342536\ttotal: 16m 21s\tremaining: 9m 48s\n","625:\tlearn: 0.1342483\ttotal: 16m 22s\tremaining: 9m 47s\n","626:\tlearn: 0.1342425\ttotal: 16m 23s\tremaining: 9m 45s\n","627:\tlearn: 0.1342406\ttotal: 16m 25s\tremaining: 9m 43s\n","628:\tlearn: 0.1342329\ttotal: 16m 28s\tremaining: 9m 42s\n","629:\tlearn: 0.1342241\ttotal: 16m 29s\tremaining: 9m 41s\n","630:\tlearn: 0.1342151\ttotal: 16m 30s\tremaining: 9m 39s\n","631:\tlearn: 0.1342053\ttotal: 16m 32s\tremaining: 9m 37s\n","632:\tlearn: 0.1341945\ttotal: 16m 33s\tremaining: 9m 36s\n","633:\tlearn: 0.1341821\ttotal: 16m 35s\tremaining: 9m 34s\n","634:\tlearn: 0.1341779\ttotal: 16m 36s\tremaining: 9m 33s\n","635:\tlearn: 0.1341762\ttotal: 16m 38s\tremaining: 9m 31s\n","636:\tlearn: 0.1341736\ttotal: 16m 40s\tremaining: 9m 30s\n","637:\tlearn: 0.1341680\ttotal: 16m 42s\tremaining: 9m 28s\n","638:\tlearn: 0.1341543\ttotal: 16m 44s\tremaining: 9m 27s\n","639:\tlearn: 0.1341479\ttotal: 16m 45s\tremaining: 9m 25s\n","640:\tlearn: 0.1341459\ttotal: 16m 46s\tremaining: 9m 23s\n","641:\tlearn: 0.1341357\ttotal: 16m 47s\tremaining: 9m 22s\n","642:\tlearn: 0.1341264\ttotal: 16m 49s\tremaining: 9m 20s\n","643:\tlearn: 0.1341249\ttotal: 16m 50s\tremaining: 9m 18s\n","644:\tlearn: 0.1341160\ttotal: 16m 52s\tremaining: 9m 17s\n","645:\tlearn: 0.1341081\ttotal: 16m 54s\tremaining: 9m 15s\n","646:\tlearn: 0.1341049\ttotal: 16m 56s\tremaining: 9m 14s\n","647:\tlearn: 0.1340985\ttotal: 16m 57s\tremaining: 9m 12s\n","648:\tlearn: 0.1340888\ttotal: 16m 59s\tremaining: 9m 11s\n","649:\tlearn: 0.1340745\ttotal: 17m\tremaining: 9m 9s\n","650:\tlearn: 0.1340596\ttotal: 17m 2s\tremaining: 9m 7s\n","651:\tlearn: 0.1340505\ttotal: 17m 3s\tremaining: 9m 6s\n","652:\tlearn: 0.1340401\ttotal: 17m 5s\tremaining: 9m 4s\n","653:\tlearn: 0.1340328\ttotal: 17m 7s\tremaining: 9m 3s\n","654:\tlearn: 0.1340200\ttotal: 17m 9s\tremaining: 9m 2s\n","655:\tlearn: 0.1340116\ttotal: 17m 10s\tremaining: 9m\n","656:\tlearn: 0.1340026\ttotal: 17m 12s\tremaining: 8m 58s\n","657:\tlearn: 0.1339986\ttotal: 17m 13s\tremaining: 8m 57s\n","658:\tlearn: 0.1339899\ttotal: 17m 14s\tremaining: 8m 55s\n","659:\tlearn: 0.1339820\ttotal: 17m 16s\tremaining: 8m 53s\n","660:\tlearn: 0.1339715\ttotal: 17m 17s\tremaining: 8m 52s\n","661:\tlearn: 0.1339680\ttotal: 17m 18s\tremaining: 8m 50s\n","662:\tlearn: 0.1339576\ttotal: 17m 20s\tremaining: 8m 48s\n","663:\tlearn: 0.1339557\ttotal: 17m 22s\tremaining: 8m 47s\n","664:\tlearn: 0.1339500\ttotal: 17m 23s\tremaining: 8m 45s\n","665:\tlearn: 0.1339379\ttotal: 17m 25s\tremaining: 8m 44s\n","666:\tlearn: 0.1339290\ttotal: 17m 27s\tremaining: 8m 42s\n","667:\tlearn: 0.1339273\ttotal: 17m 28s\tremaining: 8m 40s\n","668:\tlearn: 0.1339223\ttotal: 17m 29s\tremaining: 8m 39s\n","669:\tlearn: 0.1339160\ttotal: 17m 30s\tremaining: 8m 37s\n","670:\tlearn: 0.1339083\ttotal: 17m 32s\tremaining: 8m 35s\n","671:\tlearn: 0.1339066\ttotal: 17m 33s\tremaining: 8m 34s\n","672:\tlearn: 0.1339011\ttotal: 17m 35s\tremaining: 8m 32s\n","673:\tlearn: 0.1338886\ttotal: 17m 37s\tremaining: 8m 31s\n","674:\tlearn: 0.1338798\ttotal: 17m 38s\tremaining: 8m 29s\n","675:\tlearn: 0.1338720\ttotal: 17m 39s\tremaining: 8m 27s\n","676:\tlearn: 0.1338600\ttotal: 17m 41s\tremaining: 8m 26s\n","677:\tlearn: 0.1338496\ttotal: 17m 42s\tremaining: 8m 24s\n","678:\tlearn: 0.1338414\ttotal: 17m 44s\tremaining: 8m 23s\n","679:\tlearn: 0.1338342\ttotal: 17m 45s\tremaining: 8m 21s\n","680:\tlearn: 0.1338324\ttotal: 17m 46s\tremaining: 8m 19s\n","681:\tlearn: 0.1338229\ttotal: 17m 48s\tremaining: 8m 18s\n","682:\tlearn: 0.1338191\ttotal: 17m 50s\tremaining: 8m 16s\n","683:\tlearn: 0.1338126\ttotal: 17m 51s\tremaining: 8m 15s\n","684:\tlearn: 0.1338093\ttotal: 17m 53s\tremaining: 8m 13s\n","685:\tlearn: 0.1338008\ttotal: 17m 54s\tremaining: 8m 11s\n","686:\tlearn: 0.1337893\ttotal: 17m 55s\tremaining: 8m 10s\n","687:\tlearn: 0.1337864\ttotal: 17m 57s\tremaining: 8m 8s\n","688:\tlearn: 0.1337757\ttotal: 17m 58s\tremaining: 8m 6s\n","689:\tlearn: 0.1337700\ttotal: 17m 59s\tremaining: 8m 5s\n","690:\tlearn: 0.1337651\ttotal: 18m 1s\tremaining: 8m 3s\n","691:\tlearn: 0.1337590\ttotal: 18m 3s\tremaining: 8m 2s\n","692:\tlearn: 0.1337525\ttotal: 18m 5s\tremaining: 8m\n","693:\tlearn: 0.1337427\ttotal: 18m 6s\tremaining: 7m 59s\n","694:\tlearn: 0.1337325\ttotal: 18m 7s\tremaining: 7m 57s\n","695:\tlearn: 0.1337223\ttotal: 18m 9s\tremaining: 7m 55s\n","696:\tlearn: 0.1337128\ttotal: 18m 10s\tremaining: 7m 54s\n","697:\tlearn: 0.1337098\ttotal: 18m 11s\tremaining: 7m 52s\n","698:\tlearn: 0.1337084\ttotal: 18m 12s\tremaining: 7m 50s\n","699:\tlearn: 0.1337028\ttotal: 18m 14s\tremaining: 7m 49s\n","700:\tlearn: 0.1336954\ttotal: 18m 17s\tremaining: 7m 48s\n","701:\tlearn: 0.1336856\ttotal: 18m 18s\tremaining: 7m 46s\n","702:\tlearn: 0.1336716\ttotal: 18m 19s\tremaining: 7m 44s\n","703:\tlearn: 0.1336665\ttotal: 18m 21s\tremaining: 7m 42s\n","704:\tlearn: 0.1336518\ttotal: 18m 22s\tremaining: 7m 41s\n","705:\tlearn: 0.1336443\ttotal: 18m 23s\tremaining: 7m 39s\n","706:\tlearn: 0.1336377\ttotal: 18m 25s\tremaining: 7m 38s\n","707:\tlearn: 0.1336336\ttotal: 18m 26s\tremaining: 7m 36s\n","708:\tlearn: 0.1336257\ttotal: 18m 28s\tremaining: 7m 35s\n","709:\tlearn: 0.1336151\ttotal: 18m 31s\tremaining: 7m 34s\n","710:\tlearn: 0.1336076\ttotal: 18m 33s\tremaining: 7m 32s\n","711:\tlearn: 0.1335915\ttotal: 18m 34s\tremaining: 7m 30s\n","712:\tlearn: 0.1335820\ttotal: 18m 36s\tremaining: 7m 29s\n","713:\tlearn: 0.1335726\ttotal: 18m 37s\tremaining: 7m 27s\n","714:\tlearn: 0.1335671\ttotal: 18m 39s\tremaining: 7m 26s\n","715:\tlearn: 0.1335654\ttotal: 18m 40s\tremaining: 7m 24s\n","716:\tlearn: 0.1335635\ttotal: 18m 41s\tremaining: 7m 22s\n","717:\tlearn: 0.1335564\ttotal: 18m 43s\tremaining: 7m 21s\n","718:\tlearn: 0.1335477\ttotal: 18m 45s\tremaining: 7m 19s\n","719:\tlearn: 0.1335403\ttotal: 18m 47s\tremaining: 7m 18s\n","720:\tlearn: 0.1335352\ttotal: 18m 48s\tremaining: 7m 16s\n","721:\tlearn: 0.1335304\ttotal: 18m 50s\tremaining: 7m 15s\n","722:\tlearn: 0.1335195\ttotal: 18m 51s\tremaining: 7m 13s\n","723:\tlearn: 0.1335144\ttotal: 18m 52s\tremaining: 7m 11s\n","724:\tlearn: 0.1335126\ttotal: 18m 53s\tremaining: 7m 10s\n","725:\tlearn: 0.1335085\ttotal: 18m 54s\tremaining: 7m 8s\n","726:\tlearn: 0.1334936\ttotal: 18m 57s\tremaining: 7m 7s\n","727:\tlearn: 0.1334878\ttotal: 18m 59s\tremaining: 7m 5s\n","728:\tlearn: 0.1334770\ttotal: 19m 1s\tremaining: 7m 4s\n","729:\tlearn: 0.1334749\ttotal: 19m 2s\tremaining: 7m 2s\n","730:\tlearn: 0.1334590\ttotal: 19m 3s\tremaining: 7m\n","731:\tlearn: 0.1334523\ttotal: 19m 5s\tremaining: 6m 59s\n","732:\tlearn: 0.1334423\ttotal: 19m 6s\tremaining: 6m 57s\n","733:\tlearn: 0.1334364\ttotal: 19m 7s\tremaining: 6m 55s\n","734:\tlearn: 0.1334292\ttotal: 19m 9s\tremaining: 6m 54s\n","735:\tlearn: 0.1334245\ttotal: 19m 10s\tremaining: 6m 52s\n","736:\tlearn: 0.1334111\ttotal: 19m 13s\tremaining: 6m 51s\n","737:\tlearn: 0.1333986\ttotal: 19m 14s\tremaining: 6m 49s\n","738:\tlearn: 0.1333877\ttotal: 19m 16s\tremaining: 6m 48s\n","739:\tlearn: 0.1333824\ttotal: 19m 17s\tremaining: 6m 46s\n","740:\tlearn: 0.1333703\ttotal: 19m 19s\tremaining: 6m 45s\n","741:\tlearn: 0.1333617\ttotal: 19m 20s\tremaining: 6m 43s\n","742:\tlearn: 0.1333509\ttotal: 19m 22s\tremaining: 6m 42s\n","743:\tlearn: 0.1333434\ttotal: 19m 24s\tremaining: 6m 40s\n","744:\tlearn: 0.1333346\ttotal: 19m 27s\tremaining: 6m 39s\n","745:\tlearn: 0.1333299\ttotal: 19m 28s\tremaining: 6m 37s\n","746:\tlearn: 0.1333288\ttotal: 19m 29s\tremaining: 6m 36s\n","747:\tlearn: 0.1333209\ttotal: 19m 31s\tremaining: 6m 34s\n","748:\tlearn: 0.1333172\ttotal: 19m 32s\tremaining: 6m 32s\n","749:\tlearn: 0.1333101\ttotal: 19m 33s\tremaining: 6m 31s\n","750:\tlearn: 0.1333076\ttotal: 19m 34s\tremaining: 6m 29s\n","751:\tlearn: 0.1333014\ttotal: 19m 35s\tremaining: 6m 27s\n","752:\tlearn: 0.1332883\ttotal: 19m 38s\tremaining: 6m 26s\n","753:\tlearn: 0.1332795\ttotal: 19m 40s\tremaining: 6m 25s\n","754:\tlearn: 0.1332700\ttotal: 19m 42s\tremaining: 6m 23s\n","755:\tlearn: 0.1332644\ttotal: 19m 43s\tremaining: 6m 21s\n","756:\tlearn: 0.1332600\ttotal: 19m 44s\tremaining: 6m 20s\n","757:\tlearn: 0.1332541\ttotal: 19m 45s\tremaining: 6m 18s\n","758:\tlearn: 0.1332478\ttotal: 19m 47s\tremaining: 6m 16s\n","759:\tlearn: 0.1332374\ttotal: 19m 48s\tremaining: 6m 15s\n","760:\tlearn: 0.1332362\ttotal: 19m 49s\tremaining: 6m 13s\n","761:\tlearn: 0.1332335\ttotal: 19m 51s\tremaining: 6m 12s\n","762:\tlearn: 0.1332231\ttotal: 19m 54s\tremaining: 6m 10s\n","763:\tlearn: 0.1332171\ttotal: 19m 55s\tremaining: 6m 9s\n","764:\tlearn: 0.1332113\ttotal: 19m 56s\tremaining: 6m 7s\n","765:\tlearn: 0.1332083\ttotal: 19m 57s\tremaining: 6m 5s\n","766:\tlearn: 0.1332038\ttotal: 19m 59s\tremaining: 6m 4s\n","767:\tlearn: 0.1331976\ttotal: 20m\tremaining: 6m 2s\n","768:\tlearn: 0.1331881\ttotal: 20m 1s\tremaining: 6m\n","769:\tlearn: 0.1331788\ttotal: 20m 3s\tremaining: 5m 59s\n","770:\tlearn: 0.1331703\ttotal: 20m 4s\tremaining: 5m 57s\n","771:\tlearn: 0.1331629\ttotal: 20m 7s\tremaining: 5m 56s\n","772:\tlearn: 0.1331611\ttotal: 20m 8s\tremaining: 5m 54s\n","773:\tlearn: 0.1331516\ttotal: 20m 10s\tremaining: 5m 53s\n","774:\tlearn: 0.1331479\ttotal: 20m 11s\tremaining: 5m 51s\n","775:\tlearn: 0.1331406\ttotal: 20m 12s\tremaining: 5m 50s\n","776:\tlearn: 0.1331302\ttotal: 20m 14s\tremaining: 5m 48s\n","777:\tlearn: 0.1331199\ttotal: 20m 16s\tremaining: 5m 47s\n","778:\tlearn: 0.1331137\ttotal: 20m 17s\tremaining: 5m 45s\n","779:\tlearn: 0.1331026\ttotal: 20m 20s\tremaining: 5m 44s\n","780:\tlearn: 0.1330977\ttotal: 20m 22s\tremaining: 5m 42s\n","781:\tlearn: 0.1330892\ttotal: 20m 23s\tremaining: 5m 41s\n","782:\tlearn: 0.1330867\ttotal: 20m 24s\tremaining: 5m 39s\n","783:\tlearn: 0.1330793\ttotal: 20m 26s\tremaining: 5m 37s\n","784:\tlearn: 0.1330739\ttotal: 20m 27s\tremaining: 5m 36s\n","785:\tlearn: 0.1330697\ttotal: 20m 28s\tremaining: 5m 34s\n","786:\tlearn: 0.1330634\ttotal: 20m 30s\tremaining: 5m 32s\n","787:\tlearn: 0.1330595\ttotal: 20m 31s\tremaining: 5m 31s\n","788:\tlearn: 0.1330557\ttotal: 20m 32s\tremaining: 5m 29s\n","789:\tlearn: 0.1330437\ttotal: 20m 35s\tremaining: 5m 28s\n","790:\tlearn: 0.1330427\ttotal: 20m 36s\tremaining: 5m 26s\n","791:\tlearn: 0.1330384\ttotal: 20m 37s\tremaining: 5m 25s\n","792:\tlearn: 0.1330279\ttotal: 20m 39s\tremaining: 5m 23s\n","793:\tlearn: 0.1330230\ttotal: 20m 40s\tremaining: 5m 21s\n","794:\tlearn: 0.1330213\ttotal: 20m 41s\tremaining: 5m 20s\n","795:\tlearn: 0.1330203\ttotal: 20m 42s\tremaining: 5m 18s\n","796:\tlearn: 0.1330140\ttotal: 20m 44s\tremaining: 5m 16s\n","797:\tlearn: 0.1330013\ttotal: 20m 45s\tremaining: 5m 15s\n","798:\tlearn: 0.1329964\ttotal: 20m 47s\tremaining: 5m 13s\n","799:\tlearn: 0.1329918\ttotal: 20m 49s\tremaining: 5m 12s\n","800:\tlearn: 0.1329832\ttotal: 20m 51s\tremaining: 5m 10s\n","801:\tlearn: 0.1329785\ttotal: 20m 52s\tremaining: 5m 9s\n","802:\tlearn: 0.1329701\ttotal: 20m 54s\tremaining: 5m 7s\n","803:\tlearn: 0.1329631\ttotal: 20m 55s\tremaining: 5m 6s\n","804:\tlearn: 0.1329622\ttotal: 20m 56s\tremaining: 5m 4s\n","805:\tlearn: 0.1329529\ttotal: 20m 57s\tremaining: 5m 2s\n","806:\tlearn: 0.1329457\ttotal: 20m 59s\tremaining: 5m 1s\n","807:\tlearn: 0.1329406\ttotal: 21m 1s\tremaining: 4m 59s\n","808:\tlearn: 0.1329373\ttotal: 21m 3s\tremaining: 4m 58s\n","809:\tlearn: 0.1329305\ttotal: 21m 5s\tremaining: 4m 56s\n","810:\tlearn: 0.1329230\ttotal: 21m 6s\tremaining: 4m 55s\n","811:\tlearn: 0.1329132\ttotal: 21m 8s\tremaining: 4m 53s\n","812:\tlearn: 0.1329095\ttotal: 21m 9s\tremaining: 4m 52s\n","813:\tlearn: 0.1329074\ttotal: 21m 10s\tremaining: 4m 50s\n","814:\tlearn: 0.1329060\ttotal: 21m 11s\tremaining: 4m 48s\n","815:\tlearn: 0.1328998\ttotal: 21m 13s\tremaining: 4m 47s\n","816:\tlearn: 0.1328980\ttotal: 21m 15s\tremaining: 4m 45s\n","817:\tlearn: 0.1328900\ttotal: 21m 17s\tremaining: 4m 44s\n","818:\tlearn: 0.1328803\ttotal: 21m 19s\tremaining: 4m 42s\n","819:\tlearn: 0.1328753\ttotal: 21m 20s\tremaining: 4m 41s\n","820:\tlearn: 0.1328735\ttotal: 21m 21s\tremaining: 4m 39s\n","821:\tlearn: 0.1328723\ttotal: 21m 23s\tremaining: 4m 37s\n","822:\tlearn: 0.1328630\ttotal: 21m 24s\tremaining: 4m 36s\n","823:\tlearn: 0.1328528\ttotal: 21m 26s\tremaining: 4m 34s\n","824:\tlearn: 0.1328405\ttotal: 21m 28s\tremaining: 4m 33s\n","825:\tlearn: 0.1328309\ttotal: 21m 31s\tremaining: 4m 31s\n","826:\tlearn: 0.1328219\ttotal: 21m 32s\tremaining: 4m 30s\n","827:\tlearn: 0.1328132\ttotal: 21m 33s\tremaining: 4m 28s\n","828:\tlearn: 0.1328037\ttotal: 21m 35s\tremaining: 4m 27s\n","829:\tlearn: 0.1328024\ttotal: 21m 36s\tremaining: 4m 25s\n","830:\tlearn: 0.1327899\ttotal: 21m 38s\tremaining: 4m 24s\n","831:\tlearn: 0.1327884\ttotal: 21m 39s\tremaining: 4m 22s\n","832:\tlearn: 0.1327821\ttotal: 21m 40s\tremaining: 4m 20s\n","833:\tlearn: 0.1327728\ttotal: 21m 42s\tremaining: 4m 19s\n","834:\tlearn: 0.1327715\ttotal: 21m 44s\tremaining: 4m 17s\n","835:\tlearn: 0.1327693\ttotal: 21m 46s\tremaining: 4m 16s\n","836:\tlearn: 0.1327647\ttotal: 21m 47s\tremaining: 4m 14s\n","837:\tlearn: 0.1327566\ttotal: 21m 48s\tremaining: 4m 12s\n","838:\tlearn: 0.1327477\ttotal: 21m 50s\tremaining: 4m 11s\n","839:\tlearn: 0.1327422\ttotal: 21m 51s\tremaining: 4m 9s\n","840:\tlearn: 0.1327314\ttotal: 21m 52s\tremaining: 4m 8s\n","841:\tlearn: 0.1327224\ttotal: 21m 54s\tremaining: 4m 6s\n","842:\tlearn: 0.1327187\ttotal: 21m 56s\tremaining: 4m 5s\n","843:\tlearn: 0.1327112\ttotal: 21m 58s\tremaining: 4m 3s\n","844:\tlearn: 0.1327071\ttotal: 22m\tremaining: 4m 2s\n","845:\tlearn: 0.1327048\ttotal: 22m 1s\tremaining: 4m\n","846:\tlearn: 0.1326956\ttotal: 22m 3s\tremaining: 3m 58s\n","847:\tlearn: 0.1326868\ttotal: 22m 4s\tremaining: 3m 57s\n","848:\tlearn: 0.1326768\ttotal: 22m 6s\tremaining: 3m 55s\n","849:\tlearn: 0.1326661\ttotal: 22m 7s\tremaining: 3m 54s\n","850:\tlearn: 0.1326615\ttotal: 22m 9s\tremaining: 3m 52s\n","851:\tlearn: 0.1326596\ttotal: 22m 11s\tremaining: 3m 51s\n","852:\tlearn: 0.1326536\ttotal: 22m 13s\tremaining: 3m 49s\n","853:\tlearn: 0.1326430\ttotal: 22m 14s\tremaining: 3m 48s\n","854:\tlearn: 0.1326400\ttotal: 22m 15s\tremaining: 3m 46s\n","855:\tlearn: 0.1326291\ttotal: 22m 16s\tremaining: 3m 44s\n","856:\tlearn: 0.1326148\ttotal: 22m 18s\tremaining: 3m 43s\n","857:\tlearn: 0.1326092\ttotal: 22m 19s\tremaining: 3m 41s\n","858:\tlearn: 0.1325971\ttotal: 22m 21s\tremaining: 3m 40s\n","859:\tlearn: 0.1325948\ttotal: 22m 23s\tremaining: 3m 38s\n","860:\tlearn: 0.1325901\ttotal: 22m 25s\tremaining: 3m 37s\n","861:\tlearn: 0.1325889\ttotal: 22m 27s\tremaining: 3m 35s\n","862:\tlearn: 0.1325870\ttotal: 22m 28s\tremaining: 3m 34s\n","863:\tlearn: 0.1325850\ttotal: 22m 29s\tremaining: 3m 32s\n","864:\tlearn: 0.1325769\ttotal: 22m 30s\tremaining: 3m 30s\n","865:\tlearn: 0.1325745\ttotal: 22m 31s\tremaining: 3m 29s\n","866:\tlearn: 0.1325683\ttotal: 22m 33s\tremaining: 3m 27s\n","867:\tlearn: 0.1325601\ttotal: 22m 34s\tremaining: 3m 26s\n","868:\tlearn: 0.1325501\ttotal: 22m 36s\tremaining: 3m 24s\n","869:\tlearn: 0.1325408\ttotal: 22m 39s\tremaining: 3m 23s\n","870:\tlearn: 0.1325371\ttotal: 22m 40s\tremaining: 3m 21s\n","871:\tlearn: 0.1325330\ttotal: 22m 41s\tremaining: 3m 19s\n","872:\tlearn: 0.1325235\ttotal: 22m 43s\tremaining: 3m 18s\n","873:\tlearn: 0.1325167\ttotal: 22m 44s\tremaining: 3m 16s\n","874:\tlearn: 0.1325095\ttotal: 22m 45s\tremaining: 3m 15s\n","875:\tlearn: 0.1325036\ttotal: 22m 47s\tremaining: 3m 13s\n","876:\tlearn: 0.1325023\ttotal: 22m 48s\tremaining: 3m 11s\n","877:\tlearn: 0.1324929\ttotal: 22m 50s\tremaining: 3m 10s\n","878:\tlearn: 0.1324875\ttotal: 22m 52s\tremaining: 3m 8s\n","879:\tlearn: 0.1324801\ttotal: 22m 54s\tremaining: 3m 7s\n","880:\tlearn: 0.1324783\ttotal: 22m 55s\tremaining: 3m 5s\n","881:\tlearn: 0.1324722\ttotal: 22m 57s\tremaining: 3m 4s\n","882:\tlearn: 0.1324659\ttotal: 22m 58s\tremaining: 3m 2s\n","883:\tlearn: 0.1324638\ttotal: 22m 59s\tremaining: 3m\n","884:\tlearn: 0.1324611\ttotal: 23m\tremaining: 2m 59s\n","885:\tlearn: 0.1324600\ttotal: 23m 1s\tremaining: 2m 57s\n","886:\tlearn: 0.1324586\ttotal: 23m 2s\tremaining: 2m 56s\n","887:\tlearn: 0.1324521\ttotal: 23m 4s\tremaining: 2m 54s\n","888:\tlearn: 0.1324499\ttotal: 23m 5s\tremaining: 2m 53s\n","889:\tlearn: 0.1324438\ttotal: 23m 7s\tremaining: 2m 51s\n","890:\tlearn: 0.1324319\ttotal: 23m 9s\tremaining: 2m 49s\n","891:\tlearn: 0.1324201\ttotal: 23m 10s\tremaining: 2m 48s\n","892:\tlearn: 0.1324066\ttotal: 23m 12s\tremaining: 2m 46s\n","893:\tlearn: 0.1324045\ttotal: 23m 13s\tremaining: 2m 45s\n","894:\tlearn: 0.1324022\ttotal: 23m 14s\tremaining: 2m 43s\n","895:\tlearn: 0.1323960\ttotal: 23m 16s\tremaining: 2m 42s\n","896:\tlearn: 0.1323931\ttotal: 23m 17s\tremaining: 2m 40s\n","897:\tlearn: 0.1323900\ttotal: 23m 19s\tremaining: 2m 38s\n","898:\tlearn: 0.1323785\ttotal: 23m 21s\tremaining: 2m 37s\n","899:\tlearn: 0.1323762\ttotal: 23m 23s\tremaining: 2m 35s\n","900:\tlearn: 0.1323702\ttotal: 23m 24s\tremaining: 2m 34s\n","901:\tlearn: 0.1323686\ttotal: 23m 26s\tremaining: 2m 32s\n","902:\tlearn: 0.1323599\ttotal: 23m 27s\tremaining: 2m 31s\n","903:\tlearn: 0.1323550\ttotal: 23m 28s\tremaining: 2m 29s\n","904:\tlearn: 0.1323472\ttotal: 23m 30s\tremaining: 2m 28s\n","905:\tlearn: 0.1323381\ttotal: 23m 31s\tremaining: 2m 26s\n","906:\tlearn: 0.1323311\ttotal: 23m 33s\tremaining: 2m 24s\n","907:\tlearn: 0.1323264\ttotal: 23m 35s\tremaining: 2m 23s\n","908:\tlearn: 0.1323215\ttotal: 23m 37s\tremaining: 2m 21s\n","909:\tlearn: 0.1323149\ttotal: 23m 38s\tremaining: 2m 20s\n","910:\tlearn: 0.1323102\ttotal: 23m 39s\tremaining: 2m 18s\n","911:\tlearn: 0.1323023\ttotal: 23m 41s\tremaining: 2m 17s\n","912:\tlearn: 0.1322942\ttotal: 23m 42s\tremaining: 2m 15s\n","913:\tlearn: 0.1322781\ttotal: 23m 44s\tremaining: 2m 14s\n","914:\tlearn: 0.1322772\ttotal: 23m 46s\tremaining: 2m 12s\n","915:\tlearn: 0.1322741\ttotal: 23m 47s\tremaining: 2m 10s\n","916:\tlearn: 0.1322697\ttotal: 23m 49s\tremaining: 2m 9s\n","917:\tlearn: 0.1322635\ttotal: 23m 50s\tremaining: 2m 7s\n","918:\tlearn: 0.1322570\ttotal: 23m 52s\tremaining: 2m 6s\n","919:\tlearn: 0.1322493\ttotal: 23m 53s\tremaining: 2m 4s\n","920:\tlearn: 0.1322435\ttotal: 23m 54s\tremaining: 2m 3s\n","921:\tlearn: 0.1322429\ttotal: 23m 55s\tremaining: 2m 1s\n","922:\tlearn: 0.1322379\ttotal: 23m 56s\tremaining: 1m 59s\n","923:\tlearn: 0.1322340\ttotal: 23m 57s\tremaining: 1m 58s\n","924:\tlearn: 0.1322311\ttotal: 23m 59s\tremaining: 1m 56s\n","925:\tlearn: 0.1322207\ttotal: 24m 2s\tremaining: 1m 55s\n","926:\tlearn: 0.1322138\ttotal: 24m 3s\tremaining: 1m 53s\n","927:\tlearn: 0.1322118\ttotal: 24m 5s\tremaining: 1m 52s\n","928:\tlearn: 0.1322097\ttotal: 24m 6s\tremaining: 1m 50s\n","929:\tlearn: 0.1322016\ttotal: 24m 7s\tremaining: 1m 48s\n","930:\tlearn: 0.1321960\ttotal: 24m 9s\tremaining: 1m 47s\n","931:\tlearn: 0.1321910\ttotal: 24m 10s\tremaining: 1m 45s\n","932:\tlearn: 0.1321894\ttotal: 24m 11s\tremaining: 1m 44s\n","933:\tlearn: 0.1321827\ttotal: 24m 14s\tremaining: 1m 42s\n","934:\tlearn: 0.1321809\ttotal: 24m 15s\tremaining: 1m 41s\n","935:\tlearn: 0.1321788\ttotal: 24m 17s\tremaining: 1m 39s\n","936:\tlearn: 0.1321763\ttotal: 24m 18s\tremaining: 1m 38s\n","937:\tlearn: 0.1321740\ttotal: 24m 19s\tremaining: 1m 36s\n","938:\tlearn: 0.1321702\ttotal: 24m 20s\tremaining: 1m 34s\n","939:\tlearn: 0.1321661\ttotal: 24m 21s\tremaining: 1m 33s\n","940:\tlearn: 0.1321632\ttotal: 24m 22s\tremaining: 1m 31s\n","941:\tlearn: 0.1321577\ttotal: 24m 24s\tremaining: 1m 30s\n","942:\tlearn: 0.1321543\ttotal: 24m 25s\tremaining: 1m 28s\n","943:\tlearn: 0.1321502\ttotal: 24m 27s\tremaining: 1m 27s\n","944:\tlearn: 0.1321449\ttotal: 24m 29s\tremaining: 1m 25s\n","945:\tlearn: 0.1321408\ttotal: 24m 30s\tremaining: 1m 23s\n","946:\tlearn: 0.1321321\ttotal: 24m 32s\tremaining: 1m 22s\n","947:\tlearn: 0.1321260\ttotal: 24m 33s\tremaining: 1m 20s\n","948:\tlearn: 0.1321246\ttotal: 24m 35s\tremaining: 1m 19s\n","949:\tlearn: 0.1321171\ttotal: 24m 36s\tremaining: 1m 17s\n","950:\tlearn: 0.1321071\ttotal: 24m 37s\tremaining: 1m 16s\n","951:\tlearn: 0.1321056\ttotal: 24m 39s\tremaining: 1m 14s\n","952:\tlearn: 0.1321010\ttotal: 24m 40s\tremaining: 1m 13s\n","953:\tlearn: 0.1320953\ttotal: 24m 42s\tremaining: 1m 11s\n","954:\tlearn: 0.1320848\ttotal: 24m 44s\tremaining: 1m 9s\n","955:\tlearn: 0.1320837\ttotal: 24m 45s\tremaining: 1m 8s\n","956:\tlearn: 0.1320820\ttotal: 24m 46s\tremaining: 1m 6s\n","957:\tlearn: 0.1320725\ttotal: 24m 48s\tremaining: 1m 5s\n","958:\tlearn: 0.1320608\ttotal: 24m 49s\tremaining: 1m 3s\n","959:\tlearn: 0.1320575\ttotal: 24m 51s\tremaining: 1m 2s\n","960:\tlearn: 0.1320519\ttotal: 24m 52s\tremaining: 1m\n","961:\tlearn: 0.1320467\ttotal: 24m 54s\tremaining: 59s\n","962:\tlearn: 0.1320408\ttotal: 24m 57s\tremaining: 57.5s\n","963:\tlearn: 0.1320398\ttotal: 24m 58s\tremaining: 55.9s\n","964:\tlearn: 0.1320278\ttotal: 24m 59s\tremaining: 54.4s\n","965:\tlearn: 0.1320198\ttotal: 25m 1s\tremaining: 52.8s\n","966:\tlearn: 0.1320146\ttotal: 25m 2s\tremaining: 51.3s\n","967:\tlearn: 0.1320064\ttotal: 25m 4s\tremaining: 49.7s\n","968:\tlearn: 0.1319966\ttotal: 25m 5s\tremaining: 48.2s\n","969:\tlearn: 0.1319866\ttotal: 25m 6s\tremaining: 46.6s\n","970:\tlearn: 0.1319765\ttotal: 25m 9s\tremaining: 45.1s\n","971:\tlearn: 0.1319738\ttotal: 25m 11s\tremaining: 43.5s\n","972:\tlearn: 0.1319729\ttotal: 25m 12s\tremaining: 42s\n","973:\tlearn: 0.1319700\ttotal: 25m 13s\tremaining: 40.4s\n","974:\tlearn: 0.1319681\ttotal: 25m 14s\tremaining: 38.8s\n","975:\tlearn: 0.1319611\ttotal: 25m 15s\tremaining: 37.3s\n","976:\tlearn: 0.1319548\ttotal: 25m 16s\tremaining: 35.7s\n","977:\tlearn: 0.1319491\ttotal: 25m 18s\tremaining: 34.2s\n","978:\tlearn: 0.1319399\ttotal: 25m 19s\tremaining: 32.6s\n","979:\tlearn: 0.1319345\ttotal: 25m 21s\tremaining: 31s\n","980:\tlearn: 0.1319315\ttotal: 25m 24s\tremaining: 29.5s\n","981:\tlearn: 0.1319194\ttotal: 25m 26s\tremaining: 28s\n","982:\tlearn: 0.1319164\ttotal: 25m 28s\tremaining: 26.4s\n","983:\tlearn: 0.1319089\ttotal: 25m 29s\tremaining: 24.9s\n","984:\tlearn: 0.1319027\ttotal: 25m 31s\tremaining: 23.3s\n","985:\tlearn: 0.1319000\ttotal: 25m 32s\tremaining: 21.8s\n","986:\tlearn: 0.1318881\ttotal: 25m 33s\tremaining: 20.2s\n","987:\tlearn: 0.1318814\ttotal: 25m 35s\tremaining: 18.6s\n","988:\tlearn: 0.1318770\ttotal: 25m 36s\tremaining: 17.1s\n","989:\tlearn: 0.1318701\ttotal: 25m 38s\tremaining: 15.5s\n","990:\tlearn: 0.1318633\ttotal: 25m 41s\tremaining: 14s\n","991:\tlearn: 0.1318575\ttotal: 25m 42s\tremaining: 12.4s\n","992:\tlearn: 0.1318531\ttotal: 25m 43s\tremaining: 10.9s\n","993:\tlearn: 0.1318420\ttotal: 25m 45s\tremaining: 9.33s\n","994:\tlearn: 0.1318386\ttotal: 25m 46s\tremaining: 7.77s\n","995:\tlearn: 0.1318320\ttotal: 25m 47s\tremaining: 6.21s\n","996:\tlearn: 0.1318262\ttotal: 25m 49s\tremaining: 4.66s\n","997:\tlearn: 0.1318248\ttotal: 25m 50s\tremaining: 3.11s\n","998:\tlearn: 0.1318205\ttotal: 25m 52s\tremaining: 1.55s\n","999:\tlearn: 0.1318190\ttotal: 25m 53s\tremaining: 0us\n","train: 0.5094475964722414\n","test: 0.5010228013056938\n","test conf matrix: \n"," [[867890    124]\n"," [ 31916     70]]\n"]}]},{"cell_type":"code","source":["# с балансировкой классов\n","classes = np.unique(y_train)\n","weights = compute_class_weight(class_weight='balanced', classes=classes, y=y_train['flag'])\n","class_weights = dict(zip(classes, weights))\n","\n","model_catb = CatBoostClassifier(class_weights=class_weights, verbose=False)\n","model_catb.fit(x_train, y_train)\n","\n","pred_train = model_catb.predict(x_train)\n","pred_test = model_catb.predict(x_test)\n","\n","print(f'train: {roc_auc_score(y_train, pred_train)}')\n","print(f'test: {roc_auc_score(y_test, pred_test)}')\n","print(f'test conf matrix: \\n {confusion_matrix(y_test, pred_test)}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aTOHd5s3J5uT","executionInfo":{"status":"ok","timestamp":1708686860930,"user_tz":-240,"elapsed":1733738,"user":{"displayName":"Евгений Малов","userId":"06257165098392198337"}},"outputId":"66a0a00a-670a-43d8-f3e5-632d91eb64e5"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["train: 0.753122237508023\n","test: 0.6730652402971351\n","test conf matrix: \n"," [[625931 242083]\n"," [ 11994  19992]]\n"]}]},{"cell_type":"code","source":["# обучение дефолтных моделей, проверить балансировку классов\n","estimators = [\n","    ('lgbm', model_lgbm),\n","    ('xgb', model_xbm),\n","    ('cb', model_catb)\n","    ]\n","\n","sample_weights = np.zeros(len(y_train))\n","sample_weights[y_train['flag'] == 0] = 1.0\n","sample_weights[y_train['flag'] == 1] = 27.0\n","\n","reg = StackingClassifier(\n","    estimators=estimators,\n","    final_estimator=GradientBoostingClassifier(learning_rate = 0.02, n_estimators = 100, random_state=42))\n","\n","reg.fit(x_train, y_train, sample_weight=sample_weights)\n","pred_train = reg.predict(x_train)\n","pred_test = reg.predict(x_test)\n","\n","print(f'train: {roc_auc_score(y_train, pred_train)}')\n","print(f'test: {roc_auc_score(y_test, pred_test)}')\n","print(f'test conf matrix: \\n {confusion_matrix(y_test, pred_test)}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1708695772474,"user_tz":-240,"elapsed":8237822,"user":{"displayName":"Евгений Малов","userId":"06257165098392198337"}},"outputId":"511aad42-ca8e-4285-9893-21556e044802","id":"7_liMtmtRDne"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["[LightGBM] [Info] Number of positive: 74456, number of negative: 2025544\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 6.547675 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 3878\n","[LightGBM] [Info] Number of data points in the train set: 2100000, number of used features: 219\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.964286 -> initscore=3.295837\n","[LightGBM] [Info] Start training from score 3.295837\n","[LightGBM] [Info] Number of positive: 59565, number of negative: 1620435\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 5.481097 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 3865\n","[LightGBM] [Info] Number of data points in the train set: 1680000, number of used features: 219\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.964286 -> initscore=3.295837\n","[LightGBM] [Info] Start training from score 3.295837\n","[LightGBM] [Info] Number of positive: 59565, number of negative: 1620435\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 4.931360 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 3881\n","[LightGBM] [Info] Number of data points in the train set: 1680000, number of used features: 219\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.964286 -> initscore=3.295837\n","[LightGBM] [Info] Start training from score 3.295837\n","[LightGBM] [Info] Number of positive: 59565, number of negative: 1620435\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 5.143298 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 3872\n","[LightGBM] [Info] Number of data points in the train set: 1680000, number of used features: 219\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.964286 -> initscore=3.295837\n","[LightGBM] [Info] Start training from score 3.295837\n","[LightGBM] [Info] Number of positive: 59565, number of negative: 1620435\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 5.140389 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 3884\n","[LightGBM] [Info] Number of data points in the train set: 1680000, number of used features: 219\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.964286 -> initscore=3.295837\n","[LightGBM] [Info] Start training from score 3.295837\n","[LightGBM] [Info] Number of positive: 59564, number of negative: 1620436\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 4.566811 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 3869\n","[LightGBM] [Info] Number of data points in the train set: 1680000, number of used features: 219\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.964286 -> initscore=3.295837\n","[LightGBM] [Info] Start training from score 3.295837\n","train: 0.6957385007914969\n","test: 0.6804790416214369\n","test conf matrix: \n"," [[562600 305414]\n"," [  9186  22800]]\n"]}]},{"cell_type":"code","source":["with open(os.path.join(path, f'222_default_model.pkl'), 'wb') as file:\n","    dill.dump(reg, file)"],"metadata":{"id":"MbH_2uEMRDnj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["with open(path + '/222_default_model.pkl', 'rb') as file:\n","    222_default_model = dill.load(file)\n","222_default_model"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":164},"executionInfo":{"status":"ok","timestamp":1708279976529,"user_tz":-240,"elapsed":304,"user":{"displayName":"Евгений Малов","userId":"06257165098392198337"}},"outputId":"fbe13d13-9600-4ac0-cfb4-dff8df5d9d96","id":"BGqSW3I1RDnm"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["StackingClassifier(estimators=[('lgbm', LGBMClassifier()),\n","                               ('xgb',\n","                                XGBClassifier(base_score=None, booster=None,\n","                                              callbacks=None,\n","                                              colsample_bylevel=None,\n","                                              colsample_bynode=None,\n","                                              colsample_bytree=None,\n","                                              device=None,\n","                                              early_stopping_rounds=None,\n","                                              enable_categorical=False,\n","                                              eval_metric=None,\n","                                              feature_types=None, gamma=None,\n","                                              grow_policy=None,\n","                                              importance_type=None,\n","                                              interaction_...\n","                                              max_delta_step=None,\n","                                              max_depth=None, max_leaves=None,\n","                                              min_child_weight=None,\n","                                              missing=nan,\n","                                              monotone_constraints=None,\n","                                              multi_strategy=None,\n","                                              n_estimators=None, n_jobs=None,\n","                                              num_parallel_tree=None,\n","                                              random_state=None, ...)),\n","                               ('cb',\n","                                <catboost.core.CatBoostClassifier object at 0x7d38094fbb80>)],\n","                   final_estimator=GradientBoostingClassifier(learning_rate=0.02,\n","                                                              random_state=42))"],"text/html":["<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>StackingClassifier(estimators=[(&#x27;lgbm&#x27;, LGBMClassifier()),\n","                               (&#x27;xgb&#x27;,\n","                                XGBClassifier(base_score=None, booster=None,\n","                                              callbacks=None,\n","                                              colsample_bylevel=None,\n","                                              colsample_bynode=None,\n","                                              colsample_bytree=None,\n","                                              device=None,\n","                                              early_stopping_rounds=None,\n","                                              enable_categorical=False,\n","                                              eval_metric=None,\n","                                              feature_types=None, gamma=None,\n","                                              grow_policy=None,\n","                                              importance_type=None,\n","                                              interaction_...\n","                                              max_delta_step=None,\n","                                              max_depth=None, max_leaves=None,\n","                                              min_child_weight=None,\n","                                              missing=nan,\n","                                              monotone_constraints=None,\n","                                              multi_strategy=None,\n","                                              n_estimators=None, n_jobs=None,\n","                                              num_parallel_tree=None,\n","                                              random_state=None, ...)),\n","                               (&#x27;cb&#x27;,\n","                                &lt;catboost.core.CatBoostClassifier object at 0x7d38094fbb80&gt;)],\n","                   final_estimator=GradientBoostingClassifier(learning_rate=0.02,\n","                                                              random_state=42))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StackingClassifier</label><div class=\"sk-toggleable__content\"><pre>StackingClassifier(estimators=[(&#x27;lgbm&#x27;, LGBMClassifier()),\n","                               (&#x27;xgb&#x27;,\n","                                XGBClassifier(base_score=None, booster=None,\n","                                              callbacks=None,\n","                                              colsample_bylevel=None,\n","                                              colsample_bynode=None,\n","                                              colsample_bytree=None,\n","                                              device=None,\n","                                              early_stopping_rounds=None,\n","                                              enable_categorical=False,\n","                                              eval_metric=None,\n","                                              feature_types=None, gamma=None,\n","                                              grow_policy=None,\n","                                              importance_type=None,\n","                                              interaction_...\n","                                              max_delta_step=None,\n","                                              max_depth=None, max_leaves=None,\n","                                              min_child_weight=None,\n","                                              missing=nan,\n","                                              monotone_constraints=None,\n","                                              multi_strategy=None,\n","                                              n_estimators=None, n_jobs=None,\n","                                              num_parallel_tree=None,\n","                                              random_state=None, ...)),\n","                               (&#x27;cb&#x27;,\n","                                &lt;catboost.core.CatBoostClassifier object at 0x7d38094fbb80&gt;)],\n","                   final_estimator=GradientBoostingClassifier(learning_rate=0.02,\n","                                                              random_state=42))</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>lgbm</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>xgb</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n","              colsample_bylevel=None, colsample_bynode=None,\n","              colsample_bytree=None, device=None, early_stopping_rounds=None,\n","              enable_categorical=False, eval_metric=None, feature_types=None,\n","              gamma=None, grow_policy=None, importance_type=None,\n","              interaction_constraints=None, learning_rate=None, max_bin=None,\n","              max_cat_threshold=None, max_cat_to_onehot=None,\n","              max_delta_step=None, max_depth=None, max_leaves=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              multi_strategy=None, n_estimators=None, n_jobs=None,\n","              num_parallel_tree=None, random_state=None, ...)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>cb</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CatBoostClassifier</label><div class=\"sk-toggleable__content\"><pre>&lt;catboost.core.CatBoostClassifier object at 0x7d38094fbb80&gt;</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>final_estimator</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier(learning_rate=0.02, random_state=42)</pre></div></div></div></div></div></div></div></div></div></div></div></div>"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","source":["# не запускается - выдает ошибку переполнения памяти.\n","def objective_lgbm(trial):\n","    max_depth = trial.suggest_int(\"max_depth\", 2, 15)\n","    learning_rate = trial.suggest_float(\"learning_rate\", 1e-5, 1, log=True)\n","    n_estimators = trial.suggest_int(\"n_estimators\", 10, 700)\n","\n","    score = cross_val_score(LGBMClassifier(max_depth=max_depth, learning_rate=learning_rate, n_estimators=n_estimators),\n","                            x_train, y_train, cv=3, scoring='roc_auc', n_jobs=-1).mean()\n","    return score\n","\n","\n","study_lgbm = optuna.create_study(direction=\"maximize\")\n","study_lgbm.optimize(objective_lgbm, n_trials=50)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":897},"id":"A7on1HkeVimR","executionInfo":{"status":"error","timestamp":1708683274899,"user_tz":-240,"elapsed":15920,"user":{"displayName":"Евгений Малов","userId":"06257165098392198337"}},"outputId":"349ba510-5e9d-45fa-8380-0b3368f1a95b"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stderr","text":["[I 2024-02-23 10:14:18,691] A new study created in memory with name: no-name-9a589ebb-8614-432f-9602-1a60ec6d0521\n","[W 2024-02-23 10:14:33,944] Trial 0 failed with parameters: {'max_depth': 3, 'learning_rate': 0.777730918778325, 'n_estimators': 61} because of the following error: TerminatedWorkerError('A worker process managed by the executor was unexpectedly terminated. This could be caused by a segmentation fault while calling the function or by an excessive memory usage causing the Operating System to kill the worker.\\n\\nThe exit codes of the workers are {SIGKILL(-9)}').\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n","    value_or_values = func(trial)\n","  File \"<ipython-input-8-7c090013dbec>\", line 6, in objective_lgbm\n","    score = cross_val_score(LGBMClassifier(max_depth=max_depth, learning_rate=learning_rate, n_estimators=n_estimators),\n","  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 515, in cross_val_score\n","    cv_results = cross_validate(\n","  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 266, in cross_validate\n","    results = parallel(\n","  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 63, in __call__\n","    return super().__call__(iterable_with_config)\n","  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 1952, in __call__\n","    return output if self.return_generator else list(output)\n","  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 1595, in _get_outputs\n","    yield from self._retrieve()\n","  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 1699, in _retrieve\n","    self._raise_error_fast()\n","  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 1734, in _raise_error_fast\n","    error_job.get_result(self.timeout)\n","  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 736, in get_result\n","    return self._return_or_raise()\n","  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 754, in _return_or_raise\n","    raise self._result\n","joblib.externals.loky.process_executor.TerminatedWorkerError: A worker process managed by the executor was unexpectedly terminated. This could be caused by a segmentation fault while calling the function or by an excessive memory usage causing the Operating System to kill the worker.\n","\n","The exit codes of the workers are {SIGKILL(-9)}\n","[W 2024-02-23 10:14:33,954] Trial 0 failed with value None.\n"]},{"output_type":"error","ename":"TerminatedWorkerError","evalue":"A worker process managed by the executor was unexpectedly terminated. This could be caused by a segmentation fault while calling the function or by an excessive memory usage causing the Operating System to kill the worker.\n\nThe exit codes of the workers are {SIGKILL(-9)}","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTerminatedWorkerError\u001b[0m                     Traceback (most recent call last)","\u001b[0;32m<ipython-input-8-7c090013dbec>\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mstudy_lgbm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_study\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirection\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"maximize\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mstudy_lgbm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective_lgbm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/optuna/study/study.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    449\u001b[0m                 \u001b[0mIf\u001b[0m \u001b[0mnested\u001b[0m \u001b[0minvocation\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0moccurs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m         \"\"\"\n\u001b[0;32m--> 451\u001b[0;31m         _optimize(\n\u001b[0m\u001b[1;32m    452\u001b[0m             \u001b[0mstudy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m             \u001b[0mfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m             _optimize_sequential(\n\u001b[0m\u001b[1;32m     67\u001b[0m                 \u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m                 \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m             \u001b[0mfrozen_trial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0;31m# The following line mitigates memory problems that can be occurred in some\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m     ):\n\u001b[0;32m--> 251\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mfunc_err\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfrozen_trial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mget_heartbeat_thread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trial_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_storage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m             \u001b[0mvalue_or_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m             \u001b[0;31m# TODO(mamu): Handle multi-objective cases.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-8-7c090013dbec>\u001b[0m in \u001b[0;36mobjective_lgbm\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mn_estimators\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuggest_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"n_estimators\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m700\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     score = cross_val_score(LGBMClassifier(max_depth=max_depth, learning_rate=learning_rate, n_estimators=n_estimators),\n\u001b[0m\u001b[1;32m      7\u001b[0m                             x_train, y_train, cv=3, scoring='roc_auc', n_jobs=-1).mean()\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    513\u001b[0m     \u001b[0mscorer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_scoring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 515\u001b[0;31m     cv_results = cross_validate(\n\u001b[0m\u001b[1;32m    516\u001b[0m         \u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[0;31m# independent, and that it is pickle-able.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0mparallel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mParallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpre_dispatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpre_dispatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m     results = parallel(\n\u001b[0m\u001b[1;32m    267\u001b[0m         delayed(_fit_and_score)(\n\u001b[1;32m    268\u001b[0m             \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         )\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1950\u001b[0m         \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1952\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_generator\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1953\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1954\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1593\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1594\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1595\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_retrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1596\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1597\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mGeneratorExit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1697\u001b[0m             \u001b[0;31m# worker traceback.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1698\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_aborting\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1699\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_error_fast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1700\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_raise_error_fast\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1732\u001b[0m         \u001b[0;31m# called directly or if the generator is gc'ed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1733\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0merror_job\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1734\u001b[0;31m             \u001b[0merror_job\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1735\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1736\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_warn_exit_early\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mget_result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    734\u001b[0m             \u001b[0;31m# callback thread, and is stored internally. It's just waiting to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m             \u001b[0;31m# be returned.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_return_or_raise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m         \u001b[0;31m# For other backends, the main thread needs to run the retrieval step.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_return_or_raise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    752\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mTASK_ERROR\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 754\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    755\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTerminatedWorkerError\u001b[0m: A worker process managed by the executor was unexpectedly terminated. This could be caused by a segmentation fault while calling the function or by an excessive memory usage causing the Operating System to kill the worker.\n\nThe exit codes of the workers are {SIGKILL(-9)}"]}]},{"cell_type":"code","source":["study_lgbm.best_params"],"metadata":{"id":"mjoFN16YVipu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["opt_model_lgbm = LGBMClassifier(**study_lgbm.best_params)\n","opt_model_lgbm.fit(x_train, y_train)\n","\n","pred_train = opt_model_lgbm.predict(x_train)\n","pred_test = opt_model_lgbm.predict(x_test)\n","\n","print(f'train: {roc_auc_score(y_train, pred_train)}')\n","print(f'test: {roc_auc_score(y_test, pred_test)}')\n","print(f'test conf matrix: \\n {confusion_matrix(y_test, pred_test)}')"],"metadata":{"id":"tOCQ49YMVitZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Downsampling 222 feat"],"metadata":{"id":"WGL8TFkSaxVE"}},{"cell_type":"code","source":["x_train = pd.read_parquet(path + '/ds_min_x_train.parquet').drop('id', axis=1)\n","x_test = pd.read_parquet(path + '/ds_min_x_test.parquet').drop('id', axis=1)\n","y_train = pd.read_parquet(path + '/ds_min_y_train.parquet').drop('id', axis=1)\n","y_test = pd.read_parquet(path + '/ds_min_y_test.parquet').drop('id', axis=1)"],"metadata":{"id":"ZJfnZRkqViwV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model_log_reg = LogisticRegression()\n","model_log_reg.fit(x_train, y_train)\n","\n","pred_train = model_log_reg.predict(x_train)\n","pred_test = model_log_reg.predict(x_test)\n","\n","print(f'train: {roc_auc_score(y_train, pred_train)}')\n","print(f'test: {roc_auc_score(y_test, pred_test)}')\n","print(f'test conf matrix: \\n {confusion_matrix(y_test, pred_test)}')"],"metadata":{"id":"jefO8lhTViz7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1707743312385,"user_tz":-240,"elapsed":15197,"user":{"displayName":"Евгений Малов","userId":"06257165098392198337"}},"outputId":"ff7ece41-9f12-4551-c5ce-a17f5da40704"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["train: 0.6673738068939925\n","test: 0.6643939694283889\n","test conf matrix: \n"," [[20163 11710]\n"," [ 9720 22273]]\n"]}]},{"cell_type":"code","source":["model_lgbm = LGBMClassifier()\n","model_lgbm.fit(x_train, y_train)\n","\n","pred_train = model_lgbm.predict(x_train)\n","pred_test = model_lgbm.predict(x_test)\n","\n","print(f'train: {roc_auc_score(y_train, pred_train)}')\n","print(f'test: {roc_auc_score(y_test, pred_test)}')\n","print(f'test conf matrix: \\n {confusion_matrix(y_test, pred_test)}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"A8XyUAMEbW25","executionInfo":{"status":"ok","timestamp":1707743339920,"user_tz":-240,"elapsed":14978,"user":{"displayName":"Евгений Малов","userId":"06257165098392198337"}},"outputId":"fe0ddb45-64e4-497d-cad5-e935433033f8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[LightGBM] [Info] Number of positive: 74449, number of negative: 74569\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.408629 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 3855\n","[LightGBM] [Info] Number of data points in the train set: 149018, number of used features: 216\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499597 -> initscore=-0.001611\n","[LightGBM] [Info] Start training from score -0.001611\n","train: 0.6943635650510611\n","test: 0.6789568416448643\n","test conf matrix: \n"," [[20912 10961]\n"," [ 9540 22453]]\n"]}]},{"cell_type":"code","source":["model_xbm = XGBClassifier()\n","model_xbm.fit(x_train, y_train)\n","\n","pred_train = model_xbm.predict(x_train)\n","pred_test = model_xbm.predict(x_test)\n","\n","print(f'train: {roc_auc_score(y_train, pred_train)}')\n","print(f'test: {roc_auc_score(y_test, pred_test)}')\n","print(f'test conf matrix: \\n {confusion_matrix(y_test, pred_test)}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"n7o2FfcrbW6j","executionInfo":{"status":"ok","timestamp":1707743384795,"user_tz":-240,"elapsed":13703,"user":{"displayName":"Евгений Малов","userId":"06257165098392198337"}},"outputId":"53dcc0fd-f07d-469e-d254-9e4da8a3a78c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["train: 0.7315510405626264\n","test: 0.6768461455624497\n","test conf matrix: \n"," [[21163 10710]\n"," [ 9927 22066]]\n"]}]},{"cell_type":"code","source":["model_catb = CatBoostClassifier()\n","model_catb.fit(x_train, y_train)\n","\n","pred_train = model_catb.predict(x_train)\n","pred_test = model_catb.predict(x_test)\n","\n","print(f'train: {roc_auc_score(y_train, pred_train)}')\n","print(f'test: {roc_auc_score(y_test, pred_test)}')\n","print(f'test conf matrix: \\n {confusion_matrix(y_test, pred_test)}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Bi8To6Z6bW94","executionInfo":{"status":"ok","timestamp":1707743580820,"user_tz":-240,"elapsed":165570,"user":{"displayName":"Евгений Малов","userId":"06257165098392198337"}},"outputId":"d2d265ab-7e3f-492f-8e0f-6c68351a0f86"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Learning rate set to 0.087278\n","0:\tlearn: 0.6863191\ttotal: 218ms\tremaining: 3m 37s\n","1:\tlearn: 0.6807780\ttotal: 366ms\tremaining: 3m 2s\n","2:\tlearn: 0.6757498\ttotal: 487ms\tremaining: 2m 41s\n","3:\tlearn: 0.6714841\ttotal: 610ms\tremaining: 2m 32s\n","4:\tlearn: 0.6674330\ttotal: 767ms\tremaining: 2m 32s\n","5:\tlearn: 0.6639273\ttotal: 886ms\tremaining: 2m 26s\n","6:\tlearn: 0.6609987\ttotal: 1s\tremaining: 2m 22s\n","7:\tlearn: 0.6581947\ttotal: 1.15s\tremaining: 2m 23s\n","8:\tlearn: 0.6553109\ttotal: 1.31s\tremaining: 2m 24s\n","9:\tlearn: 0.6529071\ttotal: 1.47s\tremaining: 2m 25s\n","10:\tlearn: 0.6508180\ttotal: 1.61s\tremaining: 2m 24s\n","11:\tlearn: 0.6488189\ttotal: 1.74s\tremaining: 2m 23s\n","12:\tlearn: 0.6467174\ttotal: 1.86s\tremaining: 2m 20s\n","13:\tlearn: 0.6449168\ttotal: 1.99s\tremaining: 2m 20s\n","14:\tlearn: 0.6433705\ttotal: 2.13s\tremaining: 2m 20s\n","15:\tlearn: 0.6418639\ttotal: 2.25s\tremaining: 2m 18s\n","16:\tlearn: 0.6404114\ttotal: 2.39s\tremaining: 2m 18s\n","17:\tlearn: 0.6390782\ttotal: 2.54s\tremaining: 2m 18s\n","18:\tlearn: 0.6378622\ttotal: 2.68s\tremaining: 2m 18s\n","19:\tlearn: 0.6367837\ttotal: 2.81s\tremaining: 2m 17s\n","20:\tlearn: 0.6357314\ttotal: 2.94s\tremaining: 2m 16s\n","21:\tlearn: 0.6346311\ttotal: 3.04s\tremaining: 2m 14s\n","22:\tlearn: 0.6336216\ttotal: 3.15s\tremaining: 2m 13s\n","23:\tlearn: 0.6327296\ttotal: 3.27s\tremaining: 2m 12s\n","24:\tlearn: 0.6319024\ttotal: 3.4s\tremaining: 2m 12s\n","25:\tlearn: 0.6309973\ttotal: 3.54s\tremaining: 2m 12s\n","26:\tlearn: 0.6301389\ttotal: 3.67s\tremaining: 2m 12s\n","27:\tlearn: 0.6289813\ttotal: 3.81s\tremaining: 2m 12s\n","28:\tlearn: 0.6282326\ttotal: 3.93s\tremaining: 2m 11s\n","29:\tlearn: 0.6271256\ttotal: 4.06s\tremaining: 2m 11s\n","30:\tlearn: 0.6263963\ttotal: 4.19s\tremaining: 2m 11s\n","31:\tlearn: 0.6256600\ttotal: 4.31s\tremaining: 2m 10s\n","32:\tlearn: 0.6250944\ttotal: 4.44s\tremaining: 2m 10s\n","33:\tlearn: 0.6243590\ttotal: 4.61s\tremaining: 2m 10s\n","34:\tlearn: 0.6238170\ttotal: 4.72s\tremaining: 2m 10s\n","35:\tlearn: 0.6231874\ttotal: 4.84s\tremaining: 2m 9s\n","36:\tlearn: 0.6224645\ttotal: 4.97s\tremaining: 2m 9s\n","37:\tlearn: 0.6219057\ttotal: 5.11s\tremaining: 2m 9s\n","38:\tlearn: 0.6213718\ttotal: 5.24s\tremaining: 2m 9s\n","39:\tlearn: 0.6208648\ttotal: 5.34s\tremaining: 2m 8s\n","40:\tlearn: 0.6204186\ttotal: 5.45s\tremaining: 2m 7s\n","41:\tlearn: 0.6198927\ttotal: 5.59s\tremaining: 2m 7s\n","42:\tlearn: 0.6194448\ttotal: 5.7s\tremaining: 2m 6s\n","43:\tlearn: 0.6189631\ttotal: 5.81s\tremaining: 2m 6s\n","44:\tlearn: 0.6186356\ttotal: 5.91s\tremaining: 2m 5s\n","45:\tlearn: 0.6179619\ttotal: 6.03s\tremaining: 2m 5s\n","46:\tlearn: 0.6175418\ttotal: 6.15s\tremaining: 2m 4s\n","47:\tlearn: 0.6171938\ttotal: 6.26s\tremaining: 2m 4s\n","48:\tlearn: 0.6168187\ttotal: 6.38s\tremaining: 2m 3s\n","49:\tlearn: 0.6164650\ttotal: 6.52s\tremaining: 2m 3s\n","50:\tlearn: 0.6161204\ttotal: 6.65s\tremaining: 2m 3s\n","51:\tlearn: 0.6158047\ttotal: 6.75s\tremaining: 2m 3s\n","52:\tlearn: 0.6155103\ttotal: 6.87s\tremaining: 2m 2s\n","53:\tlearn: 0.6151171\ttotal: 7.01s\tremaining: 2m 2s\n","54:\tlearn: 0.6147138\ttotal: 7.17s\tremaining: 2m 3s\n","55:\tlearn: 0.6143360\ttotal: 7.3s\tremaining: 2m 3s\n","56:\tlearn: 0.6140308\ttotal: 7.43s\tremaining: 2m 2s\n","57:\tlearn: 0.6138002\ttotal: 7.53s\tremaining: 2m 2s\n","58:\tlearn: 0.6135237\ttotal: 7.67s\tremaining: 2m 2s\n","59:\tlearn: 0.6132391\ttotal: 7.8s\tremaining: 2m 2s\n","60:\tlearn: 0.6128004\ttotal: 7.93s\tremaining: 2m 2s\n","61:\tlearn: 0.6124223\ttotal: 8.07s\tremaining: 2m 2s\n","62:\tlearn: 0.6121854\ttotal: 8.19s\tremaining: 2m 1s\n","63:\tlearn: 0.6117699\ttotal: 8.33s\tremaining: 2m 1s\n","64:\tlearn: 0.6115055\ttotal: 8.49s\tremaining: 2m 2s\n","65:\tlearn: 0.6112660\ttotal: 8.6s\tremaining: 2m 1s\n","66:\tlearn: 0.6110440\ttotal: 8.68s\tremaining: 2m\n","67:\tlearn: 0.6108423\ttotal: 8.8s\tremaining: 2m\n","68:\tlearn: 0.6105229\ttotal: 8.92s\tremaining: 2m\n","69:\tlearn: 0.6102967\ttotal: 9.04s\tremaining: 2m\n","70:\tlearn: 0.6100738\ttotal: 9.14s\tremaining: 1m 59s\n","71:\tlearn: 0.6098632\ttotal: 9.25s\tremaining: 1m 59s\n","72:\tlearn: 0.6095072\ttotal: 9.36s\tremaining: 1m 58s\n","73:\tlearn: 0.6093111\ttotal: 9.5s\tremaining: 1m 58s\n","74:\tlearn: 0.6091066\ttotal: 9.61s\tremaining: 1m 58s\n","75:\tlearn: 0.6087177\ttotal: 9.76s\tremaining: 1m 58s\n","76:\tlearn: 0.6085521\ttotal: 9.87s\tremaining: 1m 58s\n","77:\tlearn: 0.6083549\ttotal: 9.97s\tremaining: 1m 57s\n","78:\tlearn: 0.6081784\ttotal: 10.1s\tremaining: 1m 57s\n","79:\tlearn: 0.6079925\ttotal: 10.3s\tremaining: 1m 58s\n","80:\tlearn: 0.6078223\ttotal: 10.5s\tremaining: 1m 59s\n","81:\tlearn: 0.6076559\ttotal: 10.7s\tremaining: 1m 59s\n","82:\tlearn: 0.6074421\ttotal: 11s\tremaining: 2m 1s\n","83:\tlearn: 0.6072912\ttotal: 11.2s\tremaining: 2m 2s\n","84:\tlearn: 0.6070979\ttotal: 11.5s\tremaining: 2m 3s\n","85:\tlearn: 0.6068742\ttotal: 11.7s\tremaining: 2m 4s\n","86:\tlearn: 0.6066744\ttotal: 11.9s\tremaining: 2m 5s\n","87:\tlearn: 0.6064501\ttotal: 12.1s\tremaining: 2m 5s\n","88:\tlearn: 0.6062951\ttotal: 12.4s\tremaining: 2m 6s\n","89:\tlearn: 0.6060794\ttotal: 12.6s\tremaining: 2m 7s\n","90:\tlearn: 0.6059432\ttotal: 12.8s\tremaining: 2m 8s\n","91:\tlearn: 0.6058128\ttotal: 13s\tremaining: 2m 8s\n","92:\tlearn: 0.6056376\ttotal: 13.3s\tremaining: 2m 9s\n","93:\tlearn: 0.6055080\ttotal: 13.4s\tremaining: 2m 9s\n","94:\tlearn: 0.6053092\ttotal: 13.7s\tremaining: 2m 10s\n","95:\tlearn: 0.6051527\ttotal: 13.9s\tremaining: 2m 11s\n","96:\tlearn: 0.6050509\ttotal: 14s\tremaining: 2m 10s\n","97:\tlearn: 0.6048986\ttotal: 14.1s\tremaining: 2m 10s\n","98:\tlearn: 0.6046683\ttotal: 14.3s\tremaining: 2m 9s\n","99:\tlearn: 0.6044865\ttotal: 14.4s\tremaining: 2m 9s\n","100:\tlearn: 0.6043259\ttotal: 14.5s\tremaining: 2m 8s\n","101:\tlearn: 0.6041824\ttotal: 14.6s\tremaining: 2m 8s\n","102:\tlearn: 0.6039835\ttotal: 14.7s\tremaining: 2m 8s\n","103:\tlearn: 0.6038429\ttotal: 14.9s\tremaining: 2m 8s\n","104:\tlearn: 0.6036830\ttotal: 15s\tremaining: 2m 7s\n","105:\tlearn: 0.6035387\ttotal: 15.1s\tremaining: 2m 7s\n","106:\tlearn: 0.6034132\ttotal: 15.2s\tremaining: 2m 7s\n","107:\tlearn: 0.6032913\ttotal: 15.3s\tremaining: 2m 6s\n","108:\tlearn: 0.6031557\ttotal: 15.5s\tremaining: 2m 6s\n","109:\tlearn: 0.6030506\ttotal: 15.6s\tremaining: 2m 6s\n","110:\tlearn: 0.6028201\ttotal: 15.7s\tremaining: 2m 5s\n","111:\tlearn: 0.6026252\ttotal: 15.9s\tremaining: 2m 5s\n","112:\tlearn: 0.6025247\ttotal: 16s\tremaining: 2m 5s\n","113:\tlearn: 0.6023166\ttotal: 16.1s\tremaining: 2m 5s\n","114:\tlearn: 0.6021690\ttotal: 16.2s\tremaining: 2m 4s\n","115:\tlearn: 0.6019185\ttotal: 16.4s\tremaining: 2m 4s\n","116:\tlearn: 0.6017979\ttotal: 16.5s\tremaining: 2m 4s\n","117:\tlearn: 0.6016453\ttotal: 16.6s\tremaining: 2m 4s\n","118:\tlearn: 0.6014914\ttotal: 16.7s\tremaining: 2m 3s\n","119:\tlearn: 0.6013568\ttotal: 16.8s\tremaining: 2m 3s\n","120:\tlearn: 0.6012330\ttotal: 17s\tremaining: 2m 3s\n","121:\tlearn: 0.6011350\ttotal: 17.1s\tremaining: 2m 3s\n","122:\tlearn: 0.6010080\ttotal: 17.2s\tremaining: 2m 2s\n","123:\tlearn: 0.6008855\ttotal: 17.3s\tremaining: 2m 2s\n","124:\tlearn: 0.6007488\ttotal: 17.4s\tremaining: 2m 1s\n","125:\tlearn: 0.6006138\ttotal: 17.5s\tremaining: 2m 1s\n","126:\tlearn: 0.6004443\ttotal: 17.6s\tremaining: 2m 1s\n","127:\tlearn: 0.6003393\ttotal: 17.7s\tremaining: 2m\n","128:\tlearn: 0.6001059\ttotal: 17.9s\tremaining: 2m\n","129:\tlearn: 0.5999047\ttotal: 18s\tremaining: 2m\n","130:\tlearn: 0.5997913\ttotal: 18.1s\tremaining: 2m\n","131:\tlearn: 0.5996784\ttotal: 18.3s\tremaining: 2m\n","132:\tlearn: 0.5995030\ttotal: 18.4s\tremaining: 1m 59s\n","133:\tlearn: 0.5993042\ttotal: 18.5s\tremaining: 1m 59s\n","134:\tlearn: 0.5991900\ttotal: 18.7s\tremaining: 1m 59s\n","135:\tlearn: 0.5990100\ttotal: 18.8s\tremaining: 1m 59s\n","136:\tlearn: 0.5989059\ttotal: 18.9s\tremaining: 1m 59s\n","137:\tlearn: 0.5987929\ttotal: 19s\tremaining: 1m 58s\n","138:\tlearn: 0.5986782\ttotal: 19.2s\tremaining: 1m 58s\n","139:\tlearn: 0.5985075\ttotal: 19.3s\tremaining: 1m 58s\n","140:\tlearn: 0.5983520\ttotal: 19.4s\tremaining: 1m 58s\n","141:\tlearn: 0.5981854\ttotal: 19.5s\tremaining: 1m 57s\n","142:\tlearn: 0.5980349\ttotal: 19.6s\tremaining: 1m 57s\n","143:\tlearn: 0.5978841\ttotal: 19.7s\tremaining: 1m 57s\n","144:\tlearn: 0.5977691\ttotal: 19.8s\tremaining: 1m 57s\n","145:\tlearn: 0.5976500\ttotal: 19.9s\tremaining: 1m 56s\n","146:\tlearn: 0.5974892\ttotal: 20.1s\tremaining: 1m 56s\n","147:\tlearn: 0.5973283\ttotal: 20.2s\tremaining: 1m 56s\n","148:\tlearn: 0.5971591\ttotal: 20.3s\tremaining: 1m 56s\n","149:\tlearn: 0.5970014\ttotal: 20.4s\tremaining: 1m 55s\n","150:\tlearn: 0.5968609\ttotal: 20.6s\tremaining: 1m 55s\n","151:\tlearn: 0.5966952\ttotal: 20.7s\tremaining: 1m 55s\n","152:\tlearn: 0.5965364\ttotal: 20.8s\tremaining: 1m 55s\n","153:\tlearn: 0.5963846\ttotal: 20.9s\tremaining: 1m 55s\n","154:\tlearn: 0.5962550\ttotal: 21.1s\tremaining: 1m 54s\n","155:\tlearn: 0.5961147\ttotal: 21.2s\tremaining: 1m 54s\n","156:\tlearn: 0.5959329\ttotal: 21.3s\tremaining: 1m 54s\n","157:\tlearn: 0.5957667\ttotal: 21.4s\tremaining: 1m 54s\n","158:\tlearn: 0.5956643\ttotal: 21.5s\tremaining: 1m 53s\n","159:\tlearn: 0.5955383\ttotal: 21.6s\tremaining: 1m 53s\n","160:\tlearn: 0.5954296\ttotal: 21.8s\tremaining: 1m 53s\n","161:\tlearn: 0.5953169\ttotal: 21.9s\tremaining: 1m 53s\n","162:\tlearn: 0.5951523\ttotal: 22s\tremaining: 1m 53s\n","163:\tlearn: 0.5950267\ttotal: 22.1s\tremaining: 1m 52s\n","164:\tlearn: 0.5949196\ttotal: 22.3s\tremaining: 1m 52s\n","165:\tlearn: 0.5947857\ttotal: 22.4s\tremaining: 1m 52s\n","166:\tlearn: 0.5946412\ttotal: 22.5s\tremaining: 1m 52s\n","167:\tlearn: 0.5944906\ttotal: 22.6s\tremaining: 1m 52s\n","168:\tlearn: 0.5943121\ttotal: 22.8s\tremaining: 1m 52s\n","169:\tlearn: 0.5942062\ttotal: 22.9s\tremaining: 1m 51s\n","170:\tlearn: 0.5940864\ttotal: 23s\tremaining: 1m 51s\n","171:\tlearn: 0.5939678\ttotal: 23.2s\tremaining: 1m 51s\n","172:\tlearn: 0.5938906\ttotal: 23.3s\tremaining: 1m 51s\n","173:\tlearn: 0.5938052\ttotal: 23.3s\tremaining: 1m 50s\n","174:\tlearn: 0.5937059\ttotal: 23.4s\tremaining: 1m 50s\n","175:\tlearn: 0.5935920\ttotal: 23.6s\tremaining: 1m 50s\n","176:\tlearn: 0.5934696\ttotal: 23.7s\tremaining: 1m 50s\n","177:\tlearn: 0.5933550\ttotal: 23.8s\tremaining: 1m 50s\n","178:\tlearn: 0.5932391\ttotal: 24s\tremaining: 1m 50s\n","179:\tlearn: 0.5931187\ttotal: 24.3s\tremaining: 1m 50s\n","180:\tlearn: 0.5930177\ttotal: 24.5s\tremaining: 1m 50s\n","181:\tlearn: 0.5928975\ttotal: 24.6s\tremaining: 1m 50s\n","182:\tlearn: 0.5927564\ttotal: 24.9s\tremaining: 1m 51s\n","183:\tlearn: 0.5926696\ttotal: 25.1s\tremaining: 1m 51s\n","184:\tlearn: 0.5925565\ttotal: 25.4s\tremaining: 1m 51s\n","185:\tlearn: 0.5924924\ttotal: 25.5s\tremaining: 1m 51s\n","186:\tlearn: 0.5923954\ttotal: 25.7s\tremaining: 1m 51s\n","187:\tlearn: 0.5922858\ttotal: 25.9s\tremaining: 1m 52s\n","188:\tlearn: 0.5921731\ttotal: 26.2s\tremaining: 1m 52s\n","189:\tlearn: 0.5920502\ttotal: 26.4s\tremaining: 1m 52s\n","190:\tlearn: 0.5919534\ttotal: 26.7s\tremaining: 1m 52s\n","191:\tlearn: 0.5918357\ttotal: 26.9s\tremaining: 1m 53s\n","192:\tlearn: 0.5916954\ttotal: 27.1s\tremaining: 1m 53s\n","193:\tlearn: 0.5915884\ttotal: 27.3s\tremaining: 1m 53s\n","194:\tlearn: 0.5914324\ttotal: 27.6s\tremaining: 1m 53s\n","195:\tlearn: 0.5913238\ttotal: 27.8s\tremaining: 1m 53s\n","196:\tlearn: 0.5911767\ttotal: 27.9s\tremaining: 1m 53s\n","197:\tlearn: 0.5910779\ttotal: 28s\tremaining: 1m 53s\n","198:\tlearn: 0.5909689\ttotal: 28.1s\tremaining: 1m 53s\n","199:\tlearn: 0.5908677\ttotal: 28.3s\tremaining: 1m 53s\n","200:\tlearn: 0.5907791\ttotal: 28.4s\tremaining: 1m 52s\n","201:\tlearn: 0.5906942\ttotal: 28.5s\tremaining: 1m 52s\n","202:\tlearn: 0.5905798\ttotal: 28.6s\tremaining: 1m 52s\n","203:\tlearn: 0.5904906\ttotal: 28.7s\tremaining: 1m 52s\n","204:\tlearn: 0.5903737\ttotal: 28.9s\tremaining: 1m 51s\n","205:\tlearn: 0.5902937\ttotal: 28.9s\tremaining: 1m 51s\n","206:\tlearn: 0.5902038\ttotal: 29s\tremaining: 1m 51s\n","207:\tlearn: 0.5901081\ttotal: 29.2s\tremaining: 1m 51s\n","208:\tlearn: 0.5899781\ttotal: 29.3s\tremaining: 1m 50s\n","209:\tlearn: 0.5898695\ttotal: 29.4s\tremaining: 1m 50s\n","210:\tlearn: 0.5897611\ttotal: 29.5s\tremaining: 1m 50s\n","211:\tlearn: 0.5896270\ttotal: 29.6s\tremaining: 1m 50s\n","212:\tlearn: 0.5895067\ttotal: 29.7s\tremaining: 1m 49s\n","213:\tlearn: 0.5894007\ttotal: 29.9s\tremaining: 1m 49s\n","214:\tlearn: 0.5892894\ttotal: 30s\tremaining: 1m 49s\n","215:\tlearn: 0.5891649\ttotal: 30.1s\tremaining: 1m 49s\n","216:\tlearn: 0.5890861\ttotal: 30.3s\tremaining: 1m 49s\n","217:\tlearn: 0.5889678\ttotal: 30.5s\tremaining: 1m 49s\n","218:\tlearn: 0.5888791\ttotal: 30.6s\tremaining: 1m 49s\n","219:\tlearn: 0.5887852\ttotal: 30.8s\tremaining: 1m 49s\n","220:\tlearn: 0.5887038\ttotal: 31s\tremaining: 1m 49s\n","221:\tlearn: 0.5886269\ttotal: 31.1s\tremaining: 1m 48s\n","222:\tlearn: 0.5885485\ttotal: 31.3s\tremaining: 1m 48s\n","223:\tlearn: 0.5884640\ttotal: 31.5s\tremaining: 1m 49s\n","224:\tlearn: 0.5883850\ttotal: 31.7s\tremaining: 1m 49s\n","225:\tlearn: 0.5882509\ttotal: 31.9s\tremaining: 1m 49s\n","226:\tlearn: 0.5881710\ttotal: 32s\tremaining: 1m 49s\n","227:\tlearn: 0.5880986\ttotal: 32.2s\tremaining: 1m 49s\n","228:\tlearn: 0.5880064\ttotal: 32.4s\tremaining: 1m 49s\n","229:\tlearn: 0.5879207\ttotal: 32.6s\tremaining: 1m 49s\n","230:\tlearn: 0.5878253\ttotal: 32.8s\tremaining: 1m 49s\n","231:\tlearn: 0.5877295\ttotal: 33s\tremaining: 1m 49s\n","232:\tlearn: 0.5876548\ttotal: 33.2s\tremaining: 1m 49s\n","233:\tlearn: 0.5875397\ttotal: 33.4s\tremaining: 1m 49s\n","234:\tlearn: 0.5874723\ttotal: 33.5s\tremaining: 1m 48s\n","235:\tlearn: 0.5873982\ttotal: 33.6s\tremaining: 1m 48s\n","236:\tlearn: 0.5872821\ttotal: 33.8s\tremaining: 1m 48s\n","237:\tlearn: 0.5871827\ttotal: 34s\tremaining: 1m 48s\n","238:\tlearn: 0.5870765\ttotal: 34.3s\tremaining: 1m 49s\n","239:\tlearn: 0.5869959\ttotal: 34.5s\tremaining: 1m 49s\n","240:\tlearn: 0.5869098\ttotal: 34.6s\tremaining: 1m 49s\n","241:\tlearn: 0.5868024\ttotal: 34.8s\tremaining: 1m 49s\n","242:\tlearn: 0.5867151\ttotal: 35s\tremaining: 1m 49s\n","243:\tlearn: 0.5866231\ttotal: 35.3s\tremaining: 1m 49s\n","244:\tlearn: 0.5865360\ttotal: 35.4s\tremaining: 1m 49s\n","245:\tlearn: 0.5864605\ttotal: 35.6s\tremaining: 1m 49s\n","246:\tlearn: 0.5863897\ttotal: 35.7s\tremaining: 1m 48s\n","247:\tlearn: 0.5863241\ttotal: 35.8s\tremaining: 1m 48s\n","248:\tlearn: 0.5862187\ttotal: 35.9s\tremaining: 1m 48s\n","249:\tlearn: 0.5861208\ttotal: 36s\tremaining: 1m 48s\n","250:\tlearn: 0.5860382\ttotal: 36.1s\tremaining: 1m 47s\n","251:\tlearn: 0.5859654\ttotal: 36.2s\tremaining: 1m 47s\n","252:\tlearn: 0.5858672\ttotal: 36.4s\tremaining: 1m 47s\n","253:\tlearn: 0.5857964\ttotal: 36.5s\tremaining: 1m 47s\n","254:\tlearn: 0.5856976\ttotal: 36.6s\tremaining: 1m 47s\n","255:\tlearn: 0.5856336\ttotal: 36.7s\tremaining: 1m 46s\n","256:\tlearn: 0.5855222\ttotal: 36.9s\tremaining: 1m 46s\n","257:\tlearn: 0.5854382\ttotal: 37s\tremaining: 1m 46s\n","258:\tlearn: 0.5853811\ttotal: 37.1s\tremaining: 1m 46s\n","259:\tlearn: 0.5852875\ttotal: 37.2s\tremaining: 1m 45s\n","260:\tlearn: 0.5851819\ttotal: 37.3s\tremaining: 1m 45s\n","261:\tlearn: 0.5851079\ttotal: 37.4s\tremaining: 1m 45s\n","262:\tlearn: 0.5850035\ttotal: 37.5s\tremaining: 1m 45s\n","263:\tlearn: 0.5849328\ttotal: 37.6s\tremaining: 1m 44s\n","264:\tlearn: 0.5848415\ttotal: 37.8s\tremaining: 1m 44s\n","265:\tlearn: 0.5847686\ttotal: 38s\tremaining: 1m 44s\n","266:\tlearn: 0.5847099\ttotal: 38.2s\tremaining: 1m 44s\n","267:\tlearn: 0.5846308\ttotal: 38.5s\tremaining: 1m 45s\n","268:\tlearn: 0.5845436\ttotal: 38.7s\tremaining: 1m 45s\n","269:\tlearn: 0.5844358\ttotal: 38.9s\tremaining: 1m 45s\n","270:\tlearn: 0.5843404\ttotal: 39.1s\tremaining: 1m 45s\n","271:\tlearn: 0.5842717\ttotal: 39.3s\tremaining: 1m 45s\n","272:\tlearn: 0.5842005\ttotal: 39.5s\tremaining: 1m 45s\n","273:\tlearn: 0.5841559\ttotal: 39.7s\tremaining: 1m 45s\n","274:\tlearn: 0.5840972\ttotal: 40.1s\tremaining: 1m 45s\n","275:\tlearn: 0.5840106\ttotal: 40.7s\tremaining: 1m 46s\n","276:\tlearn: 0.5839278\ttotal: 41.2s\tremaining: 1m 47s\n","277:\tlearn: 0.5838775\ttotal: 41.4s\tremaining: 1m 47s\n","278:\tlearn: 0.5837881\ttotal: 41.9s\tremaining: 1m 48s\n","279:\tlearn: 0.5837216\ttotal: 42.3s\tremaining: 1m 48s\n","280:\tlearn: 0.5836381\ttotal: 42.4s\tremaining: 1m 48s\n","281:\tlearn: 0.5835530\ttotal: 42.5s\tremaining: 1m 48s\n","282:\tlearn: 0.5834974\ttotal: 42.6s\tremaining: 1m 47s\n","283:\tlearn: 0.5834087\ttotal: 42.7s\tremaining: 1m 47s\n","284:\tlearn: 0.5833322\ttotal: 42.9s\tremaining: 1m 47s\n","285:\tlearn: 0.5832751\ttotal: 43s\tremaining: 1m 47s\n","286:\tlearn: 0.5831770\ttotal: 43.1s\tremaining: 1m 47s\n","287:\tlearn: 0.5830809\ttotal: 43.2s\tremaining: 1m 46s\n","288:\tlearn: 0.5830061\ttotal: 43.3s\tremaining: 1m 46s\n","289:\tlearn: 0.5829367\ttotal: 43.4s\tremaining: 1m 46s\n","290:\tlearn: 0.5828453\ttotal: 43.5s\tremaining: 1m 46s\n","291:\tlearn: 0.5827756\ttotal: 43.6s\tremaining: 1m 45s\n","292:\tlearn: 0.5827064\ttotal: 43.7s\tremaining: 1m 45s\n","293:\tlearn: 0.5826361\ttotal: 43.8s\tremaining: 1m 45s\n","294:\tlearn: 0.5825672\ttotal: 44s\tremaining: 1m 45s\n","295:\tlearn: 0.5824911\ttotal: 44.1s\tremaining: 1m 44s\n","296:\tlearn: 0.5824254\ttotal: 44.2s\tremaining: 1m 44s\n","297:\tlearn: 0.5823564\ttotal: 44.3s\tremaining: 1m 44s\n","298:\tlearn: 0.5822589\ttotal: 44.4s\tremaining: 1m 44s\n","299:\tlearn: 0.5821891\ttotal: 44.6s\tremaining: 1m 44s\n","300:\tlearn: 0.5821095\ttotal: 44.7s\tremaining: 1m 43s\n","301:\tlearn: 0.5820310\ttotal: 44.8s\tremaining: 1m 43s\n","302:\tlearn: 0.5819598\ttotal: 44.9s\tremaining: 1m 43s\n","303:\tlearn: 0.5818605\ttotal: 45s\tremaining: 1m 43s\n","304:\tlearn: 0.5817995\ttotal: 45.1s\tremaining: 1m 42s\n","305:\tlearn: 0.5817594\ttotal: 45.2s\tremaining: 1m 42s\n","306:\tlearn: 0.5817055\ttotal: 45.3s\tremaining: 1m 42s\n","307:\tlearn: 0.5816328\ttotal: 45.4s\tremaining: 1m 41s\n","308:\tlearn: 0.5815768\ttotal: 45.5s\tremaining: 1m 41s\n","309:\tlearn: 0.5814780\ttotal: 45.6s\tremaining: 1m 41s\n","310:\tlearn: 0.5814248\ttotal: 45.8s\tremaining: 1m 41s\n","311:\tlearn: 0.5813391\ttotal: 45.9s\tremaining: 1m 41s\n","312:\tlearn: 0.5812801\ttotal: 46s\tremaining: 1m 40s\n","313:\tlearn: 0.5811750\ttotal: 46.1s\tremaining: 1m 40s\n","314:\tlearn: 0.5811015\ttotal: 46.2s\tremaining: 1m 40s\n","315:\tlearn: 0.5810424\ttotal: 46.3s\tremaining: 1m 40s\n","316:\tlearn: 0.5809764\ttotal: 46.4s\tremaining: 1m 40s\n","317:\tlearn: 0.5808954\ttotal: 46.5s\tremaining: 1m 39s\n","318:\tlearn: 0.5807910\ttotal: 46.7s\tremaining: 1m 39s\n","319:\tlearn: 0.5807160\ttotal: 46.8s\tremaining: 1m 39s\n","320:\tlearn: 0.5806428\ttotal: 46.9s\tremaining: 1m 39s\n","321:\tlearn: 0.5805806\ttotal: 47s\tremaining: 1m 39s\n","322:\tlearn: 0.5804969\ttotal: 47.1s\tremaining: 1m 38s\n","323:\tlearn: 0.5804369\ttotal: 47.3s\tremaining: 1m 38s\n","324:\tlearn: 0.5803687\ttotal: 47.4s\tremaining: 1m 38s\n","325:\tlearn: 0.5802654\ttotal: 47.5s\tremaining: 1m 38s\n","326:\tlearn: 0.5802422\ttotal: 47.6s\tremaining: 1m 37s\n","327:\tlearn: 0.5801388\ttotal: 47.7s\tremaining: 1m 37s\n","328:\tlearn: 0.5800611\ttotal: 47.9s\tremaining: 1m 37s\n","329:\tlearn: 0.5799975\ttotal: 48s\tremaining: 1m 37s\n","330:\tlearn: 0.5799049\ttotal: 48.1s\tremaining: 1m 37s\n","331:\tlearn: 0.5798207\ttotal: 48.2s\tremaining: 1m 37s\n","332:\tlearn: 0.5797337\ttotal: 48.3s\tremaining: 1m 36s\n","333:\tlearn: 0.5796524\ttotal: 48.5s\tremaining: 1m 36s\n","334:\tlearn: 0.5795926\ttotal: 48.6s\tremaining: 1m 36s\n","335:\tlearn: 0.5794999\ttotal: 48.7s\tremaining: 1m 36s\n","336:\tlearn: 0.5794549\ttotal: 48.8s\tremaining: 1m 35s\n","337:\tlearn: 0.5793949\ttotal: 48.9s\tremaining: 1m 35s\n","338:\tlearn: 0.5793179\ttotal: 49s\tremaining: 1m 35s\n","339:\tlearn: 0.5792673\ttotal: 49.1s\tremaining: 1m 35s\n","340:\tlearn: 0.5792129\ttotal: 49.2s\tremaining: 1m 35s\n","341:\tlearn: 0.5791380\ttotal: 49.3s\tremaining: 1m 34s\n","342:\tlearn: 0.5790620\ttotal: 49.4s\tremaining: 1m 34s\n","343:\tlearn: 0.5789782\ttotal: 49.6s\tremaining: 1m 34s\n","344:\tlearn: 0.5789076\ttotal: 49.9s\tremaining: 1m 34s\n","345:\tlearn: 0.5788475\ttotal: 50.2s\tremaining: 1m 34s\n","346:\tlearn: 0.5787622\ttotal: 50.5s\tremaining: 1m 35s\n","347:\tlearn: 0.5786849\ttotal: 50.9s\tremaining: 1m 35s\n","348:\tlearn: 0.5786158\ttotal: 51.3s\tremaining: 1m 35s\n","349:\tlearn: 0.5785348\ttotal: 51.6s\tremaining: 1m 35s\n","350:\tlearn: 0.5784546\ttotal: 52.1s\tremaining: 1m 36s\n","351:\tlearn: 0.5783695\ttotal: 52.6s\tremaining: 1m 36s\n","352:\tlearn: 0.5783036\ttotal: 53.1s\tremaining: 1m 37s\n","353:\tlearn: 0.5781998\ttotal: 53.7s\tremaining: 1m 37s\n","354:\tlearn: 0.5781371\ttotal: 54.2s\tremaining: 1m 38s\n","355:\tlearn: 0.5780583\ttotal: 54.8s\tremaining: 1m 39s\n","356:\tlearn: 0.5779863\ttotal: 55.4s\tremaining: 1m 39s\n","357:\tlearn: 0.5779372\ttotal: 55.9s\tremaining: 1m 40s\n","358:\tlearn: 0.5778820\ttotal: 56.3s\tremaining: 1m 40s\n","359:\tlearn: 0.5778190\ttotal: 56.7s\tremaining: 1m 40s\n","360:\tlearn: 0.5777409\ttotal: 57.2s\tremaining: 1m 41s\n","361:\tlearn: 0.5776688\ttotal: 57.6s\tremaining: 1m 41s\n","362:\tlearn: 0.5776196\ttotal: 57.9s\tremaining: 1m 41s\n","363:\tlearn: 0.5775483\ttotal: 58.2s\tremaining: 1m 41s\n","364:\tlearn: 0.5774783\ttotal: 58.5s\tremaining: 1m 41s\n","365:\tlearn: 0.5773836\ttotal: 58.9s\tremaining: 1m 42s\n","366:\tlearn: 0.5773257\ttotal: 59.2s\tremaining: 1m 42s\n","367:\tlearn: 0.5772640\ttotal: 59.5s\tremaining: 1m 42s\n","368:\tlearn: 0.5771957\ttotal: 59.8s\tremaining: 1m 42s\n","369:\tlearn: 0.5771276\ttotal: 1m\tremaining: 1m 42s\n","370:\tlearn: 0.5770974\ttotal: 1m\tremaining: 1m 42s\n","371:\tlearn: 0.5770268\ttotal: 1m\tremaining: 1m 42s\n","372:\tlearn: 0.5769831\ttotal: 1m 1s\tremaining: 1m 42s\n","373:\tlearn: 0.5768884\ttotal: 1m 1s\tremaining: 1m 42s\n","374:\tlearn: 0.5768309\ttotal: 1m 1s\tremaining: 1m 42s\n","375:\tlearn: 0.5767688\ttotal: 1m 1s\tremaining: 1m 42s\n","376:\tlearn: 0.5767348\ttotal: 1m 1s\tremaining: 1m 42s\n","377:\tlearn: 0.5766901\ttotal: 1m 1s\tremaining: 1m 41s\n","378:\tlearn: 0.5766458\ttotal: 1m 2s\tremaining: 1m 41s\n","379:\tlearn: 0.5765713\ttotal: 1m 2s\tremaining: 1m 41s\n","380:\tlearn: 0.5765026\ttotal: 1m 2s\tremaining: 1m 41s\n","381:\tlearn: 0.5764511\ttotal: 1m 2s\tremaining: 1m 41s\n","382:\tlearn: 0.5763921\ttotal: 1m 2s\tremaining: 1m 41s\n","383:\tlearn: 0.5763444\ttotal: 1m 3s\tremaining: 1m 41s\n","384:\tlearn: 0.5762841\ttotal: 1m 3s\tremaining: 1m 40s\n","385:\tlearn: 0.5762062\ttotal: 1m 3s\tremaining: 1m 40s\n","386:\tlearn: 0.5761069\ttotal: 1m 3s\tremaining: 1m 40s\n","387:\tlearn: 0.5760761\ttotal: 1m 3s\tremaining: 1m 40s\n","388:\tlearn: 0.5760151\ttotal: 1m 4s\tremaining: 1m 40s\n","389:\tlearn: 0.5759554\ttotal: 1m 4s\tremaining: 1m 40s\n","390:\tlearn: 0.5758833\ttotal: 1m 4s\tremaining: 1m 40s\n","391:\tlearn: 0.5758400\ttotal: 1m 4s\tremaining: 1m 40s\n","392:\tlearn: 0.5757718\ttotal: 1m 4s\tremaining: 1m 39s\n","393:\tlearn: 0.5757051\ttotal: 1m 4s\tremaining: 1m 39s\n","394:\tlearn: 0.5756266\ttotal: 1m 5s\tremaining: 1m 39s\n","395:\tlearn: 0.5755695\ttotal: 1m 5s\tremaining: 1m 39s\n","396:\tlearn: 0.5754794\ttotal: 1m 5s\tremaining: 1m 39s\n","397:\tlearn: 0.5754025\ttotal: 1m 5s\tremaining: 1m 39s\n","398:\tlearn: 0.5753507\ttotal: 1m 6s\tremaining: 1m 39s\n","399:\tlearn: 0.5752942\ttotal: 1m 6s\tremaining: 1m 39s\n","400:\tlearn: 0.5752218\ttotal: 1m 6s\tremaining: 1m 39s\n","401:\tlearn: 0.5751547\ttotal: 1m 6s\tremaining: 1m 39s\n","402:\tlearn: 0.5751468\ttotal: 1m 6s\tremaining: 1m 38s\n","403:\tlearn: 0.5750805\ttotal: 1m 7s\tremaining: 1m 38s\n","404:\tlearn: 0.5750161\ttotal: 1m 7s\tremaining: 1m 38s\n","405:\tlearn: 0.5749968\ttotal: 1m 7s\tremaining: 1m 38s\n","406:\tlearn: 0.5749351\ttotal: 1m 7s\tremaining: 1m 38s\n","407:\tlearn: 0.5748787\ttotal: 1m 7s\tremaining: 1m 38s\n","408:\tlearn: 0.5748123\ttotal: 1m 8s\tremaining: 1m 38s\n","409:\tlearn: 0.5747866\ttotal: 1m 8s\tremaining: 1m 38s\n","410:\tlearn: 0.5747156\ttotal: 1m 8s\tremaining: 1m 37s\n","411:\tlearn: 0.5746539\ttotal: 1m 8s\tremaining: 1m 37s\n","412:\tlearn: 0.5745884\ttotal: 1m 8s\tremaining: 1m 37s\n","413:\tlearn: 0.5745235\ttotal: 1m 9s\tremaining: 1m 37s\n","414:\tlearn: 0.5744673\ttotal: 1m 9s\tremaining: 1m 37s\n","415:\tlearn: 0.5744145\ttotal: 1m 9s\tremaining: 1m 37s\n","416:\tlearn: 0.5743288\ttotal: 1m 9s\tremaining: 1m 37s\n","417:\tlearn: 0.5742333\ttotal: 1m 9s\tremaining: 1m 37s\n","418:\tlearn: 0.5741809\ttotal: 1m 9s\tremaining: 1m 36s\n","419:\tlearn: 0.5741582\ttotal: 1m 10s\tremaining: 1m 36s\n","420:\tlearn: 0.5740956\ttotal: 1m 10s\tremaining: 1m 36s\n","421:\tlearn: 0.5740543\ttotal: 1m 10s\tremaining: 1m 36s\n","422:\tlearn: 0.5739953\ttotal: 1m 10s\tremaining: 1m 35s\n","423:\tlearn: 0.5739410\ttotal: 1m 10s\tremaining: 1m 35s\n","424:\tlearn: 0.5738607\ttotal: 1m 10s\tremaining: 1m 35s\n","425:\tlearn: 0.5738245\ttotal: 1m 10s\tremaining: 1m 35s\n","426:\tlearn: 0.5737454\ttotal: 1m 10s\tremaining: 1m 35s\n","427:\tlearn: 0.5737028\ttotal: 1m 10s\tremaining: 1m 34s\n","428:\tlearn: 0.5736612\ttotal: 1m 11s\tremaining: 1m 34s\n","429:\tlearn: 0.5735933\ttotal: 1m 11s\tremaining: 1m 34s\n","430:\tlearn: 0.5735442\ttotal: 1m 11s\tremaining: 1m 34s\n","431:\tlearn: 0.5735027\ttotal: 1m 11s\tremaining: 1m 33s\n","432:\tlearn: 0.5734345\ttotal: 1m 11s\tremaining: 1m 33s\n","433:\tlearn: 0.5733991\ttotal: 1m 11s\tremaining: 1m 33s\n","434:\tlearn: 0.5733433\ttotal: 1m 11s\tremaining: 1m 33s\n","435:\tlearn: 0.5732477\ttotal: 1m 11s\tremaining: 1m 32s\n","436:\tlearn: 0.5732021\ttotal: 1m 11s\tremaining: 1m 32s\n","437:\tlearn: 0.5731435\ttotal: 1m 12s\tremaining: 1m 32s\n","438:\tlearn: 0.5730787\ttotal: 1m 12s\tremaining: 1m 32s\n","439:\tlearn: 0.5730331\ttotal: 1m 12s\tremaining: 1m 32s\n","440:\tlearn: 0.5729809\ttotal: 1m 12s\tremaining: 1m 32s\n","441:\tlearn: 0.5729230\ttotal: 1m 12s\tremaining: 1m 31s\n","442:\tlearn: 0.5728605\ttotal: 1m 13s\tremaining: 1m 31s\n","443:\tlearn: 0.5728068\ttotal: 1m 13s\tremaining: 1m 32s\n","444:\tlearn: 0.5727552\ttotal: 1m 13s\tremaining: 1m 32s\n","445:\tlearn: 0.5726920\ttotal: 1m 14s\tremaining: 1m 31s\n","446:\tlearn: 0.5726550\ttotal: 1m 14s\tremaining: 1m 32s\n","447:\tlearn: 0.5725967\ttotal: 1m 14s\tremaining: 1m 32s\n","448:\tlearn: 0.5725195\ttotal: 1m 15s\tremaining: 1m 32s\n","449:\tlearn: 0.5724587\ttotal: 1m 15s\tremaining: 1m 32s\n","450:\tlearn: 0.5724177\ttotal: 1m 15s\tremaining: 1m 32s\n","451:\tlearn: 0.5723362\ttotal: 1m 15s\tremaining: 1m 32s\n","452:\tlearn: 0.5722831\ttotal: 1m 16s\tremaining: 1m 31s\n","453:\tlearn: 0.5722226\ttotal: 1m 16s\tremaining: 1m 32s\n","454:\tlearn: 0.5721554\ttotal: 1m 16s\tremaining: 1m 32s\n","455:\tlearn: 0.5720771\ttotal: 1m 17s\tremaining: 1m 31s\n","456:\tlearn: 0.5720401\ttotal: 1m 17s\tremaining: 1m 31s\n","457:\tlearn: 0.5719934\ttotal: 1m 17s\tremaining: 1m 31s\n","458:\tlearn: 0.5719124\ttotal: 1m 17s\tremaining: 1m 31s\n","459:\tlearn: 0.5718485\ttotal: 1m 18s\tremaining: 1m 31s\n","460:\tlearn: 0.5717925\ttotal: 1m 18s\tremaining: 1m 31s\n","461:\tlearn: 0.5717121\ttotal: 1m 18s\tremaining: 1m 31s\n","462:\tlearn: 0.5716597\ttotal: 1m 19s\tremaining: 1m 31s\n","463:\tlearn: 0.5716017\ttotal: 1m 19s\tremaining: 1m 31s\n","464:\tlearn: 0.5715576\ttotal: 1m 19s\tremaining: 1m 31s\n","465:\tlearn: 0.5714991\ttotal: 1m 20s\tremaining: 1m 32s\n","466:\tlearn: 0.5714477\ttotal: 1m 20s\tremaining: 1m 32s\n","467:\tlearn: 0.5713837\ttotal: 1m 21s\tremaining: 1m 32s\n","468:\tlearn: 0.5713330\ttotal: 1m 21s\tremaining: 1m 32s\n","469:\tlearn: 0.5712847\ttotal: 1m 21s\tremaining: 1m 32s\n","470:\tlearn: 0.5712143\ttotal: 1m 22s\tremaining: 1m 32s\n","471:\tlearn: 0.5711572\ttotal: 1m 22s\tremaining: 1m 32s\n","472:\tlearn: 0.5711103\ttotal: 1m 23s\tremaining: 1m 32s\n","473:\tlearn: 0.5710408\ttotal: 1m 23s\tremaining: 1m 32s\n","474:\tlearn: 0.5709975\ttotal: 1m 23s\tremaining: 1m 32s\n","475:\tlearn: 0.5709866\ttotal: 1m 23s\tremaining: 1m 32s\n","476:\tlearn: 0.5709182\ttotal: 1m 23s\tremaining: 1m 32s\n","477:\tlearn: 0.5709100\ttotal: 1m 24s\tremaining: 1m 31s\n","478:\tlearn: 0.5708570\ttotal: 1m 24s\tremaining: 1m 31s\n","479:\tlearn: 0.5707937\ttotal: 1m 24s\tremaining: 1m 31s\n","480:\tlearn: 0.5707144\ttotal: 1m 24s\tremaining: 1m 31s\n","481:\tlearn: 0.5706885\ttotal: 1m 24s\tremaining: 1m 30s\n","482:\tlearn: 0.5706307\ttotal: 1m 24s\tremaining: 1m 30s\n","483:\tlearn: 0.5705813\ttotal: 1m 24s\tremaining: 1m 30s\n","484:\tlearn: 0.5705343\ttotal: 1m 24s\tremaining: 1m 30s\n","485:\tlearn: 0.5704564\ttotal: 1m 25s\tremaining: 1m 29s\n","486:\tlearn: 0.5703734\ttotal: 1m 25s\tremaining: 1m 29s\n","487:\tlearn: 0.5703040\ttotal: 1m 25s\tremaining: 1m 29s\n","488:\tlearn: 0.5702297\ttotal: 1m 25s\tremaining: 1m 29s\n","489:\tlearn: 0.5701877\ttotal: 1m 25s\tremaining: 1m 29s\n","490:\tlearn: 0.5701293\ttotal: 1m 26s\tremaining: 1m 29s\n","491:\tlearn: 0.5700634\ttotal: 1m 26s\tremaining: 1m 29s\n","492:\tlearn: 0.5700100\ttotal: 1m 26s\tremaining: 1m 29s\n","493:\tlearn: 0.5699532\ttotal: 1m 26s\tremaining: 1m 29s\n","494:\tlearn: 0.5699184\ttotal: 1m 27s\tremaining: 1m 28s\n","495:\tlearn: 0.5698884\ttotal: 1m 27s\tremaining: 1m 28s\n","496:\tlearn: 0.5698475\ttotal: 1m 27s\tremaining: 1m 28s\n","497:\tlearn: 0.5698001\ttotal: 1m 28s\tremaining: 1m 28s\n","498:\tlearn: 0.5697113\ttotal: 1m 28s\tremaining: 1m 28s\n","499:\tlearn: 0.5696325\ttotal: 1m 28s\tremaining: 1m 28s\n","500:\tlearn: 0.5695824\ttotal: 1m 28s\tremaining: 1m 28s\n","501:\tlearn: 0.5695112\ttotal: 1m 28s\tremaining: 1m 28s\n","502:\tlearn: 0.5694481\ttotal: 1m 29s\tremaining: 1m 27s\n","503:\tlearn: 0.5694016\ttotal: 1m 29s\tremaining: 1m 27s\n","504:\tlearn: 0.5693777\ttotal: 1m 29s\tremaining: 1m 27s\n","505:\tlearn: 0.5693486\ttotal: 1m 29s\tremaining: 1m 27s\n","506:\tlearn: 0.5693108\ttotal: 1m 29s\tremaining: 1m 27s\n","507:\tlearn: 0.5692586\ttotal: 1m 29s\tremaining: 1m 27s\n","508:\tlearn: 0.5691844\ttotal: 1m 30s\tremaining: 1m 26s\n","509:\tlearn: 0.5691215\ttotal: 1m 30s\tremaining: 1m 26s\n","510:\tlearn: 0.5690673\ttotal: 1m 30s\tremaining: 1m 26s\n","511:\tlearn: 0.5690022\ttotal: 1m 30s\tremaining: 1m 26s\n","512:\tlearn: 0.5689637\ttotal: 1m 30s\tremaining: 1m 26s\n","513:\tlearn: 0.5689237\ttotal: 1m 31s\tremaining: 1m 26s\n","514:\tlearn: 0.5688535\ttotal: 1m 31s\tremaining: 1m 26s\n","515:\tlearn: 0.5688044\ttotal: 1m 31s\tremaining: 1m 25s\n","516:\tlearn: 0.5687266\ttotal: 1m 32s\tremaining: 1m 26s\n","517:\tlearn: 0.5686725\ttotal: 1m 32s\tremaining: 1m 26s\n","518:\tlearn: 0.5686221\ttotal: 1m 32s\tremaining: 1m 25s\n","519:\tlearn: 0.5685643\ttotal: 1m 32s\tremaining: 1m 25s\n","520:\tlearn: 0.5685345\ttotal: 1m 32s\tremaining: 1m 25s\n","521:\tlearn: 0.5684742\ttotal: 1m 33s\tremaining: 1m 25s\n","522:\tlearn: 0.5683955\ttotal: 1m 33s\tremaining: 1m 25s\n","523:\tlearn: 0.5683452\ttotal: 1m 33s\tremaining: 1m 25s\n","524:\tlearn: 0.5683179\ttotal: 1m 33s\tremaining: 1m 24s\n","525:\tlearn: 0.5682635\ttotal: 1m 34s\tremaining: 1m 24s\n","526:\tlearn: 0.5682131\ttotal: 1m 34s\tremaining: 1m 24s\n","527:\tlearn: 0.5681765\ttotal: 1m 35s\tremaining: 1m 25s\n","528:\tlearn: 0.5681125\ttotal: 1m 35s\tremaining: 1m 25s\n","529:\tlearn: 0.5680873\ttotal: 1m 35s\tremaining: 1m 25s\n","530:\tlearn: 0.5680356\ttotal: 1m 36s\tremaining: 1m 25s\n","531:\tlearn: 0.5679754\ttotal: 1m 36s\tremaining: 1m 25s\n","532:\tlearn: 0.5679202\ttotal: 1m 37s\tremaining: 1m 25s\n","533:\tlearn: 0.5678629\ttotal: 1m 37s\tremaining: 1m 25s\n","534:\tlearn: 0.5678127\ttotal: 1m 37s\tremaining: 1m 24s\n","535:\tlearn: 0.5677533\ttotal: 1m 38s\tremaining: 1m 24s\n","536:\tlearn: 0.5676999\ttotal: 1m 38s\tremaining: 1m 25s\n","537:\tlearn: 0.5676450\ttotal: 1m 38s\tremaining: 1m 24s\n","538:\tlearn: 0.5675857\ttotal: 1m 39s\tremaining: 1m 24s\n","539:\tlearn: 0.5675358\ttotal: 1m 39s\tremaining: 1m 24s\n","540:\tlearn: 0.5674816\ttotal: 1m 39s\tremaining: 1m 24s\n","541:\tlearn: 0.5674330\ttotal: 1m 39s\tremaining: 1m 24s\n","542:\tlearn: 0.5673691\ttotal: 1m 40s\tremaining: 1m 24s\n","543:\tlearn: 0.5673131\ttotal: 1m 40s\tremaining: 1m 24s\n","544:\tlearn: 0.5672488\ttotal: 1m 40s\tremaining: 1m 24s\n","545:\tlearn: 0.5672007\ttotal: 1m 40s\tremaining: 1m 23s\n","546:\tlearn: 0.5671310\ttotal: 1m 41s\tremaining: 1m 23s\n","547:\tlearn: 0.5670793\ttotal: 1m 41s\tremaining: 1m 23s\n","548:\tlearn: 0.5670357\ttotal: 1m 41s\tremaining: 1m 23s\n","549:\tlearn: 0.5670065\ttotal: 1m 41s\tremaining: 1m 23s\n","550:\tlearn: 0.5669417\ttotal: 1m 41s\tremaining: 1m 22s\n","551:\tlearn: 0.5668758\ttotal: 1m 41s\tremaining: 1m 22s\n","552:\tlearn: 0.5668133\ttotal: 1m 42s\tremaining: 1m 22s\n","553:\tlearn: 0.5667541\ttotal: 1m 42s\tremaining: 1m 22s\n","554:\tlearn: 0.5667268\ttotal: 1m 42s\tremaining: 1m 22s\n","555:\tlearn: 0.5666853\ttotal: 1m 42s\tremaining: 1m 22s\n","556:\tlearn: 0.5666423\ttotal: 1m 42s\tremaining: 1m 21s\n","557:\tlearn: 0.5665933\ttotal: 1m 43s\tremaining: 1m 21s\n","558:\tlearn: 0.5665380\ttotal: 1m 43s\tremaining: 1m 21s\n","559:\tlearn: 0.5665304\ttotal: 1m 43s\tremaining: 1m 21s\n","560:\tlearn: 0.5664772\ttotal: 1m 43s\tremaining: 1m 21s\n","561:\tlearn: 0.5664723\ttotal: 1m 44s\tremaining: 1m 21s\n","562:\tlearn: 0.5664027\ttotal: 1m 44s\tremaining: 1m 21s\n","563:\tlearn: 0.5663550\ttotal: 1m 44s\tremaining: 1m 20s\n","564:\tlearn: 0.5663168\ttotal: 1m 44s\tremaining: 1m 20s\n","565:\tlearn: 0.5662508\ttotal: 1m 44s\tremaining: 1m 20s\n","566:\tlearn: 0.5661916\ttotal: 1m 44s\tremaining: 1m 20s\n","567:\tlearn: 0.5661223\ttotal: 1m 45s\tremaining: 1m 19s\n","568:\tlearn: 0.5660576\ttotal: 1m 45s\tremaining: 1m 19s\n","569:\tlearn: 0.5660303\ttotal: 1m 45s\tremaining: 1m 19s\n","570:\tlearn: 0.5659850\ttotal: 1m 45s\tremaining: 1m 19s\n","571:\tlearn: 0.5659548\ttotal: 1m 45s\tremaining: 1m 18s\n","572:\tlearn: 0.5659251\ttotal: 1m 45s\tremaining: 1m 18s\n","573:\tlearn: 0.5658521\ttotal: 1m 45s\tremaining: 1m 18s\n","574:\tlearn: 0.5657994\ttotal: 1m 45s\tremaining: 1m 18s\n","575:\tlearn: 0.5657428\ttotal: 1m 45s\tremaining: 1m 17s\n","576:\tlearn: 0.5656923\ttotal: 1m 46s\tremaining: 1m 17s\n","577:\tlearn: 0.5656469\ttotal: 1m 46s\tremaining: 1m 17s\n","578:\tlearn: 0.5655934\ttotal: 1m 46s\tremaining: 1m 17s\n","579:\tlearn: 0.5655380\ttotal: 1m 46s\tremaining: 1m 17s\n","580:\tlearn: 0.5654829\ttotal: 1m 46s\tremaining: 1m 16s\n","581:\tlearn: 0.5654146\ttotal: 1m 46s\tremaining: 1m 16s\n","582:\tlearn: 0.5653547\ttotal: 1m 46s\tremaining: 1m 16s\n","583:\tlearn: 0.5653126\ttotal: 1m 46s\tremaining: 1m 16s\n","584:\tlearn: 0.5652924\ttotal: 1m 46s\tremaining: 1m 15s\n","585:\tlearn: 0.5652426\ttotal: 1m 47s\tremaining: 1m 15s\n","586:\tlearn: 0.5651900\ttotal: 1m 47s\tremaining: 1m 15s\n","587:\tlearn: 0.5651216\ttotal: 1m 47s\tremaining: 1m 15s\n","588:\tlearn: 0.5650452\ttotal: 1m 47s\tremaining: 1m 14s\n","589:\tlearn: 0.5649634\ttotal: 1m 47s\tremaining: 1m 14s\n","590:\tlearn: 0.5649103\ttotal: 1m 47s\tremaining: 1m 14s\n","591:\tlearn: 0.5648965\ttotal: 1m 47s\tremaining: 1m 14s\n","592:\tlearn: 0.5648374\ttotal: 1m 47s\tremaining: 1m 14s\n","593:\tlearn: 0.5648081\ttotal: 1m 47s\tremaining: 1m 13s\n","594:\tlearn: 0.5647468\ttotal: 1m 48s\tremaining: 1m 13s\n","595:\tlearn: 0.5647113\ttotal: 1m 48s\tremaining: 1m 13s\n","596:\tlearn: 0.5646572\ttotal: 1m 48s\tremaining: 1m 13s\n","597:\tlearn: 0.5646055\ttotal: 1m 48s\tremaining: 1m 12s\n","598:\tlearn: 0.5645646\ttotal: 1m 48s\tremaining: 1m 12s\n","599:\tlearn: 0.5644924\ttotal: 1m 48s\tremaining: 1m 12s\n","600:\tlearn: 0.5644310\ttotal: 1m 48s\tremaining: 1m 12s\n","601:\tlearn: 0.5643739\ttotal: 1m 48s\tremaining: 1m 12s\n","602:\tlearn: 0.5643302\ttotal: 1m 49s\tremaining: 1m 11s\n","603:\tlearn: 0.5642767\ttotal: 1m 49s\tremaining: 1m 11s\n","604:\tlearn: 0.5642318\ttotal: 1m 49s\tremaining: 1m 11s\n","605:\tlearn: 0.5641873\ttotal: 1m 49s\tremaining: 1m 11s\n","606:\tlearn: 0.5641134\ttotal: 1m 49s\tremaining: 1m 11s\n","607:\tlearn: 0.5640748\ttotal: 1m 50s\tremaining: 1m 11s\n","608:\tlearn: 0.5640238\ttotal: 1m 50s\tremaining: 1m 10s\n","609:\tlearn: 0.5639719\ttotal: 1m 50s\tremaining: 1m 10s\n","610:\tlearn: 0.5639391\ttotal: 1m 50s\tremaining: 1m 10s\n","611:\tlearn: 0.5638901\ttotal: 1m 51s\tremaining: 1m 10s\n","612:\tlearn: 0.5638393\ttotal: 1m 51s\tremaining: 1m 10s\n","613:\tlearn: 0.5637982\ttotal: 1m 51s\tremaining: 1m 10s\n","614:\tlearn: 0.5637329\ttotal: 1m 51s\tremaining: 1m 9s\n","615:\tlearn: 0.5636822\ttotal: 1m 51s\tremaining: 1m 9s\n","616:\tlearn: 0.5636195\ttotal: 1m 52s\tremaining: 1m 9s\n","617:\tlearn: 0.5635841\ttotal: 1m 52s\tremaining: 1m 9s\n","618:\tlearn: 0.5635489\ttotal: 1m 52s\tremaining: 1m 9s\n","619:\tlearn: 0.5634800\ttotal: 1m 52s\tremaining: 1m 9s\n","620:\tlearn: 0.5634140\ttotal: 1m 52s\tremaining: 1m 8s\n","621:\tlearn: 0.5633531\ttotal: 1m 52s\tremaining: 1m 8s\n","622:\tlearn: 0.5632924\ttotal: 1m 53s\tremaining: 1m 8s\n","623:\tlearn: 0.5632432\ttotal: 1m 53s\tremaining: 1m 8s\n","624:\tlearn: 0.5631740\ttotal: 1m 53s\tremaining: 1m 7s\n","625:\tlearn: 0.5631116\ttotal: 1m 53s\tremaining: 1m 7s\n","626:\tlearn: 0.5630617\ttotal: 1m 53s\tremaining: 1m 7s\n","627:\tlearn: 0.5630288\ttotal: 1m 53s\tremaining: 1m 7s\n","628:\tlearn: 0.5629865\ttotal: 1m 53s\tremaining: 1m 7s\n","629:\tlearn: 0.5629283\ttotal: 1m 53s\tremaining: 1m 6s\n","630:\tlearn: 0.5628698\ttotal: 1m 53s\tremaining: 1m 6s\n","631:\tlearn: 0.5628291\ttotal: 1m 54s\tremaining: 1m 6s\n","632:\tlearn: 0.5627662\ttotal: 1m 54s\tremaining: 1m 6s\n","633:\tlearn: 0.5627033\ttotal: 1m 54s\tremaining: 1m 5s\n","634:\tlearn: 0.5626323\ttotal: 1m 54s\tremaining: 1m 5s\n","635:\tlearn: 0.5626007\ttotal: 1m 54s\tremaining: 1m 5s\n","636:\tlearn: 0.5625811\ttotal: 1m 54s\tremaining: 1m 5s\n","637:\tlearn: 0.5625271\ttotal: 1m 54s\tremaining: 1m 5s\n","638:\tlearn: 0.5624694\ttotal: 1m 54s\tremaining: 1m 4s\n","639:\tlearn: 0.5624173\ttotal: 1m 54s\tremaining: 1m 4s\n","640:\tlearn: 0.5623671\ttotal: 1m 55s\tremaining: 1m 4s\n","641:\tlearn: 0.5623210\ttotal: 1m 55s\tremaining: 1m 4s\n","642:\tlearn: 0.5622619\ttotal: 1m 55s\tremaining: 1m 4s\n","643:\tlearn: 0.5622557\ttotal: 1m 55s\tremaining: 1m 3s\n","644:\tlearn: 0.5622176\ttotal: 1m 55s\tremaining: 1m 3s\n","645:\tlearn: 0.5621580\ttotal: 1m 55s\tremaining: 1m 3s\n","646:\tlearn: 0.5621203\ttotal: 1m 55s\tremaining: 1m 3s\n","647:\tlearn: 0.5620540\ttotal: 1m 55s\tremaining: 1m 2s\n","648:\tlearn: 0.5620190\ttotal: 1m 55s\tremaining: 1m 2s\n","649:\tlearn: 0.5619665\ttotal: 1m 56s\tremaining: 1m 2s\n","650:\tlearn: 0.5619356\ttotal: 1m 56s\tremaining: 1m 2s\n","651:\tlearn: 0.5618991\ttotal: 1m 56s\tremaining: 1m 2s\n","652:\tlearn: 0.5618382\ttotal: 1m 56s\tremaining: 1m 1s\n","653:\tlearn: 0.5617924\ttotal: 1m 56s\tremaining: 1m 1s\n","654:\tlearn: 0.5617380\ttotal: 1m 56s\tremaining: 1m 1s\n","655:\tlearn: 0.5616834\ttotal: 1m 56s\tremaining: 1m 1s\n","656:\tlearn: 0.5616236\ttotal: 1m 56s\tremaining: 1m 1s\n","657:\tlearn: 0.5615464\ttotal: 1m 57s\tremaining: 1m\n","658:\tlearn: 0.5614908\ttotal: 1m 57s\tremaining: 1m\n","659:\tlearn: 0.5614696\ttotal: 1m 57s\tremaining: 1m\n","660:\tlearn: 0.5614245\ttotal: 1m 57s\tremaining: 1m\n","661:\tlearn: 0.5614020\ttotal: 1m 57s\tremaining: 1m\n","662:\tlearn: 0.5613383\ttotal: 1m 57s\tremaining: 59.8s\n","663:\tlearn: 0.5612997\ttotal: 1m 57s\tremaining: 59.6s\n","664:\tlearn: 0.5612410\ttotal: 1m 57s\tremaining: 59.4s\n","665:\tlearn: 0.5612025\ttotal: 1m 57s\tremaining: 59.2s\n","666:\tlearn: 0.5611378\ttotal: 1m 58s\tremaining: 58.9s\n","667:\tlearn: 0.5610954\ttotal: 1m 58s\tremaining: 58.7s\n","668:\tlearn: 0.5610542\ttotal: 1m 58s\tremaining: 58.5s\n","669:\tlearn: 0.5610043\ttotal: 1m 58s\tremaining: 58.3s\n","670:\tlearn: 0.5609973\ttotal: 1m 58s\tremaining: 58.1s\n","671:\tlearn: 0.5609645\ttotal: 1m 58s\tremaining: 57.9s\n","672:\tlearn: 0.5608879\ttotal: 1m 58s\tremaining: 57.7s\n","673:\tlearn: 0.5608482\ttotal: 1m 58s\tremaining: 57.4s\n","674:\tlearn: 0.5608080\ttotal: 1m 58s\tremaining: 57.2s\n","675:\tlearn: 0.5607723\ttotal: 1m 58s\tremaining: 57s\n","676:\tlearn: 0.5607426\ttotal: 1m 59s\tremaining: 56.8s\n","677:\tlearn: 0.5606792\ttotal: 1m 59s\tremaining: 56.6s\n","678:\tlearn: 0.5606485\ttotal: 1m 59s\tremaining: 56.4s\n","679:\tlearn: 0.5606154\ttotal: 1m 59s\tremaining: 56.1s\n","680:\tlearn: 0.5605636\ttotal: 1m 59s\tremaining: 55.9s\n","681:\tlearn: 0.5605196\ttotal: 1m 59s\tremaining: 55.7s\n","682:\tlearn: 0.5604576\ttotal: 1m 59s\tremaining: 55.6s\n","683:\tlearn: 0.5604312\ttotal: 1m 59s\tremaining: 55.3s\n","684:\tlearn: 0.5603906\ttotal: 1m 59s\tremaining: 55.1s\n","685:\tlearn: 0.5603082\ttotal: 2m\tremaining: 54.9s\n","686:\tlearn: 0.5602355\ttotal: 2m\tremaining: 54.7s\n","687:\tlearn: 0.5601899\ttotal: 2m\tremaining: 54.5s\n","688:\tlearn: 0.5601463\ttotal: 2m\tremaining: 54.3s\n","689:\tlearn: 0.5600995\ttotal: 2m\tremaining: 54.1s\n","690:\tlearn: 0.5600723\ttotal: 2m\tremaining: 53.9s\n","691:\tlearn: 0.5600326\ttotal: 2m\tremaining: 53.7s\n","692:\tlearn: 0.5599925\ttotal: 2m\tremaining: 53.5s\n","693:\tlearn: 0.5599480\ttotal: 2m\tremaining: 53.3s\n","694:\tlearn: 0.5599437\ttotal: 2m 1s\tremaining: 53.1s\n","695:\tlearn: 0.5598977\ttotal: 2m 1s\tremaining: 52.9s\n","696:\tlearn: 0.5598364\ttotal: 2m 1s\tremaining: 52.7s\n","697:\tlearn: 0.5598080\ttotal: 2m 1s\tremaining: 52.5s\n","698:\tlearn: 0.5597515\ttotal: 2m 1s\tremaining: 52.3s\n","699:\tlearn: 0.5597142\ttotal: 2m 1s\tremaining: 52.1s\n","700:\tlearn: 0.5596601\ttotal: 2m 1s\tremaining: 51.9s\n","701:\tlearn: 0.5595998\ttotal: 2m 1s\tremaining: 51.7s\n","702:\tlearn: 0.5595580\ttotal: 2m 1s\tremaining: 51.5s\n","703:\tlearn: 0.5595505\ttotal: 2m 2s\tremaining: 51.3s\n","704:\tlearn: 0.5594858\ttotal: 2m 2s\tremaining: 51.1s\n","705:\tlearn: 0.5594531\ttotal: 2m 2s\tremaining: 50.9s\n","706:\tlearn: 0.5594044\ttotal: 2m 2s\tremaining: 50.7s\n","707:\tlearn: 0.5593498\ttotal: 2m 2s\tremaining: 50.5s\n","708:\tlearn: 0.5592814\ttotal: 2m 2s\tremaining: 50.3s\n","709:\tlearn: 0.5592283\ttotal: 2m 2s\tremaining: 50.2s\n","710:\tlearn: 0.5591986\ttotal: 2m 3s\tremaining: 50s\n","711:\tlearn: 0.5591465\ttotal: 2m 3s\tremaining: 49.9s\n","712:\tlearn: 0.5591123\ttotal: 2m 3s\tremaining: 49.7s\n","713:\tlearn: 0.5590805\ttotal: 2m 3s\tremaining: 49.5s\n","714:\tlearn: 0.5590291\ttotal: 2m 3s\tremaining: 49.4s\n","715:\tlearn: 0.5589771\ttotal: 2m 3s\tremaining: 49.2s\n","716:\tlearn: 0.5589028\ttotal: 2m 4s\tremaining: 49s\n","717:\tlearn: 0.5588618\ttotal: 2m 4s\tremaining: 48.9s\n","718:\tlearn: 0.5588033\ttotal: 2m 4s\tremaining: 48.7s\n","719:\tlearn: 0.5587520\ttotal: 2m 4s\tremaining: 48.5s\n","720:\tlearn: 0.5587094\ttotal: 2m 4s\tremaining: 48.4s\n","721:\tlearn: 0.5586641\ttotal: 2m 5s\tremaining: 48.2s\n","722:\tlearn: 0.5586160\ttotal: 2m 5s\tremaining: 48s\n","723:\tlearn: 0.5585537\ttotal: 2m 5s\tremaining: 47.9s\n","724:\tlearn: 0.5584933\ttotal: 2m 5s\tremaining: 47.7s\n","725:\tlearn: 0.5584643\ttotal: 2m 6s\tremaining: 47.6s\n","726:\tlearn: 0.5584377\ttotal: 2m 6s\tremaining: 47.4s\n","727:\tlearn: 0.5583817\ttotal: 2m 6s\tremaining: 47.2s\n","728:\tlearn: 0.5583459\ttotal: 2m 6s\tremaining: 47s\n","729:\tlearn: 0.5582840\ttotal: 2m 6s\tremaining: 46.8s\n","730:\tlearn: 0.5582221\ttotal: 2m 6s\tremaining: 46.6s\n","731:\tlearn: 0.5581955\ttotal: 2m 6s\tremaining: 46.4s\n","732:\tlearn: 0.5581431\ttotal: 2m 6s\tremaining: 46.2s\n","733:\tlearn: 0.5580981\ttotal: 2m 7s\tremaining: 46s\n","734:\tlearn: 0.5580673\ttotal: 2m 7s\tremaining: 45.8s\n","735:\tlearn: 0.5580017\ttotal: 2m 7s\tremaining: 45.6s\n","736:\tlearn: 0.5579471\ttotal: 2m 7s\tremaining: 45.5s\n","737:\tlearn: 0.5579179\ttotal: 2m 7s\tremaining: 45.3s\n","738:\tlearn: 0.5578636\ttotal: 2m 7s\tremaining: 45.1s\n","739:\tlearn: 0.5578361\ttotal: 2m 7s\tremaining: 44.9s\n","740:\tlearn: 0.5578117\ttotal: 2m 7s\tremaining: 44.7s\n","741:\tlearn: 0.5577457\ttotal: 2m 7s\tremaining: 44.5s\n","742:\tlearn: 0.5576867\ttotal: 2m 8s\tremaining: 44.3s\n","743:\tlearn: 0.5576311\ttotal: 2m 8s\tremaining: 44.1s\n","744:\tlearn: 0.5575906\ttotal: 2m 8s\tremaining: 43.9s\n","745:\tlearn: 0.5575484\ttotal: 2m 8s\tremaining: 43.7s\n","746:\tlearn: 0.5575007\ttotal: 2m 8s\tremaining: 43.5s\n","747:\tlearn: 0.5574731\ttotal: 2m 8s\tremaining: 43.3s\n","748:\tlearn: 0.5574274\ttotal: 2m 8s\tremaining: 43.2s\n","749:\tlearn: 0.5574202\ttotal: 2m 8s\tremaining: 42.9s\n","750:\tlearn: 0.5573655\ttotal: 2m 8s\tremaining: 42.8s\n","751:\tlearn: 0.5573350\ttotal: 2m 9s\tremaining: 42.6s\n","752:\tlearn: 0.5572937\ttotal: 2m 9s\tremaining: 42.4s\n","753:\tlearn: 0.5572582\ttotal: 2m 9s\tremaining: 42.2s\n","754:\tlearn: 0.5572128\ttotal: 2m 9s\tremaining: 42s\n","755:\tlearn: 0.5571389\ttotal: 2m 9s\tremaining: 41.8s\n","756:\tlearn: 0.5570997\ttotal: 2m 9s\tremaining: 41.6s\n","757:\tlearn: 0.5570476\ttotal: 2m 9s\tremaining: 41.4s\n","758:\tlearn: 0.5570005\ttotal: 2m 9s\tremaining: 41.2s\n","759:\tlearn: 0.5569361\ttotal: 2m 10s\tremaining: 41.1s\n","760:\tlearn: 0.5568654\ttotal: 2m 10s\tremaining: 40.9s\n","761:\tlearn: 0.5568115\ttotal: 2m 10s\tremaining: 40.7s\n","762:\tlearn: 0.5568038\ttotal: 2m 10s\tremaining: 40.5s\n","763:\tlearn: 0.5567283\ttotal: 2m 10s\tremaining: 40.3s\n","764:\tlearn: 0.5566698\ttotal: 2m 10s\tremaining: 40.1s\n","765:\tlearn: 0.5566108\ttotal: 2m 10s\tremaining: 40s\n","766:\tlearn: 0.5565746\ttotal: 2m 10s\tremaining: 39.8s\n","767:\tlearn: 0.5565362\ttotal: 2m 10s\tremaining: 39.6s\n","768:\tlearn: 0.5565084\ttotal: 2m 11s\tremaining: 39.4s\n","769:\tlearn: 0.5564776\ttotal: 2m 11s\tremaining: 39.2s\n","770:\tlearn: 0.5564498\ttotal: 2m 11s\tremaining: 39s\n","771:\tlearn: 0.5563984\ttotal: 2m 11s\tremaining: 38.8s\n","772:\tlearn: 0.5563477\ttotal: 2m 11s\tremaining: 38.6s\n","773:\tlearn: 0.5562864\ttotal: 2m 11s\tremaining: 38.4s\n","774:\tlearn: 0.5562569\ttotal: 2m 11s\tremaining: 38.2s\n","775:\tlearn: 0.5562377\ttotal: 2m 11s\tremaining: 38.1s\n","776:\tlearn: 0.5561849\ttotal: 2m 11s\tremaining: 37.9s\n","777:\tlearn: 0.5561211\ttotal: 2m 12s\tremaining: 37.7s\n","778:\tlearn: 0.5560845\ttotal: 2m 12s\tremaining: 37.5s\n","779:\tlearn: 0.5560422\ttotal: 2m 12s\tremaining: 37.3s\n","780:\tlearn: 0.5559908\ttotal: 2m 12s\tremaining: 37.1s\n","781:\tlearn: 0.5559600\ttotal: 2m 12s\tremaining: 36.9s\n","782:\tlearn: 0.5559078\ttotal: 2m 12s\tremaining: 36.8s\n","783:\tlearn: 0.5558458\ttotal: 2m 12s\tremaining: 36.6s\n","784:\tlearn: 0.5557953\ttotal: 2m 12s\tremaining: 36.4s\n","785:\tlearn: 0.5557344\ttotal: 2m 12s\tremaining: 36.2s\n","786:\tlearn: 0.5556887\ttotal: 2m 13s\tremaining: 36s\n","787:\tlearn: 0.5556399\ttotal: 2m 13s\tremaining: 35.8s\n","788:\tlearn: 0.5556001\ttotal: 2m 13s\tremaining: 35.7s\n","789:\tlearn: 0.5555399\ttotal: 2m 13s\tremaining: 35.5s\n","790:\tlearn: 0.5554773\ttotal: 2m 13s\tremaining: 35.3s\n","791:\tlearn: 0.5554444\ttotal: 2m 13s\tremaining: 35.1s\n","792:\tlearn: 0.5554404\ttotal: 2m 13s\tremaining: 34.9s\n","793:\tlearn: 0.5553952\ttotal: 2m 13s\tremaining: 34.7s\n","794:\tlearn: 0.5553446\ttotal: 2m 14s\tremaining: 34.6s\n","795:\tlearn: 0.5553201\ttotal: 2m 14s\tremaining: 34.4s\n","796:\tlearn: 0.5552871\ttotal: 2m 14s\tremaining: 34.2s\n","797:\tlearn: 0.5552597\ttotal: 2m 14s\tremaining: 34s\n","798:\tlearn: 0.5552241\ttotal: 2m 14s\tremaining: 33.8s\n","799:\tlearn: 0.5551643\ttotal: 2m 14s\tremaining: 33.6s\n","800:\tlearn: 0.5551206\ttotal: 2m 14s\tremaining: 33.5s\n","801:\tlearn: 0.5550753\ttotal: 2m 14s\tremaining: 33.3s\n","802:\tlearn: 0.5550440\ttotal: 2m 14s\tremaining: 33.1s\n","803:\tlearn: 0.5550019\ttotal: 2m 15s\tremaining: 32.9s\n","804:\tlearn: 0.5549336\ttotal: 2m 15s\tremaining: 32.7s\n","805:\tlearn: 0.5548826\ttotal: 2m 15s\tremaining: 32.6s\n","806:\tlearn: 0.5548256\ttotal: 2m 15s\tremaining: 32.4s\n","807:\tlearn: 0.5547609\ttotal: 2m 15s\tremaining: 32.2s\n","808:\tlearn: 0.5547241\ttotal: 2m 15s\tremaining: 32s\n","809:\tlearn: 0.5546690\ttotal: 2m 15s\tremaining: 31.8s\n","810:\tlearn: 0.5546381\ttotal: 2m 15s\tremaining: 31.7s\n","811:\tlearn: 0.5545721\ttotal: 2m 15s\tremaining: 31.5s\n","812:\tlearn: 0.5545429\ttotal: 2m 16s\tremaining: 31.3s\n","813:\tlearn: 0.5544912\ttotal: 2m 16s\tremaining: 31.1s\n","814:\tlearn: 0.5544496\ttotal: 2m 16s\tremaining: 31s\n","815:\tlearn: 0.5543907\ttotal: 2m 16s\tremaining: 30.8s\n","816:\tlearn: 0.5543457\ttotal: 2m 16s\tremaining: 30.6s\n","817:\tlearn: 0.5543392\ttotal: 2m 16s\tremaining: 30.5s\n","818:\tlearn: 0.5543101\ttotal: 2m 17s\tremaining: 30.3s\n","819:\tlearn: 0.5542772\ttotal: 2m 17s\tremaining: 30.2s\n","820:\tlearn: 0.5542260\ttotal: 2m 17s\tremaining: 30s\n","821:\tlearn: 0.5541798\ttotal: 2m 17s\tremaining: 29.8s\n","822:\tlearn: 0.5541602\ttotal: 2m 17s\tremaining: 29.7s\n","823:\tlearn: 0.5541282\ttotal: 2m 18s\tremaining: 29.5s\n","824:\tlearn: 0.5540653\ttotal: 2m 18s\tremaining: 29.4s\n","825:\tlearn: 0.5540216\ttotal: 2m 18s\tremaining: 29.2s\n","826:\tlearn: 0.5539946\ttotal: 2m 18s\tremaining: 29s\n","827:\tlearn: 0.5539461\ttotal: 2m 18s\tremaining: 28.9s\n","828:\tlearn: 0.5538818\ttotal: 2m 19s\tremaining: 28.7s\n","829:\tlearn: 0.5538672\ttotal: 2m 19s\tremaining: 28.6s\n","830:\tlearn: 0.5538185\ttotal: 2m 19s\tremaining: 28.4s\n","831:\tlearn: 0.5537826\ttotal: 2m 19s\tremaining: 28.2s\n","832:\tlearn: 0.5537399\ttotal: 2m 19s\tremaining: 28.1s\n","833:\tlearn: 0.5537129\ttotal: 2m 20s\tremaining: 27.9s\n","834:\tlearn: 0.5536743\ttotal: 2m 20s\tremaining: 27.7s\n","835:\tlearn: 0.5536258\ttotal: 2m 20s\tremaining: 27.5s\n","836:\tlearn: 0.5535758\ttotal: 2m 20s\tremaining: 27.3s\n","837:\tlearn: 0.5535150\ttotal: 2m 20s\tremaining: 27.2s\n","838:\tlearn: 0.5534686\ttotal: 2m 20s\tremaining: 27s\n","839:\tlearn: 0.5534224\ttotal: 2m 20s\tremaining: 26.8s\n","840:\tlearn: 0.5534032\ttotal: 2m 20s\tremaining: 26.6s\n","841:\tlearn: 0.5533631\ttotal: 2m 20s\tremaining: 26.4s\n","842:\tlearn: 0.5533100\ttotal: 2m 21s\tremaining: 26.3s\n","843:\tlearn: 0.5532719\ttotal: 2m 21s\tremaining: 26.1s\n","844:\tlearn: 0.5532214\ttotal: 2m 21s\tremaining: 25.9s\n","845:\tlearn: 0.5531711\ttotal: 2m 21s\tremaining: 25.7s\n","846:\tlearn: 0.5531107\ttotal: 2m 21s\tremaining: 25.6s\n","847:\tlearn: 0.5530726\ttotal: 2m 21s\tremaining: 25.4s\n","848:\tlearn: 0.5530517\ttotal: 2m 21s\tremaining: 25.2s\n","849:\tlearn: 0.5530327\ttotal: 2m 21s\tremaining: 25s\n","850:\tlearn: 0.5529883\ttotal: 2m 21s\tremaining: 24.9s\n","851:\tlearn: 0.5529452\ttotal: 2m 22s\tremaining: 24.7s\n","852:\tlearn: 0.5528993\ttotal: 2m 22s\tremaining: 24.5s\n","853:\tlearn: 0.5528505\ttotal: 2m 22s\tremaining: 24.3s\n","854:\tlearn: 0.5527846\ttotal: 2m 22s\tremaining: 24.1s\n","855:\tlearn: 0.5527244\ttotal: 2m 22s\tremaining: 24s\n","856:\tlearn: 0.5526655\ttotal: 2m 22s\tremaining: 23.8s\n","857:\tlearn: 0.5526152\ttotal: 2m 22s\tremaining: 23.6s\n","858:\tlearn: 0.5525754\ttotal: 2m 22s\tremaining: 23.4s\n","859:\tlearn: 0.5525437\ttotal: 2m 22s\tremaining: 23.3s\n","860:\tlearn: 0.5524957\ttotal: 2m 23s\tremaining: 23.1s\n","861:\tlearn: 0.5524472\ttotal: 2m 23s\tremaining: 22.9s\n","862:\tlearn: 0.5524118\ttotal: 2m 23s\tremaining: 22.7s\n","863:\tlearn: 0.5523682\ttotal: 2m 23s\tremaining: 22.6s\n","864:\tlearn: 0.5523283\ttotal: 2m 23s\tremaining: 22.4s\n","865:\tlearn: 0.5522989\ttotal: 2m 23s\tremaining: 22.2s\n","866:\tlearn: 0.5522600\ttotal: 2m 23s\tremaining: 22s\n","867:\tlearn: 0.5522073\ttotal: 2m 23s\tremaining: 21.9s\n","868:\tlearn: 0.5521757\ttotal: 2m 23s\tremaining: 21.7s\n","869:\tlearn: 0.5521165\ttotal: 2m 24s\tremaining: 21.5s\n","870:\tlearn: 0.5520560\ttotal: 2m 24s\tremaining: 21.4s\n","871:\tlearn: 0.5520195\ttotal: 2m 24s\tremaining: 21.2s\n","872:\tlearn: 0.5519759\ttotal: 2m 24s\tremaining: 21s\n","873:\tlearn: 0.5519324\ttotal: 2m 24s\tremaining: 20.8s\n","874:\tlearn: 0.5518984\ttotal: 2m 24s\tremaining: 20.7s\n","875:\tlearn: 0.5518530\ttotal: 2m 24s\tremaining: 20.5s\n","876:\tlearn: 0.5518018\ttotal: 2m 24s\tremaining: 20.3s\n","877:\tlearn: 0.5517718\ttotal: 2m 24s\tremaining: 20.1s\n","878:\tlearn: 0.5517120\ttotal: 2m 25s\tremaining: 20s\n","879:\tlearn: 0.5516506\ttotal: 2m 25s\tremaining: 19.8s\n","880:\tlearn: 0.5516267\ttotal: 2m 25s\tremaining: 19.6s\n","881:\tlearn: 0.5515791\ttotal: 2m 25s\tremaining: 19.4s\n","882:\tlearn: 0.5515442\ttotal: 2m 25s\tremaining: 19.3s\n","883:\tlearn: 0.5515035\ttotal: 2m 25s\tremaining: 19.1s\n","884:\tlearn: 0.5514422\ttotal: 2m 25s\tremaining: 18.9s\n","885:\tlearn: 0.5513949\ttotal: 2m 25s\tremaining: 18.8s\n","886:\tlearn: 0.5513506\ttotal: 2m 25s\tremaining: 18.6s\n","887:\tlearn: 0.5513277\ttotal: 2m 26s\tremaining: 18.4s\n","888:\tlearn: 0.5512786\ttotal: 2m 26s\tremaining: 18.3s\n","889:\tlearn: 0.5512199\ttotal: 2m 26s\tremaining: 18.1s\n","890:\tlearn: 0.5512071\ttotal: 2m 26s\tremaining: 17.9s\n","891:\tlearn: 0.5511477\ttotal: 2m 26s\tremaining: 17.7s\n","892:\tlearn: 0.5511248\ttotal: 2m 26s\tremaining: 17.6s\n","893:\tlearn: 0.5510848\ttotal: 2m 26s\tremaining: 17.4s\n","894:\tlearn: 0.5510281\ttotal: 2m 26s\tremaining: 17.2s\n","895:\tlearn: 0.5509849\ttotal: 2m 26s\tremaining: 17.1s\n","896:\tlearn: 0.5509659\ttotal: 2m 27s\tremaining: 16.9s\n","897:\tlearn: 0.5509190\ttotal: 2m 27s\tremaining: 16.7s\n","898:\tlearn: 0.5508879\ttotal: 2m 27s\tremaining: 16.5s\n","899:\tlearn: 0.5508467\ttotal: 2m 27s\tremaining: 16.4s\n","900:\tlearn: 0.5507884\ttotal: 2m 27s\tremaining: 16.2s\n","901:\tlearn: 0.5507662\ttotal: 2m 27s\tremaining: 16s\n","902:\tlearn: 0.5507223\ttotal: 2m 27s\tremaining: 15.9s\n","903:\tlearn: 0.5507060\ttotal: 2m 27s\tremaining: 15.7s\n","904:\tlearn: 0.5506495\ttotal: 2m 27s\tremaining: 15.5s\n","905:\tlearn: 0.5506042\ttotal: 2m 28s\tremaining: 15.4s\n","906:\tlearn: 0.5505517\ttotal: 2m 28s\tremaining: 15.2s\n","907:\tlearn: 0.5505134\ttotal: 2m 28s\tremaining: 15s\n","908:\tlearn: 0.5504724\ttotal: 2m 28s\tremaining: 14.9s\n","909:\tlearn: 0.5504248\ttotal: 2m 28s\tremaining: 14.7s\n","910:\tlearn: 0.5503755\ttotal: 2m 28s\tremaining: 14.5s\n","911:\tlearn: 0.5503423\ttotal: 2m 28s\tremaining: 14.4s\n","912:\tlearn: 0.5502905\ttotal: 2m 28s\tremaining: 14.2s\n","913:\tlearn: 0.5502349\ttotal: 2m 28s\tremaining: 14s\n","914:\tlearn: 0.5502008\ttotal: 2m 29s\tremaining: 13.8s\n","915:\tlearn: 0.5501856\ttotal: 2m 29s\tremaining: 13.7s\n","916:\tlearn: 0.5501618\ttotal: 2m 29s\tremaining: 13.5s\n","917:\tlearn: 0.5501185\ttotal: 2m 29s\tremaining: 13.3s\n","918:\tlearn: 0.5500757\ttotal: 2m 29s\tremaining: 13.2s\n","919:\tlearn: 0.5500426\ttotal: 2m 29s\tremaining: 13s\n","920:\tlearn: 0.5499833\ttotal: 2m 29s\tremaining: 12.8s\n","921:\tlearn: 0.5499400\ttotal: 2m 29s\tremaining: 12.7s\n","922:\tlearn: 0.5499026\ttotal: 2m 30s\tremaining: 12.5s\n","923:\tlearn: 0.5498689\ttotal: 2m 30s\tremaining: 12.4s\n","924:\tlearn: 0.5498440\ttotal: 2m 30s\tremaining: 12.2s\n","925:\tlearn: 0.5498138\ttotal: 2m 30s\tremaining: 12s\n","926:\tlearn: 0.5497657\ttotal: 2m 30s\tremaining: 11.9s\n","927:\tlearn: 0.5497249\ttotal: 2m 31s\tremaining: 11.7s\n","928:\tlearn: 0.5496794\ttotal: 2m 31s\tremaining: 11.6s\n","929:\tlearn: 0.5496301\ttotal: 2m 31s\tremaining: 11.4s\n","930:\tlearn: 0.5495800\ttotal: 2m 31s\tremaining: 11.2s\n","931:\tlearn: 0.5495213\ttotal: 2m 32s\tremaining: 11.1s\n","932:\tlearn: 0.5494830\ttotal: 2m 32s\tremaining: 10.9s\n","933:\tlearn: 0.5494219\ttotal: 2m 32s\tremaining: 10.8s\n","934:\tlearn: 0.5493905\ttotal: 2m 32s\tremaining: 10.6s\n","935:\tlearn: 0.5493618\ttotal: 2m 32s\tremaining: 10.5s\n","936:\tlearn: 0.5493245\ttotal: 2m 33s\tremaining: 10.3s\n","937:\tlearn: 0.5492841\ttotal: 2m 33s\tremaining: 10.1s\n","938:\tlearn: 0.5492285\ttotal: 2m 33s\tremaining: 9.96s\n","939:\tlearn: 0.5491907\ttotal: 2m 33s\tremaining: 9.8s\n","940:\tlearn: 0.5491331\ttotal: 2m 33s\tremaining: 9.64s\n","941:\tlearn: 0.5491068\ttotal: 2m 33s\tremaining: 9.47s\n","942:\tlearn: 0.5490411\ttotal: 2m 33s\tremaining: 9.3s\n","943:\tlearn: 0.5490271\ttotal: 2m 34s\tremaining: 9.14s\n","944:\tlearn: 0.5490014\ttotal: 2m 34s\tremaining: 8.97s\n","945:\tlearn: 0.5489697\ttotal: 2m 34s\tremaining: 8.81s\n","946:\tlearn: 0.5489184\ttotal: 2m 34s\tremaining: 8.64s\n","947:\tlearn: 0.5488886\ttotal: 2m 34s\tremaining: 8.47s\n","948:\tlearn: 0.5488479\ttotal: 2m 34s\tremaining: 8.31s\n","949:\tlearn: 0.5488130\ttotal: 2m 34s\tremaining: 8.14s\n","950:\tlearn: 0.5488036\ttotal: 2m 34s\tremaining: 7.98s\n","951:\tlearn: 0.5487557\ttotal: 2m 34s\tremaining: 7.81s\n","952:\tlearn: 0.5486969\ttotal: 2m 35s\tremaining: 7.64s\n","953:\tlearn: 0.5486578\ttotal: 2m 35s\tremaining: 7.48s\n","954:\tlearn: 0.5486167\ttotal: 2m 35s\tremaining: 7.31s\n","955:\tlearn: 0.5485417\ttotal: 2m 35s\tremaining: 7.15s\n","956:\tlearn: 0.5484781\ttotal: 2m 35s\tremaining: 6.99s\n","957:\tlearn: 0.5484452\ttotal: 2m 35s\tremaining: 6.82s\n","958:\tlearn: 0.5483975\ttotal: 2m 35s\tremaining: 6.66s\n","959:\tlearn: 0.5483565\ttotal: 2m 35s\tremaining: 6.49s\n","960:\tlearn: 0.5483108\ttotal: 2m 35s\tremaining: 6.33s\n","961:\tlearn: 0.5482850\ttotal: 2m 35s\tremaining: 6.16s\n","962:\tlearn: 0.5482508\ttotal: 2m 36s\tremaining: 6s\n","963:\tlearn: 0.5482028\ttotal: 2m 36s\tremaining: 5.83s\n","964:\tlearn: 0.5481437\ttotal: 2m 36s\tremaining: 5.67s\n","965:\tlearn: 0.5481089\ttotal: 2m 36s\tremaining: 5.51s\n","966:\tlearn: 0.5480601\ttotal: 2m 36s\tremaining: 5.34s\n","967:\tlearn: 0.5479988\ttotal: 2m 36s\tremaining: 5.18s\n","968:\tlearn: 0.5479601\ttotal: 2m 36s\tremaining: 5.02s\n","969:\tlearn: 0.5479333\ttotal: 2m 36s\tremaining: 4.85s\n","970:\tlearn: 0.5479110\ttotal: 2m 37s\tremaining: 4.69s\n","971:\tlearn: 0.5478782\ttotal: 2m 37s\tremaining: 4.53s\n","972:\tlearn: 0.5478312\ttotal: 2m 37s\tremaining: 4.36s\n","973:\tlearn: 0.5477711\ttotal: 2m 37s\tremaining: 4.2s\n","974:\tlearn: 0.5477172\ttotal: 2m 37s\tremaining: 4.04s\n","975:\tlearn: 0.5476968\ttotal: 2m 37s\tremaining: 3.88s\n","976:\tlearn: 0.5476529\ttotal: 2m 37s\tremaining: 3.71s\n","977:\tlearn: 0.5475907\ttotal: 2m 37s\tremaining: 3.55s\n","978:\tlearn: 0.5475315\ttotal: 2m 37s\tremaining: 3.39s\n","979:\tlearn: 0.5474785\ttotal: 2m 38s\tremaining: 3.23s\n","980:\tlearn: 0.5474419\ttotal: 2m 38s\tremaining: 3.06s\n","981:\tlearn: 0.5474128\ttotal: 2m 38s\tremaining: 2.9s\n","982:\tlearn: 0.5473551\ttotal: 2m 38s\tremaining: 2.74s\n","983:\tlearn: 0.5473253\ttotal: 2m 38s\tremaining: 2.58s\n","984:\tlearn: 0.5472909\ttotal: 2m 38s\tremaining: 2.42s\n","985:\tlearn: 0.5472550\ttotal: 2m 38s\tremaining: 2.25s\n","986:\tlearn: 0.5472202\ttotal: 2m 38s\tremaining: 2.09s\n","987:\tlearn: 0.5471885\ttotal: 2m 38s\tremaining: 1.93s\n","988:\tlearn: 0.5471476\ttotal: 2m 39s\tremaining: 1.77s\n","989:\tlearn: 0.5471068\ttotal: 2m 39s\tremaining: 1.61s\n","990:\tlearn: 0.5470512\ttotal: 2m 39s\tremaining: 1.45s\n","991:\tlearn: 0.5470227\ttotal: 2m 39s\tremaining: 1.29s\n","992:\tlearn: 0.5470201\ttotal: 2m 39s\tremaining: 1.13s\n","993:\tlearn: 0.5469763\ttotal: 2m 40s\tremaining: 967ms\n","994:\tlearn: 0.5469216\ttotal: 2m 40s\tremaining: 806ms\n","995:\tlearn: 0.5468560\ttotal: 2m 40s\tremaining: 645ms\n","996:\tlearn: 0.5468159\ttotal: 2m 40s\tremaining: 484ms\n","997:\tlearn: 0.5467721\ttotal: 2m 41s\tremaining: 323ms\n","998:\tlearn: 0.5467373\ttotal: 2m 41s\tremaining: 161ms\n","999:\tlearn: 0.5467041\ttotal: 2m 41s\tremaining: 0us\n","train: 0.7249637249299071\n","test: 0.6842446835052214\n","test conf matrix: \n"," [[21270 10603]\n"," [ 9561 22432]]\n"]}]},{"cell_type":"code","source":["def objective_lgbm(trial):\n","    max_depth = trial.suggest_int(\"max_depth\", 2, 15)\n","    learning_rate = trial.suggest_float(\"learning_rate\", 1e-5, 1, log=True)\n","    n_estimators = trial.suggest_int(\"n_estimators\", 10, 700)\n","\n","    score = cross_val_score(LGBMClassifier(max_depth=max_depth, learning_rate=learning_rate, n_estimators=n_estimators),\n","                            x_train, y_train, cv=3, scoring='roc_auc', n_jobs=-1).mean()\n","    return score\n","\n","\n","study_lgbm = optuna.create_study(direction=\"maximize\")\n","study_lgbm.optimize(objective_lgbm, n_trials=50)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mt0lOnwTbXB7","outputId":"b1438184-3790-4e9c-e296-ebe7e8d1766b","executionInfo":{"status":"ok","timestamp":1707750349413,"user_tz":-240,"elapsed":3159821,"user":{"displayName":"Евгений Малов","userId":"06257165098392198337"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[I 2024-02-12 14:02:31,259] A new study created in memory with name: no-name-8cc9f1b5-9eed-4def-be83-3abc910f5ea2\n","[I 2024-02-12 14:03:48,771] Trial 0 finished with value: 0.72371293043831 and parameters: {'max_depth': 8, 'learning_rate': 0.006942595306994207, 'n_estimators': 369}. Best is trial 0 with value: 0.72371293043831.\n","[I 2024-02-12 14:04:47,850] Trial 1 finished with value: 0.662459687184806 and parameters: {'max_depth': 3, 'learning_rate': 0.0006067840574096312, 'n_estimators': 530}. Best is trial 0 with value: 0.72371293043831.\n","[I 2024-02-12 14:05:37,198] Trial 2 finished with value: 0.6720922898279933 and parameters: {'max_depth': 14, 'learning_rate': 8.15729914954362e-05, 'n_estimators': 239}. Best is trial 0 with value: 0.72371293043831.\n","[I 2024-02-12 14:07:04,821] Trial 3 finished with value: 0.7439507775617039 and parameters: {'max_depth': 14, 'learning_rate': 0.037517451085913964, 'n_estimators': 582}. Best is trial 3 with value: 0.7439507775617039.\n","[I 2024-02-12 14:08:57,838] Trial 4 finished with value: 0.6894297687436411 and parameters: {'max_depth': 6, 'learning_rate': 0.0006089951043739173, 'n_estimators': 647}. Best is trial 3 with value: 0.7439507775617039.\n","[I 2024-02-12 14:09:31,051] Trial 5 finished with value: 0.6915603692067608 and parameters: {'max_depth': 7, 'learning_rate': 0.0023289124098188445, 'n_estimators': 149}. Best is trial 3 with value: 0.7439507775617039.\n","[I 2024-02-12 14:10:26,629] Trial 6 finished with value: 0.7425741281130674 and parameters: {'max_depth': 7, 'learning_rate': 0.04156353233874135, 'n_estimators': 338}. Best is trial 3 with value: 0.7439507775617039.\n","[I 2024-02-12 14:10:37,925] Trial 7 finished with value: 0.6598036770290991 and parameters: {'max_depth': 4, 'learning_rate': 0.006480234124775213, 'n_estimators': 27}. Best is trial 3 with value: 0.7439507775617039.\n","[I 2024-02-12 14:12:02,154] Trial 8 finished with value: 0.6950305433357533 and parameters: {'max_depth': 9, 'learning_rate': 0.0008841959328646633, 'n_estimators': 410}. Best is trial 3 with value: 0.7439507775617039.\n","[I 2024-02-12 14:12:41,243] Trial 9 finished with value: 0.7316658787750172 and parameters: {'max_depth': 12, 'learning_rate': 0.25158066403807067, 'n_estimators': 311}. Best is trial 3 with value: 0.7439507775617039.\n","[I 2024-02-12 14:13:51,978] Trial 10 finished with value: 0.725045657216358 and parameters: {'max_depth': 15, 'learning_rate': 0.2749197141682591, 'n_estimators': 697}. Best is trial 3 with value: 0.7439507775617039.\n","[I 2024-02-12 14:14:56,065] Trial 11 finished with value: 0.7432414727049877 and parameters: {'max_depth': 11, 'learning_rate': 0.08835017795910523, 'n_estimators': 500}. Best is trial 3 with value: 0.7439507775617039.\n","[I 2024-02-12 14:16:07,474] Trial 12 finished with value: 0.7438680465913236 and parameters: {'max_depth': 12, 'learning_rate': 0.054994433523305346, 'n_estimators': 529}. Best is trial 3 with value: 0.7439507775617039.\n","[I 2024-02-12 14:17:38,423] Trial 13 finished with value: 0.7431857817829929 and parameters: {'max_depth': 13, 'learning_rate': 0.023024932772006155, 'n_estimators': 560}. Best is trial 3 with value: 0.7439507775617039.\n","[I 2024-02-12 14:18:40,325] Trial 14 finished with value: 0.6846327309615822 and parameters: {'max_depth': 10, 'learning_rate': 0.7311158136019441, 'n_estimators': 595}. Best is trial 3 with value: 0.7439507775617039.\n","[I 2024-02-12 14:20:06,014] Trial 15 finished with value: 0.6715820970930982 and parameters: {'max_depth': 15, 'learning_rate': 1.1998817776304438e-05, 'n_estimators': 456}. Best is trial 3 with value: 0.7439507775617039.\n","[I 2024-02-12 14:21:46,148] Trial 16 finished with value: 0.7429297380426827 and parameters: {'max_depth': 12, 'learning_rate': 0.019640233825926917, 'n_estimators': 604}. Best is trial 3 with value: 0.7439507775617039.\n","[I 2024-02-12 14:22:42,761] Trial 17 finished with value: 0.7422356515196314 and parameters: {'max_depth': 13, 'learning_rate': 0.11180563465538337, 'n_estimators': 469}. Best is trial 3 with value: 0.7439507775617039.\n","[I 2024-02-12 14:23:51,738] Trial 18 finished with value: 0.674386122235 and parameters: {'max_depth': 10, 'learning_rate': 0.8918744898934005, 'n_estimators': 688}. Best is trial 3 with value: 0.7439507775617039.\n","[I 2024-02-12 14:25:15,323] Trial 19 finished with value: 0.7295503804874102 and parameters: {'max_depth': 13, 'learning_rate': 0.00787757532725278, 'n_estimators': 430}. Best is trial 3 with value: 0.7439507775617039.\n","[I 2024-02-12 14:25:56,754] Trial 20 finished with value: 0.7432276204573945 and parameters: {'max_depth': 11, 'learning_rate': 0.06861706376213848, 'n_estimators': 255}. Best is trial 3 with value: 0.7439507775617039.\n","[I 2024-02-12 14:26:57,598] Trial 21 finished with value: 0.740940872198947 and parameters: {'max_depth': 11, 'learning_rate': 0.11702640959497371, 'n_estimators': 516}. Best is trial 3 with value: 0.7439507775617039.\n","[I 2024-02-12 14:28:24,409] Trial 22 finished with value: 0.7420180112109366 and parameters: {'max_depth': 14, 'learning_rate': 0.01925632546275889, 'n_estimators': 497}. Best is trial 3 with value: 0.7439507775617039.\n","[I 2024-02-12 14:29:25,456] Trial 23 finished with value: 0.7269464060647387 and parameters: {'max_depth': 11, 'learning_rate': 0.2693721135864329, 'n_estimators': 608}. Best is trial 3 with value: 0.7439507775617039.\n","[I 2024-02-12 14:30:42,066] Trial 24 finished with value: 0.7439778536320842 and parameters: {'max_depth': 12, 'learning_rate': 0.04506002579823733, 'n_estimators': 565}. Best is trial 24 with value: 0.7439778536320842.\n","[I 2024-02-12 14:32:28,512] Trial 25 finished with value: 0.712057304613699 and parameters: {'max_depth': 14, 'learning_rate': 0.0022140590036147773, 'n_estimators': 564}. Best is trial 24 with value: 0.7439778536320842.\n","[I 2024-02-12 14:33:51,825] Trial 26 finished with value: 0.7440931155740907 and parameters: {'max_depth': 15, 'learning_rate': 0.04283658182875676, 'n_estimators': 625}. Best is trial 26 with value: 0.7440931155740907.\n","[I 2024-02-12 14:35:51,035] Trial 27 finished with value: 0.741137172621216 and parameters: {'max_depth': 15, 'learning_rate': 0.01285773916151769, 'n_estimators': 648}. Best is trial 26 with value: 0.7440931155740907.\n","[I 2024-02-12 14:37:20,917] Trial 28 finished with value: 0.7443533945348947 and parameters: {'max_depth': 14, 'learning_rate': 0.03529182073533376, 'n_estimators': 649}. Best is trial 28 with value: 0.7443533945348947.\n","[I 2024-02-12 14:39:20,874] Trial 29 finished with value: 0.7266599610480758 and parameters: {'max_depth': 15, 'learning_rate': 0.0045442973425326195, 'n_estimators': 632}. Best is trial 28 with value: 0.7443533945348947.\n","[I 2024-02-12 14:40:30,757] Trial 30 finished with value: 0.7336431157216055 and parameters: {'max_depth': 13, 'learning_rate': 0.18091013848130078, 'n_estimators': 672}. Best is trial 28 with value: 0.7443533945348947.\n","[I 2024-02-12 14:41:54,108] Trial 31 finished with value: 0.7439880020340818 and parameters: {'max_depth': 14, 'learning_rate': 0.03466073126725096, 'n_estimators': 576}. Best is trial 28 with value: 0.7443533945348947.\n","[I 2024-02-12 14:43:37,635] Trial 32 finished with value: 0.7382446917053233 and parameters: {'max_depth': 14, 'learning_rate': 0.010938664610732205, 'n_estimators': 557}. Best is trial 28 with value: 0.7443533945348947.\n","[I 2024-02-12 14:44:11,324] Trial 33 finished with value: 0.7218040706164158 and parameters: {'max_depth': 2, 'learning_rate': 0.03522349527637841, 'n_estimators': 396}. Best is trial 28 with value: 0.7443533945348947.\n","[I 2024-02-12 14:46:15,109] Trial 34 finished with value: 0.7191956245747102 and parameters: {'max_depth': 15, 'learning_rate': 0.003005004821093169, 'n_estimators': 639}. Best is trial 28 with value: 0.7443533945348947.\n","[I 2024-02-12 14:48:25,039] Trial 35 finished with value: 0.6819414541734173 and parameters: {'max_depth': 13, 'learning_rate': 0.00017305100315665237, 'n_estimators': 699}. Best is trial 28 with value: 0.7443533945348947.\n","[I 2024-02-12 14:49:25,366] Trial 36 finished with value: 0.6990153827686053 and parameters: {'max_depth': 14, 'learning_rate': 0.5210180376601483, 'n_estimators': 619}. Best is trial 28 with value: 0.7443533945348947.\n","[I 2024-02-12 14:50:54,128] Trial 37 finished with value: 0.7431251337733565 and parameters: {'max_depth': 12, 'learning_rate': 0.025399889083746605, 'n_estimators': 543}. Best is trial 28 with value: 0.7443533945348947.\n","[I 2024-02-12 14:52:58,927] Trial 38 finished with value: 0.7049026750256996 and parameters: {'max_depth': 9, 'learning_rate': 0.0011928588100900068, 'n_estimators': 660}. Best is trial 28 with value: 0.7443533945348947.\n","[I 2024-02-12 14:53:22,406] Trial 39 finished with value: 0.7298322483142797 and parameters: {'max_depth': 4, 'learning_rate': 0.05269881518093069, 'n_estimators': 141}. Best is trial 28 with value: 0.7443533945348947.\n","[I 2024-02-12 14:54:28,167] Trial 40 finished with value: 0.7377294151573125 and parameters: {'max_depth': 14, 'learning_rate': 0.16422891724246394, 'n_estimators': 587}. Best is trial 28 with value: 0.7443533945348947.\n","[I 2024-02-12 14:56:16,077] Trial 41 finished with value: 0.739871717214323 and parameters: {'max_depth': 14, 'learning_rate': 0.012230895143116208, 'n_estimators': 583}. Best is trial 28 with value: 0.7443533945348947.\n","[I 2024-02-12 14:57:22,494] Trial 42 finished with value: 0.7437235225740625 and parameters: {'max_depth': 15, 'learning_rate': 0.047653367379940546, 'n_estimators': 462}. Best is trial 28 with value: 0.7443533945348947.\n","[I 2024-02-12 14:58:57,039] Trial 43 finished with value: 0.7439224275605518 and parameters: {'max_depth': 13, 'learning_rate': 0.03058632608435941, 'n_estimators': 655}. Best is trial 28 with value: 0.7443533945348947.\n","[I 2024-02-12 15:00:25,292] Trial 44 finished with value: 0.7214756131762394 and parameters: {'max_depth': 6, 'learning_rate': 0.005119105512631009, 'n_estimators': 499}. Best is trial 28 with value: 0.7443533945348947.\n","[I 2024-02-12 15:01:31,683] Trial 45 finished with value: 0.7425647857212573 and parameters: {'max_depth': 12, 'learning_rate': 0.09055826503650122, 'n_estimators': 565}. Best is trial 28 with value: 0.7443533945348947.\n","[I 2024-02-12 15:02:12,146] Trial 46 finished with value: 0.7212426462151332 and parameters: {'max_depth': 14, 'learning_rate': 0.35624988603639257, 'n_estimators': 357}. Best is trial 28 with value: 0.7443533945348947.\n","[I 2024-02-12 15:03:28,339] Trial 47 finished with value: 0.7441479932797398 and parameters: {'max_depth': 15, 'learning_rate': 0.03869860285645532, 'n_estimators': 522}. Best is trial 28 with value: 0.7443533945348947.\n","[I 2024-02-12 15:05:06,708] Trial 48 finished with value: 0.7405854654814874 and parameters: {'max_depth': 15, 'learning_rate': 0.014608214126256458, 'n_estimators': 528}. Best is trial 28 with value: 0.7443533945348947.\n","[I 2024-02-12 15:05:48,440] Trial 49 finished with value: 0.7403685099621082 and parameters: {'max_depth': 15, 'learning_rate': 0.1395184319907225, 'n_estimators': 314}. Best is trial 28 with value: 0.7443533945348947.\n"]}]},{"cell_type":"code","source":["study_lgbm.best_params"],"metadata":{"id":"mdUFUifgbXFI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1707750878154,"user_tz":-240,"elapsed":461,"user":{"displayName":"Евгений Малов","userId":"06257165098392198337"}},"outputId":"6068ef63-5406-4fae-e24b-5bec8ece8fd7"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'max_depth': 14, 'learning_rate': 0.03529182073533376, 'n_estimators': 649}"]},"metadata":{},"execution_count":10}]},{"cell_type":"markdown","source":["Trial 20 finished with value: 0.7443991240424653 and parameters: {'max_depth': 14, 'learning_rate': 0.05718851664268871, 'n_estimators': 641}. Best is trial 20 with value: 0.7443991240424653."],"metadata":{"id":"Y-43qSoKnmIY"}},{"cell_type":"code","source":["opt_model_lgbm = LGBMClassifier(max_depth=14, learning_rate=0.05718851664268871, n_estimators=641)\n","opt_model_lgbm.fit(x_train, y_train)\n","\n","pred_train = opt_model_lgbm.predict(x_train)\n","pred_test = opt_model_lgbm.predict(x_test)\n","\n","print(f'train: {roc_auc_score(y_train, pred_train)}')\n","print(f'test: {roc_auc_score(y_test, pred_test)}')\n","print(f'test conf matrix: \\n {confusion_matrix(y_test, pred_test)}')"],"metadata":{"id":"mMXxLyYqbXIq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1707766745060,"user_tz":-240,"elapsed":75087,"user":{"displayName":"Евгений Малов","userId":"06257165098392198337"}},"outputId":"6dbdeed2-951a-4817-d9bd-46b7a645d6ab"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 74449, number of negative: 74569\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.427142 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 3855\n","[LightGBM] [Info] Number of data points in the train set: 149018, number of used features: 216\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499597 -> initscore=-0.001611\n","[LightGBM] [Info] Start training from score -0.001611\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","train: 0.7331414760966458\n","test: 0.6823719568577503\n","test conf matrix: \n"," [[21050 10823]\n"," [ 9460 22533]]\n"]}]},{"cell_type":"code","source":["def objective_xgb(trial):\n","    max_depth = trial.suggest_int(\"max_depth\", 2, 15)\n","    learning_rate = trial.suggest_float(\"learning_rate\", 1e-5, 1, log=True)\n","    n_estimators = trial.suggest_int(\"n_estimators\", 10, 700)\n","\n","    score = cross_val_score(XGBClassifier(max_depth=max_depth, n_estimators=n_estimators,\n","                                              learning_rate=learning_rate),\n","                            x_train, y_train, cv=3, scoring='roc_auc', n_jobs=-1).mean()\n","    return score\n","\n","\n","study_xgb = optuna.create_study(direction=\"maximize\")\n","study_xgb.optimize(objective_xgb, n_trials=50)"],"metadata":{"id":"6Fnaqd5Bcfjv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1707757844804,"user_tz":-240,"elapsed":6889375,"user":{"displayName":"Евгений Малов","userId":"06257165098392198337"}},"outputId":"f87a4fe0-911a-40e3-a2a1-caabaa26d8ae"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[I 2024-02-12 15:15:54,834] A new study created in memory with name: no-name-cc926de3-f4cb-4cbb-8e89-d4f6e69fe135\n","[I 2024-02-12 15:16:54,414] Trial 0 finished with value: 0.6807203949126032 and parameters: {'max_depth': 11, 'learning_rate': 0.000564231526013333, 'n_estimators': 98}. Best is trial 0 with value: 0.6807203949126032.\n","[I 2024-02-12 15:18:20,260] Trial 1 finished with value: 0.6642473675018291 and parameters: {'max_depth': 13, 'learning_rate': 1.1706615871894162e-05, 'n_estimators': 101}. Best is trial 0 with value: 0.6807203949126032.\n","[I 2024-02-12 15:19:06,493] Trial 2 finished with value: 0.6311038903593736 and parameters: {'max_depth': 3, 'learning_rate': 1.378452314561988e-05, 'n_estimators': 293}. Best is trial 0 with value: 0.6807203949126032.\n","[I 2024-02-12 15:20:21,451] Trial 3 finished with value: 0.7440286541992114 and parameters: {'max_depth': 6, 'learning_rate': 0.06288398991497926, 'n_estimators': 427}. Best is trial 3 with value: 0.7440286541992114.\n","[I 2024-02-12 15:21:08,241] Trial 4 finished with value: 0.642210737506303 and parameters: {'max_depth': 4, 'learning_rate': 1.598782811084458e-05, 'n_estimators': 256}. Best is trial 3 with value: 0.7440286541992114.\n","[I 2024-02-12 15:27:43,453] Trial 5 finished with value: 0.698456538359085 and parameters: {'max_depth': 12, 'learning_rate': 0.0003247770965804307, 'n_estimators': 605}. Best is trial 3 with value: 0.7440286541992114.\n","[I 2024-02-12 15:29:03,507] Trial 6 finished with value: 0.642368491423165 and parameters: {'max_depth': 4, 'learning_rate': 3.527270304114836e-05, 'n_estimators': 478}. Best is trial 3 with value: 0.7440286541992114.\n","[I 2024-02-12 15:36:45,795] Trial 7 finished with value: 0.7405763441825535 and parameters: {'max_depth': 14, 'learning_rate': 0.008777357090116265, 'n_estimators': 531}. Best is trial 3 with value: 0.7440286541992114.\n","[I 2024-02-12 15:37:08,002] Trial 8 finished with value: 0.7281219260435706 and parameters: {'max_depth': 5, 'learning_rate': 0.06386058093200292, 'n_estimators': 72}. Best is trial 3 with value: 0.7440286541992114.\n","[I 2024-02-12 15:39:03,302] Trial 9 finished with value: 0.7094545651165588 and parameters: {'max_depth': 14, 'learning_rate': 0.004091952172542878, 'n_estimators': 112}. Best is trial 3 with value: 0.7440286541992114.\n","[I 2024-02-12 15:40:37,632] Trial 10 finished with value: 0.6881445482096297 and parameters: {'max_depth': 8, 'learning_rate': 0.8534209103845115, 'n_estimators': 424}. Best is trial 3 with value: 0.7440286541992114.\n","[I 2024-02-12 15:43:14,139] Trial 11 finished with value: 0.7449997226086378 and parameters: {'max_depth': 8, 'learning_rate': 0.023321997996299994, 'n_estimators': 686}. Best is trial 11 with value: 0.7449997226086378.\n","[I 2024-02-12 15:45:29,008] Trial 12 finished with value: 0.7417850514274761 and parameters: {'max_depth': 8, 'learning_rate': 0.07238186358492024, 'n_estimators': 675}. Best is trial 11 with value: 0.7449997226086378.\n","[I 2024-02-12 15:47:20,898] Trial 13 finished with value: 0.7446106562112899 and parameters: {'max_depth': 6, 'learning_rate': 0.044160501194020554, 'n_estimators': 686}. Best is trial 11 with value: 0.7449997226086378.\n","[I 2024-02-12 15:50:15,725] Trial 14 finished with value: 0.7156637706432241 and parameters: {'max_depth': 10, 'learning_rate': 0.41402214179796376, 'n_estimators': 696}. Best is trial 11 with value: 0.7449997226086378.\n","[I 2024-02-12 15:52:22,423] Trial 15 finished with value: 0.743168022551798 and parameters: {'max_depth': 7, 'learning_rate': 0.019741070171558666, 'n_estimators': 581}. Best is trial 11 with value: 0.7449997226086378.\n","[I 2024-02-12 15:56:46,066] Trial 16 finished with value: 0.7143163223974813 and parameters: {'max_depth': 10, 'learning_rate': 0.0009566902621870918, 'n_estimators': 614}. Best is trial 11 with value: 0.7449997226086378.\n","[I 2024-02-12 15:58:07,219] Trial 17 finished with value: 0.7338513147861648 and parameters: {'max_depth': 6, 'learning_rate': 0.20272878374722425, 'n_estimators': 534}. Best is trial 11 with value: 0.7449997226086378.\n","[I 2024-02-12 15:59:21,004] Trial 18 finished with value: 0.7232494622975264 and parameters: {'max_depth': 2, 'learning_rate': 0.022212659530475902, 'n_estimators': 695}. Best is trial 11 with value: 0.7449997226086378.\n","[I 2024-02-12 16:00:53,533] Trial 19 finished with value: 0.717201281296291 and parameters: {'max_depth': 9, 'learning_rate': 0.00344428645670073, 'n_estimators': 246}. Best is trial 11 with value: 0.7449997226086378.\n","[I 2024-02-12 16:02:22,125] Trial 20 finished with value: 0.6701563118877453 and parameters: {'max_depth': 7, 'learning_rate': 0.0001339308623876154, 'n_estimators': 363}. Best is trial 11 with value: 0.7449997226086378.\n","[I 2024-02-12 16:03:23,928] Trial 21 finished with value: 0.7434847365814226 and parameters: {'max_depth': 5, 'learning_rate': 0.08699030406595018, 'n_estimators': 399}. Best is trial 11 with value: 0.7449997226086378.\n","[I 2024-02-12 16:05:02,598] Trial 22 finished with value: 0.7411404717310996 and parameters: {'max_depth': 6, 'learning_rate': 0.02128857101766315, 'n_estimators': 500}. Best is trial 11 with value: 0.7449997226086378.\n","[I 2024-02-12 16:06:48,561] Trial 23 finished with value: 0.7343856307959937 and parameters: {'max_depth': 7, 'learning_rate': 0.15738980347225084, 'n_estimators': 637}. Best is trial 11 with value: 0.7449997226086378.\n","[I 2024-02-12 16:09:26,153] Trial 24 finished with value: 0.7379695079792677 and parameters: {'max_depth': 9, 'learning_rate': 0.008325317611583501, 'n_estimators': 458}. Best is trial 11 with value: 0.7449997226086378.\n","[I 2024-02-12 16:10:29,617] Trial 25 finished with value: 0.7418329278276324 and parameters: {'max_depth': 6, 'learning_rate': 0.03967962543172876, 'n_estimators': 318}. Best is trial 11 with value: 0.7449997226086378.\n","[I 2024-02-12 16:11:07,761] Trial 26 finished with value: 0.6746190977281382 and parameters: {'max_depth': 5, 'learning_rate': 0.0015532366884688327, 'n_estimators': 168}. Best is trial 11 with value: 0.7449997226086378.\n","[I 2024-02-12 16:12:12,784] Trial 27 finished with value: 0.699754300438778 and parameters: {'max_depth': 2, 'learning_rate': 0.008285816028628722, 'n_estimators': 562}. Best is trial 11 with value: 0.7449997226086378.\n","[I 2024-02-12 16:14:13,399] Trial 28 finished with value: 0.7249075927413523 and parameters: {'max_depth': 8, 'learning_rate': 0.22701337007978822, 'n_estimators': 643}. Best is trial 11 with value: 0.7449997226086378.\n","[I 2024-02-12 16:14:44,107] Trial 29 finished with value: 0.7254495602165957 and parameters: {'max_depth': 4, 'learning_rate': 0.65218524198107, 'n_estimators': 200}. Best is trial 11 with value: 0.7449997226086378.\n","[I 2024-02-12 16:18:20,414] Trial 30 finished with value: 0.7424446782061528 and parameters: {'max_depth': 11, 'learning_rate': 0.041293242568901024, 'n_estimators': 648}. Best is trial 11 with value: 0.7449997226086378.\n","[I 2024-02-12 16:19:23,497] Trial 31 finished with value: 0.7428800568377897 and parameters: {'max_depth': 5, 'learning_rate': 0.12573765496242073, 'n_estimators': 437}. Best is trial 11 with value: 0.7449997226086378.\n","[I 2024-02-12 16:20:28,522] Trial 32 finished with value: 0.7439811752060521 and parameters: {'max_depth': 6, 'learning_rate': 0.08076265569525873, 'n_estimators': 370}. Best is trial 11 with value: 0.7449997226086378.\n","[I 2024-02-12 16:21:47,772] Trial 33 finished with value: 0.7437469829577673 and parameters: {'max_depth': 7, 'learning_rate': 0.037062242711485456, 'n_estimators': 360}. Best is trial 11 with value: 0.7449997226086378.\n","[I 2024-02-12 16:22:35,073] Trial 34 finished with value: 0.7202028144344036 and parameters: {'max_depth': 6, 'learning_rate': 0.41034418951301144, 'n_estimators': 280}. Best is trial 11 with value: 0.7449997226086378.\n","[I 2024-02-12 16:23:31,969] Trial 35 finished with value: 0.713168043840505 and parameters: {'max_depth': 3, 'learning_rate': 0.01170169295630067, 'n_estimators': 387}. Best is trial 11 with value: 0.7449997226086378.\n","[I 2024-02-12 16:25:00,346] Trial 36 finished with value: 0.7197575641379039 and parameters: {'max_depth': 10, 'learning_rate': 0.3189374297484627, 'n_estimators': 312}. Best is trial 11 with value: 0.7449997226086378.\n","[I 2024-02-12 16:26:08,314] Trial 37 finished with value: 0.7431489831643233 and parameters: {'max_depth': 4, 'learning_rate': 0.11674278259368476, 'n_estimators': 504}. Best is trial 11 with value: 0.7449997226086378.\n","[I 2024-02-12 16:28:31,035] Trial 38 finished with value: 0.7434641222577726 and parameters: {'max_depth': 9, 'learning_rate': 0.05050428176049711, 'n_estimators': 552}. Best is trial 11 with value: 0.7449997226086378.\n","[I 2024-02-12 16:33:19,597] Trial 39 finished with value: 0.744502390501269 and parameters: {'max_depth': 12, 'learning_rate': 0.017749203697157722, 'n_estimators': 594}. Best is trial 11 with value: 0.7449997226086378.\n","[I 2024-02-12 16:40:53,075] Trial 40 finished with value: 0.7376410710533005 and parameters: {'max_depth': 13, 'learning_rate': 0.005100751392616725, 'n_estimators': 594}. Best is trial 11 with value: 0.7449997226086378.\n","[I 2024-02-12 16:49:58,991] Trial 41 finished with value: 0.7425046720319252 and parameters: {'max_depth': 15, 'learning_rate': 0.01410380177387937, 'n_estimators': 671}. Best is trial 11 with value: 0.7449997226086378.\n","[I 2024-02-12 16:54:23,008] Trial 42 finished with value: 0.7436417518682411 and parameters: {'max_depth': 12, 'learning_rate': 0.031574107223824276, 'n_estimators': 619}. Best is trial 11 with value: 0.7449997226086378.\n","[I 2024-02-12 16:57:43,436] Trial 43 finished with value: 0.7212608290036758 and parameters: {'max_depth': 8, 'learning_rate': 0.002070915709676501, 'n_estimators': 658}. Best is trial 11 with value: 0.7449997226086378.\n","[I 2024-02-12 16:59:11,230] Trial 44 finished with value: 0.7436765889733347 and parameters: {'max_depth': 7, 'learning_rate': 0.07611573883077201, 'n_estimators': 484}. Best is trial 11 with value: 0.7449997226086378.\n","[I 2024-02-12 17:01:32,248] Trial 45 finished with value: 0.7412417031523327 and parameters: {'max_depth': 6, 'learning_rate': 0.015280177675283505, 'n_estimators': 697}. Best is trial 11 with value: 0.7449997226086378.\n","[I 2024-02-12 17:06:37,766] Trial 46 finished with value: 0.7391639317483429 and parameters: {'max_depth': 11, 'learning_rate': 0.0061065662514090775, 'n_estimators': 587}. Best is trial 11 with value: 0.7449997226086378.\n","[I 2024-02-12 17:06:56,521] Trial 47 finished with value: 0.7158367066582964 and parameters: {'max_depth': 8, 'learning_rate': 0.028602800398457372, 'n_estimators': 35}. Best is trial 11 with value: 0.7449997226086378.\n","[I 2024-02-12 17:08:14,184] Trial 48 finished with value: 0.7439377825313839 and parameters: {'max_depth': 5, 'learning_rate': 0.07562729448832657, 'n_estimators': 524}. Best is trial 11 with value: 0.7449997226086378.\n","[I 2024-02-12 17:10:43,604] Trial 49 finished with value: 0.6959218800120489 and parameters: {'max_depth': 9, 'learning_rate': 0.0004224092758651646, 'n_estimators': 432}. Best is trial 11 with value: 0.7449997226086378.\n"]}]},{"cell_type":"code","source":["study_xgb.best_params"],"metadata":{"id":"WRuf8c5TcfnL","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1707757876030,"user_tz":-240,"elapsed":912,"user":{"displayName":"Евгений Малов","userId":"06257165098392198337"}},"outputId":"36f1c13c-7889-44ee-a843-009d753d8fa0"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'max_depth': 8, 'learning_rate': 0.023321997996299994, 'n_estimators': 686}"]},"metadata":{},"execution_count":13}]},{"cell_type":"code","source":["opt_model_xgb = XGBClassifier(max_depth=8, learning_rate=0.023321997996299994, n_estimators=686)\n","opt_model_xgb.fit(x_train, y_train)\n","\n","pred_train = opt_model_xgb.predict(x_train)\n","pred_test = opt_model_xgb.predict(x_test)\n","\n","print(f'train: {roc_auc_score(y_train, pred_train)}')\n","print(f'test: {roc_auc_score(y_test, pred_test)}')\n","print(f'test conf matrix: \\n {confusion_matrix(y_test, pred_test)}')"],"metadata":{"id":"72IKRFsVcfqw","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1707766863672,"user_tz":-240,"elapsed":104610,"user":{"displayName":"Евгений Малов","userId":"06257165098392198337"}},"outputId":"c0cec26b-1be6-4c05-e3ba-f7d70be582fa"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["train: 0.7725057376250682\n","test: 0.6826777816672277\n","test conf matrix: \n"," [[21201 10672]\n"," [ 9592 22401]]\n"]}]},{"cell_type":"code","source":["def objective_catboost(trial):\n","    max_depth = trial.suggest_int(\"max_depth\", 2, 15)\n","    learning_rate = trial.suggest_float(\"learning_rate\", 1e-3, 1, log=True)\n","    n_estimators = trial.suggest_int(\"n_estimators\", 10, 150)\n","    l2_leaf_reg = trial.suggest_int('l2_leaf_reg', 1, 5)\n","\n","    score = cross_val_score(CatBoostClassifier(max_depth=max_depth, n_estimators=n_estimators,\n","                                              learning_rate=learning_rate, l2_leaf_reg=l2_leaf_reg),\n","                            x_train, y_train, cv=3, scoring='roc_auc', n_jobs=-1).mean()\n","    return score\n","\n","\n","study_catboost = optuna.create_study(direction=\"maximize\")\n","study_catboost.optimize(objective_catboost, n_trials=50)"],"metadata":{"id":"3fYJT60wcfvD","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1707766534493,"user_tz":-240,"elapsed":4246746,"user":{"displayName":"Евгений Малов","userId":"06257165098392198337"}},"outputId":"45af02eb-5497-40e6-fc4a-7e4a2a048fdd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[I 2024-02-12 18:24:46,925] A new study created in memory with name: no-name-8c27cd4a-d595-4beb-9040-4e5316ead27e\n","[I 2024-02-12 18:26:18,787] Trial 0 finished with value: 0.7083641927512024 and parameters: {'max_depth': 13, 'learning_rate': 0.01943100958284659, 'n_estimators': 28, 'l2_leaf_reg': 5}. Best is trial 0 with value: 0.7083641927512024.\n","[I 2024-02-12 18:26:40,936] Trial 1 finished with value: 0.7211363362225174 and parameters: {'max_depth': 6, 'learning_rate': 0.07123988723862416, 'n_estimators': 61, 'l2_leaf_reg': 5}. Best is trial 1 with value: 0.7211363362225174.\n","[I 2024-02-12 18:28:27,218] Trial 2 finished with value: 0.7155300242288561 and parameters: {'max_depth': 12, 'learning_rate': 0.023544977806083226, 'n_estimators': 49, 'l2_leaf_reg': 3}. Best is trial 1 with value: 0.7211363362225174.\n","[I 2024-02-12 18:29:13,526] Trial 3 finished with value: 0.7140397783627727 and parameters: {'max_depth': 7, 'learning_rate': 0.7723168615265839, 'n_estimators': 137, 'l2_leaf_reg': 3}. Best is trial 1 with value: 0.7211363362225174.\n","[I 2024-02-12 18:29:37,513] Trial 4 finished with value: 0.7322977047229656 and parameters: {'max_depth': 2, 'learning_rate': 0.45301469147508794, 'n_estimators': 132, 'l2_leaf_reg': 2}. Best is trial 4 with value: 0.7322977047229656.\n","[I 2024-02-12 18:29:54,532] Trial 5 finished with value: 0.6563600766607779 and parameters: {'max_depth': 2, 'learning_rate': 0.005744460523070895, 'n_estimators': 85, 'l2_leaf_reg': 5}. Best is trial 4 with value: 0.7322977047229656.\n","[I 2024-02-12 18:30:12,306] Trial 6 finished with value: 0.6847504479919438 and parameters: {'max_depth': 7, 'learning_rate': 0.0067281149830314205, 'n_estimators': 41, 'l2_leaf_reg': 5}. Best is trial 4 with value: 0.7322977047229656.\n","[I 2024-02-12 18:35:28,454] Trial 7 finished with value: 0.7105891750921848 and parameters: {'max_depth': 13, 'learning_rate': 0.3514055707426798, 'n_estimators': 103, 'l2_leaf_reg': 4}. Best is trial 4 with value: 0.7322977047229656.\n","[I 2024-02-12 18:36:32,674] Trial 8 finished with value: 0.732832695992809 and parameters: {'max_depth': 9, 'learning_rate': 0.046423200792374525, 'n_estimators': 133, 'l2_leaf_reg': 5}. Best is trial 8 with value: 0.732832695992809.\n","[I 2024-02-12 18:46:16,963] Trial 9 finished with value: 0.7208749878373902 and parameters: {'max_depth': 14, 'learning_rate': 0.14615644373173642, 'n_estimators': 127, 'l2_leaf_reg': 1}. Best is trial 8 with value: 0.732832695992809.\n","[I 2024-02-12 18:48:28,042] Trial 10 finished with value: 0.696955332460012 and parameters: {'max_depth': 10, 'learning_rate': 0.0018281787534521064, 'n_estimators': 101, 'l2_leaf_reg': 4}. Best is trial 8 with value: 0.732832695992809.\n","[I 2024-02-12 18:48:54,804] Trial 11 finished with value: 0.7129904951086066 and parameters: {'max_depth': 2, 'learning_rate': 0.07685415500865538, 'n_estimators': 147, 'l2_leaf_reg': 1}. Best is trial 8 with value: 0.732832695992809.\n","[I 2024-02-12 18:49:22,130] Trial 12 finished with value: 0.7290946245543243 and parameters: {'max_depth': 4, 'learning_rate': 0.9383769395291649, 'n_estimators': 114, 'l2_leaf_reg': 2}. Best is trial 8 with value: 0.732832695992809.\n","[I 2024-02-12 18:52:38,270] Trial 13 finished with value: 0.733254467174941 and parameters: {'max_depth': 10, 'learning_rate': 0.19562361361728098, 'n_estimators': 150, 'l2_leaf_reg': 2}. Best is trial 13 with value: 0.733254467174941.\n","[I 2024-02-12 18:54:20,988] Trial 14 finished with value: 0.7349028731986121 and parameters: {'max_depth': 10, 'learning_rate': 0.12312055897757379, 'n_estimators': 78, 'l2_leaf_reg': 2}. Best is trial 14 with value: 0.7349028731986121.\n","[I 2024-02-12 18:55:58,273] Trial 15 finished with value: 0.7341833218109203 and parameters: {'max_depth': 10, 'learning_rate': 0.19893440665871104, 'n_estimators': 73, 'l2_leaf_reg': 2}. Best is trial 14 with value: 0.7349028731986121.\n","[I 2024-02-12 18:57:54,961] Trial 16 finished with value: 0.7326623328909617 and parameters: {'max_depth': 11, 'learning_rate': 0.17245434765538728, 'n_estimators': 72, 'l2_leaf_reg': 2}. Best is trial 14 with value: 0.7349028731986121.\n","[I 2024-02-12 19:08:43,855] Trial 17 finished with value: 0.7172171733863159 and parameters: {'max_depth': 15, 'learning_rate': 0.011940768913439594, 'n_estimators': 82, 'l2_leaf_reg': 1}. Best is trial 14 with value: 0.7349028731986121.\n","[I 2024-02-12 19:08:55,628] Trial 18 finished with value: 0.7091914523682314 and parameters: {'max_depth': 8, 'learning_rate': 0.0868770190793159, 'n_estimators': 18, 'l2_leaf_reg': 3}. Best is trial 14 with value: 0.7349028731986121.\n","[I 2024-02-12 19:10:43,411] Trial 19 finished with value: 0.7248473651811508 and parameters: {'max_depth': 11, 'learning_rate': 0.2981696807611211, 'n_estimators': 65, 'l2_leaf_reg': 2}. Best is trial 14 with value: 0.7349028731986121.\n","[I 2024-02-12 19:11:12,222] Trial 20 finished with value: 0.7169403646936073 and parameters: {'max_depth': 5, 'learning_rate': 0.04293574185450711, 'n_estimators': 96, 'l2_leaf_reg': 3}. Best is trial 14 with value: 0.7349028731986121.\n","[I 2024-02-12 19:11:39,859] Trial 21 finished with value: 0.7330143335810586 and parameters: {'max_depth': 9, 'learning_rate': 0.17458550948956997, 'n_estimators': 53, 'l2_leaf_reg': 2}. Best is trial 14 with value: 0.7349028731986121.\n","[I 2024-02-12 19:13:38,163] Trial 22 finished with value: 0.731290803974528 and parameters: {'max_depth': 10, 'learning_rate': 0.23284560599539306, 'n_estimators': 90, 'l2_leaf_reg': 2}. Best is trial 14 with value: 0.7349028731986121.\n","[I 2024-02-12 19:15:31,299] Trial 23 finished with value: 0.6992047309248064 and parameters: {'max_depth': 11, 'learning_rate': 0.5001537868982658, 'n_estimators': 69, 'l2_leaf_reg': 1}. Best is trial 14 with value: 0.7349028731986121.\n","[I 2024-02-12 19:16:23,050] Trial 24 finished with value: 0.7373517387188215 and parameters: {'max_depth': 8, 'learning_rate': 0.11565829408433723, 'n_estimators': 114, 'l2_leaf_reg': 2}. Best is trial 24 with value: 0.7373517387188215.\n","[I 2024-02-12 19:17:13,465] Trial 25 finished with value: 0.7374209784474802 and parameters: {'max_depth': 8, 'learning_rate': 0.1101152968125992, 'n_estimators': 113, 'l2_leaf_reg': 3}. Best is trial 25 with value: 0.7374209784474802.\n","[I 2024-02-12 19:18:08,890] Trial 26 finished with value: 0.7335982535281845 and parameters: {'max_depth': 8, 'learning_rate': 0.07205533199223611, 'n_estimators': 112, 'l2_leaf_reg': 4}. Best is trial 25 with value: 0.7374209784474802.\n","[I 2024-02-12 19:18:56,245] Trial 27 finished with value: 0.7356198008868554 and parameters: {'max_depth': 7, 'learning_rate': 0.101641711668197, 'n_estimators': 113, 'l2_leaf_reg': 3}. Best is trial 25 with value: 0.7374209784474802.\n","[I 2024-02-12 19:19:29,372] Trial 28 finished with value: 0.7130658157626377 and parameters: {'max_depth': 4, 'learning_rate': 0.04139343312630532, 'n_estimators': 113, 'l2_leaf_reg': 3}. Best is trial 25 with value: 0.7374209784474802.\n","[I 2024-02-12 19:20:18,001] Trial 29 finished with value: 0.7042347214098778 and parameters: {'max_depth': 6, 'learning_rate': 0.01384629495697759, 'n_estimators': 122, 'l2_leaf_reg': 4}. Best is trial 25 with value: 0.7374209784474802.\n","[I 2024-02-12 19:21:09,914] Trial 30 finished with value: 0.719953661919919 and parameters: {'max_depth': 7, 'learning_rate': 0.027660010738403754, 'n_estimators': 117, 'l2_leaf_reg': 3}. Best is trial 25 with value: 0.7374209784474802.\n","[I 2024-02-12 19:22:00,180] Trial 31 finished with value: 0.7372812296243129 and parameters: {'max_depth': 8, 'learning_rate': 0.11657551888831984, 'n_estimators': 105, 'l2_leaf_reg': 3}. Best is trial 25 with value: 0.7374209784474802.\n","[I 2024-02-12 19:22:39,659] Trial 32 finished with value: 0.7325446505612058 and parameters: {'max_depth': 6, 'learning_rate': 0.1007588953775385, 'n_estimators': 104, 'l2_leaf_reg': 3}. Best is trial 25 with value: 0.7374209784474802.\n","[I 2024-02-12 19:23:26,146] Trial 33 finished with value: 0.7297174076388743 and parameters: {'max_depth': 8, 'learning_rate': 0.0580611722283529, 'n_estimators': 95, 'l2_leaf_reg': 3}. Best is trial 25 with value: 0.7374209784474802.\n","[I 2024-02-12 19:24:07,305] Trial 34 finished with value: 0.7340532814452478 and parameters: {'max_depth': 6, 'learning_rate': 0.1099854969240412, 'n_estimators': 107, 'l2_leaf_reg': 4}. Best is trial 25 with value: 0.7374209784474802.\n","[I 2024-02-12 19:25:02,393] Trial 35 finished with value: 0.7150638213458609 and parameters: {'max_depth': 7, 'learning_rate': 0.019844666260904746, 'n_estimators': 124, 'l2_leaf_reg': 3}. Best is trial 25 with value: 0.7374209784474802.\n","[I 2024-02-12 19:25:31,686] Trial 36 finished with value: 0.7342219685038222 and parameters: {'max_depth': 5, 'learning_rate': 0.5890283571632775, 'n_estimators': 91, 'l2_leaf_reg': 3}. Best is trial 25 with value: 0.7374209784474802.\n","[I 2024-02-12 19:26:39,316] Trial 37 finished with value: 0.7325202412417989 and parameters: {'max_depth': 9, 'learning_rate': 0.3053869188403788, 'n_estimators': 120, 'l2_leaf_reg': 4}. Best is trial 25 with value: 0.7374209784474802.\n","[I 2024-02-12 19:27:37,221] Trial 38 finished with value: 0.7274192787970063 and parameters: {'max_depth': 7, 'learning_rate': 0.037746274265772976, 'n_estimators': 141, 'l2_leaf_reg': 3}. Best is trial 25 with value: 0.7374209784474802.\n","[I 2024-02-12 19:28:35,890] Trial 39 finished with value: 0.7333960506444436 and parameters: {'max_depth': 8, 'learning_rate': 0.06196972927148847, 'n_estimators': 129, 'l2_leaf_reg': 3}. Best is trial 25 with value: 0.7374209784474802.\n","[I 2024-02-12 19:29:17,656] Trial 40 finished with value: 0.7361431045251021 and parameters: {'max_depth': 5, 'learning_rate': 0.12080472209152003, 'n_estimators': 137, 'l2_leaf_reg': 4}. Best is trial 25 with value: 0.7374209784474802.\n","[I 2024-02-12 19:29:57,720] Trial 41 finished with value: 0.7366136709104157 and parameters: {'max_depth': 5, 'learning_rate': 0.13173556813639759, 'n_estimators': 133, 'l2_leaf_reg': 4}. Best is trial 25 with value: 0.7374209784474802.\n","[I 2024-02-12 19:30:29,039] Trial 42 finished with value: 0.730697150970211 and parameters: {'max_depth': 3, 'learning_rate': 0.14108230641102223, 'n_estimators': 139, 'l2_leaf_reg': 5}. Best is trial 25 with value: 0.7374209784474802.\n","[I 2024-02-12 19:31:12,170] Trial 43 finished with value: 0.7380241273207678 and parameters: {'max_depth': 5, 'learning_rate': 0.3776739001227673, 'n_estimators': 136, 'l2_leaf_reg': 4}. Best is trial 43 with value: 0.7380241273207678.\n","[I 2024-02-12 19:31:47,427] Trial 44 finished with value: 0.7376443122172837 and parameters: {'max_depth': 4, 'learning_rate': 0.3825593553761971, 'n_estimators': 127, 'l2_leaf_reg': 4}. Best is trial 43 with value: 0.7380241273207678.\n","[I 2024-02-12 19:32:17,541] Trial 45 finished with value: 0.7367230494275775 and parameters: {'max_depth': 3, 'learning_rate': 0.4270866108950036, 'n_estimators': 124, 'l2_leaf_reg': 4}. Best is trial 43 with value: 0.7380241273207678.\n","[I 2024-02-12 19:33:42,278] Trial 46 finished with value: 0.7065154347851452 and parameters: {'max_depth': 9, 'learning_rate': 0.6289020646299537, 'n_estimators': 144, 'l2_leaf_reg': 5}. Best is trial 43 with value: 0.7380241273207678.\n","[I 2024-02-12 19:34:13,416] Trial 47 finished with value: 0.7325183025272569 and parameters: {'max_depth': 4, 'learning_rate': 0.8136355147591464, 'n_estimators': 106, 'l2_leaf_reg': 4}. Best is trial 43 with value: 0.7380241273207678.\n","[I 2024-02-12 19:35:01,184] Trial 48 finished with value: 0.7397090405757337 and parameters: {'max_depth': 6, 'learning_rate': 0.2592363872214876, 'n_estimators': 132, 'l2_leaf_reg': 5}. Best is trial 48 with value: 0.7397090405757337.\n","[I 2024-02-12 19:35:33,707] Trial 49 finished with value: 0.7356856610621559 and parameters: {'max_depth': 3, 'learning_rate': 0.26499186065288943, 'n_estimators': 132, 'l2_leaf_reg': 5}. Best is trial 48 with value: 0.7397090405757337.\n"]}]},{"cell_type":"code","source":["study_catboost.best_params"],"metadata":{"id":"T39Z2OKccfyT","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1707766547783,"user_tz":-240,"elapsed":391,"user":{"displayName":"Евгений Малов","userId":"06257165098392198337"}},"outputId":"268d617a-af6e-4719-f4b2-ca36ca9c5283"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'max_depth': 6,\n"," 'learning_rate': 0.2592363872214876,\n"," 'n_estimators': 132,\n"," 'l2_leaf_reg': 5}"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["opt_model_catb = CatBoostClassifier(**study_catboost.best_params)\n","opt_model_catb.fit(x_train, y_train)\n","\n","pred_train = opt_model_catb.predict(x_train)\n","pred_test = opt_model_catb.predict(x_test)\n","\n","print(f'train: {roc_auc_score(y_train, pred_train)}')\n","print(f'test: {roc_auc_score(y_test, pred_test)}')\n","print(f'test conf matrix: \\n {confusion_matrix(y_test, pred_test)}')"],"metadata":{"id":"zKgczWj3dH-v","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1707766574536,"user_tz":-240,"elapsed":23259,"user":{"displayName":"Евгений Малов","userId":"06257165098392198337"}},"outputId":"422ec785-48bb-4a92-8c51-ecc652bdcbb9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0:\tlearn: 0.6749255\ttotal: 191ms\tremaining: 25s\n","1:\tlearn: 0.6619847\ttotal: 336ms\tremaining: 21.8s\n","2:\tlearn: 0.6535944\ttotal: 528ms\tremaining: 22.7s\n","3:\tlearn: 0.6477695\ttotal: 658ms\tremaining: 21s\n","4:\tlearn: 0.6418796\ttotal: 820ms\tremaining: 20.8s\n","5:\tlearn: 0.6378747\ttotal: 968ms\tremaining: 20.3s\n","6:\tlearn: 0.6348522\ttotal: 1.13s\tremaining: 20.2s\n","7:\tlearn: 0.6318846\ttotal: 1.28s\tremaining: 19.9s\n","8:\tlearn: 0.6284329\ttotal: 1.44s\tremaining: 19.6s\n","9:\tlearn: 0.6265245\ttotal: 1.56s\tremaining: 19.1s\n","10:\tlearn: 0.6248702\ttotal: 1.72s\tremaining: 19s\n","11:\tlearn: 0.6228020\ttotal: 1.88s\tremaining: 18.8s\n","12:\tlearn: 0.6211927\ttotal: 2.01s\tremaining: 18.4s\n","13:\tlearn: 0.6196354\ttotal: 2.18s\tremaining: 18.4s\n","14:\tlearn: 0.6185548\ttotal: 2.32s\tremaining: 18.1s\n","15:\tlearn: 0.6172276\ttotal: 2.44s\tremaining: 17.7s\n","16:\tlearn: 0.6155196\ttotal: 2.61s\tremaining: 17.7s\n","17:\tlearn: 0.6143789\ttotal: 2.74s\tremaining: 17.4s\n","18:\tlearn: 0.6134893\ttotal: 2.88s\tremaining: 17.2s\n","19:\tlearn: 0.6128294\ttotal: 3s\tremaining: 16.8s\n","20:\tlearn: 0.6117456\ttotal: 3.15s\tremaining: 16.7s\n","21:\tlearn: 0.6111117\ttotal: 3.27s\tremaining: 16.3s\n","22:\tlearn: 0.6101311\ttotal: 3.42s\tremaining: 16.2s\n","23:\tlearn: 0.6094518\ttotal: 3.57s\tremaining: 16.1s\n","24:\tlearn: 0.6089599\ttotal: 3.71s\tremaining: 15.9s\n","25:\tlearn: 0.6083034\ttotal: 3.84s\tremaining: 15.7s\n","26:\tlearn: 0.6075881\ttotal: 3.98s\tremaining: 15.5s\n","27:\tlearn: 0.6072208\ttotal: 4.12s\tremaining: 15.3s\n","28:\tlearn: 0.6067259\ttotal: 4.25s\tremaining: 15.1s\n","29:\tlearn: 0.6061659\ttotal: 4.38s\tremaining: 14.9s\n","30:\tlearn: 0.6056793\ttotal: 4.52s\tremaining: 14.7s\n","31:\tlearn: 0.6051967\ttotal: 4.68s\tremaining: 14.6s\n","32:\tlearn: 0.6048220\ttotal: 4.82s\tremaining: 14.5s\n","33:\tlearn: 0.6043725\ttotal: 4.94s\tremaining: 14.2s\n","34:\tlearn: 0.6039929\ttotal: 5.07s\tremaining: 14s\n","35:\tlearn: 0.6035331\ttotal: 5.2s\tremaining: 13.9s\n","36:\tlearn: 0.6029273\ttotal: 5.34s\tremaining: 13.7s\n","37:\tlearn: 0.6026127\ttotal: 5.46s\tremaining: 13.5s\n","38:\tlearn: 0.6023316\ttotal: 5.6s\tremaining: 13.4s\n","39:\tlearn: 0.6018865\ttotal: 5.76s\tremaining: 13.3s\n","40:\tlearn: 0.6015400\ttotal: 5.9s\tremaining: 13.1s\n","41:\tlearn: 0.6012100\ttotal: 6.03s\tremaining: 12.9s\n","42:\tlearn: 0.6007112\ttotal: 6.17s\tremaining: 12.8s\n","43:\tlearn: 0.6004052\ttotal: 6.34s\tremaining: 12.7s\n","44:\tlearn: 0.5999793\ttotal: 6.6s\tremaining: 12.8s\n","45:\tlearn: 0.5994716\ttotal: 6.91s\tremaining: 12.9s\n","46:\tlearn: 0.5989859\ttotal: 7.16s\tremaining: 12.9s\n","47:\tlearn: 0.5986677\ttotal: 7.38s\tremaining: 12.9s\n","48:\tlearn: 0.5982261\ttotal: 7.64s\tremaining: 12.9s\n","49:\tlearn: 0.5978772\ttotal: 7.88s\tremaining: 12.9s\n","50:\tlearn: 0.5974862\ttotal: 8.11s\tremaining: 12.9s\n","51:\tlearn: 0.5971343\ttotal: 8.38s\tremaining: 12.9s\n","52:\tlearn: 0.5965703\ttotal: 8.68s\tremaining: 12.9s\n","53:\tlearn: 0.5962638\ttotal: 8.94s\tremaining: 12.9s\n","54:\tlearn: 0.5958663\ttotal: 9.22s\tremaining: 12.9s\n","55:\tlearn: 0.5955595\ttotal: 9.48s\tremaining: 12.9s\n","56:\tlearn: 0.5952109\ttotal: 9.76s\tremaining: 12.8s\n","57:\tlearn: 0.5948243\ttotal: 10.1s\tremaining: 12.8s\n","58:\tlearn: 0.5945667\ttotal: 10.3s\tremaining: 12.8s\n","59:\tlearn: 0.5942877\ttotal: 10.6s\tremaining: 12.7s\n","60:\tlearn: 0.5938861\ttotal: 10.9s\tremaining: 12.6s\n","61:\tlearn: 0.5935804\ttotal: 11s\tremaining: 12.5s\n","62:\tlearn: 0.5932413\ttotal: 11.2s\tremaining: 12.3s\n","63:\tlearn: 0.5928486\ttotal: 11.3s\tremaining: 12s\n","64:\tlearn: 0.5925098\ttotal: 11.5s\tremaining: 11.8s\n","65:\tlearn: 0.5921515\ttotal: 11.6s\tremaining: 11.6s\n","66:\tlearn: 0.5918246\ttotal: 11.8s\tremaining: 11.4s\n","67:\tlearn: 0.5915789\ttotal: 11.9s\tremaining: 11.2s\n","68:\tlearn: 0.5913101\ttotal: 12s\tremaining: 11s\n","69:\tlearn: 0.5910861\ttotal: 12.2s\tremaining: 10.8s\n","70:\tlearn: 0.5906366\ttotal: 12.3s\tremaining: 10.6s\n","71:\tlearn: 0.5903511\ttotal: 12.5s\tremaining: 10.4s\n","72:\tlearn: 0.5901601\ttotal: 12.6s\tremaining: 10.2s\n","73:\tlearn: 0.5898758\ttotal: 12.8s\tremaining: 10s\n","74:\tlearn: 0.5896328\ttotal: 12.9s\tremaining: 9.81s\n","75:\tlearn: 0.5893887\ttotal: 13s\tremaining: 9.61s\n","76:\tlearn: 0.5890620\ttotal: 13.2s\tremaining: 9.43s\n","77:\tlearn: 0.5888661\ttotal: 13.3s\tremaining: 9.24s\n","78:\tlearn: 0.5885765\ttotal: 13.5s\tremaining: 9.06s\n","79:\tlearn: 0.5882916\ttotal: 13.7s\tremaining: 8.88s\n","80:\tlearn: 0.5880443\ttotal: 13.8s\tremaining: 8.69s\n","81:\tlearn: 0.5876333\ttotal: 14s\tremaining: 8.52s\n","82:\tlearn: 0.5873746\ttotal: 14.1s\tremaining: 8.33s\n","83:\tlearn: 0.5871698\ttotal: 14.3s\tremaining: 8.14s\n","84:\tlearn: 0.5869667\ttotal: 14.4s\tremaining: 7.96s\n","85:\tlearn: 0.5866769\ttotal: 14.6s\tremaining: 7.79s\n","86:\tlearn: 0.5864181\ttotal: 14.7s\tremaining: 7.6s\n","87:\tlearn: 0.5860697\ttotal: 14.9s\tremaining: 7.43s\n","88:\tlearn: 0.5858833\ttotal: 15s\tremaining: 7.23s\n","89:\tlearn: 0.5857100\ttotal: 15.1s\tremaining: 7.04s\n","90:\tlearn: 0.5854730\ttotal: 15.2s\tremaining: 6.87s\n","91:\tlearn: 0.5852267\ttotal: 15.4s\tremaining: 6.68s\n","92:\tlearn: 0.5850592\ttotal: 15.5s\tremaining: 6.5s\n","93:\tlearn: 0.5848034\ttotal: 15.7s\tremaining: 6.33s\n","94:\tlearn: 0.5845733\ttotal: 15.8s\tremaining: 6.14s\n","95:\tlearn: 0.5843710\ttotal: 15.9s\tremaining: 5.97s\n","96:\tlearn: 0.5841351\ttotal: 16s\tremaining: 5.79s\n","97:\tlearn: 0.5839493\ttotal: 16.2s\tremaining: 5.6s\n","98:\tlearn: 0.5837772\ttotal: 16.3s\tremaining: 5.43s\n","99:\tlearn: 0.5835232\ttotal: 16.4s\tremaining: 5.26s\n","100:\tlearn: 0.5833154\ttotal: 16.5s\tremaining: 5.08s\n","101:\tlearn: 0.5832464\ttotal: 16.6s\tremaining: 4.89s\n","102:\tlearn: 0.5830785\ttotal: 16.7s\tremaining: 4.71s\n","103:\tlearn: 0.5828042\ttotal: 16.9s\tremaining: 4.54s\n","104:\tlearn: 0.5825278\ttotal: 17s\tremaining: 4.37s\n","105:\tlearn: 0.5823639\ttotal: 17.1s\tremaining: 4.2s\n","106:\tlearn: 0.5821508\ttotal: 17.3s\tremaining: 4.04s\n","107:\tlearn: 0.5818953\ttotal: 17.5s\tremaining: 3.88s\n","108:\tlearn: 0.5816095\ttotal: 17.6s\tremaining: 3.71s\n","109:\tlearn: 0.5813427\ttotal: 17.7s\tremaining: 3.55s\n","110:\tlearn: 0.5811429\ttotal: 17.9s\tremaining: 3.38s\n","111:\tlearn: 0.5810296\ttotal: 18s\tremaining: 3.21s\n","112:\tlearn: 0.5808096\ttotal: 18.1s\tremaining: 3.04s\n","113:\tlearn: 0.5807106\ttotal: 18.2s\tremaining: 2.87s\n","114:\tlearn: 0.5805407\ttotal: 18.3s\tremaining: 2.71s\n","115:\tlearn: 0.5803593\ttotal: 18.5s\tremaining: 2.55s\n","116:\tlearn: 0.5802237\ttotal: 18.6s\tremaining: 2.38s\n","117:\tlearn: 0.5800744\ttotal: 18.7s\tremaining: 2.22s\n","118:\tlearn: 0.5798634\ttotal: 18.9s\tremaining: 2.06s\n","119:\tlearn: 0.5796593\ttotal: 19s\tremaining: 1.9s\n","120:\tlearn: 0.5794132\ttotal: 19.1s\tremaining: 1.74s\n","121:\tlearn: 0.5792313\ttotal: 19.3s\tremaining: 1.58s\n","122:\tlearn: 0.5791013\ttotal: 19.4s\tremaining: 1.42s\n","123:\tlearn: 0.5788651\ttotal: 19.6s\tremaining: 1.26s\n","124:\tlearn: 0.5786838\ttotal: 19.7s\tremaining: 1.1s\n","125:\tlearn: 0.5785194\ttotal: 19.9s\tremaining: 947ms\n","126:\tlearn: 0.5783216\ttotal: 20s\tremaining: 789ms\n","127:\tlearn: 0.5781504\ttotal: 20.2s\tremaining: 630ms\n","128:\tlearn: 0.5779681\ttotal: 20.3s\tremaining: 472ms\n","129:\tlearn: 0.5778516\ttotal: 20.4s\tremaining: 314ms\n","130:\tlearn: 0.5776752\ttotal: 20.6s\tremaining: 157ms\n","131:\tlearn: 0.5774652\ttotal: 20.7s\tremaining: 0us\n","train: 0.6977194330012216\n","test: 0.6784377141475946\n","test conf matrix: \n"," [[21120 10753]\n"," [ 9782 22211]]\n"]}]},{"cell_type":"code","source":["estimators = [\n","    ('lgbm', opt_model_lgbm),\n","    ('xgb', opt_model_xgb),\n","    ('cb', opt_model_catb)\n","    ]\n","\n","reg = StackingClassifier(\n","    estimators=estimators,\n","    final_estimator=GradientBoostingClassifier(learning_rate = 0.02, n_estimators = 100, random_state=42))\n","\n","reg.fit(x_train, y_train)\n","pred_train = reg.predict(x_train)\n","pred_test = reg.predict(x_test)\n","\n","print(f'train: {roc_auc_score(y_train, pred_train)}')\n","print(f'test: {roc_auc_score(y_test, pred_test)}')\n","print(f'test conf matrix: \\n {confusion_matrix(y_test, pred_test)}')"],"metadata":{"id":"T13HVM1wdICJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1707767833428,"user_tz":-240,"elapsed":865944,"user":{"displayName":"Евгений Малов","userId":"06257165098392198337"}},"outputId":"05ed79af-e9f9-4dc3-d1dc-25a2fb7d1c0f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 74449, number of negative: 74569\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.450811 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 3855\n","[LightGBM] [Info] Number of data points in the train set: 149018, number of used features: 216\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499597 -> initscore=-0.001611\n","[LightGBM] [Info] Start training from score -0.001611\n","0:\tlearn: 0.6749255\ttotal: 130ms\tremaining: 17s\n","1:\tlearn: 0.6619847\ttotal: 281ms\tremaining: 18.3s\n","2:\tlearn: 0.6535944\ttotal: 437ms\tremaining: 18.8s\n","3:\tlearn: 0.6477695\ttotal: 562ms\tremaining: 18s\n","4:\tlearn: 0.6418796\ttotal: 709ms\tremaining: 18s\n","5:\tlearn: 0.6378747\ttotal: 842ms\tremaining: 17.7s\n","6:\tlearn: 0.6348522\ttotal: 986ms\tremaining: 17.6s\n","7:\tlearn: 0.6318846\ttotal: 1.12s\tremaining: 17.4s\n","8:\tlearn: 0.6284329\ttotal: 1.28s\tremaining: 17.5s\n","9:\tlearn: 0.6265245\ttotal: 1.38s\tremaining: 16.8s\n","10:\tlearn: 0.6248702\ttotal: 1.54s\tremaining: 16.9s\n","11:\tlearn: 0.6228020\ttotal: 1.68s\tremaining: 16.8s\n","12:\tlearn: 0.6211927\ttotal: 1.8s\tremaining: 16.5s\n","13:\tlearn: 0.6196354\ttotal: 1.94s\tremaining: 16.4s\n","14:\tlearn: 0.6185548\ttotal: 2.06s\tremaining: 16.1s\n","15:\tlearn: 0.6172276\ttotal: 2.25s\tremaining: 16.3s\n","16:\tlearn: 0.6155196\ttotal: 2.51s\tremaining: 17s\n","17:\tlearn: 0.6143789\ttotal: 2.76s\tremaining: 17.5s\n","18:\tlearn: 0.6134893\ttotal: 3.01s\tremaining: 17.9s\n","19:\tlearn: 0.6128294\ttotal: 3.19s\tremaining: 17.9s\n","20:\tlearn: 0.6117456\ttotal: 3.49s\tremaining: 18.4s\n","21:\tlearn: 0.6111117\ttotal: 3.72s\tremaining: 18.6s\n","22:\tlearn: 0.6101311\ttotal: 3.98s\tremaining: 18.9s\n","23:\tlearn: 0.6094518\ttotal: 4.29s\tremaining: 19.3s\n","24:\tlearn: 0.6089599\ttotal: 4.5s\tremaining: 19.3s\n","25:\tlearn: 0.6083034\ttotal: 4.74s\tremaining: 19.3s\n","26:\tlearn: 0.6075881\ttotal: 4.99s\tremaining: 19.4s\n","27:\tlearn: 0.6072208\ttotal: 5.26s\tremaining: 19.5s\n","28:\tlearn: 0.6067259\ttotal: 5.47s\tremaining: 19.4s\n","29:\tlearn: 0.6061659\ttotal: 5.73s\tremaining: 19.5s\n","30:\tlearn: 0.6056793\ttotal: 5.98s\tremaining: 19.5s\n","31:\tlearn: 0.6051967\ttotal: 6.19s\tremaining: 19.4s\n","32:\tlearn: 0.6048220\ttotal: 6.32s\tremaining: 19s\n","33:\tlearn: 0.6043725\ttotal: 6.45s\tremaining: 18.6s\n","34:\tlearn: 0.6039929\ttotal: 6.58s\tremaining: 18.2s\n","35:\tlearn: 0.6035331\ttotal: 6.7s\tremaining: 17.9s\n","36:\tlearn: 0.6029273\ttotal: 6.84s\tremaining: 17.6s\n","37:\tlearn: 0.6026127\ttotal: 6.96s\tremaining: 17.2s\n","38:\tlearn: 0.6023316\ttotal: 7.07s\tremaining: 16.9s\n","39:\tlearn: 0.6018865\ttotal: 7.22s\tremaining: 16.6s\n","40:\tlearn: 0.6015400\ttotal: 7.34s\tremaining: 16.3s\n","41:\tlearn: 0.6012100\ttotal: 7.47s\tremaining: 16s\n","42:\tlearn: 0.6007112\ttotal: 7.61s\tremaining: 15.8s\n","43:\tlearn: 0.6004052\ttotal: 7.72s\tremaining: 15.4s\n","44:\tlearn: 0.5999793\ttotal: 7.86s\tremaining: 15.2s\n","45:\tlearn: 0.5994716\ttotal: 8s\tremaining: 14.9s\n","46:\tlearn: 0.5989859\ttotal: 8.11s\tremaining: 14.7s\n","47:\tlearn: 0.5986677\ttotal: 8.22s\tremaining: 14.4s\n","48:\tlearn: 0.5982261\ttotal: 8.35s\tremaining: 14.1s\n","49:\tlearn: 0.5978772\ttotal: 8.49s\tremaining: 13.9s\n","50:\tlearn: 0.5974862\ttotal: 8.64s\tremaining: 13.7s\n","51:\tlearn: 0.5971343\ttotal: 8.78s\tremaining: 13.5s\n","52:\tlearn: 0.5965703\ttotal: 8.93s\tremaining: 13.3s\n","53:\tlearn: 0.5962638\ttotal: 9.04s\tremaining: 13.1s\n","54:\tlearn: 0.5958663\ttotal: 9.16s\tremaining: 12.8s\n","55:\tlearn: 0.5955595\ttotal: 9.28s\tremaining: 12.6s\n","56:\tlearn: 0.5952109\ttotal: 9.4s\tremaining: 12.4s\n","57:\tlearn: 0.5948243\ttotal: 9.53s\tremaining: 12.2s\n","58:\tlearn: 0.5945667\ttotal: 9.66s\tremaining: 12s\n","59:\tlearn: 0.5942877\ttotal: 9.77s\tremaining: 11.7s\n","60:\tlearn: 0.5938861\ttotal: 9.93s\tremaining: 11.6s\n","61:\tlearn: 0.5935804\ttotal: 10.1s\tremaining: 11.4s\n","62:\tlearn: 0.5932413\ttotal: 10.2s\tremaining: 11.2s\n","63:\tlearn: 0.5928486\ttotal: 10.3s\tremaining: 11s\n","64:\tlearn: 0.5925098\ttotal: 10.5s\tremaining: 10.8s\n","65:\tlearn: 0.5921515\ttotal: 10.6s\tremaining: 10.6s\n","66:\tlearn: 0.5918246\ttotal: 10.7s\tremaining: 10.4s\n","67:\tlearn: 0.5915789\ttotal: 10.9s\tremaining: 10.2s\n","68:\tlearn: 0.5913101\ttotal: 11s\tremaining: 10s\n","69:\tlearn: 0.5910861\ttotal: 11.1s\tremaining: 9.82s\n","70:\tlearn: 0.5906366\ttotal: 11.2s\tremaining: 9.64s\n","71:\tlearn: 0.5903511\ttotal: 11.3s\tremaining: 9.45s\n","72:\tlearn: 0.5901601\ttotal: 11.4s\tremaining: 9.25s\n","73:\tlearn: 0.5898758\ttotal: 11.6s\tremaining: 9.1s\n","74:\tlearn: 0.5896328\ttotal: 11.8s\tremaining: 8.93s\n","75:\tlearn: 0.5893887\ttotal: 11.9s\tremaining: 8.74s\n","76:\tlearn: 0.5890620\ttotal: 12s\tremaining: 8.56s\n","77:\tlearn: 0.5888661\ttotal: 12.1s\tremaining: 8.38s\n","78:\tlearn: 0.5885765\ttotal: 12.2s\tremaining: 8.21s\n","79:\tlearn: 0.5882916\ttotal: 12.4s\tremaining: 8.05s\n","80:\tlearn: 0.5880443\ttotal: 12.5s\tremaining: 7.87s\n","81:\tlearn: 0.5876333\ttotal: 12.6s\tremaining: 7.71s\n","82:\tlearn: 0.5873746\ttotal: 12.8s\tremaining: 7.55s\n","83:\tlearn: 0.5871698\ttotal: 12.9s\tremaining: 7.37s\n","84:\tlearn: 0.5869667\ttotal: 13s\tremaining: 7.19s\n","85:\tlearn: 0.5866769\ttotal: 13.2s\tremaining: 7.05s\n","86:\tlearn: 0.5864181\ttotal: 13.3s\tremaining: 6.88s\n","87:\tlearn: 0.5860697\ttotal: 13.4s\tremaining: 6.72s\n","88:\tlearn: 0.5858833\ttotal: 13.5s\tremaining: 6.54s\n","89:\tlearn: 0.5857100\ttotal: 13.7s\tremaining: 6.37s\n","90:\tlearn: 0.5854730\ttotal: 13.8s\tremaining: 6.21s\n","91:\tlearn: 0.5852267\ttotal: 13.9s\tremaining: 6.05s\n","92:\tlearn: 0.5850592\ttotal: 14s\tremaining: 5.88s\n","93:\tlearn: 0.5848034\ttotal: 14.2s\tremaining: 5.73s\n","94:\tlearn: 0.5845733\ttotal: 14.3s\tremaining: 5.56s\n","95:\tlearn: 0.5843710\ttotal: 14.4s\tremaining: 5.41s\n","96:\tlearn: 0.5841351\ttotal: 14.5s\tremaining: 5.24s\n","97:\tlearn: 0.5839493\ttotal: 14.6s\tremaining: 5.08s\n","98:\tlearn: 0.5837772\ttotal: 14.8s\tremaining: 4.92s\n","99:\tlearn: 0.5835232\ttotal: 14.9s\tremaining: 4.77s\n","100:\tlearn: 0.5833154\ttotal: 15s\tremaining: 4.61s\n","101:\tlearn: 0.5832464\ttotal: 15.1s\tremaining: 4.44s\n","102:\tlearn: 0.5830785\ttotal: 15.2s\tremaining: 4.28s\n","103:\tlearn: 0.5828042\ttotal: 15.3s\tremaining: 4.13s\n","104:\tlearn: 0.5825278\ttotal: 15.5s\tremaining: 3.98s\n","105:\tlearn: 0.5823639\ttotal: 15.6s\tremaining: 3.83s\n","106:\tlearn: 0.5821508\ttotal: 15.7s\tremaining: 3.67s\n","107:\tlearn: 0.5818953\ttotal: 15.9s\tremaining: 3.53s\n","108:\tlearn: 0.5816095\ttotal: 16s\tremaining: 3.38s\n","109:\tlearn: 0.5813427\ttotal: 16.2s\tremaining: 3.25s\n","110:\tlearn: 0.5811429\ttotal: 16.4s\tremaining: 3.11s\n","111:\tlearn: 0.5810296\ttotal: 16.5s\tremaining: 2.95s\n","112:\tlearn: 0.5808096\ttotal: 16.8s\tremaining: 2.82s\n","113:\tlearn: 0.5807106\ttotal: 17s\tremaining: 2.68s\n","114:\tlearn: 0.5805407\ttotal: 17.2s\tremaining: 2.54s\n","115:\tlearn: 0.5803593\ttotal: 17.4s\tremaining: 2.41s\n","116:\tlearn: 0.5802237\ttotal: 17.7s\tremaining: 2.27s\n","117:\tlearn: 0.5800744\ttotal: 17.9s\tremaining: 2.13s\n","118:\tlearn: 0.5798634\ttotal: 18.2s\tremaining: 1.98s\n","119:\tlearn: 0.5796593\ttotal: 18.4s\tremaining: 1.84s\n","120:\tlearn: 0.5794132\ttotal: 18.6s\tremaining: 1.69s\n","121:\tlearn: 0.5792313\ttotal: 18.8s\tremaining: 1.54s\n","122:\tlearn: 0.5791013\ttotal: 19s\tremaining: 1.39s\n","123:\tlearn: 0.5788651\ttotal: 19.3s\tremaining: 1.25s\n","124:\tlearn: 0.5786838\ttotal: 19.6s\tremaining: 1.09s\n","125:\tlearn: 0.5785194\ttotal: 19.8s\tremaining: 943ms\n","126:\tlearn: 0.5783216\ttotal: 20.1s\tremaining: 791ms\n","127:\tlearn: 0.5781504\ttotal: 20.3s\tremaining: 634ms\n","128:\tlearn: 0.5779681\ttotal: 20.4s\tremaining: 475ms\n","129:\tlearn: 0.5778516\ttotal: 20.5s\tremaining: 316ms\n","130:\tlearn: 0.5776752\ttotal: 20.6s\tremaining: 158ms\n","131:\tlearn: 0.5774652\ttotal: 20.8s\tremaining: 0us\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 59559, number of negative: 59655\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.356964 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 3785\n","[LightGBM] [Info] Number of data points in the train set: 119214, number of used features: 216\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499597 -> initscore=-0.001611\n","[LightGBM] [Info] Start training from score -0.001611\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 59559, number of negative: 59655\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.504974 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 3781\n","[LightGBM] [Info] Number of data points in the train set: 119214, number of used features: 216\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499597 -> initscore=-0.001611\n","[LightGBM] [Info] Start training from score -0.001611\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 59559, number of negative: 59655\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.362957 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 3798\n","[LightGBM] [Info] Number of data points in the train set: 119214, number of used features: 216\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499597 -> initscore=-0.001611\n","[LightGBM] [Info] Start training from score -0.001611\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 59560, number of negative: 59655\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.374785 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 3791\n","[LightGBM] [Info] Number of data points in the train set: 119215, number of used features: 216\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499602 -> initscore=-0.001594\n","[LightGBM] [Info] Start training from score -0.001594\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 59559, number of negative: 59656\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.388496 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 3775\n","[LightGBM] [Info] Number of data points in the train set: 119215, number of used features: 216\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499593 -> initscore=-0.001627\n","[LightGBM] [Info] Start training from score -0.001627\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","0:\tlearn: 0.6749642\ttotal: 131ms\tremaining: 17.2s\n","1:\tlearn: 0.6625553\ttotal: 251ms\tremaining: 16.3s\n","2:\tlearn: 0.6544023\ttotal: 380ms\tremaining: 16.3s\n","3:\tlearn: 0.6477347\ttotal: 487ms\tremaining: 15.6s\n","4:\tlearn: 0.6423999\ttotal: 608ms\tremaining: 15.4s\n","5:\tlearn: 0.6374632\ttotal: 725ms\tremaining: 15.2s\n","6:\tlearn: 0.6338209\ttotal: 845ms\tremaining: 15.1s\n","7:\tlearn: 0.6313368\ttotal: 971ms\tremaining: 15s\n","8:\tlearn: 0.6290111\ttotal: 1.08s\tremaining: 14.8s\n","9:\tlearn: 0.6269693\ttotal: 1.18s\tremaining: 14.4s\n","10:\tlearn: 0.6251737\ttotal: 1.28s\tremaining: 14.1s\n","11:\tlearn: 0.6236515\ttotal: 1.4s\tremaining: 14s\n","12:\tlearn: 0.6221334\ttotal: 1.51s\tremaining: 13.8s\n","13:\tlearn: 0.6206318\ttotal: 1.62s\tremaining: 13.6s\n","14:\tlearn: 0.6193869\ttotal: 1.73s\tremaining: 13.5s\n","15:\tlearn: 0.6184492\ttotal: 1.84s\tremaining: 13.3s\n","16:\tlearn: 0.6173362\ttotal: 1.98s\tremaining: 13.4s\n","17:\tlearn: 0.6164241\ttotal: 2.08s\tremaining: 13.2s\n","18:\tlearn: 0.6155091\ttotal: 2.18s\tremaining: 12.9s\n","19:\tlearn: 0.6147652\ttotal: 2.27s\tremaining: 12.7s\n","20:\tlearn: 0.6140253\ttotal: 2.38s\tremaining: 12.6s\n","21:\tlearn: 0.6127845\ttotal: 2.49s\tremaining: 12.5s\n","22:\tlearn: 0.6119518\ttotal: 2.62s\tremaining: 12.4s\n","23:\tlearn: 0.6114466\ttotal: 2.73s\tremaining: 12.3s\n","24:\tlearn: 0.6107446\ttotal: 2.84s\tremaining: 12.1s\n","25:\tlearn: 0.6101170\ttotal: 2.93s\tremaining: 11.9s\n","26:\tlearn: 0.6090156\ttotal: 3.06s\tremaining: 11.9s\n","27:\tlearn: 0.6084493\ttotal: 3.16s\tremaining: 11.7s\n","28:\tlearn: 0.6079046\ttotal: 3.28s\tremaining: 11.6s\n","29:\tlearn: 0.6072771\ttotal: 3.38s\tremaining: 11.5s\n","30:\tlearn: 0.6067701\ttotal: 3.51s\tremaining: 11.4s\n","31:\tlearn: 0.6063607\ttotal: 3.6s\tremaining: 11.3s\n","32:\tlearn: 0.6060837\ttotal: 3.69s\tremaining: 11.1s\n","33:\tlearn: 0.6054322\ttotal: 3.84s\tremaining: 11.1s\n","34:\tlearn: 0.6050812\ttotal: 3.93s\tremaining: 10.9s\n","35:\tlearn: 0.6046656\ttotal: 4.06s\tremaining: 10.8s\n","36:\tlearn: 0.6041555\ttotal: 4.16s\tremaining: 10.7s\n","37:\tlearn: 0.6036249\ttotal: 4.26s\tremaining: 10.5s\n","38:\tlearn: 0.6031978\ttotal: 4.37s\tremaining: 10.4s\n","39:\tlearn: 0.6026945\ttotal: 4.47s\tremaining: 10.3s\n","40:\tlearn: 0.6022975\ttotal: 4.58s\tremaining: 10.2s\n","41:\tlearn: 0.6018980\ttotal: 4.7s\tremaining: 10.1s\n","42:\tlearn: 0.6015775\ttotal: 4.78s\tremaining: 9.9s\n","43:\tlearn: 0.6009403\ttotal: 4.9s\tremaining: 9.79s\n","44:\tlearn: 0.6006305\ttotal: 4.98s\tremaining: 9.64s\n","45:\tlearn: 0.6001317\ttotal: 5.11s\tremaining: 9.56s\n","46:\tlearn: 0.5996207\ttotal: 5.24s\tremaining: 9.47s\n","47:\tlearn: 0.5991931\ttotal: 5.35s\tremaining: 9.36s\n","48:\tlearn: 0.5987830\ttotal: 5.44s\tremaining: 9.21s\n","49:\tlearn: 0.5983920\ttotal: 5.54s\tremaining: 9.09s\n","50:\tlearn: 0.5978297\ttotal: 5.67s\tremaining: 9.01s\n","51:\tlearn: 0.5974601\ttotal: 5.77s\tremaining: 8.87s\n","52:\tlearn: 0.5967699\ttotal: 5.87s\tremaining: 8.76s\n","53:\tlearn: 0.5963509\ttotal: 5.97s\tremaining: 8.63s\n","54:\tlearn: 0.5960145\ttotal: 6.06s\tremaining: 8.48s\n","55:\tlearn: 0.5954696\ttotal: 6.2s\tremaining: 8.41s\n","56:\tlearn: 0.5951911\ttotal: 6.3s\tremaining: 8.29s\n","57:\tlearn: 0.5948748\ttotal: 6.41s\tremaining: 8.18s\n","58:\tlearn: 0.5945815\ttotal: 6.53s\tremaining: 8.08s\n","59:\tlearn: 0.5940978\ttotal: 6.7s\tremaining: 8.04s\n","60:\tlearn: 0.5937190\ttotal: 6.89s\tremaining: 8.02s\n","61:\tlearn: 0.5933136\ttotal: 7.17s\tremaining: 8.09s\n","62:\tlearn: 0.5929905\ttotal: 7.35s\tremaining: 8.05s\n","63:\tlearn: 0.5927030\ttotal: 7.54s\tremaining: 8.01s\n","64:\tlearn: 0.5924516\ttotal: 7.72s\tremaining: 7.96s\n","65:\tlearn: 0.5921856\ttotal: 7.95s\tremaining: 7.95s\n","66:\tlearn: 0.5919088\ttotal: 8.11s\tremaining: 7.87s\n","67:\tlearn: 0.5915813\ttotal: 8.32s\tremaining: 7.83s\n","68:\tlearn: 0.5912646\ttotal: 8.49s\tremaining: 7.75s\n","69:\tlearn: 0.5909845\ttotal: 8.71s\tremaining: 7.71s\n","70:\tlearn: 0.5905702\ttotal: 8.9s\tremaining: 7.65s\n","71:\tlearn: 0.5902697\ttotal: 9.14s\tremaining: 7.61s\n","72:\tlearn: 0.5900496\ttotal: 9.31s\tremaining: 7.52s\n","73:\tlearn: 0.5898057\ttotal: 9.47s\tremaining: 7.42s\n","74:\tlearn: 0.5895541\ttotal: 9.66s\tremaining: 7.34s\n","75:\tlearn: 0.5892360\ttotal: 9.87s\tremaining: 7.27s\n","76:\tlearn: 0.5890274\ttotal: 10s\tremaining: 7.17s\n","77:\tlearn: 0.5886423\ttotal: 10.3s\tremaining: 7.1s\n","78:\tlearn: 0.5881800\ttotal: 10.5s\tremaining: 7.02s\n","79:\tlearn: 0.5879529\ttotal: 10.6s\tremaining: 6.88s\n","80:\tlearn: 0.5875867\ttotal: 10.7s\tremaining: 6.75s\n","81:\tlearn: 0.5872983\ttotal: 10.8s\tremaining: 6.59s\n","82:\tlearn: 0.5870292\ttotal: 10.9s\tremaining: 6.45s\n","83:\tlearn: 0.5867468\ttotal: 11s\tremaining: 6.3s\n","84:\tlearn: 0.5864974\ttotal: 11.1s\tremaining: 6.15s\n","85:\tlearn: 0.5862923\ttotal: 11.2s\tremaining: 6s\n","86:\tlearn: 0.5859888\ttotal: 11.3s\tremaining: 5.86s\n","87:\tlearn: 0.5857790\ttotal: 11.4s\tremaining: 5.71s\n","88:\tlearn: 0.5854713\ttotal: 11.5s\tremaining: 5.57s\n","89:\tlearn: 0.5851838\ttotal: 11.6s\tremaining: 5.43s\n","90:\tlearn: 0.5849418\ttotal: 11.7s\tremaining: 5.29s\n","91:\tlearn: 0.5846938\ttotal: 11.8s\tremaining: 5.14s\n","92:\tlearn: 0.5846094\ttotal: 11.9s\tremaining: 4.99s\n","93:\tlearn: 0.5842116\ttotal: 12s\tremaining: 4.86s\n","94:\tlearn: 0.5840558\ttotal: 12.1s\tremaining: 4.71s\n","95:\tlearn: 0.5837796\ttotal: 12.2s\tremaining: 4.58s\n","96:\tlearn: 0.5835887\ttotal: 12.3s\tremaining: 4.44s\n","97:\tlearn: 0.5833235\ttotal: 12.4s\tremaining: 4.31s\n","98:\tlearn: 0.5831654\ttotal: 12.5s\tremaining: 4.17s\n","99:\tlearn: 0.5828951\ttotal: 12.6s\tremaining: 4.04s\n","100:\tlearn: 0.5826402\ttotal: 12.7s\tremaining: 3.9s\n","101:\tlearn: 0.5824596\ttotal: 12.8s\tremaining: 3.77s\n","102:\tlearn: 0.5821576\ttotal: 12.9s\tremaining: 3.64s\n","103:\tlearn: 0.5818547\ttotal: 13.1s\tremaining: 3.52s\n","104:\tlearn: 0.5816650\ttotal: 13.2s\tremaining: 3.38s\n","105:\tlearn: 0.5814688\ttotal: 13.3s\tremaining: 3.25s\n","106:\tlearn: 0.5812508\ttotal: 13.4s\tremaining: 3.12s\n","107:\tlearn: 0.5811913\ttotal: 13.4s\tremaining: 2.99s\n","108:\tlearn: 0.5810504\ttotal: 13.5s\tremaining: 2.85s\n","109:\tlearn: 0.5809180\ttotal: 13.6s\tremaining: 2.72s\n","110:\tlearn: 0.5807731\ttotal: 13.7s\tremaining: 2.59s\n","111:\tlearn: 0.5805435\ttotal: 13.8s\tremaining: 2.46s\n","112:\tlearn: 0.5803133\ttotal: 13.9s\tremaining: 2.34s\n","113:\tlearn: 0.5800419\ttotal: 14s\tremaining: 2.21s\n","114:\tlearn: 0.5797723\ttotal: 14.1s\tremaining: 2.08s\n","115:\tlearn: 0.5796920\ttotal: 14.2s\tremaining: 1.96s\n","116:\tlearn: 0.5793597\ttotal: 14.3s\tremaining: 1.83s\n","117:\tlearn: 0.5792200\ttotal: 14.4s\tremaining: 1.71s\n","118:\tlearn: 0.5789086\ttotal: 14.5s\tremaining: 1.59s\n","119:\tlearn: 0.5786572\ttotal: 14.6s\tremaining: 1.46s\n","120:\tlearn: 0.5784365\ttotal: 14.7s\tremaining: 1.34s\n","121:\tlearn: 0.5781514\ttotal: 14.9s\tremaining: 1.22s\n","122:\tlearn: 0.5778078\ttotal: 15s\tremaining: 1.1s\n","123:\tlearn: 0.5777062\ttotal: 15.1s\tremaining: 972ms\n","124:\tlearn: 0.5775223\ttotal: 15.2s\tremaining: 849ms\n","125:\tlearn: 0.5772910\ttotal: 15.3s\tremaining: 728ms\n","126:\tlearn: 0.5769593\ttotal: 15.4s\tremaining: 606ms\n","127:\tlearn: 0.5766508\ttotal: 15.5s\tremaining: 485ms\n","128:\tlearn: 0.5766223\ttotal: 15.6s\tremaining: 363ms\n","129:\tlearn: 0.5766056\ttotal: 15.7s\tremaining: 241ms\n","130:\tlearn: 0.5764137\ttotal: 15.7s\tremaining: 120ms\n","131:\tlearn: 0.5761742\ttotal: 15.8s\tremaining: 0us\n","0:\tlearn: 0.6752701\ttotal: 116ms\tremaining: 15.2s\n","1:\tlearn: 0.6640916\ttotal: 236ms\tremaining: 15.4s\n","2:\tlearn: 0.6546976\ttotal: 372ms\tremaining: 16s\n","3:\tlearn: 0.6478973\ttotal: 480ms\tremaining: 15.4s\n","4:\tlearn: 0.6427958\ttotal: 575ms\tremaining: 14.6s\n","5:\tlearn: 0.6388954\ttotal: 695ms\tremaining: 14.6s\n","6:\tlearn: 0.6350518\ttotal: 836ms\tremaining: 14.9s\n","7:\tlearn: 0.6317507\ttotal: 956ms\tremaining: 14.8s\n","8:\tlearn: 0.6295091\ttotal: 1.07s\tremaining: 14.7s\n","9:\tlearn: 0.6265450\ttotal: 1.17s\tremaining: 14.3s\n","10:\tlearn: 0.6247860\ttotal: 1.27s\tremaining: 14s\n","11:\tlearn: 0.6231732\ttotal: 1.37s\tremaining: 13.7s\n","12:\tlearn: 0.6214489\ttotal: 1.48s\tremaining: 13.5s\n","13:\tlearn: 0.6197174\ttotal: 1.59s\tremaining: 13.4s\n","14:\tlearn: 0.6184249\ttotal: 1.71s\tremaining: 13.3s\n","15:\tlearn: 0.6173055\ttotal: 1.84s\tremaining: 13.3s\n","16:\tlearn: 0.6163650\ttotal: 1.94s\tremaining: 13.2s\n","17:\tlearn: 0.6154734\ttotal: 2.06s\tremaining: 13s\n","18:\tlearn: 0.6143861\ttotal: 2.16s\tremaining: 12.9s\n","19:\tlearn: 0.6136389\ttotal: 2.25s\tremaining: 12.6s\n","20:\tlearn: 0.6130117\ttotal: 2.35s\tremaining: 12.4s\n","21:\tlearn: 0.6124457\ttotal: 2.45s\tremaining: 12.2s\n","22:\tlearn: 0.6118364\ttotal: 2.54s\tremaining: 12.1s\n","23:\tlearn: 0.6108647\ttotal: 2.66s\tremaining: 12s\n","24:\tlearn: 0.6104335\ttotal: 2.76s\tremaining: 11.8s\n","25:\tlearn: 0.6097687\ttotal: 2.87s\tremaining: 11.7s\n","26:\tlearn: 0.6091134\ttotal: 2.98s\tremaining: 11.6s\n","27:\tlearn: 0.6084137\ttotal: 3.1s\tremaining: 11.5s\n","28:\tlearn: 0.6077862\ttotal: 3.2s\tremaining: 11.4s\n","29:\tlearn: 0.6073252\ttotal: 3.3s\tremaining: 11.2s\n","30:\tlearn: 0.6067035\ttotal: 3.41s\tremaining: 11.1s\n","31:\tlearn: 0.6062355\ttotal: 3.5s\tremaining: 10.9s\n","32:\tlearn: 0.6058022\ttotal: 3.59s\tremaining: 10.8s\n","33:\tlearn: 0.6053333\ttotal: 3.73s\tremaining: 10.8s\n","34:\tlearn: 0.6048658\ttotal: 3.94s\tremaining: 10.9s\n","35:\tlearn: 0.6044819\ttotal: 4.17s\tremaining: 11.1s\n","36:\tlearn: 0.6038482\ttotal: 4.39s\tremaining: 11.3s\n","37:\tlearn: 0.6031129\ttotal: 4.6s\tremaining: 11.4s\n","38:\tlearn: 0.6026796\ttotal: 4.8s\tremaining: 11.4s\n","39:\tlearn: 0.6022024\ttotal: 4.99s\tremaining: 11.5s\n","40:\tlearn: 0.6016736\ttotal: 5.2s\tremaining: 11.5s\n","41:\tlearn: 0.6013443\ttotal: 5.4s\tremaining: 11.6s\n","42:\tlearn: 0.6005894\ttotal: 5.63s\tremaining: 11.7s\n","43:\tlearn: 0.6000464\ttotal: 5.9s\tremaining: 11.8s\n","44:\tlearn: 0.5996463\ttotal: 6.09s\tremaining: 11.8s\n","45:\tlearn: 0.5991436\ttotal: 6.28s\tremaining: 11.7s\n","46:\tlearn: 0.5987681\ttotal: 6.49s\tremaining: 11.7s\n","47:\tlearn: 0.5982716\ttotal: 6.69s\tremaining: 11.7s\n","48:\tlearn: 0.5979207\ttotal: 6.88s\tremaining: 11.7s\n","49:\tlearn: 0.5975116\ttotal: 7.07s\tremaining: 11.6s\n","50:\tlearn: 0.5970542\ttotal: 7.32s\tremaining: 11.6s\n","51:\tlearn: 0.5966510\ttotal: 7.5s\tremaining: 11.5s\n","52:\tlearn: 0.5962427\ttotal: 7.71s\tremaining: 11.5s\n","53:\tlearn: 0.5956570\ttotal: 7.87s\tremaining: 11.4s\n","54:\tlearn: 0.5953336\ttotal: 7.96s\tremaining: 11.1s\n","55:\tlearn: 0.5948988\ttotal: 8.07s\tremaining: 11s\n","56:\tlearn: 0.5945478\ttotal: 8.18s\tremaining: 10.8s\n","57:\tlearn: 0.5942446\ttotal: 8.29s\tremaining: 10.6s\n","58:\tlearn: 0.5938196\ttotal: 8.4s\tremaining: 10.4s\n","59:\tlearn: 0.5934712\ttotal: 8.5s\tremaining: 10.2s\n","60:\tlearn: 0.5930520\ttotal: 8.62s\tremaining: 10s\n","61:\tlearn: 0.5927025\ttotal: 8.73s\tremaining: 9.86s\n","62:\tlearn: 0.5921931\ttotal: 8.86s\tremaining: 9.7s\n","63:\tlearn: 0.5918743\ttotal: 8.95s\tremaining: 9.51s\n","64:\tlearn: 0.5915792\ttotal: 9.04s\tremaining: 9.32s\n","65:\tlearn: 0.5910867\ttotal: 9.16s\tremaining: 9.16s\n","66:\tlearn: 0.5907238\ttotal: 9.28s\tremaining: 9s\n","67:\tlearn: 0.5904265\ttotal: 9.37s\tremaining: 8.82s\n","68:\tlearn: 0.5900866\ttotal: 9.49s\tremaining: 8.66s\n","69:\tlearn: 0.5897329\ttotal: 9.62s\tremaining: 8.52s\n","70:\tlearn: 0.5894766\ttotal: 9.7s\tremaining: 8.34s\n","71:\tlearn: 0.5892454\ttotal: 9.81s\tremaining: 8.17s\n","72:\tlearn: 0.5887798\ttotal: 9.93s\tremaining: 8.03s\n","73:\tlearn: 0.5884918\ttotal: 10s\tremaining: 7.87s\n","74:\tlearn: 0.5881756\ttotal: 10.1s\tremaining: 7.7s\n","75:\tlearn: 0.5879082\ttotal: 10.3s\tremaining: 7.56s\n","76:\tlearn: 0.5875714\ttotal: 10.4s\tremaining: 7.4s\n","77:\tlearn: 0.5871558\ttotal: 10.5s\tremaining: 7.25s\n","78:\tlearn: 0.5868423\ttotal: 10.6s\tremaining: 7.1s\n","79:\tlearn: 0.5865603\ttotal: 10.7s\tremaining: 6.93s\n","80:\tlearn: 0.5862614\ttotal: 10.8s\tremaining: 6.77s\n","81:\tlearn: 0.5859204\ttotal: 10.9s\tremaining: 6.63s\n","82:\tlearn: 0.5857187\ttotal: 11s\tremaining: 6.48s\n","83:\tlearn: 0.5854411\ttotal: 11.1s\tremaining: 6.33s\n","84:\tlearn: 0.5851609\ttotal: 11.2s\tremaining: 6.18s\n","85:\tlearn: 0.5849230\ttotal: 11.3s\tremaining: 6.04s\n","86:\tlearn: 0.5845749\ttotal: 11.4s\tremaining: 5.9s\n","87:\tlearn: 0.5843454\ttotal: 11.5s\tremaining: 5.75s\n","88:\tlearn: 0.5840331\ttotal: 11.6s\tremaining: 5.62s\n","89:\tlearn: 0.5836983\ttotal: 11.7s\tremaining: 5.48s\n","90:\tlearn: 0.5835188\ttotal: 11.8s\tremaining: 5.33s\n","91:\tlearn: 0.5833193\ttotal: 11.9s\tremaining: 5.19s\n","92:\tlearn: 0.5831052\ttotal: 12.1s\tremaining: 5.06s\n","93:\tlearn: 0.5829063\ttotal: 12.2s\tremaining: 4.91s\n","94:\tlearn: 0.5827517\ttotal: 12.3s\tremaining: 4.77s\n","95:\tlearn: 0.5825263\ttotal: 12.4s\tremaining: 4.64s\n","96:\tlearn: 0.5822630\ttotal: 12.5s\tremaining: 4.5s\n","97:\tlearn: 0.5819651\ttotal: 12.6s\tremaining: 4.36s\n","98:\tlearn: 0.5817562\ttotal: 12.7s\tremaining: 4.22s\n","99:\tlearn: 0.5815415\ttotal: 12.8s\tremaining: 4.09s\n","100:\tlearn: 0.5812997\ttotal: 12.9s\tremaining: 3.95s\n","101:\tlearn: 0.5809583\ttotal: 13s\tremaining: 3.82s\n","102:\tlearn: 0.5806797\ttotal: 13.1s\tremaining: 3.68s\n","103:\tlearn: 0.5805078\ttotal: 13.2s\tremaining: 3.54s\n","104:\tlearn: 0.5801822\ttotal: 13.3s\tremaining: 3.42s\n","105:\tlearn: 0.5797792\ttotal: 13.4s\tremaining: 3.29s\n","106:\tlearn: 0.5795050\ttotal: 13.5s\tremaining: 3.16s\n","107:\tlearn: 0.5792809\ttotal: 13.6s\tremaining: 3.03s\n","108:\tlearn: 0.5790667\ttotal: 13.7s\tremaining: 2.89s\n","109:\tlearn: 0.5788798\ttotal: 13.8s\tremaining: 2.76s\n","110:\tlearn: 0.5785900\ttotal: 13.9s\tremaining: 2.63s\n","111:\tlearn: 0.5783265\ttotal: 14s\tremaining: 2.51s\n","112:\tlearn: 0.5780695\ttotal: 14.1s\tremaining: 2.38s\n","113:\tlearn: 0.5778597\ttotal: 14.2s\tremaining: 2.25s\n","114:\tlearn: 0.5775886\ttotal: 14.4s\tremaining: 2.12s\n","115:\tlearn: 0.5773245\ttotal: 14.5s\tremaining: 2s\n","116:\tlearn: 0.5770916\ttotal: 14.6s\tremaining: 1.87s\n","117:\tlearn: 0.5768951\ttotal: 14.7s\tremaining: 1.74s\n","118:\tlearn: 0.5765930\ttotal: 14.8s\tremaining: 1.61s\n","119:\tlearn: 0.5764506\ttotal: 14.9s\tremaining: 1.49s\n","120:\tlearn: 0.5763056\ttotal: 15s\tremaining: 1.36s\n","121:\tlearn: 0.5762693\ttotal: 15s\tremaining: 1.23s\n","122:\tlearn: 0.5759936\ttotal: 15.1s\tremaining: 1.11s\n","123:\tlearn: 0.5756999\ttotal: 15.3s\tremaining: 985ms\n","124:\tlearn: 0.5754768\ttotal: 15.4s\tremaining: 860ms\n","125:\tlearn: 0.5752398\ttotal: 15.5s\tremaining: 738ms\n","126:\tlearn: 0.5749657\ttotal: 15.6s\tremaining: 614ms\n","127:\tlearn: 0.5748450\ttotal: 15.7s\tremaining: 490ms\n","128:\tlearn: 0.5745800\ttotal: 15.8s\tremaining: 367ms\n","129:\tlearn: 0.5743872\ttotal: 15.9s\tremaining: 244ms\n","130:\tlearn: 0.5741348\ttotal: 16s\tremaining: 122ms\n","131:\tlearn: 0.5738719\ttotal: 16.1s\tremaining: 0us\n","0:\tlearn: 0.6747901\ttotal: 112ms\tremaining: 14.7s\n","1:\tlearn: 0.6632097\ttotal: 224ms\tremaining: 14.5s\n","2:\tlearn: 0.6541269\ttotal: 354ms\tremaining: 15.2s\n","3:\tlearn: 0.6469164\ttotal: 500ms\tremaining: 16s\n","4:\tlearn: 0.6423826\ttotal: 602ms\tremaining: 15.3s\n","5:\tlearn: 0.6379912\ttotal: 779ms\tremaining: 16.4s\n","6:\tlearn: 0.6345062\ttotal: 961ms\tremaining: 17.2s\n","7:\tlearn: 0.6317891\ttotal: 1.19s\tremaining: 18.4s\n","8:\tlearn: 0.6293348\ttotal: 1.43s\tremaining: 19.6s\n","9:\tlearn: 0.6274333\ttotal: 1.58s\tremaining: 19.3s\n","10:\tlearn: 0.6246821\ttotal: 1.78s\tremaining: 19.6s\n","11:\tlearn: 0.6230844\ttotal: 2s\tremaining: 20s\n","12:\tlearn: 0.6208586\ttotal: 2.19s\tremaining: 20s\n","13:\tlearn: 0.6195336\ttotal: 2.43s\tremaining: 20.5s\n","14:\tlearn: 0.6181797\ttotal: 2.62s\tremaining: 20.4s\n","15:\tlearn: 0.6169256\ttotal: 2.84s\tremaining: 20.6s\n","16:\tlearn: 0.6159283\ttotal: 3.03s\tremaining: 20.5s\n","17:\tlearn: 0.6149709\ttotal: 3.21s\tremaining: 20.3s\n","18:\tlearn: 0.6141014\ttotal: 3.39s\tremaining: 20.2s\n","19:\tlearn: 0.6125953\ttotal: 3.64s\tremaining: 20.4s\n","20:\tlearn: 0.6117678\ttotal: 3.88s\tremaining: 20.5s\n","21:\tlearn: 0.6108966\ttotal: 4.11s\tremaining: 20.6s\n","22:\tlearn: 0.6103576\ttotal: 4.3s\tremaining: 20.4s\n","23:\tlearn: 0.6096425\ttotal: 4.52s\tremaining: 20.4s\n","24:\tlearn: 0.6091131\ttotal: 4.71s\tremaining: 20.2s\n","25:\tlearn: 0.6084932\ttotal: 4.92s\tremaining: 20s\n","26:\tlearn: 0.6079503\ttotal: 5.04s\tremaining: 19.6s\n","27:\tlearn: 0.6073413\ttotal: 5.14s\tremaining: 19.1s\n","28:\tlearn: 0.6066632\ttotal: 5.25s\tremaining: 18.6s\n","29:\tlearn: 0.6062566\ttotal: 5.34s\tremaining: 18.2s\n","30:\tlearn: 0.6057377\ttotal: 5.44s\tremaining: 17.7s\n","31:\tlearn: 0.6052801\ttotal: 5.54s\tremaining: 17.3s\n","32:\tlearn: 0.6048049\ttotal: 5.64s\tremaining: 16.9s\n","33:\tlearn: 0.6042117\ttotal: 5.75s\tremaining: 16.6s\n","34:\tlearn: 0.6038859\ttotal: 5.85s\tremaining: 16.2s\n","35:\tlearn: 0.6034885\ttotal: 5.95s\tremaining: 15.9s\n","36:\tlearn: 0.6031454\ttotal: 6.06s\tremaining: 15.6s\n","37:\tlearn: 0.6026298\ttotal: 6.16s\tremaining: 15.2s\n","38:\tlearn: 0.6023205\ttotal: 6.27s\tremaining: 15s\n","39:\tlearn: 0.6018136\ttotal: 6.39s\tremaining: 14.7s\n","40:\tlearn: 0.6014172\ttotal: 6.49s\tremaining: 14.4s\n","41:\tlearn: 0.6010174\ttotal: 6.58s\tremaining: 14.1s\n","42:\tlearn: 0.6006188\ttotal: 6.7s\tremaining: 13.9s\n","43:\tlearn: 0.6000775\ttotal: 6.84s\tremaining: 13.7s\n","44:\tlearn: 0.5996878\ttotal: 6.94s\tremaining: 13.4s\n","45:\tlearn: 0.5992723\ttotal: 7.04s\tremaining: 13.2s\n","46:\tlearn: 0.5989846\ttotal: 7.14s\tremaining: 12.9s\n","47:\tlearn: 0.5983777\ttotal: 7.26s\tremaining: 12.7s\n","48:\tlearn: 0.5979521\ttotal: 7.38s\tremaining: 12.5s\n","49:\tlearn: 0.5976562\ttotal: 7.47s\tremaining: 12.3s\n","50:\tlearn: 0.5971667\ttotal: 7.57s\tremaining: 12s\n","51:\tlearn: 0.5965641\ttotal: 7.71s\tremaining: 11.9s\n","52:\tlearn: 0.5962147\ttotal: 7.8s\tremaining: 11.6s\n","53:\tlearn: 0.5958219\ttotal: 7.92s\tremaining: 11.4s\n","54:\tlearn: 0.5954801\ttotal: 8.01s\tremaining: 11.2s\n","55:\tlearn: 0.5949609\ttotal: 8.11s\tremaining: 11s\n","56:\tlearn: 0.5945807\ttotal: 8.22s\tremaining: 10.8s\n","57:\tlearn: 0.5941958\ttotal: 8.32s\tremaining: 10.6s\n","58:\tlearn: 0.5939143\ttotal: 8.41s\tremaining: 10.4s\n","59:\tlearn: 0.5935061\ttotal: 8.55s\tremaining: 10.3s\n","60:\tlearn: 0.5932216\ttotal: 8.65s\tremaining: 10.1s\n","61:\tlearn: 0.5929002\ttotal: 8.75s\tremaining: 9.88s\n","62:\tlearn: 0.5923411\ttotal: 8.89s\tremaining: 9.74s\n","63:\tlearn: 0.5919816\ttotal: 8.99s\tremaining: 9.55s\n","64:\tlearn: 0.5916433\ttotal: 9.1s\tremaining: 9.38s\n","65:\tlearn: 0.5914249\ttotal: 9.19s\tremaining: 9.19s\n","66:\tlearn: 0.5912025\ttotal: 9.28s\tremaining: 9s\n","67:\tlearn: 0.5907902\ttotal: 9.39s\tremaining: 8.83s\n","68:\tlearn: 0.5904691\ttotal: 9.48s\tremaining: 8.66s\n","69:\tlearn: 0.5902166\ttotal: 9.59s\tremaining: 8.49s\n","70:\tlearn: 0.5898970\ttotal: 9.71s\tremaining: 8.34s\n","71:\tlearn: 0.5895911\ttotal: 9.81s\tremaining: 8.18s\n","72:\tlearn: 0.5892362\ttotal: 9.98s\tremaining: 8.06s\n","73:\tlearn: 0.5888505\ttotal: 10.1s\tremaining: 7.91s\n","74:\tlearn: 0.5885979\ttotal: 10.2s\tremaining: 7.74s\n","75:\tlearn: 0.5883029\ttotal: 10.3s\tremaining: 7.58s\n","76:\tlearn: 0.5879373\ttotal: 10.4s\tremaining: 7.43s\n","77:\tlearn: 0.5876645\ttotal: 10.5s\tremaining: 7.27s\n","78:\tlearn: 0.5871932\ttotal: 10.6s\tremaining: 7.11s\n","79:\tlearn: 0.5869212\ttotal: 10.7s\tremaining: 6.97s\n","80:\tlearn: 0.5865854\ttotal: 10.8s\tremaining: 6.81s\n","81:\tlearn: 0.5861629\ttotal: 11s\tremaining: 6.68s\n","82:\tlearn: 0.5857789\ttotal: 11.1s\tremaining: 6.53s\n","83:\tlearn: 0.5853849\ttotal: 11.2s\tremaining: 6.39s\n","84:\tlearn: 0.5851009\ttotal: 11.3s\tremaining: 6.25s\n","85:\tlearn: 0.5848445\ttotal: 11.4s\tremaining: 6.09s\n","86:\tlearn: 0.5845517\ttotal: 11.5s\tremaining: 5.95s\n","87:\tlearn: 0.5842845\ttotal: 11.6s\tremaining: 5.8s\n","88:\tlearn: 0.5840138\ttotal: 11.7s\tremaining: 5.67s\n","89:\tlearn: 0.5837769\ttotal: 11.8s\tremaining: 5.53s\n","90:\tlearn: 0.5835867\ttotal: 12s\tremaining: 5.39s\n","91:\tlearn: 0.5833720\ttotal: 12.1s\tremaining: 5.25s\n","92:\tlearn: 0.5831866\ttotal: 12.2s\tremaining: 5.1s\n","93:\tlearn: 0.5829362\ttotal: 12.3s\tremaining: 4.97s\n","94:\tlearn: 0.5826638\ttotal: 12.4s\tremaining: 4.82s\n","95:\tlearn: 0.5823487\ttotal: 12.5s\tremaining: 4.68s\n","96:\tlearn: 0.5820950\ttotal: 12.6s\tremaining: 4.54s\n","97:\tlearn: 0.5819401\ttotal: 12.7s\tremaining: 4.39s\n","98:\tlearn: 0.5816953\ttotal: 12.8s\tremaining: 4.25s\n","99:\tlearn: 0.5814735\ttotal: 12.9s\tremaining: 4.12s\n","100:\tlearn: 0.5811643\ttotal: 13s\tremaining: 3.98s\n","101:\tlearn: 0.5808742\ttotal: 13.1s\tremaining: 3.85s\n","102:\tlearn: 0.5805610\ttotal: 13.2s\tremaining: 3.72s\n","103:\tlearn: 0.5802953\ttotal: 13.3s\tremaining: 3.58s\n","104:\tlearn: 0.5801265\ttotal: 13.4s\tremaining: 3.45s\n","105:\tlearn: 0.5798378\ttotal: 13.5s\tremaining: 3.32s\n","106:\tlearn: 0.5795866\ttotal: 13.6s\tremaining: 3.19s\n","107:\tlearn: 0.5793263\ttotal: 13.7s\tremaining: 3.05s\n","108:\tlearn: 0.5791548\ttotal: 13.8s\tremaining: 2.92s\n","109:\tlearn: 0.5791091\ttotal: 13.9s\tremaining: 2.78s\n","110:\tlearn: 0.5788677\ttotal: 14s\tremaining: 2.65s\n","111:\tlearn: 0.5787201\ttotal: 14.1s\tremaining: 2.52s\n","112:\tlearn: 0.5785851\ttotal: 14.2s\tremaining: 2.38s\n","113:\tlearn: 0.5783368\ttotal: 14.3s\tremaining: 2.25s\n","114:\tlearn: 0.5781116\ttotal: 14.4s\tremaining: 2.12s\n","115:\tlearn: 0.5778469\ttotal: 14.5s\tremaining: 2s\n","116:\tlearn: 0.5775945\ttotal: 14.6s\tremaining: 1.87s\n","117:\tlearn: 0.5773676\ttotal: 14.7s\tremaining: 1.75s\n","118:\tlearn: 0.5772284\ttotal: 14.8s\tremaining: 1.61s\n","119:\tlearn: 0.5770320\ttotal: 14.9s\tremaining: 1.49s\n","120:\tlearn: 0.5767819\ttotal: 15.1s\tremaining: 1.37s\n","121:\tlearn: 0.5765295\ttotal: 15.2s\tremaining: 1.25s\n","122:\tlearn: 0.5763238\ttotal: 15.4s\tremaining: 1.13s\n","123:\tlearn: 0.5761166\ttotal: 15.6s\tremaining: 1s\n","124:\tlearn: 0.5758963\ttotal: 15.8s\tremaining: 886ms\n","125:\tlearn: 0.5757875\ttotal: 16s\tremaining: 760ms\n","126:\tlearn: 0.5755735\ttotal: 16.2s\tremaining: 637ms\n","127:\tlearn: 0.5753543\ttotal: 16.4s\tremaining: 511ms\n","128:\tlearn: 0.5750618\ttotal: 16.6s\tremaining: 385ms\n","129:\tlearn: 0.5748647\ttotal: 16.8s\tremaining: 258ms\n","130:\tlearn: 0.5746426\ttotal: 16.9s\tremaining: 129ms\n","131:\tlearn: 0.5743765\ttotal: 17.1s\tremaining: 0us\n","0:\tlearn: 0.6757697\ttotal: 231ms\tremaining: 30.3s\n","1:\tlearn: 0.6636778\ttotal: 429ms\tremaining: 27.9s\n","2:\tlearn: 0.6552288\ttotal: 581ms\tremaining: 25s\n","3:\tlearn: 0.6480566\ttotal: 687ms\tremaining: 22s\n","4:\tlearn: 0.6430172\ttotal: 799ms\tremaining: 20.3s\n","5:\tlearn: 0.6382983\ttotal: 899ms\tremaining: 18.9s\n","6:\tlearn: 0.6346732\ttotal: 1.01s\tremaining: 18.1s\n","7:\tlearn: 0.6317495\ttotal: 1.13s\tremaining: 17.5s\n","8:\tlearn: 0.6283455\ttotal: 1.25s\tremaining: 17.1s\n","9:\tlearn: 0.6263226\ttotal: 1.36s\tremaining: 16.6s\n","10:\tlearn: 0.6242570\ttotal: 1.51s\tremaining: 16.6s\n","11:\tlearn: 0.6227879\ttotal: 1.61s\tremaining: 16.1s\n","12:\tlearn: 0.6202731\ttotal: 1.74s\tremaining: 15.9s\n","13:\tlearn: 0.6184591\ttotal: 1.85s\tremaining: 15.6s\n","14:\tlearn: 0.6171861\ttotal: 1.96s\tremaining: 15.3s\n","15:\tlearn: 0.6163126\ttotal: 2.06s\tremaining: 14.9s\n","16:\tlearn: 0.6152340\ttotal: 2.17s\tremaining: 14.7s\n","17:\tlearn: 0.6140016\ttotal: 2.3s\tremaining: 14.6s\n","18:\tlearn: 0.6131855\ttotal: 2.4s\tremaining: 14.3s\n","19:\tlearn: 0.6124671\ttotal: 2.5s\tremaining: 14s\n","20:\tlearn: 0.6118528\ttotal: 2.62s\tremaining: 13.8s\n","21:\tlearn: 0.6111374\ttotal: 2.71s\tremaining: 13.5s\n","22:\tlearn: 0.6099508\ttotal: 2.81s\tremaining: 13.3s\n","23:\tlearn: 0.6092995\ttotal: 2.92s\tremaining: 13.1s\n","24:\tlearn: 0.6086469\ttotal: 3.02s\tremaining: 12.9s\n","25:\tlearn: 0.6080000\ttotal: 3.14s\tremaining: 12.8s\n","26:\tlearn: 0.6072068\ttotal: 3.25s\tremaining: 12.6s\n","27:\tlearn: 0.6067624\ttotal: 3.35s\tremaining: 12.5s\n","28:\tlearn: 0.6062325\ttotal: 3.46s\tremaining: 12.3s\n","29:\tlearn: 0.6058266\ttotal: 3.58s\tremaining: 12.2s\n","30:\tlearn: 0.6053512\ttotal: 3.68s\tremaining: 12s\n","31:\tlearn: 0.6048532\ttotal: 3.78s\tremaining: 11.8s\n","32:\tlearn: 0.6046064\ttotal: 3.87s\tremaining: 11.6s\n","33:\tlearn: 0.6039759\ttotal: 3.98s\tremaining: 11.5s\n","34:\tlearn: 0.6036162\ttotal: 4.09s\tremaining: 11.3s\n","35:\tlearn: 0.6031702\ttotal: 4.18s\tremaining: 11.2s\n","36:\tlearn: 0.6028221\ttotal: 4.28s\tremaining: 11s\n","37:\tlearn: 0.6022486\ttotal: 4.42s\tremaining: 10.9s\n","38:\tlearn: 0.6019711\ttotal: 4.51s\tremaining: 10.8s\n","39:\tlearn: 0.6014937\ttotal: 4.64s\tremaining: 10.7s\n","40:\tlearn: 0.6010547\ttotal: 4.76s\tremaining: 10.6s\n","41:\tlearn: 0.6006606\ttotal: 4.87s\tremaining: 10.4s\n","42:\tlearn: 0.6002767\ttotal: 4.97s\tremaining: 10.3s\n","43:\tlearn: 0.5996521\ttotal: 5.07s\tremaining: 10.1s\n","44:\tlearn: 0.5991701\ttotal: 5.19s\tremaining: 10s\n","45:\tlearn: 0.5986084\ttotal: 5.3s\tremaining: 9.9s\n","46:\tlearn: 0.5982402\ttotal: 5.39s\tremaining: 9.74s\n","47:\tlearn: 0.5976480\ttotal: 5.5s\tremaining: 9.63s\n","48:\tlearn: 0.5971876\ttotal: 5.63s\tremaining: 9.54s\n","49:\tlearn: 0.5967303\ttotal: 5.76s\tremaining: 9.44s\n","50:\tlearn: 0.5963541\ttotal: 5.86s\tremaining: 9.3s\n","51:\tlearn: 0.5960329\ttotal: 5.94s\tremaining: 9.14s\n","52:\tlearn: 0.5955012\ttotal: 6.06s\tremaining: 9.03s\n","53:\tlearn: 0.5949522\ttotal: 6.19s\tremaining: 8.94s\n","54:\tlearn: 0.5945300\ttotal: 6.3s\tremaining: 8.82s\n","55:\tlearn: 0.5941436\ttotal: 6.4s\tremaining: 8.69s\n","56:\tlearn: 0.5937923\ttotal: 6.52s\tremaining: 8.58s\n","57:\tlearn: 0.5933696\ttotal: 6.65s\tremaining: 8.49s\n","58:\tlearn: 0.5930013\ttotal: 6.79s\tremaining: 8.4s\n","59:\tlearn: 0.5926000\ttotal: 6.91s\tremaining: 8.29s\n","60:\tlearn: 0.5922530\ttotal: 7.03s\tremaining: 8.18s\n","61:\tlearn: 0.5919105\ttotal: 7.13s\tremaining: 8.05s\n","62:\tlearn: 0.5914228\ttotal: 7.25s\tremaining: 7.94s\n","63:\tlearn: 0.5911576\ttotal: 7.33s\tremaining: 7.79s\n","64:\tlearn: 0.5908211\ttotal: 7.47s\tremaining: 7.7s\n","65:\tlearn: 0.5904994\ttotal: 7.55s\tremaining: 7.55s\n","66:\tlearn: 0.5900696\ttotal: 7.69s\tremaining: 7.46s\n","67:\tlearn: 0.5897836\ttotal: 7.81s\tremaining: 7.35s\n","68:\tlearn: 0.5894005\ttotal: 7.92s\tremaining: 7.23s\n","69:\tlearn: 0.5890964\ttotal: 8.04s\tremaining: 7.12s\n","70:\tlearn: 0.5887776\ttotal: 8.14s\tremaining: 6.99s\n","71:\tlearn: 0.5885348\ttotal: 8.22s\tremaining: 6.85s\n","72:\tlearn: 0.5881989\ttotal: 8.35s\tremaining: 6.75s\n","73:\tlearn: 0.5878718\ttotal: 8.46s\tremaining: 6.63s\n","74:\tlearn: 0.5876427\ttotal: 8.56s\tremaining: 6.5s\n","75:\tlearn: 0.5873555\ttotal: 8.65s\tremaining: 6.38s\n","76:\tlearn: 0.5871141\ttotal: 8.78s\tremaining: 6.27s\n","77:\tlearn: 0.5868781\ttotal: 8.86s\tremaining: 6.13s\n","78:\tlearn: 0.5865270\ttotal: 8.95s\tremaining: 6.01s\n","79:\tlearn: 0.5862675\ttotal: 9.06s\tremaining: 5.89s\n","80:\tlearn: 0.5861428\ttotal: 9.14s\tremaining: 5.76s\n","81:\tlearn: 0.5859198\ttotal: 9.24s\tremaining: 5.64s\n","82:\tlearn: 0.5855746\ttotal: 9.38s\tremaining: 5.54s\n","83:\tlearn: 0.5853356\ttotal: 9.46s\tremaining: 5.41s\n","84:\tlearn: 0.5850231\ttotal: 9.59s\tremaining: 5.3s\n","85:\tlearn: 0.5848127\ttotal: 9.67s\tremaining: 5.17s\n","86:\tlearn: 0.5845601\ttotal: 9.8s\tremaining: 5.07s\n","87:\tlearn: 0.5843171\ttotal: 9.89s\tremaining: 4.95s\n","88:\tlearn: 0.5840041\ttotal: 9.98s\tremaining: 4.82s\n","89:\tlearn: 0.5836936\ttotal: 10.1s\tremaining: 4.71s\n","90:\tlearn: 0.5834759\ttotal: 10.2s\tremaining: 4.6s\n","91:\tlearn: 0.5832085\ttotal: 10.3s\tremaining: 4.49s\n","92:\tlearn: 0.5829377\ttotal: 10.5s\tremaining: 4.41s\n","93:\tlearn: 0.5827083\ttotal: 10.7s\tremaining: 4.32s\n","94:\tlearn: 0.5825361\ttotal: 10.9s\tremaining: 4.24s\n","95:\tlearn: 0.5823272\ttotal: 11s\tremaining: 4.14s\n","96:\tlearn: 0.5820493\ttotal: 11.3s\tremaining: 4.07s\n","97:\tlearn: 0.5818459\ttotal: 11.4s\tremaining: 3.96s\n","98:\tlearn: 0.5815715\ttotal: 11.6s\tremaining: 3.88s\n","99:\tlearn: 0.5812059\ttotal: 11.8s\tremaining: 3.79s\n","100:\tlearn: 0.5809453\ttotal: 12.1s\tremaining: 3.7s\n","101:\tlearn: 0.5807323\ttotal: 12.2s\tremaining: 3.6s\n","102:\tlearn: 0.5804520\ttotal: 12.4s\tremaining: 3.48s\n","103:\tlearn: 0.5801400\ttotal: 12.6s\tremaining: 3.39s\n","104:\tlearn: 0.5799217\ttotal: 12.8s\tremaining: 3.29s\n","105:\tlearn: 0.5796989\ttotal: 13s\tremaining: 3.19s\n","106:\tlearn: 0.5794702\ttotal: 13.2s\tremaining: 3.08s\n","107:\tlearn: 0.5792517\ttotal: 13.3s\tremaining: 2.96s\n","108:\tlearn: 0.5790533\ttotal: 13.6s\tremaining: 2.86s\n","109:\tlearn: 0.5789319\ttotal: 13.7s\tremaining: 2.74s\n","110:\tlearn: 0.5787398\ttotal: 13.9s\tremaining: 2.63s\n","111:\tlearn: 0.5784581\ttotal: 14.1s\tremaining: 2.52s\n","112:\tlearn: 0.5782408\ttotal: 14.3s\tremaining: 2.41s\n","113:\tlearn: 0.5780074\ttotal: 14.5s\tremaining: 2.29s\n","114:\tlearn: 0.5778979\ttotal: 14.6s\tremaining: 2.17s\n","115:\tlearn: 0.5777136\ttotal: 14.8s\tremaining: 2.04s\n","116:\tlearn: 0.5774601\ttotal: 14.9s\tremaining: 1.91s\n","117:\tlearn: 0.5772587\ttotal: 15s\tremaining: 1.77s\n","118:\tlearn: 0.5769146\ttotal: 15.1s\tremaining: 1.65s\n","119:\tlearn: 0.5766816\ttotal: 15.2s\tremaining: 1.52s\n","120:\tlearn: 0.5766152\ttotal: 15.3s\tremaining: 1.39s\n","121:\tlearn: 0.5763497\ttotal: 15.4s\tremaining: 1.26s\n","122:\tlearn: 0.5760599\ttotal: 15.5s\tremaining: 1.14s\n","123:\tlearn: 0.5758948\ttotal: 15.6s\tremaining: 1.01s\n","124:\tlearn: 0.5757046\ttotal: 15.7s\tremaining: 879ms\n","125:\tlearn: 0.5754507\ttotal: 15.8s\tremaining: 753ms\n","126:\tlearn: 0.5751531\ttotal: 15.9s\tremaining: 627ms\n","127:\tlearn: 0.5748930\ttotal: 16s\tremaining: 501ms\n","128:\tlearn: 0.5746147\ttotal: 16.1s\tremaining: 375ms\n","129:\tlearn: 0.5743973\ttotal: 16.2s\tremaining: 250ms\n","130:\tlearn: 0.5741741\ttotal: 16.3s\tremaining: 125ms\n","131:\tlearn: 0.5739409\ttotal: 16.4s\tremaining: 0us\n","0:\tlearn: 0.6755140\ttotal: 119ms\tremaining: 15.6s\n","1:\tlearn: 0.6628703\ttotal: 247ms\tremaining: 16.1s\n","2:\tlearn: 0.6542770\ttotal: 390ms\tremaining: 16.8s\n","3:\tlearn: 0.6479015\ttotal: 510ms\tremaining: 16.3s\n","4:\tlearn: 0.6428555\ttotal: 617ms\tremaining: 15.7s\n","5:\tlearn: 0.6389459\ttotal: 728ms\tremaining: 15.3s\n","6:\tlearn: 0.6349990\ttotal: 856ms\tremaining: 15.3s\n","7:\tlearn: 0.6319594\ttotal: 964ms\tremaining: 14.9s\n","8:\tlearn: 0.6285756\ttotal: 1.08s\tremaining: 14.7s\n","9:\tlearn: 0.6261452\ttotal: 1.19s\tremaining: 14.6s\n","10:\tlearn: 0.6241060\ttotal: 1.31s\tremaining: 14.5s\n","11:\tlearn: 0.6224773\ttotal: 1.44s\tremaining: 14.4s\n","12:\tlearn: 0.6210823\ttotal: 1.55s\tremaining: 14.2s\n","13:\tlearn: 0.6196299\ttotal: 1.67s\tremaining: 14.1s\n","14:\tlearn: 0.6182720\ttotal: 1.79s\tremaining: 13.9s\n","15:\tlearn: 0.6170837\ttotal: 1.87s\tremaining: 13.6s\n","16:\tlearn: 0.6160621\ttotal: 1.98s\tremaining: 13.4s\n","17:\tlearn: 0.6153429\ttotal: 2.09s\tremaining: 13.2s\n","18:\tlearn: 0.6142762\ttotal: 2.2s\tremaining: 13.1s\n","19:\tlearn: 0.6134388\ttotal: 2.29s\tremaining: 12.8s\n","20:\tlearn: 0.6126663\ttotal: 2.41s\tremaining: 12.7s\n","21:\tlearn: 0.6118957\ttotal: 2.52s\tremaining: 12.6s\n","22:\tlearn: 0.6112429\ttotal: 2.63s\tremaining: 12.5s\n","23:\tlearn: 0.6101281\ttotal: 2.72s\tremaining: 12.3s\n","24:\tlearn: 0.6094715\ttotal: 2.83s\tremaining: 12.1s\n","25:\tlearn: 0.6086076\ttotal: 2.94s\tremaining: 12s\n","26:\tlearn: 0.6080943\ttotal: 3.04s\tremaining: 11.8s\n","27:\tlearn: 0.6075658\ttotal: 3.15s\tremaining: 11.7s\n","28:\tlearn: 0.6071188\ttotal: 3.27s\tremaining: 11.6s\n","29:\tlearn: 0.6066849\ttotal: 3.37s\tremaining: 11.5s\n","30:\tlearn: 0.6062614\ttotal: 3.49s\tremaining: 11.4s\n","31:\tlearn: 0.6058227\ttotal: 3.58s\tremaining: 11.2s\n","32:\tlearn: 0.6048504\ttotal: 3.68s\tremaining: 11.1s\n","33:\tlearn: 0.6044247\ttotal: 3.8s\tremaining: 11s\n","34:\tlearn: 0.6041525\ttotal: 3.88s\tremaining: 10.8s\n","35:\tlearn: 0.6037393\ttotal: 3.98s\tremaining: 10.6s\n","36:\tlearn: 0.6030528\ttotal: 4.11s\tremaining: 10.5s\n","37:\tlearn: 0.6025543\ttotal: 4.21s\tremaining: 10.4s\n","38:\tlearn: 0.6022136\ttotal: 4.33s\tremaining: 10.3s\n","39:\tlearn: 0.6018657\ttotal: 4.44s\tremaining: 10.2s\n","40:\tlearn: 0.6015397\ttotal: 4.56s\tremaining: 10.1s\n","41:\tlearn: 0.6009570\ttotal: 4.68s\tremaining: 10s\n","42:\tlearn: 0.6005275\ttotal: 4.79s\tremaining: 9.9s\n","43:\tlearn: 0.6000728\ttotal: 4.9s\tremaining: 9.8s\n","44:\tlearn: 0.5996687\ttotal: 5s\tremaining: 9.66s\n","45:\tlearn: 0.5992865\ttotal: 5.09s\tremaining: 9.53s\n","46:\tlearn: 0.5987874\ttotal: 5.19s\tremaining: 9.39s\n","47:\tlearn: 0.5982146\ttotal: 5.3s\tremaining: 9.28s\n","48:\tlearn: 0.5978328\ttotal: 5.4s\tremaining: 9.14s\n","49:\tlearn: 0.5973264\ttotal: 5.54s\tremaining: 9.09s\n","50:\tlearn: 0.5968910\ttotal: 5.65s\tremaining: 8.97s\n","51:\tlearn: 0.5965283\ttotal: 5.74s\tremaining: 8.82s\n","52:\tlearn: 0.5959908\ttotal: 5.86s\tremaining: 8.73s\n","53:\tlearn: 0.5955403\ttotal: 5.96s\tremaining: 8.62s\n","54:\tlearn: 0.5951003\ttotal: 6.09s\tremaining: 8.53s\n","55:\tlearn: 0.5947744\ttotal: 6.19s\tremaining: 8.4s\n","56:\tlearn: 0.5944734\ttotal: 6.28s\tremaining: 8.26s\n","57:\tlearn: 0.5940076\ttotal: 6.4s\tremaining: 8.17s\n","58:\tlearn: 0.5936596\ttotal: 6.5s\tremaining: 8.05s\n","59:\tlearn: 0.5933436\ttotal: 6.61s\tremaining: 7.94s\n","60:\tlearn: 0.5930111\ttotal: 6.71s\tremaining: 7.81s\n","61:\tlearn: 0.5924705\ttotal: 6.91s\tremaining: 7.8s\n","62:\tlearn: 0.5919096\ttotal: 7.16s\tremaining: 7.84s\n","63:\tlearn: 0.5916162\ttotal: 7.36s\tremaining: 7.82s\n","64:\tlearn: 0.5912396\ttotal: 7.54s\tremaining: 7.77s\n","65:\tlearn: 0.5908866\ttotal: 7.74s\tremaining: 7.74s\n","66:\tlearn: 0.5906110\ttotal: 7.93s\tremaining: 7.69s\n","67:\tlearn: 0.5903345\ttotal: 8.14s\tremaining: 7.67s\n","68:\tlearn: 0.5899684\ttotal: 8.37s\tremaining: 7.64s\n","69:\tlearn: 0.5895814\ttotal: 8.56s\tremaining: 7.59s\n","70:\tlearn: 0.5893390\ttotal: 8.78s\tremaining: 7.54s\n","71:\tlearn: 0.5889356\ttotal: 9.02s\tremaining: 7.52s\n","72:\tlearn: 0.5885704\ttotal: 9.24s\tremaining: 7.47s\n","73:\tlearn: 0.5883368\ttotal: 9.41s\tremaining: 7.37s\n","74:\tlearn: 0.5881650\ttotal: 9.57s\tremaining: 7.27s\n","75:\tlearn: 0.5879235\ttotal: 9.77s\tremaining: 7.2s\n","76:\tlearn: 0.5876224\ttotal: 9.95s\tremaining: 7.11s\n","77:\tlearn: 0.5872323\ttotal: 10.1s\tremaining: 6.99s\n","78:\tlearn: 0.5870257\ttotal: 10.3s\tremaining: 6.88s\n","79:\tlearn: 0.5866082\ttotal: 10.5s\tremaining: 6.83s\n","80:\tlearn: 0.5862775\ttotal: 10.7s\tremaining: 6.76s\n","81:\tlearn: 0.5859759\ttotal: 10.9s\tremaining: 6.65s\n","82:\tlearn: 0.5857966\ttotal: 11s\tremaining: 6.49s\n","83:\tlearn: 0.5855234\ttotal: 11.1s\tremaining: 6.33s\n","84:\tlearn: 0.5852793\ttotal: 11.2s\tremaining: 6.19s\n","85:\tlearn: 0.5849604\ttotal: 11.3s\tremaining: 6.04s\n","86:\tlearn: 0.5846377\ttotal: 11.4s\tremaining: 5.9s\n","87:\tlearn: 0.5843062\ttotal: 11.5s\tremaining: 5.76s\n","88:\tlearn: 0.5840717\ttotal: 11.6s\tremaining: 5.61s\n","89:\tlearn: 0.5838248\ttotal: 11.7s\tremaining: 5.46s\n","90:\tlearn: 0.5834851\ttotal: 11.8s\tremaining: 5.32s\n","91:\tlearn: 0.5831521\ttotal: 11.9s\tremaining: 5.18s\n","92:\tlearn: 0.5831016\ttotal: 12s\tremaining: 5.02s\n","93:\tlearn: 0.5828745\ttotal: 12.1s\tremaining: 4.89s\n","94:\tlearn: 0.5825759\ttotal: 12.2s\tremaining: 4.75s\n","95:\tlearn: 0.5823232\ttotal: 12.3s\tremaining: 4.62s\n","96:\tlearn: 0.5820750\ttotal: 12.4s\tremaining: 4.48s\n","97:\tlearn: 0.5816598\ttotal: 12.5s\tremaining: 4.35s\n","98:\tlearn: 0.5813688\ttotal: 12.7s\tremaining: 4.22s\n","99:\tlearn: 0.5812080\ttotal: 12.7s\tremaining: 4.07s\n","100:\tlearn: 0.5809855\ttotal: 12.8s\tremaining: 3.93s\n","101:\tlearn: 0.5807950\ttotal: 12.9s\tremaining: 3.8s\n","102:\tlearn: 0.5806109\ttotal: 13s\tremaining: 3.66s\n","103:\tlearn: 0.5803575\ttotal: 13.1s\tremaining: 3.53s\n","104:\tlearn: 0.5800922\ttotal: 13.2s\tremaining: 3.4s\n","105:\tlearn: 0.5797650\ttotal: 13.3s\tremaining: 3.27s\n","106:\tlearn: 0.5795868\ttotal: 13.4s\tremaining: 3.13s\n","107:\tlearn: 0.5792633\ttotal: 13.5s\tremaining: 3s\n","108:\tlearn: 0.5790717\ttotal: 13.6s\tremaining: 2.87s\n","109:\tlearn: 0.5788237\ttotal: 13.7s\tremaining: 2.75s\n","110:\tlearn: 0.5786583\ttotal: 13.8s\tremaining: 2.61s\n","111:\tlearn: 0.5783431\ttotal: 13.9s\tremaining: 2.49s\n","112:\tlearn: 0.5782162\ttotal: 14s\tremaining: 2.35s\n","113:\tlearn: 0.5779620\ttotal: 14.1s\tremaining: 2.23s\n","114:\tlearn: 0.5777311\ttotal: 14.2s\tremaining: 2.1s\n","115:\tlearn: 0.5774768\ttotal: 14.3s\tremaining: 1.98s\n","116:\tlearn: 0.5773091\ttotal: 14.4s\tremaining: 1.85s\n","117:\tlearn: 0.5770895\ttotal: 14.5s\tremaining: 1.72s\n","118:\tlearn: 0.5768864\ttotal: 14.6s\tremaining: 1.59s\n","119:\tlearn: 0.5766266\ttotal: 14.7s\tremaining: 1.47s\n","120:\tlearn: 0.5763993\ttotal: 14.8s\tremaining: 1.35s\n","121:\tlearn: 0.5761964\ttotal: 14.9s\tremaining: 1.22s\n","122:\tlearn: 0.5759804\ttotal: 15s\tremaining: 1.1s\n","123:\tlearn: 0.5757726\ttotal: 15.1s\tremaining: 976ms\n","124:\tlearn: 0.5756286\ttotal: 15.2s\tremaining: 852ms\n","125:\tlearn: 0.5753624\ttotal: 15.3s\tremaining: 729ms\n","126:\tlearn: 0.5752019\ttotal: 15.4s\tremaining: 606ms\n","127:\tlearn: 0.5749904\ttotal: 15.5s\tremaining: 484ms\n","128:\tlearn: 0.5749651\ttotal: 15.6s\tremaining: 362ms\n","129:\tlearn: 0.5749492\ttotal: 15.6s\tremaining: 240ms\n","130:\tlearn: 0.5747546\ttotal: 15.7s\tremaining: 120ms\n","131:\tlearn: 0.5744779\ttotal: 15.8s\tremaining: 0us\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","train: 0.7504771912104541\n","test: 0.6840961559131573\n","test conf matrix: \n"," [[20605 11268]\n"," [ 8903 23090]]\n"]}]},{"cell_type":"markdown","source":["## Downsampling 338 feat"],"metadata":{"id":"dPT5eLgKavIm"}},{"cell_type":"code","source":["x_train = pd.read_parquet(path + '/ds_x_train.parquet').drop('id', axis=1)\n","x_test = pd.read_parquet(path + '/ds_x_test.parquet').drop('id', axis=1)\n","y_train = pd.read_parquet(path + '/ds_y_train.parquet').drop('id', axis=1)\n","y_test = pd.read_parquet(path + '/ds_y_test.parquet').drop('id', axis=1)"],"metadata":{"id":"JqNIgSt7dIGQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["x_train.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ywxuDL8cc_go","executionInfo":{"status":"ok","timestamp":1707827544128,"user_tz":-240,"elapsed":290,"user":{"displayName":"Евгений Малов","userId":"06257165098392198337"}},"outputId":"5496d6e4-92e3-452f-abcb-07c23e553189"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(149018, 337)"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["model_log_reg = LogisticRegression()\n","model_log_reg.fit(x_train, y_train)\n","\n","pred_train = model_log_reg.predict(x_train)\n","pred_test = model_log_reg.predict(x_test)\n","\n","print(f'train: {roc_auc_score(y_train, pred_train)}')\n","print(f'test: {roc_auc_score(y_test, pred_test)}')\n","print(f'test conf matrix: \\n {confusion_matrix(y_test, pred_test)}')"],"metadata":{"id":"qNu7YLkcdIKI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1707827521235,"user_tz":-240,"elapsed":13350,"user":{"displayName":"Евгений Малов","userId":"06257165098392198337"}},"outputId":"a6bfac0d-986a-4a84-952b-6ca5104cbe6a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["train: 0.6767731106075037\n","test: 0.6741866563801957\n","test conf matrix: \n"," [[21059 10894]\n"," [ 9915 21998]]\n"]}]},{"cell_type":"code","source":["model_lgbm = LGBMClassifier()\n","model_lgbm.fit(x_train, y_train)\n","\n","pred_train = model_lgbm.predict(x_train)\n","pred_test = model_lgbm.predict(x_test)\n","\n","print(f'train: {roc_auc_score(y_train, pred_train)}')\n","print(f'test: {roc_auc_score(y_test, pred_test)}')\n","print(f'test conf matrix: \\n {confusion_matrix(y_test, pred_test)}')"],"metadata":{"id":"IyBNkQuSdINS","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1707827576479,"user_tz":-240,"elapsed":17974,"user":{"displayName":"Евгений Малов","userId":"06257165098392198337"}},"outputId":"ac23cfaf-1283-43fc-ff50-ef8eee7d39f5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[LightGBM] [Info] Number of positive: 74529, number of negative: 74489\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.553334 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 4670\n","[LightGBM] [Info] Number of data points in the train set: 149018, number of used features: 306\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500134 -> initscore=0.000537\n","[LightGBM] [Info] Start training from score 0.000537\n","train: 0.7009620125306208\n","test: 0.684856250218486\n","test conf matrix: \n"," [[21061 10892]\n"," [ 9236 22677]]\n"]}]},{"cell_type":"code","source":["model_lgbm = LGBMClassifier()\n","model_lgbm.fit(x_train, y_train)\n","\n","pred_proba = pd.DataFrame({'proba': model_lgbm.predict_proba(x_test)[:,1].T})\n","\n","treshold = 0\n","best_res = 0\n","for i in np.arange(0.05, 0.95, 0.05):\n","    res = pred_proba['proba'].apply(lambda x:0 if x < i else 1)\n","    tmp_score = round(roc_auc_score(y_test, res), 4)\n","    if tmp_score > best_res:\n","        best_res = tmp_score\n","        treshold = i\n","    print(f\"i - {i}, res - {tmp_score}\")\n","print(treshold)\n","print(best_res)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1-7-1Q00NWVc","executionInfo":{"status":"ok","timestamp":1708008012996,"user_tz":-240,"elapsed":18548,"user":{"displayName":"Евгений Малов","userId":"06257165098392198337"}},"outputId":"c2cf658f-b76f-4e15-fd92-76ce30bf4ec9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[LightGBM] [Info] Number of positive: 74529, number of negative: 74489\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.559626 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 4670\n","[LightGBM] [Info] Number of data points in the train set: 149018, number of used features: 306\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500134 -> initscore=0.000537\n","[LightGBM] [Info] Start training from score 0.000537\n","i - 0.05, res - 0.5001\n","i - 0.1, res - 0.5128\n","i - 0.15000000000000002, res - 0.5447\n","i - 0.2, res - 0.5781\n","i - 0.25, res - 0.6069\n","i - 0.3, res - 0.6324\n","i - 0.35000000000000003, res - 0.6548\n","i - 0.4, res - 0.6711\n","i - 0.45, res - 0.6821\n","i - 0.5, res - 0.6849\n","i - 0.55, res - 0.6805\n","i - 0.6000000000000001, res - 0.6674\n","i - 0.6500000000000001, res - 0.6457\n","i - 0.7000000000000001, res - 0.6139\n","i - 0.7500000000000001, res - 0.58\n","i - 0.8, res - 0.5433\n","i - 0.8500000000000001, res - 0.5151\n","i - 0.9000000000000001, res - 0.5026\n","0.5\n","0.6849\n"]}]},{"cell_type":"code","source":["model_xbm = XGBClassifier()\n","model_xbm.fit(x_train, y_train)\n","\n","pred_train = model_xbm.predict(x_train)\n","pred_test = model_xbm.predict(x_test)\n","\n","print(f'train: {roc_auc_score(y_train, pred_train)}')\n","print(f'test: {roc_auc_score(y_test, pred_test)}')\n","print(f'test conf matrix: \\n {confusion_matrix(y_test, pred_test)}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"g8gXdnK8bvlI","executionInfo":{"status":"ok","timestamp":1707827607793,"user_tz":-240,"elapsed":19474,"user":{"displayName":"Евгений Малов","userId":"06257165098392198337"}},"outputId":"c7e90686-699b-402f-bb64-15f63f54a773"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["train: 0.7359282872713648\n","test: 0.681980685606305\n","test conf matrix: \n"," [[21489 10464]\n"," [ 9847 22066]]\n"]}]},{"cell_type":"code","source":["model_xbm = XGBClassifier()\n","model_xbm.fit(x_train, y_train)\n","\n","pred_proba = pd.DataFrame({'proba': model_xbm.predict_proba(x_test)[:,1].T})\n","\n","treshold = 0\n","best_res = 0\n","for i in np.arange(0.05, 0.95, 0.05):\n","    res = pred_proba['proba'].apply(lambda x:0 if x < i else 1)\n","    tmp_score = round(roc_auc_score(y_test, res), 4)\n","    if tmp_score > best_res:\n","        best_res = tmp_score\n","        treshold = i\n","    print(f\"i - {i}, res - {tmp_score}\")\n","print(treshold)\n","print(best_res)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qcVsmr7iMb6W","executionInfo":{"status":"ok","timestamp":1708007932661,"user_tz":-240,"elapsed":20220,"user":{"displayName":"Евгений Малов","userId":"06257165098392198337"}},"outputId":"e37f5231-7920-4f40-c06b-cc7aa6e2ed28"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["i - 0.05, res - 0.5022\n","i - 0.1, res - 0.5221\n","i - 0.15000000000000002, res - 0.5545\n","i - 0.2, res - 0.588\n","i - 0.25, res - 0.6165\n","i - 0.3, res - 0.6403\n","i - 0.35000000000000003, res - 0.659\n","i - 0.4, res - 0.6723\n","i - 0.45, res - 0.6803\n","i - 0.5, res - 0.682\n","i - 0.55, res - 0.6769\n","i - 0.6000000000000001, res - 0.6667\n","i - 0.6500000000000001, res - 0.6485\n","i - 0.7000000000000001, res - 0.6239\n","i - 0.7500000000000001, res - 0.596\n","i - 0.8, res - 0.5665\n","i - 0.8500000000000001, res - 0.5364\n","i - 0.9000000000000001, res - 0.5129\n","0.5\n","0.682\n"]}]},{"cell_type":"code","source":["model_catb = CatBoostClassifier()\n","model_catb.fit(x_train, y_train)\n","\n","pred_train = model_catb.predict(x_train)\n","pred_test = model_catb.predict(x_test)\n","\n","print(f'train: {roc_auc_score(y_train, pred_train)}')\n","print(f'test: {roc_auc_score(y_test, pred_test)}')\n","print(f'test conf matrix: \\n {confusion_matrix(y_test, pred_test)}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"K-nm4qKsbvuO","executionInfo":{"status":"ok","timestamp":1707827781089,"user_tz":-240,"elapsed":163692,"user":{"displayName":"Евгений Малов","userId":"06257165098392198337"}},"outputId":"529b0278-560f-44f8-bae6-f5cbd4a846ea"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Learning rate set to 0.087278\n","0:\tlearn: 0.6853203\ttotal: 227ms\tremaining: 3m 46s\n","1:\tlearn: 0.6784332\ttotal: 386ms\tremaining: 3m 12s\n","2:\tlearn: 0.6722734\ttotal: 572ms\tremaining: 3m 10s\n","3:\tlearn: 0.6668897\ttotal: 762ms\tremaining: 3m 9s\n","4:\tlearn: 0.6621721\ttotal: 931ms\tremaining: 3m 5s\n","5:\tlearn: 0.6583644\ttotal: 1.09s\tremaining: 3m\n","6:\tlearn: 0.6548527\ttotal: 1.27s\tremaining: 2m 59s\n","7:\tlearn: 0.6515997\ttotal: 1.44s\tremaining: 2m 58s\n","8:\tlearn: 0.6486987\ttotal: 1.58s\tremaining: 2m 54s\n","9:\tlearn: 0.6458337\ttotal: 1.77s\tremaining: 2m 55s\n","10:\tlearn: 0.6435745\ttotal: 1.91s\tremaining: 2m 51s\n","11:\tlearn: 0.6411898\ttotal: 2.06s\tremaining: 2m 49s\n","12:\tlearn: 0.6391037\ttotal: 2.23s\tremaining: 2m 49s\n","13:\tlearn: 0.6372205\ttotal: 2.4s\tremaining: 2m 49s\n","14:\tlearn: 0.6354741\ttotal: 2.56s\tremaining: 2m 48s\n","15:\tlearn: 0.6339281\ttotal: 2.75s\tremaining: 2m 48s\n","16:\tlearn: 0.6324966\ttotal: 3.03s\tremaining: 2m 55s\n","17:\tlearn: 0.6312105\ttotal: 3.33s\tremaining: 3m 1s\n","18:\tlearn: 0.6297366\ttotal: 3.63s\tremaining: 3m 7s\n","19:\tlearn: 0.6283756\ttotal: 3.93s\tremaining: 3m 12s\n","20:\tlearn: 0.6270470\ttotal: 4.29s\tremaining: 3m 20s\n","21:\tlearn: 0.6259955\ttotal: 4.58s\tremaining: 3m 23s\n","22:\tlearn: 0.6251003\ttotal: 4.81s\tremaining: 3m 24s\n","23:\tlearn: 0.6240241\ttotal: 5.11s\tremaining: 3m 27s\n","24:\tlearn: 0.6230403\ttotal: 5.44s\tremaining: 3m 32s\n","25:\tlearn: 0.6220473\ttotal: 5.72s\tremaining: 3m 34s\n","26:\tlearn: 0.6212786\ttotal: 6.01s\tremaining: 3m 36s\n","27:\tlearn: 0.6204698\ttotal: 6.29s\tremaining: 3m 38s\n","28:\tlearn: 0.6197485\ttotal: 6.53s\tremaining: 3m 38s\n","29:\tlearn: 0.6190729\ttotal: 6.69s\tremaining: 3m 36s\n","30:\tlearn: 0.6182226\ttotal: 6.87s\tremaining: 3m 34s\n","31:\tlearn: 0.6176202\ttotal: 7s\tremaining: 3m 31s\n","32:\tlearn: 0.6169877\ttotal: 7.16s\tremaining: 3m 29s\n","33:\tlearn: 0.6162964\ttotal: 7.32s\tremaining: 3m 27s\n","34:\tlearn: 0.6157414\ttotal: 7.45s\tremaining: 3m 25s\n","35:\tlearn: 0.6151353\ttotal: 7.6s\tremaining: 3m 23s\n","36:\tlearn: 0.6144736\ttotal: 7.75s\tremaining: 3m 21s\n","37:\tlearn: 0.6139149\ttotal: 7.91s\tremaining: 3m 20s\n","38:\tlearn: 0.6134219\ttotal: 8.08s\tremaining: 3m 19s\n","39:\tlearn: 0.6128850\ttotal: 8.23s\tremaining: 3m 17s\n","40:\tlearn: 0.6122752\ttotal: 8.41s\tremaining: 3m 16s\n","41:\tlearn: 0.6118384\ttotal: 8.53s\tremaining: 3m 14s\n","42:\tlearn: 0.6113904\ttotal: 8.69s\tremaining: 3m 13s\n","43:\tlearn: 0.6109074\ttotal: 8.86s\tremaining: 3m 12s\n","44:\tlearn: 0.6104551\ttotal: 9.03s\tremaining: 3m 11s\n","45:\tlearn: 0.6099486\ttotal: 9.2s\tremaining: 3m 10s\n","46:\tlearn: 0.6094380\ttotal: 9.34s\tremaining: 3m 9s\n","47:\tlearn: 0.6090024\ttotal: 9.5s\tremaining: 3m 8s\n","48:\tlearn: 0.6086525\ttotal: 9.64s\tremaining: 3m 7s\n","49:\tlearn: 0.6083133\ttotal: 9.77s\tremaining: 3m 5s\n","50:\tlearn: 0.6078785\ttotal: 9.93s\tremaining: 3m 4s\n","51:\tlearn: 0.6075098\ttotal: 10.1s\tremaining: 3m 3s\n","52:\tlearn: 0.6071912\ttotal: 10.2s\tremaining: 3m 3s\n","53:\tlearn: 0.6068191\ttotal: 10.4s\tremaining: 3m 2s\n","54:\tlearn: 0.6065556\ttotal: 10.5s\tremaining: 3m 1s\n","55:\tlearn: 0.6062771\ttotal: 10.7s\tremaining: 2m 59s\n","56:\tlearn: 0.6059925\ttotal: 10.8s\tremaining: 2m 58s\n","57:\tlearn: 0.6057459\ttotal: 10.9s\tremaining: 2m 57s\n","58:\tlearn: 0.6054378\ttotal: 11.1s\tremaining: 2m 56s\n","59:\tlearn: 0.6051938\ttotal: 11.2s\tremaining: 2m 55s\n","60:\tlearn: 0.6048908\ttotal: 11.4s\tremaining: 2m 55s\n","61:\tlearn: 0.6046331\ttotal: 11.5s\tremaining: 2m 54s\n","62:\tlearn: 0.6043254\ttotal: 11.7s\tremaining: 2m 53s\n","63:\tlearn: 0.6039572\ttotal: 11.8s\tremaining: 2m 52s\n","64:\tlearn: 0.6036944\ttotal: 12s\tremaining: 2m 52s\n","65:\tlearn: 0.6033729\ttotal: 12.1s\tremaining: 2m 51s\n","66:\tlearn: 0.6031156\ttotal: 12.3s\tremaining: 2m 50s\n","67:\tlearn: 0.6028700\ttotal: 12.4s\tremaining: 2m 49s\n","68:\tlearn: 0.6025331\ttotal: 12.6s\tremaining: 2m 49s\n","69:\tlearn: 0.6022922\ttotal: 12.7s\tremaining: 2m 48s\n","70:\tlearn: 0.6020400\ttotal: 12.9s\tremaining: 2m 48s\n","71:\tlearn: 0.6016383\ttotal: 13s\tremaining: 2m 47s\n","72:\tlearn: 0.6014343\ttotal: 13.2s\tremaining: 2m 47s\n","73:\tlearn: 0.6012354\ttotal: 13.3s\tremaining: 2m 46s\n","74:\tlearn: 0.6009852\ttotal: 13.5s\tremaining: 2m 46s\n","75:\tlearn: 0.6007512\ttotal: 13.6s\tremaining: 2m 45s\n","76:\tlearn: 0.6005347\ttotal: 13.8s\tremaining: 2m 44s\n","77:\tlearn: 0.6003331\ttotal: 13.9s\tremaining: 2m 44s\n","78:\tlearn: 0.6000966\ttotal: 14.1s\tremaining: 2m 43s\n","79:\tlearn: 0.5997198\ttotal: 14.2s\tremaining: 2m 43s\n","80:\tlearn: 0.5994801\ttotal: 14.4s\tremaining: 2m 43s\n","81:\tlearn: 0.5992782\ttotal: 14.6s\tremaining: 2m 42s\n","82:\tlearn: 0.5989645\ttotal: 14.8s\tremaining: 2m 43s\n","83:\tlearn: 0.5987868\ttotal: 14.9s\tremaining: 2m 42s\n","84:\tlearn: 0.5985435\ttotal: 15.1s\tremaining: 2m 42s\n","85:\tlearn: 0.5982448\ttotal: 15.2s\tremaining: 2m 41s\n","86:\tlearn: 0.5980524\ttotal: 15.4s\tremaining: 2m 41s\n","87:\tlearn: 0.5978589\ttotal: 15.5s\tremaining: 2m 40s\n","88:\tlearn: 0.5976705\ttotal: 15.7s\tremaining: 2m 40s\n","89:\tlearn: 0.5975146\ttotal: 15.8s\tremaining: 2m 39s\n","90:\tlearn: 0.5973618\ttotal: 15.9s\tremaining: 2m 39s\n","91:\tlearn: 0.5972047\ttotal: 16.1s\tremaining: 2m 38s\n","92:\tlearn: 0.5970373\ttotal: 16.2s\tremaining: 2m 38s\n","93:\tlearn: 0.5968973\ttotal: 16.4s\tremaining: 2m 37s\n","94:\tlearn: 0.5967316\ttotal: 16.5s\tremaining: 2m 37s\n","95:\tlearn: 0.5965777\ttotal: 16.8s\tremaining: 2m 37s\n","96:\tlearn: 0.5963900\ttotal: 17s\tremaining: 2m 38s\n","97:\tlearn: 0.5962612\ttotal: 17.3s\tremaining: 2m 38s\n","98:\tlearn: 0.5961371\ttotal: 17.5s\tremaining: 2m 39s\n","99:\tlearn: 0.5958901\ttotal: 17.8s\tremaining: 2m 40s\n","100:\tlearn: 0.5957768\ttotal: 18.1s\tremaining: 2m 40s\n","101:\tlearn: 0.5956978\ttotal: 18.3s\tremaining: 2m 41s\n","102:\tlearn: 0.5954547\ttotal: 18.6s\tremaining: 2m 42s\n","103:\tlearn: 0.5953300\ttotal: 18.9s\tremaining: 2m 42s\n","104:\tlearn: 0.5952163\ttotal: 19.2s\tremaining: 2m 43s\n","105:\tlearn: 0.5950753\ttotal: 19.5s\tremaining: 2m 44s\n","106:\tlearn: 0.5949197\ttotal: 19.8s\tremaining: 2m 45s\n","107:\tlearn: 0.5947860\ttotal: 20s\tremaining: 2m 45s\n","108:\tlearn: 0.5946757\ttotal: 20.2s\tremaining: 2m 45s\n","109:\tlearn: 0.5944816\ttotal: 20.4s\tremaining: 2m 44s\n","110:\tlearn: 0.5943173\ttotal: 20.5s\tremaining: 2m 44s\n","111:\tlearn: 0.5942315\ttotal: 20.7s\tremaining: 2m 43s\n","112:\tlearn: 0.5939592\ttotal: 20.8s\tremaining: 2m 43s\n","113:\tlearn: 0.5938170\ttotal: 21s\tremaining: 2m 43s\n","114:\tlearn: 0.5936994\ttotal: 21.1s\tremaining: 2m 42s\n","115:\tlearn: 0.5935636\ttotal: 21.2s\tremaining: 2m 41s\n","116:\tlearn: 0.5934232\ttotal: 21.4s\tremaining: 2m 41s\n","117:\tlearn: 0.5932865\ttotal: 21.5s\tremaining: 2m 40s\n","118:\tlearn: 0.5931494\ttotal: 21.7s\tremaining: 2m 40s\n","119:\tlearn: 0.5930380\ttotal: 21.8s\tremaining: 2m 39s\n","120:\tlearn: 0.5928830\ttotal: 22s\tremaining: 2m 39s\n","121:\tlearn: 0.5926478\ttotal: 22.1s\tremaining: 2m 39s\n","122:\tlearn: 0.5925399\ttotal: 22.3s\tremaining: 2m 38s\n","123:\tlearn: 0.5924225\ttotal: 22.4s\tremaining: 2m 38s\n","124:\tlearn: 0.5923318\ttotal: 22.5s\tremaining: 2m 37s\n","125:\tlearn: 0.5921459\ttotal: 22.7s\tremaining: 2m 37s\n","126:\tlearn: 0.5919693\ttotal: 22.8s\tremaining: 2m 36s\n","127:\tlearn: 0.5918396\ttotal: 23s\tremaining: 2m 36s\n","128:\tlearn: 0.5917317\ttotal: 23.2s\tremaining: 2m 36s\n","129:\tlearn: 0.5916015\ttotal: 23.3s\tremaining: 2m 36s\n","130:\tlearn: 0.5914779\ttotal: 23.5s\tremaining: 2m 35s\n","131:\tlearn: 0.5913950\ttotal: 23.6s\tremaining: 2m 35s\n","132:\tlearn: 0.5912766\ttotal: 23.7s\tremaining: 2m 34s\n","133:\tlearn: 0.5911610\ttotal: 23.9s\tremaining: 2m 34s\n","134:\tlearn: 0.5910695\ttotal: 24s\tremaining: 2m 33s\n","135:\tlearn: 0.5908838\ttotal: 24.2s\tremaining: 2m 33s\n","136:\tlearn: 0.5907224\ttotal: 24.3s\tremaining: 2m 33s\n","137:\tlearn: 0.5905940\ttotal: 24.4s\tremaining: 2m 32s\n","138:\tlearn: 0.5904257\ttotal: 24.6s\tremaining: 2m 32s\n","139:\tlearn: 0.5902844\ttotal: 24.8s\tremaining: 2m 32s\n","140:\tlearn: 0.5901587\ttotal: 24.9s\tremaining: 2m 31s\n","141:\tlearn: 0.5900083\ttotal: 25.1s\tremaining: 2m 31s\n","142:\tlearn: 0.5899136\ttotal: 25.2s\tremaining: 2m 31s\n","143:\tlearn: 0.5898012\ttotal: 25.3s\tremaining: 2m 30s\n","144:\tlearn: 0.5896715\ttotal: 25.5s\tremaining: 2m 30s\n","145:\tlearn: 0.5895151\ttotal: 25.6s\tremaining: 2m 29s\n","146:\tlearn: 0.5893781\ttotal: 25.8s\tremaining: 2m 29s\n","147:\tlearn: 0.5892376\ttotal: 26s\tremaining: 2m 29s\n","148:\tlearn: 0.5891321\ttotal: 26.1s\tremaining: 2m 29s\n","149:\tlearn: 0.5889958\ttotal: 26.2s\tremaining: 2m 28s\n","150:\tlearn: 0.5888668\ttotal: 26.4s\tremaining: 2m 28s\n","151:\tlearn: 0.5887210\ttotal: 26.6s\tremaining: 2m 28s\n","152:\tlearn: 0.5885791\ttotal: 26.7s\tremaining: 2m 27s\n","153:\tlearn: 0.5884507\ttotal: 26.9s\tremaining: 2m 27s\n","154:\tlearn: 0.5883164\ttotal: 27s\tremaining: 2m 27s\n","155:\tlearn: 0.5881869\ttotal: 27.2s\tremaining: 2m 26s\n","156:\tlearn: 0.5880541\ttotal: 27.3s\tremaining: 2m 26s\n","157:\tlearn: 0.5879328\ttotal: 27.4s\tremaining: 2m 26s\n","158:\tlearn: 0.5877862\ttotal: 27.6s\tremaining: 2m 26s\n","159:\tlearn: 0.5876786\ttotal: 27.8s\tremaining: 2m 25s\n","160:\tlearn: 0.5875611\ttotal: 27.9s\tremaining: 2m 25s\n","161:\tlearn: 0.5874152\ttotal: 28.1s\tremaining: 2m 25s\n","162:\tlearn: 0.5872912\ttotal: 28.2s\tremaining: 2m 24s\n","163:\tlearn: 0.5871630\ttotal: 28.3s\tremaining: 2m 24s\n","164:\tlearn: 0.5870474\ttotal: 28.4s\tremaining: 2m 23s\n","165:\tlearn: 0.5869529\ttotal: 28.6s\tremaining: 2m 23s\n","166:\tlearn: 0.5868397\ttotal: 28.7s\tremaining: 2m 23s\n","167:\tlearn: 0.5867436\ttotal: 28.8s\tremaining: 2m 22s\n","168:\tlearn: 0.5866171\ttotal: 29s\tremaining: 2m 22s\n","169:\tlearn: 0.5864610\ttotal: 29.2s\tremaining: 2m 22s\n","170:\tlearn: 0.5863614\ttotal: 29.3s\tremaining: 2m 22s\n","171:\tlearn: 0.5862414\ttotal: 29.5s\tremaining: 2m 21s\n","172:\tlearn: 0.5861483\ttotal: 29.6s\tremaining: 2m 21s\n","173:\tlearn: 0.5860298\ttotal: 29.7s\tremaining: 2m 21s\n","174:\tlearn: 0.5859084\ttotal: 29.9s\tremaining: 2m 21s\n","175:\tlearn: 0.5857676\ttotal: 30.1s\tremaining: 2m 20s\n","176:\tlearn: 0.5856522\ttotal: 30.3s\tremaining: 2m 20s\n","177:\tlearn: 0.5855775\ttotal: 30.5s\tremaining: 2m 20s\n","178:\tlearn: 0.5854850\ttotal: 30.7s\tremaining: 2m 20s\n","179:\tlearn: 0.5853772\ttotal: 31s\tremaining: 2m 21s\n","180:\tlearn: 0.5852833\ttotal: 31.2s\tremaining: 2m 21s\n","181:\tlearn: 0.5851788\ttotal: 31.5s\tremaining: 2m 21s\n","182:\tlearn: 0.5850580\ttotal: 31.8s\tremaining: 2m 21s\n","183:\tlearn: 0.5849215\ttotal: 32s\tremaining: 2m 22s\n","184:\tlearn: 0.5848163\ttotal: 32.3s\tremaining: 2m 22s\n","185:\tlearn: 0.5846742\ttotal: 32.6s\tremaining: 2m 22s\n","186:\tlearn: 0.5845542\ttotal: 32.9s\tremaining: 2m 23s\n","187:\tlearn: 0.5844443\ttotal: 33.3s\tremaining: 2m 23s\n","188:\tlearn: 0.5843171\ttotal: 33.5s\tremaining: 2m 23s\n","189:\tlearn: 0.5842227\ttotal: 33.8s\tremaining: 2m 24s\n","190:\tlearn: 0.5840979\ttotal: 34s\tremaining: 2m 24s\n","191:\tlearn: 0.5840206\ttotal: 34.2s\tremaining: 2m 23s\n","192:\tlearn: 0.5838907\ttotal: 34.3s\tremaining: 2m 23s\n","193:\tlearn: 0.5837640\ttotal: 34.5s\tremaining: 2m 23s\n","194:\tlearn: 0.5836288\ttotal: 34.6s\tremaining: 2m 23s\n","195:\tlearn: 0.5835444\ttotal: 34.8s\tremaining: 2m 22s\n","196:\tlearn: 0.5834589\ttotal: 34.9s\tremaining: 2m 22s\n","197:\tlearn: 0.5833822\ttotal: 35s\tremaining: 2m 21s\n","198:\tlearn: 0.5832492\ttotal: 35.2s\tremaining: 2m 21s\n","199:\tlearn: 0.5831241\ttotal: 35.4s\tremaining: 2m 21s\n","200:\tlearn: 0.5830375\ttotal: 35.5s\tremaining: 2m 21s\n","201:\tlearn: 0.5829635\ttotal: 35.7s\tremaining: 2m 20s\n","202:\tlearn: 0.5828718\ttotal: 35.8s\tremaining: 2m 20s\n","203:\tlearn: 0.5827677\ttotal: 36s\tremaining: 2m 20s\n","204:\tlearn: 0.5826442\ttotal: 36.1s\tremaining: 2m 20s\n","205:\tlearn: 0.5825342\ttotal: 36.3s\tremaining: 2m 19s\n","206:\tlearn: 0.5824467\ttotal: 36.4s\tremaining: 2m 19s\n","207:\tlearn: 0.5823614\ttotal: 36.6s\tremaining: 2m 19s\n","208:\tlearn: 0.5822523\ttotal: 36.8s\tremaining: 2m 19s\n","209:\tlearn: 0.5821437\ttotal: 36.9s\tremaining: 2m 18s\n","210:\tlearn: 0.5820418\ttotal: 37.1s\tremaining: 2m 18s\n","211:\tlearn: 0.5819519\ttotal: 37.2s\tremaining: 2m 18s\n","212:\tlearn: 0.5818691\ttotal: 37.4s\tremaining: 2m 18s\n","213:\tlearn: 0.5817650\ttotal: 37.5s\tremaining: 2m 17s\n","214:\tlearn: 0.5816792\ttotal: 37.7s\tremaining: 2m 17s\n","215:\tlearn: 0.5815724\ttotal: 37.8s\tremaining: 2m 17s\n","216:\tlearn: 0.5814782\ttotal: 38s\tremaining: 2m 17s\n","217:\tlearn: 0.5813995\ttotal: 38.1s\tremaining: 2m 16s\n","218:\tlearn: 0.5813242\ttotal: 38.3s\tremaining: 2m 16s\n","219:\tlearn: 0.5812406\ttotal: 38.4s\tremaining: 2m 16s\n","220:\tlearn: 0.5811470\ttotal: 38.6s\tremaining: 2m 15s\n","221:\tlearn: 0.5810635\ttotal: 38.7s\tremaining: 2m 15s\n","222:\tlearn: 0.5809912\ttotal: 38.8s\tremaining: 2m 15s\n","223:\tlearn: 0.5809287\ttotal: 38.9s\tremaining: 2m 14s\n","224:\tlearn: 0.5808228\ttotal: 39.1s\tremaining: 2m 14s\n","225:\tlearn: 0.5807412\ttotal: 39.2s\tremaining: 2m 14s\n","226:\tlearn: 0.5806542\ttotal: 39.3s\tremaining: 2m 13s\n","227:\tlearn: 0.5805597\ttotal: 39.5s\tremaining: 2m 13s\n","228:\tlearn: 0.5804923\ttotal: 39.6s\tremaining: 2m 13s\n","229:\tlearn: 0.5804077\ttotal: 39.7s\tremaining: 2m 13s\n","230:\tlearn: 0.5803580\ttotal: 39.9s\tremaining: 2m 12s\n","231:\tlearn: 0.5802732\ttotal: 40s\tremaining: 2m 12s\n","232:\tlearn: 0.5801954\ttotal: 40.1s\tremaining: 2m 12s\n","233:\tlearn: 0.5801087\ttotal: 40.3s\tremaining: 2m 11s\n","234:\tlearn: 0.5800056\ttotal: 40.5s\tremaining: 2m 11s\n","235:\tlearn: 0.5798770\ttotal: 40.6s\tremaining: 2m 11s\n","236:\tlearn: 0.5797919\ttotal: 40.7s\tremaining: 2m 11s\n","237:\tlearn: 0.5796970\ttotal: 40.9s\tremaining: 2m 10s\n","238:\tlearn: 0.5796476\ttotal: 41s\tremaining: 2m 10s\n","239:\tlearn: 0.5795920\ttotal: 41.2s\tremaining: 2m 10s\n","240:\tlearn: 0.5795258\ttotal: 41.3s\tremaining: 2m 9s\n","241:\tlearn: 0.5794360\ttotal: 41.4s\tremaining: 2m 9s\n","242:\tlearn: 0.5793316\ttotal: 41.6s\tremaining: 2m 9s\n","243:\tlearn: 0.5792513\ttotal: 41.7s\tremaining: 2m 9s\n","244:\tlearn: 0.5791474\ttotal: 41.9s\tremaining: 2m 9s\n","245:\tlearn: 0.5790958\ttotal: 42s\tremaining: 2m 8s\n","246:\tlearn: 0.5790109\ttotal: 42.1s\tremaining: 2m 8s\n","247:\tlearn: 0.5789243\ttotal: 42.3s\tremaining: 2m 8s\n","248:\tlearn: 0.5788618\ttotal: 42.4s\tremaining: 2m 7s\n","249:\tlearn: 0.5787665\ttotal: 42.6s\tremaining: 2m 7s\n","250:\tlearn: 0.5786871\ttotal: 42.7s\tremaining: 2m 7s\n","251:\tlearn: 0.5786470\ttotal: 42.8s\tremaining: 2m 7s\n","252:\tlearn: 0.5785757\ttotal: 43s\tremaining: 2m 6s\n","253:\tlearn: 0.5784820\ttotal: 43.1s\tremaining: 2m 6s\n","254:\tlearn: 0.5783645\ttotal: 43.3s\tremaining: 2m 6s\n","255:\tlearn: 0.5782921\ttotal: 43.4s\tremaining: 2m 6s\n","256:\tlearn: 0.5782200\ttotal: 43.6s\tremaining: 2m 6s\n","257:\tlearn: 0.5781731\ttotal: 43.7s\tremaining: 2m 5s\n","258:\tlearn: 0.5780906\ttotal: 43.9s\tremaining: 2m 5s\n","259:\tlearn: 0.5780214\ttotal: 44s\tremaining: 2m 5s\n","260:\tlearn: 0.5779405\ttotal: 44.2s\tremaining: 2m 5s\n","261:\tlearn: 0.5778669\ttotal: 44.5s\tremaining: 2m 5s\n","262:\tlearn: 0.5777819\ttotal: 44.7s\tremaining: 2m 5s\n","263:\tlearn: 0.5776818\ttotal: 45s\tremaining: 2m 5s\n","264:\tlearn: 0.5775997\ttotal: 45.2s\tremaining: 2m 5s\n","265:\tlearn: 0.5775586\ttotal: 45.5s\tremaining: 2m 5s\n","266:\tlearn: 0.5775090\ttotal: 45.7s\tremaining: 2m 5s\n","267:\tlearn: 0.5774353\ttotal: 45.9s\tremaining: 2m 5s\n","268:\tlearn: 0.5773520\ttotal: 46.2s\tremaining: 2m 5s\n","269:\tlearn: 0.5772707\ttotal: 46.4s\tremaining: 2m 5s\n","270:\tlearn: 0.5771989\ttotal: 46.7s\tremaining: 2m 5s\n","271:\tlearn: 0.5771337\ttotal: 46.9s\tremaining: 2m 5s\n","272:\tlearn: 0.5770616\ttotal: 47.2s\tremaining: 2m 5s\n","273:\tlearn: 0.5769963\ttotal: 47.4s\tremaining: 2m 5s\n","274:\tlearn: 0.5769035\ttotal: 47.7s\tremaining: 2m 5s\n","275:\tlearn: 0.5768305\ttotal: 47.9s\tremaining: 2m 5s\n","276:\tlearn: 0.5767798\ttotal: 48s\tremaining: 2m 5s\n","277:\tlearn: 0.5766874\ttotal: 48.2s\tremaining: 2m 5s\n","278:\tlearn: 0.5766140\ttotal: 48.3s\tremaining: 2m 4s\n","279:\tlearn: 0.5765400\ttotal: 48.5s\tremaining: 2m 4s\n","280:\tlearn: 0.5764707\ttotal: 48.6s\tremaining: 2m 4s\n","281:\tlearn: 0.5764069\ttotal: 48.8s\tremaining: 2m 4s\n","282:\tlearn: 0.5763325\ttotal: 48.9s\tremaining: 2m 3s\n","283:\tlearn: 0.5762622\ttotal: 49s\tremaining: 2m 3s\n","284:\tlearn: 0.5762104\ttotal: 49.2s\tremaining: 2m 3s\n","285:\tlearn: 0.5761206\ttotal: 49.4s\tremaining: 2m 3s\n","286:\tlearn: 0.5760448\ttotal: 49.5s\tremaining: 2m 2s\n","287:\tlearn: 0.5759358\ttotal: 49.6s\tremaining: 2m 2s\n","288:\tlearn: 0.5758991\ttotal: 49.7s\tremaining: 2m 2s\n","289:\tlearn: 0.5758126\ttotal: 49.9s\tremaining: 2m 2s\n","290:\tlearn: 0.5757067\ttotal: 50.1s\tremaining: 2m 1s\n","291:\tlearn: 0.5756133\ttotal: 50.2s\tremaining: 2m 1s\n","292:\tlearn: 0.5755377\ttotal: 50.4s\tremaining: 2m 1s\n","293:\tlearn: 0.5754742\ttotal: 50.5s\tremaining: 2m 1s\n","294:\tlearn: 0.5754405\ttotal: 50.6s\tremaining: 2m\n","295:\tlearn: 0.5753610\ttotal: 50.8s\tremaining: 2m\n","296:\tlearn: 0.5752798\ttotal: 50.9s\tremaining: 2m\n","297:\tlearn: 0.5751820\ttotal: 51.1s\tremaining: 2m\n","298:\tlearn: 0.5751182\ttotal: 51.2s\tremaining: 2m\n","299:\tlearn: 0.5750701\ttotal: 51.3s\tremaining: 1m 59s\n","300:\tlearn: 0.5749804\ttotal: 51.5s\tremaining: 1m 59s\n","301:\tlearn: 0.5749180\ttotal: 51.6s\tremaining: 1m 59s\n","302:\tlearn: 0.5748869\ttotal: 51.7s\tremaining: 1m 59s\n","303:\tlearn: 0.5748430\ttotal: 51.9s\tremaining: 1m 58s\n","304:\tlearn: 0.5747946\ttotal: 52s\tremaining: 1m 58s\n","305:\tlearn: 0.5747347\ttotal: 52.1s\tremaining: 1m 58s\n","306:\tlearn: 0.5746561\ttotal: 52.3s\tremaining: 1m 58s\n","307:\tlearn: 0.5745604\ttotal: 52.4s\tremaining: 1m 57s\n","308:\tlearn: 0.5744880\ttotal: 52.6s\tremaining: 1m 57s\n","309:\tlearn: 0.5744355\ttotal: 52.7s\tremaining: 1m 57s\n","310:\tlearn: 0.5743679\ttotal: 52.9s\tremaining: 1m 57s\n","311:\tlearn: 0.5742885\ttotal: 53s\tremaining: 1m 56s\n","312:\tlearn: 0.5742237\ttotal: 53.2s\tremaining: 1m 56s\n","313:\tlearn: 0.5741608\ttotal: 53.3s\tremaining: 1m 56s\n","314:\tlearn: 0.5740927\ttotal: 53.4s\tremaining: 1m 56s\n","315:\tlearn: 0.5740396\ttotal: 53.5s\tremaining: 1m 55s\n","316:\tlearn: 0.5739809\ttotal: 53.7s\tremaining: 1m 55s\n","317:\tlearn: 0.5739137\ttotal: 53.8s\tremaining: 1m 55s\n","318:\tlearn: 0.5738162\ttotal: 53.9s\tremaining: 1m 55s\n","319:\tlearn: 0.5737373\ttotal: 54.1s\tremaining: 1m 55s\n","320:\tlearn: 0.5736788\ttotal: 54.3s\tremaining: 1m 54s\n","321:\tlearn: 0.5736078\ttotal: 54.4s\tremaining: 1m 54s\n","322:\tlearn: 0.5735829\ttotal: 54.5s\tremaining: 1m 54s\n","323:\tlearn: 0.5734960\ttotal: 54.7s\tremaining: 1m 54s\n","324:\tlearn: 0.5734450\ttotal: 54.8s\tremaining: 1m 53s\n","325:\tlearn: 0.5733665\ttotal: 54.9s\tremaining: 1m 53s\n","326:\tlearn: 0.5733008\ttotal: 55.1s\tremaining: 1m 53s\n","327:\tlearn: 0.5732365\ttotal: 55.2s\tremaining: 1m 53s\n","328:\tlearn: 0.5731647\ttotal: 55.4s\tremaining: 1m 52s\n","329:\tlearn: 0.5730947\ttotal: 55.5s\tremaining: 1m 52s\n","330:\tlearn: 0.5730229\ttotal: 55.7s\tremaining: 1m 52s\n","331:\tlearn: 0.5729663\ttotal: 55.8s\tremaining: 1m 52s\n","332:\tlearn: 0.5729025\ttotal: 56s\tremaining: 1m 52s\n","333:\tlearn: 0.5728297\ttotal: 56.1s\tremaining: 1m 51s\n","334:\tlearn: 0.5727797\ttotal: 56.2s\tremaining: 1m 51s\n","335:\tlearn: 0.5727330\ttotal: 56.4s\tremaining: 1m 51s\n","336:\tlearn: 0.5726802\ttotal: 56.5s\tremaining: 1m 51s\n","337:\tlearn: 0.5726216\ttotal: 56.6s\tremaining: 1m 50s\n","338:\tlearn: 0.5725214\ttotal: 56.8s\tremaining: 1m 50s\n","339:\tlearn: 0.5724796\ttotal: 56.9s\tremaining: 1m 50s\n","340:\tlearn: 0.5723953\ttotal: 57s\tremaining: 1m 50s\n","341:\tlearn: 0.5723428\ttotal: 57.2s\tremaining: 1m 50s\n","342:\tlearn: 0.5722928\ttotal: 57.3s\tremaining: 1m 49s\n","343:\tlearn: 0.5722394\ttotal: 57.4s\tremaining: 1m 49s\n","344:\tlearn: 0.5721698\ttotal: 57.5s\tremaining: 1m 49s\n","345:\tlearn: 0.5721124\ttotal: 57.7s\tremaining: 1m 49s\n","346:\tlearn: 0.5720274\ttotal: 57.8s\tremaining: 1m 48s\n","347:\tlearn: 0.5719704\ttotal: 58s\tremaining: 1m 48s\n","348:\tlearn: 0.5719096\ttotal: 58.2s\tremaining: 1m 48s\n","349:\tlearn: 0.5718412\ttotal: 58.6s\tremaining: 1m 48s\n","350:\tlearn: 0.5717927\ttotal: 58.8s\tremaining: 1m 48s\n","351:\tlearn: 0.5717444\ttotal: 59s\tremaining: 1m 48s\n","352:\tlearn: 0.5717369\ttotal: 59.2s\tremaining: 1m 48s\n","353:\tlearn: 0.5716641\ttotal: 59.4s\tremaining: 1m 48s\n","354:\tlearn: 0.5715906\ttotal: 59.7s\tremaining: 1m 48s\n","355:\tlearn: 0.5715449\ttotal: 59.9s\tremaining: 1m 48s\n","356:\tlearn: 0.5714866\ttotal: 1m\tremaining: 1m 48s\n","357:\tlearn: 0.5714399\ttotal: 1m\tremaining: 1m 48s\n","358:\tlearn: 0.5713801\ttotal: 1m\tremaining: 1m 48s\n","359:\tlearn: 0.5713187\ttotal: 1m\tremaining: 1m 48s\n","360:\tlearn: 0.5712668\ttotal: 1m 1s\tremaining: 1m 48s\n","361:\tlearn: 0.5711936\ttotal: 1m 1s\tremaining: 1m 48s\n","362:\tlearn: 0.5711407\ttotal: 1m 1s\tremaining: 1m 48s\n","363:\tlearn: 0.5710718\ttotal: 1m 1s\tremaining: 1m 47s\n","364:\tlearn: 0.5710333\ttotal: 1m 1s\tremaining: 1m 47s\n","365:\tlearn: 0.5709774\ttotal: 1m 2s\tremaining: 1m 47s\n","366:\tlearn: 0.5708821\ttotal: 1m 2s\tremaining: 1m 47s\n","367:\tlearn: 0.5708182\ttotal: 1m 2s\tremaining: 1m 47s\n","368:\tlearn: 0.5707751\ttotal: 1m 2s\tremaining: 1m 46s\n","369:\tlearn: 0.5706874\ttotal: 1m 2s\tremaining: 1m 46s\n","370:\tlearn: 0.5706124\ttotal: 1m 2s\tremaining: 1m 46s\n","371:\tlearn: 0.5705696\ttotal: 1m 2s\tremaining: 1m 46s\n","372:\tlearn: 0.5704999\ttotal: 1m 2s\tremaining: 1m 45s\n","373:\tlearn: 0.5704458\ttotal: 1m 3s\tremaining: 1m 45s\n","374:\tlearn: 0.5703748\ttotal: 1m 3s\tremaining: 1m 45s\n","375:\tlearn: 0.5702881\ttotal: 1m 3s\tremaining: 1m 45s\n","376:\tlearn: 0.5702088\ttotal: 1m 3s\tremaining: 1m 45s\n","377:\tlearn: 0.5701378\ttotal: 1m 3s\tremaining: 1m 44s\n","378:\tlearn: 0.5700597\ttotal: 1m 3s\tremaining: 1m 44s\n","379:\tlearn: 0.5699869\ttotal: 1m 3s\tremaining: 1m 44s\n","380:\tlearn: 0.5699348\ttotal: 1m 4s\tremaining: 1m 44s\n","381:\tlearn: 0.5698576\ttotal: 1m 4s\tremaining: 1m 43s\n","382:\tlearn: 0.5697820\ttotal: 1m 4s\tremaining: 1m 43s\n","383:\tlearn: 0.5696785\ttotal: 1m 4s\tremaining: 1m 43s\n","384:\tlearn: 0.5696301\ttotal: 1m 4s\tremaining: 1m 43s\n","385:\tlearn: 0.5695598\ttotal: 1m 4s\tremaining: 1m 43s\n","386:\tlearn: 0.5694953\ttotal: 1m 4s\tremaining: 1m 42s\n","387:\tlearn: 0.5694252\ttotal: 1m 5s\tremaining: 1m 42s\n","388:\tlearn: 0.5693493\ttotal: 1m 5s\tremaining: 1m 42s\n","389:\tlearn: 0.5692866\ttotal: 1m 5s\tremaining: 1m 42s\n","390:\tlearn: 0.5692283\ttotal: 1m 5s\tremaining: 1m 42s\n","391:\tlearn: 0.5691674\ttotal: 1m 5s\tremaining: 1m 42s\n","392:\tlearn: 0.5691337\ttotal: 1m 5s\tremaining: 1m 41s\n","393:\tlearn: 0.5690877\ttotal: 1m 6s\tremaining: 1m 41s\n","394:\tlearn: 0.5690287\ttotal: 1m 6s\tremaining: 1m 41s\n","395:\tlearn: 0.5689770\ttotal: 1m 6s\tremaining: 1m 41s\n","396:\tlearn: 0.5689017\ttotal: 1m 6s\tremaining: 1m 40s\n","397:\tlearn: 0.5688404\ttotal: 1m 6s\tremaining: 1m 40s\n","398:\tlearn: 0.5687682\ttotal: 1m 6s\tremaining: 1m 40s\n","399:\tlearn: 0.5687539\ttotal: 1m 6s\tremaining: 1m 40s\n","400:\tlearn: 0.5686525\ttotal: 1m 7s\tremaining: 1m 40s\n","401:\tlearn: 0.5685605\ttotal: 1m 7s\tremaining: 1m 40s\n","402:\tlearn: 0.5685362\ttotal: 1m 7s\tremaining: 1m 39s\n","403:\tlearn: 0.5684648\ttotal: 1m 7s\tremaining: 1m 39s\n","404:\tlearn: 0.5684165\ttotal: 1m 7s\tremaining: 1m 39s\n","405:\tlearn: 0.5683591\ttotal: 1m 7s\tremaining: 1m 39s\n","406:\tlearn: 0.5683120\ttotal: 1m 7s\tremaining: 1m 38s\n","407:\tlearn: 0.5682390\ttotal: 1m 7s\tremaining: 1m 38s\n","408:\tlearn: 0.5681830\ttotal: 1m 8s\tremaining: 1m 38s\n","409:\tlearn: 0.5681251\ttotal: 1m 8s\tremaining: 1m 38s\n","410:\tlearn: 0.5680553\ttotal: 1m 8s\tremaining: 1m 38s\n","411:\tlearn: 0.5679998\ttotal: 1m 8s\tremaining: 1m 37s\n","412:\tlearn: 0.5679259\ttotal: 1m 8s\tremaining: 1m 37s\n","413:\tlearn: 0.5678576\ttotal: 1m 8s\tremaining: 1m 37s\n","414:\tlearn: 0.5677857\ttotal: 1m 8s\tremaining: 1m 37s\n","415:\tlearn: 0.5677264\ttotal: 1m 9s\tremaining: 1m 37s\n","416:\tlearn: 0.5677207\ttotal: 1m 9s\tremaining: 1m 36s\n","417:\tlearn: 0.5676466\ttotal: 1m 9s\tremaining: 1m 36s\n","418:\tlearn: 0.5676176\ttotal: 1m 9s\tremaining: 1m 36s\n","419:\tlearn: 0.5676130\ttotal: 1m 9s\tremaining: 1m 36s\n","420:\tlearn: 0.5676058\ttotal: 1m 9s\tremaining: 1m 35s\n","421:\tlearn: 0.5675290\ttotal: 1m 9s\tremaining: 1m 35s\n","422:\tlearn: 0.5674605\ttotal: 1m 9s\tremaining: 1m 35s\n","423:\tlearn: 0.5674013\ttotal: 1m 10s\tremaining: 1m 35s\n","424:\tlearn: 0.5673460\ttotal: 1m 10s\tremaining: 1m 35s\n","425:\tlearn: 0.5672903\ttotal: 1m 10s\tremaining: 1m 34s\n","426:\tlearn: 0.5672133\ttotal: 1m 10s\tremaining: 1m 34s\n","427:\tlearn: 0.5671611\ttotal: 1m 10s\tremaining: 1m 34s\n","428:\tlearn: 0.5670684\ttotal: 1m 10s\tremaining: 1m 34s\n","429:\tlearn: 0.5669955\ttotal: 1m 11s\tremaining: 1m 34s\n","430:\tlearn: 0.5669255\ttotal: 1m 11s\tremaining: 1m 33s\n","431:\tlearn: 0.5668690\ttotal: 1m 11s\tremaining: 1m 33s\n","432:\tlearn: 0.5668185\ttotal: 1m 11s\tremaining: 1m 33s\n","433:\tlearn: 0.5667444\ttotal: 1m 11s\tremaining: 1m 33s\n","434:\tlearn: 0.5667034\ttotal: 1m 11s\tremaining: 1m 33s\n","435:\tlearn: 0.5666531\ttotal: 1m 12s\tremaining: 1m 33s\n","436:\tlearn: 0.5666000\ttotal: 1m 12s\tremaining: 1m 33s\n","437:\tlearn: 0.5665333\ttotal: 1m 12s\tremaining: 1m 33s\n","438:\tlearn: 0.5664705\ttotal: 1m 12s\tremaining: 1m 33s\n","439:\tlearn: 0.5664118\ttotal: 1m 13s\tremaining: 1m 33s\n","440:\tlearn: 0.5663747\ttotal: 1m 13s\tremaining: 1m 32s\n","441:\tlearn: 0.5663203\ttotal: 1m 13s\tremaining: 1m 32s\n","442:\tlearn: 0.5662568\ttotal: 1m 13s\tremaining: 1m 32s\n","443:\tlearn: 0.5661998\ttotal: 1m 14s\tremaining: 1m 32s\n","444:\tlearn: 0.5661512\ttotal: 1m 14s\tremaining: 1m 32s\n","445:\tlearn: 0.5660935\ttotal: 1m 14s\tremaining: 1m 32s\n","446:\tlearn: 0.5660467\ttotal: 1m 14s\tremaining: 1m 32s\n","447:\tlearn: 0.5660010\ttotal: 1m 15s\tremaining: 1m 32s\n","448:\tlearn: 0.5659278\ttotal: 1m 15s\tremaining: 1m 32s\n","449:\tlearn: 0.5658799\ttotal: 1m 15s\tremaining: 1m 32s\n","450:\tlearn: 0.5658147\ttotal: 1m 15s\tremaining: 1m 32s\n","451:\tlearn: 0.5657804\ttotal: 1m 15s\tremaining: 1m 31s\n","452:\tlearn: 0.5657073\ttotal: 1m 15s\tremaining: 1m 31s\n","453:\tlearn: 0.5656412\ttotal: 1m 16s\tremaining: 1m 31s\n","454:\tlearn: 0.5655727\ttotal: 1m 16s\tremaining: 1m 31s\n","455:\tlearn: 0.5655019\ttotal: 1m 16s\tremaining: 1m 31s\n","456:\tlearn: 0.5654421\ttotal: 1m 16s\tremaining: 1m 30s\n","457:\tlearn: 0.5653750\ttotal: 1m 16s\tremaining: 1m 30s\n","458:\tlearn: 0.5653175\ttotal: 1m 16s\tremaining: 1m 30s\n","459:\tlearn: 0.5652647\ttotal: 1m 17s\tremaining: 1m 30s\n","460:\tlearn: 0.5652064\ttotal: 1m 17s\tremaining: 1m 30s\n","461:\tlearn: 0.5651436\ttotal: 1m 17s\tremaining: 1m 30s\n","462:\tlearn: 0.5651071\ttotal: 1m 17s\tremaining: 1m 29s\n","463:\tlearn: 0.5650244\ttotal: 1m 17s\tremaining: 1m 29s\n","464:\tlearn: 0.5650201\ttotal: 1m 17s\tremaining: 1m 29s\n","465:\tlearn: 0.5649784\ttotal: 1m 17s\tremaining: 1m 29s\n","466:\tlearn: 0.5649305\ttotal: 1m 17s\tremaining: 1m 29s\n","467:\tlearn: 0.5648899\ttotal: 1m 18s\tremaining: 1m 28s\n","468:\tlearn: 0.5648384\ttotal: 1m 18s\tremaining: 1m 28s\n","469:\tlearn: 0.5647869\ttotal: 1m 18s\tremaining: 1m 28s\n","470:\tlearn: 0.5647399\ttotal: 1m 18s\tremaining: 1m 28s\n","471:\tlearn: 0.5646739\ttotal: 1m 18s\tremaining: 1m 28s\n","472:\tlearn: 0.5646084\ttotal: 1m 18s\tremaining: 1m 27s\n","473:\tlearn: 0.5645476\ttotal: 1m 18s\tremaining: 1m 27s\n","474:\tlearn: 0.5644955\ttotal: 1m 19s\tremaining: 1m 27s\n","475:\tlearn: 0.5644244\ttotal: 1m 19s\tremaining: 1m 27s\n","476:\tlearn: 0.5643407\ttotal: 1m 19s\tremaining: 1m 27s\n","477:\tlearn: 0.5642689\ttotal: 1m 19s\tremaining: 1m 26s\n","478:\tlearn: 0.5642249\ttotal: 1m 19s\tremaining: 1m 26s\n","479:\tlearn: 0.5641571\ttotal: 1m 19s\tremaining: 1m 26s\n","480:\tlearn: 0.5641515\ttotal: 1m 19s\tremaining: 1m 26s\n","481:\tlearn: 0.5641189\ttotal: 1m 20s\tremaining: 1m 26s\n","482:\tlearn: 0.5640614\ttotal: 1m 20s\tremaining: 1m 25s\n","483:\tlearn: 0.5639787\ttotal: 1m 20s\tremaining: 1m 25s\n","484:\tlearn: 0.5639104\ttotal: 1m 20s\tremaining: 1m 25s\n","485:\tlearn: 0.5638726\ttotal: 1m 20s\tremaining: 1m 25s\n","486:\tlearn: 0.5638241\ttotal: 1m 20s\tremaining: 1m 25s\n","487:\tlearn: 0.5637373\ttotal: 1m 21s\tremaining: 1m 25s\n","488:\tlearn: 0.5636644\ttotal: 1m 21s\tremaining: 1m 24s\n","489:\tlearn: 0.5636099\ttotal: 1m 21s\tremaining: 1m 24s\n","490:\tlearn: 0.5635620\ttotal: 1m 21s\tremaining: 1m 24s\n","491:\tlearn: 0.5635432\ttotal: 1m 21s\tremaining: 1m 24s\n","492:\tlearn: 0.5634737\ttotal: 1m 21s\tremaining: 1m 24s\n","493:\tlearn: 0.5634236\ttotal: 1m 21s\tremaining: 1m 23s\n","494:\tlearn: 0.5633590\ttotal: 1m 21s\tremaining: 1m 23s\n","495:\tlearn: 0.5632977\ttotal: 1m 22s\tremaining: 1m 23s\n","496:\tlearn: 0.5632514\ttotal: 1m 22s\tremaining: 1m 23s\n","497:\tlearn: 0.5632206\ttotal: 1m 22s\tremaining: 1m 22s\n","498:\tlearn: 0.5632014\ttotal: 1m 22s\tremaining: 1m 22s\n","499:\tlearn: 0.5631457\ttotal: 1m 22s\tremaining: 1m 22s\n","500:\tlearn: 0.5631032\ttotal: 1m 22s\tremaining: 1m 22s\n","501:\tlearn: 0.5630635\ttotal: 1m 22s\tremaining: 1m 22s\n","502:\tlearn: 0.5630096\ttotal: 1m 22s\tremaining: 1m 22s\n","503:\tlearn: 0.5629551\ttotal: 1m 23s\tremaining: 1m 21s\n","504:\tlearn: 0.5628996\ttotal: 1m 23s\tremaining: 1m 21s\n","505:\tlearn: 0.5628370\ttotal: 1m 23s\tremaining: 1m 21s\n","506:\tlearn: 0.5627980\ttotal: 1m 23s\tremaining: 1m 21s\n","507:\tlearn: 0.5627483\ttotal: 1m 23s\tremaining: 1m 21s\n","508:\tlearn: 0.5626956\ttotal: 1m 23s\tremaining: 1m 20s\n","509:\tlearn: 0.5626429\ttotal: 1m 23s\tremaining: 1m 20s\n","510:\tlearn: 0.5625985\ttotal: 1m 24s\tremaining: 1m 20s\n","511:\tlearn: 0.5625946\ttotal: 1m 24s\tremaining: 1m 20s\n","512:\tlearn: 0.5625906\ttotal: 1m 24s\tremaining: 1m 19s\n","513:\tlearn: 0.5625200\ttotal: 1m 24s\tremaining: 1m 19s\n","514:\tlearn: 0.5624733\ttotal: 1m 24s\tremaining: 1m 19s\n","515:\tlearn: 0.5624106\ttotal: 1m 24s\tremaining: 1m 19s\n","516:\tlearn: 0.5623552\ttotal: 1m 24s\tremaining: 1m 19s\n","517:\tlearn: 0.5623140\ttotal: 1m 25s\tremaining: 1m 19s\n","518:\tlearn: 0.5622691\ttotal: 1m 25s\tremaining: 1m 18s\n","519:\tlearn: 0.5622171\ttotal: 1m 25s\tremaining: 1m 18s\n","520:\tlearn: 0.5621620\ttotal: 1m 25s\tremaining: 1m 18s\n","521:\tlearn: 0.5621031\ttotal: 1m 25s\tremaining: 1m 18s\n","522:\tlearn: 0.5620403\ttotal: 1m 25s\tremaining: 1m 18s\n","523:\tlearn: 0.5619904\ttotal: 1m 26s\tremaining: 1m 18s\n","524:\tlearn: 0.5619303\ttotal: 1m 26s\tremaining: 1m 18s\n","525:\tlearn: 0.5618518\ttotal: 1m 26s\tremaining: 1m 18s\n","526:\tlearn: 0.5617968\ttotal: 1m 27s\tremaining: 1m 18s\n","527:\tlearn: 0.5617632\ttotal: 1m 27s\tremaining: 1m 17s\n","528:\tlearn: 0.5617297\ttotal: 1m 27s\tremaining: 1m 17s\n","529:\tlearn: 0.5617009\ttotal: 1m 27s\tremaining: 1m 17s\n","530:\tlearn: 0.5616347\ttotal: 1m 28s\tremaining: 1m 17s\n","531:\tlearn: 0.5616317\ttotal: 1m 28s\tremaining: 1m 17s\n","532:\tlearn: 0.5615816\ttotal: 1m 28s\tremaining: 1m 17s\n","533:\tlearn: 0.5615081\ttotal: 1m 28s\tremaining: 1m 17s\n","534:\tlearn: 0.5614597\ttotal: 1m 29s\tremaining: 1m 17s\n","535:\tlearn: 0.5614296\ttotal: 1m 29s\tremaining: 1m 17s\n","536:\tlearn: 0.5613836\ttotal: 1m 29s\tremaining: 1m 17s\n","537:\tlearn: 0.5613376\ttotal: 1m 29s\tremaining: 1m 16s\n","538:\tlearn: 0.5612730\ttotal: 1m 29s\tremaining: 1m 16s\n","539:\tlearn: 0.5612281\ttotal: 1m 29s\tremaining: 1m 16s\n","540:\tlearn: 0.5611784\ttotal: 1m 29s\tremaining: 1m 16s\n","541:\tlearn: 0.5611234\ttotal: 1m 30s\tremaining: 1m 16s\n","542:\tlearn: 0.5610455\ttotal: 1m 30s\tremaining: 1m 15s\n","543:\tlearn: 0.5610123\ttotal: 1m 30s\tremaining: 1m 15s\n","544:\tlearn: 0.5609836\ttotal: 1m 30s\tremaining: 1m 15s\n","545:\tlearn: 0.5609119\ttotal: 1m 30s\tremaining: 1m 15s\n","546:\tlearn: 0.5608218\ttotal: 1m 30s\tremaining: 1m 15s\n","547:\tlearn: 0.5608002\ttotal: 1m 30s\tremaining: 1m 15s\n","548:\tlearn: 0.5607893\ttotal: 1m 31s\tremaining: 1m 14s\n","549:\tlearn: 0.5607342\ttotal: 1m 31s\tremaining: 1m 14s\n","550:\tlearn: 0.5606890\ttotal: 1m 31s\tremaining: 1m 14s\n","551:\tlearn: 0.5606336\ttotal: 1m 31s\tremaining: 1m 14s\n","552:\tlearn: 0.5605674\ttotal: 1m 31s\tremaining: 1m 14s\n","553:\tlearn: 0.5605106\ttotal: 1m 31s\tremaining: 1m 13s\n","554:\tlearn: 0.5604408\ttotal: 1m 31s\tremaining: 1m 13s\n","555:\tlearn: 0.5604210\ttotal: 1m 32s\tremaining: 1m 13s\n","556:\tlearn: 0.5603546\ttotal: 1m 32s\tremaining: 1m 13s\n","557:\tlearn: 0.5603424\ttotal: 1m 32s\tremaining: 1m 13s\n","558:\tlearn: 0.5602880\ttotal: 1m 32s\tremaining: 1m 12s\n","559:\tlearn: 0.5602203\ttotal: 1m 32s\tremaining: 1m 12s\n","560:\tlearn: 0.5601882\ttotal: 1m 32s\tremaining: 1m 12s\n","561:\tlearn: 0.5601208\ttotal: 1m 32s\tremaining: 1m 12s\n","562:\tlearn: 0.5600513\ttotal: 1m 33s\tremaining: 1m 12s\n","563:\tlearn: 0.5600034\ttotal: 1m 33s\tremaining: 1m 12s\n","564:\tlearn: 0.5599434\ttotal: 1m 33s\tremaining: 1m 11s\n","565:\tlearn: 0.5599293\ttotal: 1m 33s\tremaining: 1m 11s\n","566:\tlearn: 0.5598965\ttotal: 1m 33s\tremaining: 1m 11s\n","567:\tlearn: 0.5598413\ttotal: 1m 33s\tremaining: 1m 11s\n","568:\tlearn: 0.5597682\ttotal: 1m 33s\tremaining: 1m 11s\n","569:\tlearn: 0.5597144\ttotal: 1m 33s\tremaining: 1m 10s\n","570:\tlearn: 0.5596394\ttotal: 1m 34s\tremaining: 1m 10s\n","571:\tlearn: 0.5596217\ttotal: 1m 34s\tremaining: 1m 10s\n","572:\tlearn: 0.5596054\ttotal: 1m 34s\tremaining: 1m 10s\n","573:\tlearn: 0.5595533\ttotal: 1m 34s\tremaining: 1m 10s\n","574:\tlearn: 0.5595508\ttotal: 1m 34s\tremaining: 1m 9s\n","575:\tlearn: 0.5594852\ttotal: 1m 34s\tremaining: 1m 9s\n","576:\tlearn: 0.5594323\ttotal: 1m 34s\tremaining: 1m 9s\n","577:\tlearn: 0.5593700\ttotal: 1m 35s\tremaining: 1m 9s\n","578:\tlearn: 0.5593148\ttotal: 1m 35s\tremaining: 1m 9s\n","579:\tlearn: 0.5592279\ttotal: 1m 35s\tremaining: 1m 9s\n","580:\tlearn: 0.5592251\ttotal: 1m 35s\tremaining: 1m 8s\n","581:\tlearn: 0.5592234\ttotal: 1m 35s\tremaining: 1m 8s\n","582:\tlearn: 0.5591837\ttotal: 1m 35s\tremaining: 1m 8s\n","583:\tlearn: 0.5591268\ttotal: 1m 35s\tremaining: 1m 8s\n","584:\tlearn: 0.5590934\ttotal: 1m 36s\tremaining: 1m 8s\n","585:\tlearn: 0.5590896\ttotal: 1m 36s\tremaining: 1m 7s\n","586:\tlearn: 0.5590461\ttotal: 1m 36s\tremaining: 1m 7s\n","587:\tlearn: 0.5589921\ttotal: 1m 36s\tremaining: 1m 7s\n","588:\tlearn: 0.5589459\ttotal: 1m 36s\tremaining: 1m 7s\n","589:\tlearn: 0.5588899\ttotal: 1m 36s\tremaining: 1m 7s\n","590:\tlearn: 0.5588558\ttotal: 1m 36s\tremaining: 1m 6s\n","591:\tlearn: 0.5587850\ttotal: 1m 36s\tremaining: 1m 6s\n","592:\tlearn: 0.5587695\ttotal: 1m 36s\tremaining: 1m 6s\n","593:\tlearn: 0.5587030\ttotal: 1m 37s\tremaining: 1m 6s\n","594:\tlearn: 0.5586753\ttotal: 1m 37s\tremaining: 1m 6s\n","595:\tlearn: 0.5586353\ttotal: 1m 37s\tremaining: 1m 6s\n","596:\tlearn: 0.5585693\ttotal: 1m 37s\tremaining: 1m 5s\n","597:\tlearn: 0.5584972\ttotal: 1m 37s\tremaining: 1m 5s\n","598:\tlearn: 0.5584436\ttotal: 1m 37s\tremaining: 1m 5s\n","599:\tlearn: 0.5583783\ttotal: 1m 38s\tremaining: 1m 5s\n","600:\tlearn: 0.5583410\ttotal: 1m 38s\tremaining: 1m 5s\n","601:\tlearn: 0.5583025\ttotal: 1m 38s\tremaining: 1m 4s\n","602:\tlearn: 0.5582275\ttotal: 1m 38s\tremaining: 1m 4s\n","603:\tlearn: 0.5581654\ttotal: 1m 38s\tremaining: 1m 4s\n","604:\tlearn: 0.5581122\ttotal: 1m 38s\tremaining: 1m 4s\n","605:\tlearn: 0.5580660\ttotal: 1m 38s\tremaining: 1m 4s\n","606:\tlearn: 0.5580086\ttotal: 1m 39s\tremaining: 1m 4s\n","607:\tlearn: 0.5579728\ttotal: 1m 39s\tremaining: 1m 3s\n","608:\tlearn: 0.5579231\ttotal: 1m 39s\tremaining: 1m 3s\n","609:\tlearn: 0.5578880\ttotal: 1m 39s\tremaining: 1m 3s\n","610:\tlearn: 0.5578469\ttotal: 1m 39s\tremaining: 1m 3s\n","611:\tlearn: 0.5577929\ttotal: 1m 40s\tremaining: 1m 3s\n","612:\tlearn: 0.5577331\ttotal: 1m 40s\tremaining: 1m 3s\n","613:\tlearn: 0.5576723\ttotal: 1m 40s\tremaining: 1m 3s\n","614:\tlearn: 0.5576170\ttotal: 1m 40s\tremaining: 1m 3s\n","615:\tlearn: 0.5575790\ttotal: 1m 41s\tremaining: 1m 3s\n","616:\tlearn: 0.5575465\ttotal: 1m 41s\tremaining: 1m 2s\n","617:\tlearn: 0.5574808\ttotal: 1m 41s\tremaining: 1m 2s\n","618:\tlearn: 0.5574135\ttotal: 1m 41s\tremaining: 1m 2s\n","619:\tlearn: 0.5573648\ttotal: 1m 42s\tremaining: 1m 2s\n","620:\tlearn: 0.5573267\ttotal: 1m 42s\tremaining: 1m 2s\n","621:\tlearn: 0.5572757\ttotal: 1m 42s\tremaining: 1m 2s\n","622:\tlearn: 0.5572304\ttotal: 1m 42s\tremaining: 1m 2s\n","623:\tlearn: 0.5571782\ttotal: 1m 43s\tremaining: 1m 2s\n","624:\tlearn: 0.5571395\ttotal: 1m 43s\tremaining: 1m 1s\n","625:\tlearn: 0.5571064\ttotal: 1m 43s\tremaining: 1m 1s\n","626:\tlearn: 0.5570427\ttotal: 1m 43s\tremaining: 1m 1s\n","627:\tlearn: 0.5570124\ttotal: 1m 43s\tremaining: 1m 1s\n","628:\tlearn: 0.5569730\ttotal: 1m 43s\tremaining: 1m 1s\n","629:\tlearn: 0.5569291\ttotal: 1m 43s\tremaining: 1m 1s\n","630:\tlearn: 0.5569263\ttotal: 1m 44s\tremaining: 1m\n","631:\tlearn: 0.5568803\ttotal: 1m 44s\tremaining: 1m\n","632:\tlearn: 0.5568322\ttotal: 1m 44s\tremaining: 1m\n","633:\tlearn: 0.5567698\ttotal: 1m 44s\tremaining: 1m\n","634:\tlearn: 0.5567140\ttotal: 1m 44s\tremaining: 1m\n","635:\tlearn: 0.5566684\ttotal: 1m 44s\tremaining: 59.9s\n","636:\tlearn: 0.5566116\ttotal: 1m 44s\tremaining: 59.8s\n","637:\tlearn: 0.5565659\ttotal: 1m 45s\tremaining: 59.6s\n","638:\tlearn: 0.5564914\ttotal: 1m 45s\tremaining: 59.4s\n","639:\tlearn: 0.5564360\ttotal: 1m 45s\tremaining: 59.3s\n","640:\tlearn: 0.5563776\ttotal: 1m 45s\tremaining: 59.1s\n","641:\tlearn: 0.5563375\ttotal: 1m 45s\tremaining: 58.9s\n","642:\tlearn: 0.5563357\ttotal: 1m 45s\tremaining: 58.7s\n","643:\tlearn: 0.5563216\ttotal: 1m 45s\tremaining: 58.5s\n","644:\tlearn: 0.5562683\ttotal: 1m 45s\tremaining: 58.3s\n","645:\tlearn: 0.5562064\ttotal: 1m 46s\tremaining: 58.1s\n","646:\tlearn: 0.5561533\ttotal: 1m 46s\tremaining: 58s\n","647:\tlearn: 0.5560847\ttotal: 1m 46s\tremaining: 57.8s\n","648:\tlearn: 0.5560290\ttotal: 1m 46s\tremaining: 57.6s\n","649:\tlearn: 0.5559770\ttotal: 1m 46s\tremaining: 57.5s\n","650:\tlearn: 0.5559042\ttotal: 1m 46s\tremaining: 57.3s\n","651:\tlearn: 0.5558627\ttotal: 1m 47s\tremaining: 57.1s\n","652:\tlearn: 0.5558100\ttotal: 1m 47s\tremaining: 56.9s\n","653:\tlearn: 0.5558086\ttotal: 1m 47s\tremaining: 56.7s\n","654:\tlearn: 0.5557571\ttotal: 1m 47s\tremaining: 56.6s\n","655:\tlearn: 0.5556887\ttotal: 1m 47s\tremaining: 56.4s\n","656:\tlearn: 0.5556389\ttotal: 1m 47s\tremaining: 56.2s\n","657:\tlearn: 0.5555872\ttotal: 1m 47s\tremaining: 56s\n","658:\tlearn: 0.5555270\ttotal: 1m 47s\tremaining: 55.9s\n","659:\tlearn: 0.5554747\ttotal: 1m 48s\tremaining: 55.7s\n","660:\tlearn: 0.5554417\ttotal: 1m 48s\tremaining: 55.5s\n","661:\tlearn: 0.5554294\ttotal: 1m 48s\tremaining: 55.3s\n","662:\tlearn: 0.5553567\ttotal: 1m 48s\tremaining: 55.1s\n","663:\tlearn: 0.5552847\ttotal: 1m 48s\tremaining: 55s\n","664:\tlearn: 0.5552312\ttotal: 1m 48s\tremaining: 54.8s\n","665:\tlearn: 0.5551468\ttotal: 1m 48s\tremaining: 54.6s\n","666:\tlearn: 0.5551308\ttotal: 1m 49s\tremaining: 54.5s\n","667:\tlearn: 0.5550858\ttotal: 1m 49s\tremaining: 54.3s\n","668:\tlearn: 0.5550442\ttotal: 1m 49s\tremaining: 54.1s\n","669:\tlearn: 0.5549878\ttotal: 1m 49s\tremaining: 53.9s\n","670:\tlearn: 0.5549249\ttotal: 1m 49s\tremaining: 53.8s\n","671:\tlearn: 0.5548817\ttotal: 1m 49s\tremaining: 53.6s\n","672:\tlearn: 0.5548449\ttotal: 1m 49s\tremaining: 53.4s\n","673:\tlearn: 0.5548043\ttotal: 1m 50s\tremaining: 53.2s\n","674:\tlearn: 0.5547657\ttotal: 1m 50s\tremaining: 53s\n","675:\tlearn: 0.5547347\ttotal: 1m 50s\tremaining: 52.8s\n","676:\tlearn: 0.5546738\ttotal: 1m 50s\tremaining: 52.7s\n","677:\tlearn: 0.5546305\ttotal: 1m 50s\tremaining: 52.5s\n","678:\tlearn: 0.5545838\ttotal: 1m 50s\tremaining: 52.3s\n","679:\tlearn: 0.5545218\ttotal: 1m 50s\tremaining: 52.2s\n","680:\tlearn: 0.5544854\ttotal: 1m 50s\tremaining: 52s\n","681:\tlearn: 0.5544237\ttotal: 1m 51s\tremaining: 51.8s\n","682:\tlearn: 0.5544012\ttotal: 1m 51s\tremaining: 51.6s\n","683:\tlearn: 0.5543867\ttotal: 1m 51s\tremaining: 51.4s\n","684:\tlearn: 0.5543433\ttotal: 1m 51s\tremaining: 51.3s\n","685:\tlearn: 0.5542986\ttotal: 1m 51s\tremaining: 51.1s\n","686:\tlearn: 0.5542501\ttotal: 1m 51s\tremaining: 50.9s\n","687:\tlearn: 0.5541806\ttotal: 1m 51s\tremaining: 50.7s\n","688:\tlearn: 0.5541561\ttotal: 1m 51s\tremaining: 50.5s\n","689:\tlearn: 0.5540987\ttotal: 1m 52s\tremaining: 50.4s\n","690:\tlearn: 0.5540301\ttotal: 1m 52s\tremaining: 50.2s\n","691:\tlearn: 0.5539902\ttotal: 1m 52s\tremaining: 50s\n","692:\tlearn: 0.5539557\ttotal: 1m 52s\tremaining: 49.9s\n","693:\tlearn: 0.5538866\ttotal: 1m 52s\tremaining: 49.7s\n","694:\tlearn: 0.5538490\ttotal: 1m 52s\tremaining: 49.5s\n","695:\tlearn: 0.5537827\ttotal: 1m 53s\tremaining: 49.4s\n","696:\tlearn: 0.5537573\ttotal: 1m 53s\tremaining: 49.2s\n","697:\tlearn: 0.5536829\ttotal: 1m 53s\tremaining: 49.1s\n","698:\tlearn: 0.5536591\ttotal: 1m 53s\tremaining: 48.9s\n","699:\tlearn: 0.5536577\ttotal: 1m 53s\tremaining: 48.8s\n","700:\tlearn: 0.5536114\ttotal: 1m 54s\tremaining: 48.7s\n","701:\tlearn: 0.5535758\ttotal: 1m 54s\tremaining: 48.5s\n","702:\tlearn: 0.5535383\ttotal: 1m 54s\tremaining: 48.4s\n","703:\tlearn: 0.5534926\ttotal: 1m 54s\tremaining: 48.3s\n","704:\tlearn: 0.5534488\ttotal: 1m 55s\tremaining: 48.2s\n","705:\tlearn: 0.5534457\ttotal: 1m 55s\tremaining: 48s\n","706:\tlearn: 0.5533926\ttotal: 1m 55s\tremaining: 47.9s\n","707:\tlearn: 0.5533738\ttotal: 1m 55s\tremaining: 47.7s\n","708:\tlearn: 0.5533202\ttotal: 1m 55s\tremaining: 47.6s\n","709:\tlearn: 0.5532635\ttotal: 1m 56s\tremaining: 47.5s\n","710:\tlearn: 0.5532090\ttotal: 1m 56s\tremaining: 47.3s\n","711:\tlearn: 0.5531625\ttotal: 1m 56s\tremaining: 47.2s\n","712:\tlearn: 0.5531413\ttotal: 1m 56s\tremaining: 47.1s\n","713:\tlearn: 0.5530856\ttotal: 1m 57s\tremaining: 46.9s\n","714:\tlearn: 0.5530415\ttotal: 1m 57s\tremaining: 46.7s\n","715:\tlearn: 0.5529910\ttotal: 1m 57s\tremaining: 46.6s\n","716:\tlearn: 0.5529378\ttotal: 1m 57s\tremaining: 46.4s\n","717:\tlearn: 0.5528940\ttotal: 1m 57s\tremaining: 46.2s\n","718:\tlearn: 0.5528228\ttotal: 1m 57s\tremaining: 46s\n","719:\tlearn: 0.5527676\ttotal: 1m 57s\tremaining: 45.9s\n","720:\tlearn: 0.5527340\ttotal: 1m 58s\tremaining: 45.7s\n","721:\tlearn: 0.5526933\ttotal: 1m 58s\tremaining: 45.5s\n","722:\tlearn: 0.5526362\ttotal: 1m 58s\tremaining: 45.3s\n","723:\tlearn: 0.5525722\ttotal: 1m 58s\tremaining: 45.2s\n","724:\tlearn: 0.5525438\ttotal: 1m 58s\tremaining: 45s\n","725:\tlearn: 0.5524856\ttotal: 1m 58s\tremaining: 44.8s\n","726:\tlearn: 0.5524352\ttotal: 1m 58s\tremaining: 44.7s\n","727:\tlearn: 0.5523807\ttotal: 1m 59s\tremaining: 44.5s\n","728:\tlearn: 0.5523579\ttotal: 1m 59s\tremaining: 44.3s\n","729:\tlearn: 0.5523560\ttotal: 1m 59s\tremaining: 44.1s\n","730:\tlearn: 0.5523128\ttotal: 1m 59s\tremaining: 44s\n","731:\tlearn: 0.5522616\ttotal: 1m 59s\tremaining: 43.8s\n","732:\tlearn: 0.5522064\ttotal: 1m 59s\tremaining: 43.6s\n","733:\tlearn: 0.5521300\ttotal: 1m 59s\tremaining: 43.5s\n","734:\tlearn: 0.5520919\ttotal: 2m\tremaining: 43.3s\n","735:\tlearn: 0.5520566\ttotal: 2m\tremaining: 43.1s\n","736:\tlearn: 0.5519906\ttotal: 2m\tremaining: 42.9s\n","737:\tlearn: 0.5519653\ttotal: 2m\tremaining: 42.8s\n","738:\tlearn: 0.5519210\ttotal: 2m\tremaining: 42.6s\n","739:\tlearn: 0.5518561\ttotal: 2m\tremaining: 42.4s\n","740:\tlearn: 0.5518059\ttotal: 2m\tremaining: 42.2s\n","741:\tlearn: 0.5517569\ttotal: 2m 1s\tremaining: 42.1s\n","742:\tlearn: 0.5517137\ttotal: 2m 1s\tremaining: 41.9s\n","743:\tlearn: 0.5516796\ttotal: 2m 1s\tremaining: 41.7s\n","744:\tlearn: 0.5516324\ttotal: 2m 1s\tremaining: 41.6s\n","745:\tlearn: 0.5516309\ttotal: 2m 1s\tremaining: 41.4s\n","746:\tlearn: 0.5516003\ttotal: 2m 1s\tremaining: 41.2s\n","747:\tlearn: 0.5515296\ttotal: 2m 1s\tremaining: 41s\n","748:\tlearn: 0.5515273\ttotal: 2m 1s\tremaining: 40.9s\n","749:\tlearn: 0.5514979\ttotal: 2m 2s\tremaining: 40.7s\n","750:\tlearn: 0.5514370\ttotal: 2m 2s\tremaining: 40.5s\n","751:\tlearn: 0.5514064\ttotal: 2m 2s\tremaining: 40.3s\n","752:\tlearn: 0.5513580\ttotal: 2m 2s\tremaining: 40.2s\n","753:\tlearn: 0.5513233\ttotal: 2m 2s\tremaining: 40s\n","754:\tlearn: 0.5512859\ttotal: 2m 2s\tremaining: 39.8s\n","755:\tlearn: 0.5512295\ttotal: 2m 2s\tremaining: 39.6s\n","756:\tlearn: 0.5511833\ttotal: 2m 2s\tremaining: 39.5s\n","757:\tlearn: 0.5511322\ttotal: 2m 3s\tremaining: 39.3s\n","758:\tlearn: 0.5510895\ttotal: 2m 3s\tremaining: 39.1s\n","759:\tlearn: 0.5510171\ttotal: 2m 3s\tremaining: 39s\n","760:\tlearn: 0.5509761\ttotal: 2m 3s\tremaining: 38.8s\n","761:\tlearn: 0.5509468\ttotal: 2m 3s\tremaining: 38.6s\n","762:\tlearn: 0.5509021\ttotal: 2m 3s\tremaining: 38.5s\n","763:\tlearn: 0.5508909\ttotal: 2m 3s\tremaining: 38.3s\n","764:\tlearn: 0.5508338\ttotal: 2m 4s\tremaining: 38.1s\n","765:\tlearn: 0.5507709\ttotal: 2m 4s\tremaining: 38s\n","766:\tlearn: 0.5507191\ttotal: 2m 4s\tremaining: 37.8s\n","767:\tlearn: 0.5506914\ttotal: 2m 4s\tremaining: 37.6s\n","768:\tlearn: 0.5506540\ttotal: 2m 4s\tremaining: 37.4s\n","769:\tlearn: 0.5505896\ttotal: 2m 4s\tremaining: 37.3s\n","770:\tlearn: 0.5505341\ttotal: 2m 4s\tremaining: 37.1s\n","771:\tlearn: 0.5504710\ttotal: 2m 5s\tremaining: 36.9s\n","772:\tlearn: 0.5504402\ttotal: 2m 5s\tremaining: 36.8s\n","773:\tlearn: 0.5503875\ttotal: 2m 5s\tremaining: 36.6s\n","774:\tlearn: 0.5503848\ttotal: 2m 5s\tremaining: 36.4s\n","775:\tlearn: 0.5503827\ttotal: 2m 5s\tremaining: 36.2s\n","776:\tlearn: 0.5503799\ttotal: 2m 5s\tremaining: 36.1s\n","777:\tlearn: 0.5503456\ttotal: 2m 5s\tremaining: 35.9s\n","778:\tlearn: 0.5503004\ttotal: 2m 5s\tremaining: 35.7s\n","779:\tlearn: 0.5502521\ttotal: 2m 6s\tremaining: 35.6s\n","780:\tlearn: 0.5501965\ttotal: 2m 6s\tremaining: 35.4s\n","781:\tlearn: 0.5501513\ttotal: 2m 6s\tremaining: 35.2s\n","782:\tlearn: 0.5501138\ttotal: 2m 6s\tremaining: 35s\n","783:\tlearn: 0.5500561\ttotal: 2m 6s\tremaining: 34.9s\n","784:\tlearn: 0.5499885\ttotal: 2m 6s\tremaining: 34.7s\n","785:\tlearn: 0.5499442\ttotal: 2m 6s\tremaining: 34.6s\n","786:\tlearn: 0.5499093\ttotal: 2m 7s\tremaining: 34.4s\n","787:\tlearn: 0.5498562\ttotal: 2m 7s\tremaining: 34.3s\n","788:\tlearn: 0.5498085\ttotal: 2m 7s\tremaining: 34.2s\n","789:\tlearn: 0.5497329\ttotal: 2m 8s\tremaining: 34s\n","790:\tlearn: 0.5496769\ttotal: 2m 8s\tremaining: 33.9s\n","791:\tlearn: 0.5496458\ttotal: 2m 8s\tremaining: 33.7s\n","792:\tlearn: 0.5495849\ttotal: 2m 8s\tremaining: 33.6s\n","793:\tlearn: 0.5495296\ttotal: 2m 9s\tremaining: 33.5s\n","794:\tlearn: 0.5494662\ttotal: 2m 9s\tremaining: 33.4s\n","795:\tlearn: 0.5494247\ttotal: 2m 9s\tremaining: 33.2s\n","796:\tlearn: 0.5493825\ttotal: 2m 9s\tremaining: 33.1s\n","797:\tlearn: 0.5493346\ttotal: 2m 10s\tremaining: 32.9s\n","798:\tlearn: 0.5493061\ttotal: 2m 10s\tremaining: 32.8s\n","799:\tlearn: 0.5492695\ttotal: 2m 10s\tremaining: 32.6s\n","800:\tlearn: 0.5492312\ttotal: 2m 10s\tremaining: 32.5s\n","801:\tlearn: 0.5491874\ttotal: 2m 10s\tremaining: 32.3s\n","802:\tlearn: 0.5491592\ttotal: 2m 10s\tremaining: 32.1s\n","803:\tlearn: 0.5491358\ttotal: 2m 11s\tremaining: 31.9s\n","804:\tlearn: 0.5490726\ttotal: 2m 11s\tremaining: 31.8s\n","805:\tlearn: 0.5490285\ttotal: 2m 11s\tremaining: 31.6s\n","806:\tlearn: 0.5489810\ttotal: 2m 11s\tremaining: 31.4s\n","807:\tlearn: 0.5489274\ttotal: 2m 11s\tremaining: 31.3s\n","808:\tlearn: 0.5488824\ttotal: 2m 11s\tremaining: 31.1s\n","809:\tlearn: 0.5488808\ttotal: 2m 11s\tremaining: 30.9s\n","810:\tlearn: 0.5488430\ttotal: 2m 11s\tremaining: 30.8s\n","811:\tlearn: 0.5488002\ttotal: 2m 12s\tremaining: 30.6s\n","812:\tlearn: 0.5487724\ttotal: 2m 12s\tremaining: 30.4s\n","813:\tlearn: 0.5487496\ttotal: 2m 12s\tremaining: 30.2s\n","814:\tlearn: 0.5487213\ttotal: 2m 12s\tremaining: 30.1s\n","815:\tlearn: 0.5486641\ttotal: 2m 12s\tremaining: 29.9s\n","816:\tlearn: 0.5486315\ttotal: 2m 12s\tremaining: 29.7s\n","817:\tlearn: 0.5485720\ttotal: 2m 12s\tremaining: 29.6s\n","818:\tlearn: 0.5485696\ttotal: 2m 12s\tremaining: 29.4s\n","819:\tlearn: 0.5485094\ttotal: 2m 13s\tremaining: 29.2s\n","820:\tlearn: 0.5485046\ttotal: 2m 13s\tremaining: 29s\n","821:\tlearn: 0.5484595\ttotal: 2m 13s\tremaining: 28.9s\n","822:\tlearn: 0.5484106\ttotal: 2m 13s\tremaining: 28.7s\n","823:\tlearn: 0.5483554\ttotal: 2m 13s\tremaining: 28.5s\n","824:\tlearn: 0.5483175\ttotal: 2m 13s\tremaining: 28.4s\n","825:\tlearn: 0.5482576\ttotal: 2m 13s\tremaining: 28.2s\n","826:\tlearn: 0.5481942\ttotal: 2m 14s\tremaining: 28.1s\n","827:\tlearn: 0.5481369\ttotal: 2m 14s\tremaining: 27.9s\n","828:\tlearn: 0.5480980\ttotal: 2m 14s\tremaining: 27.7s\n","829:\tlearn: 0.5480431\ttotal: 2m 14s\tremaining: 27.6s\n","830:\tlearn: 0.5480219\ttotal: 2m 14s\tremaining: 27.4s\n","831:\tlearn: 0.5479899\ttotal: 2m 14s\tremaining: 27.2s\n","832:\tlearn: 0.5479887\ttotal: 2m 14s\tremaining: 27s\n","833:\tlearn: 0.5479618\ttotal: 2m 15s\tremaining: 26.9s\n","834:\tlearn: 0.5479547\ttotal: 2m 15s\tremaining: 26.7s\n","835:\tlearn: 0.5479147\ttotal: 2m 15s\tremaining: 26.5s\n","836:\tlearn: 0.5478867\ttotal: 2m 15s\tremaining: 26.4s\n","837:\tlearn: 0.5478455\ttotal: 2m 15s\tremaining: 26.2s\n","838:\tlearn: 0.5478005\ttotal: 2m 15s\tremaining: 26s\n","839:\tlearn: 0.5477351\ttotal: 2m 15s\tremaining: 25.9s\n","840:\tlearn: 0.5476679\ttotal: 2m 15s\tremaining: 25.7s\n","841:\tlearn: 0.5476620\ttotal: 2m 16s\tremaining: 25.5s\n","842:\tlearn: 0.5476172\ttotal: 2m 16s\tremaining: 25.4s\n","843:\tlearn: 0.5475685\ttotal: 2m 16s\tremaining: 25.2s\n","844:\tlearn: 0.5474936\ttotal: 2m 16s\tremaining: 25s\n","845:\tlearn: 0.5474424\ttotal: 2m 16s\tremaining: 24.9s\n","846:\tlearn: 0.5474136\ttotal: 2m 16s\tremaining: 24.7s\n","847:\tlearn: 0.5473706\ttotal: 2m 16s\tremaining: 24.5s\n","848:\tlearn: 0.5473149\ttotal: 2m 16s\tremaining: 24.4s\n","849:\tlearn: 0.5472828\ttotal: 2m 17s\tremaining: 24.2s\n","850:\tlearn: 0.5472536\ttotal: 2m 17s\tremaining: 24s\n","851:\tlearn: 0.5472108\ttotal: 2m 17s\tremaining: 23.9s\n","852:\tlearn: 0.5471759\ttotal: 2m 17s\tremaining: 23.7s\n","853:\tlearn: 0.5471334\ttotal: 2m 17s\tremaining: 23.5s\n","854:\tlearn: 0.5470968\ttotal: 2m 17s\tremaining: 23.4s\n","855:\tlearn: 0.5470685\ttotal: 2m 17s\tremaining: 23.2s\n","856:\tlearn: 0.5470266\ttotal: 2m 18s\tremaining: 23s\n","857:\tlearn: 0.5469907\ttotal: 2m 18s\tremaining: 22.9s\n","858:\tlearn: 0.5469503\ttotal: 2m 18s\tremaining: 22.7s\n","859:\tlearn: 0.5469249\ttotal: 2m 18s\tremaining: 22.5s\n","860:\tlearn: 0.5468831\ttotal: 2m 18s\tremaining: 22.4s\n","861:\tlearn: 0.5468507\ttotal: 2m 18s\tremaining: 22.2s\n","862:\tlearn: 0.5468490\ttotal: 2m 18s\tremaining: 22s\n","863:\tlearn: 0.5468242\ttotal: 2m 18s\tremaining: 21.9s\n","864:\tlearn: 0.5467626\ttotal: 2m 19s\tremaining: 21.7s\n","865:\tlearn: 0.5466792\ttotal: 2m 19s\tremaining: 21.5s\n","866:\tlearn: 0.5466237\ttotal: 2m 19s\tremaining: 21.4s\n","867:\tlearn: 0.5465632\ttotal: 2m 19s\tremaining: 21.2s\n","868:\tlearn: 0.5465162\ttotal: 2m 19s\tremaining: 21.1s\n","869:\tlearn: 0.5465105\ttotal: 2m 19s\tremaining: 20.9s\n","870:\tlearn: 0.5464571\ttotal: 2m 19s\tremaining: 20.7s\n","871:\tlearn: 0.5464071\ttotal: 2m 20s\tremaining: 20.6s\n","872:\tlearn: 0.5463676\ttotal: 2m 20s\tremaining: 20.4s\n","873:\tlearn: 0.5463462\ttotal: 2m 20s\tremaining: 20.2s\n","874:\tlearn: 0.5463359\ttotal: 2m 20s\tremaining: 20.1s\n","875:\tlearn: 0.5463041\ttotal: 2m 20s\tremaining: 19.9s\n","876:\tlearn: 0.5462502\ttotal: 2m 20s\tremaining: 19.7s\n","877:\tlearn: 0.5461933\ttotal: 2m 21s\tremaining: 19.6s\n","878:\tlearn: 0.5461518\ttotal: 2m 21s\tremaining: 19.4s\n","879:\tlearn: 0.5461129\ttotal: 2m 21s\tremaining: 19.3s\n","880:\tlearn: 0.5460736\ttotal: 2m 21s\tremaining: 19.1s\n","881:\tlearn: 0.5460345\ttotal: 2m 22s\tremaining: 19s\n","882:\tlearn: 0.5459940\ttotal: 2m 22s\tremaining: 18.8s\n","883:\tlearn: 0.5459464\ttotal: 2m 22s\tremaining: 18.7s\n","884:\tlearn: 0.5459095\ttotal: 2m 22s\tremaining: 18.6s\n","885:\tlearn: 0.5458798\ttotal: 2m 23s\tremaining: 18.4s\n","886:\tlearn: 0.5458590\ttotal: 2m 23s\tremaining: 18.3s\n","887:\tlearn: 0.5458031\ttotal: 2m 23s\tremaining: 18.1s\n","888:\tlearn: 0.5457677\ttotal: 2m 23s\tremaining: 18s\n","889:\tlearn: 0.5457018\ttotal: 2m 24s\tremaining: 17.8s\n","890:\tlearn: 0.5456994\ttotal: 2m 24s\tremaining: 17.6s\n","891:\tlearn: 0.5456454\ttotal: 2m 24s\tremaining: 17.5s\n","892:\tlearn: 0.5456054\ttotal: 2m 24s\tremaining: 17.3s\n","893:\tlearn: 0.5455906\ttotal: 2m 24s\tremaining: 17.2s\n","894:\tlearn: 0.5455404\ttotal: 2m 24s\tremaining: 17s\n","895:\tlearn: 0.5455382\ttotal: 2m 24s\tremaining: 16.8s\n","896:\tlearn: 0.5455039\ttotal: 2m 25s\tremaining: 16.7s\n","897:\tlearn: 0.5454659\ttotal: 2m 25s\tremaining: 16.5s\n","898:\tlearn: 0.5454264\ttotal: 2m 25s\tremaining: 16.3s\n","899:\tlearn: 0.5453857\ttotal: 2m 25s\tremaining: 16.2s\n","900:\tlearn: 0.5453642\ttotal: 2m 25s\tremaining: 16s\n","901:\tlearn: 0.5452945\ttotal: 2m 25s\tremaining: 15.8s\n","902:\tlearn: 0.5452425\ttotal: 2m 25s\tremaining: 15.7s\n","903:\tlearn: 0.5452120\ttotal: 2m 26s\tremaining: 15.5s\n","904:\tlearn: 0.5452103\ttotal: 2m 26s\tremaining: 15.3s\n","905:\tlearn: 0.5451751\ttotal: 2m 26s\tremaining: 15.2s\n","906:\tlearn: 0.5451502\ttotal: 2m 26s\tremaining: 15s\n","907:\tlearn: 0.5451056\ttotal: 2m 26s\tremaining: 14.8s\n","908:\tlearn: 0.5450680\ttotal: 2m 26s\tremaining: 14.7s\n","909:\tlearn: 0.5450313\ttotal: 2m 26s\tremaining: 14.5s\n","910:\tlearn: 0.5450065\ttotal: 2m 26s\tremaining: 14.3s\n","911:\tlearn: 0.5449654\ttotal: 2m 26s\tremaining: 14.2s\n","912:\tlearn: 0.5449401\ttotal: 2m 27s\tremaining: 14s\n","913:\tlearn: 0.5448827\ttotal: 2m 27s\tremaining: 13.8s\n","914:\tlearn: 0.5448498\ttotal: 2m 27s\tremaining: 13.7s\n","915:\tlearn: 0.5448113\ttotal: 2m 27s\tremaining: 13.5s\n","916:\tlearn: 0.5447811\ttotal: 2m 27s\tremaining: 13.4s\n","917:\tlearn: 0.5447798\ttotal: 2m 27s\tremaining: 13.2s\n","918:\tlearn: 0.5447478\ttotal: 2m 27s\tremaining: 13s\n","919:\tlearn: 0.5447296\ttotal: 2m 27s\tremaining: 12.9s\n","920:\tlearn: 0.5446865\ttotal: 2m 28s\tremaining: 12.7s\n","921:\tlearn: 0.5446526\ttotal: 2m 28s\tremaining: 12.5s\n","922:\tlearn: 0.5446064\ttotal: 2m 28s\tremaining: 12.4s\n","923:\tlearn: 0.5445464\ttotal: 2m 28s\tremaining: 12.2s\n","924:\tlearn: 0.5444954\ttotal: 2m 28s\tremaining: 12s\n","925:\tlearn: 0.5444346\ttotal: 2m 28s\tremaining: 11.9s\n","926:\tlearn: 0.5443881\ttotal: 2m 28s\tremaining: 11.7s\n","927:\tlearn: 0.5443356\ttotal: 2m 28s\tremaining: 11.6s\n","928:\tlearn: 0.5442894\ttotal: 2m 29s\tremaining: 11.4s\n","929:\tlearn: 0.5442047\ttotal: 2m 29s\tremaining: 11.2s\n","930:\tlearn: 0.5441683\ttotal: 2m 29s\tremaining: 11.1s\n","931:\tlearn: 0.5441255\ttotal: 2m 29s\tremaining: 10.9s\n","932:\tlearn: 0.5440836\ttotal: 2m 29s\tremaining: 10.8s\n","933:\tlearn: 0.5440269\ttotal: 2m 29s\tremaining: 10.6s\n","934:\tlearn: 0.5440005\ttotal: 2m 30s\tremaining: 10.4s\n","935:\tlearn: 0.5439583\ttotal: 2m 30s\tremaining: 10.3s\n","936:\tlearn: 0.5439170\ttotal: 2m 30s\tremaining: 10.1s\n","937:\tlearn: 0.5438753\ttotal: 2m 30s\tremaining: 9.94s\n","938:\tlearn: 0.5438484\ttotal: 2m 30s\tremaining: 9.78s\n","939:\tlearn: 0.5438196\ttotal: 2m 30s\tremaining: 9.62s\n","940:\tlearn: 0.5437717\ttotal: 2m 30s\tremaining: 9.46s\n","941:\tlearn: 0.5437141\ttotal: 2m 31s\tremaining: 9.3s\n","942:\tlearn: 0.5436850\ttotal: 2m 31s\tremaining: 9.14s\n","943:\tlearn: 0.5436821\ttotal: 2m 31s\tremaining: 8.97s\n","944:\tlearn: 0.5436410\ttotal: 2m 31s\tremaining: 8.81s\n","945:\tlearn: 0.5436203\ttotal: 2m 31s\tremaining: 8.65s\n","946:\tlearn: 0.5435757\ttotal: 2m 31s\tremaining: 8.49s\n","947:\tlearn: 0.5435424\ttotal: 2m 31s\tremaining: 8.32s\n","948:\tlearn: 0.5435022\ttotal: 2m 31s\tremaining: 8.16s\n","949:\tlearn: 0.5434532\ttotal: 2m 32s\tremaining: 8s\n","950:\tlearn: 0.5434045\ttotal: 2m 32s\tremaining: 7.84s\n","951:\tlearn: 0.5433655\ttotal: 2m 32s\tremaining: 7.68s\n","952:\tlearn: 0.5433067\ttotal: 2m 32s\tremaining: 7.52s\n","953:\tlearn: 0.5432524\ttotal: 2m 32s\tremaining: 7.36s\n","954:\tlearn: 0.5432154\ttotal: 2m 32s\tremaining: 7.2s\n","955:\tlearn: 0.5431632\ttotal: 2m 32s\tremaining: 7.04s\n","956:\tlearn: 0.5431379\ttotal: 2m 32s\tremaining: 6.87s\n","957:\tlearn: 0.5431227\ttotal: 2m 33s\tremaining: 6.71s\n","958:\tlearn: 0.5430713\ttotal: 2m 33s\tremaining: 6.55s\n","959:\tlearn: 0.5430212\ttotal: 2m 33s\tremaining: 6.39s\n","960:\tlearn: 0.5429789\ttotal: 2m 33s\tremaining: 6.23s\n","961:\tlearn: 0.5429489\ttotal: 2m 33s\tremaining: 6.07s\n","962:\tlearn: 0.5429473\ttotal: 2m 33s\tremaining: 5.91s\n","963:\tlearn: 0.5428855\ttotal: 2m 33s\tremaining: 5.75s\n","964:\tlearn: 0.5428439\ttotal: 2m 34s\tremaining: 5.59s\n","965:\tlearn: 0.5427877\ttotal: 2m 34s\tremaining: 5.43s\n","966:\tlearn: 0.5427485\ttotal: 2m 34s\tremaining: 5.27s\n","967:\tlearn: 0.5427086\ttotal: 2m 34s\tremaining: 5.11s\n","968:\tlearn: 0.5426712\ttotal: 2m 34s\tremaining: 4.95s\n","969:\tlearn: 0.5426209\ttotal: 2m 35s\tremaining: 4.8s\n","970:\tlearn: 0.5425721\ttotal: 2m 35s\tremaining: 4.64s\n","971:\tlearn: 0.5425708\ttotal: 2m 35s\tremaining: 4.48s\n","972:\tlearn: 0.5425227\ttotal: 2m 35s\tremaining: 4.33s\n","973:\tlearn: 0.5424707\ttotal: 2m 36s\tremaining: 4.17s\n","974:\tlearn: 0.5424372\ttotal: 2m 36s\tremaining: 4.01s\n","975:\tlearn: 0.5423955\ttotal: 2m 36s\tremaining: 3.85s\n","976:\tlearn: 0.5423572\ttotal: 2m 36s\tremaining: 3.69s\n","977:\tlearn: 0.5423211\ttotal: 2m 37s\tremaining: 3.54s\n","978:\tlearn: 0.5422834\ttotal: 2m 37s\tremaining: 3.38s\n","979:\tlearn: 0.5422533\ttotal: 2m 37s\tremaining: 3.22s\n","980:\tlearn: 0.5422230\ttotal: 2m 37s\tremaining: 3.06s\n","981:\tlearn: 0.5422209\ttotal: 2m 38s\tremaining: 2.9s\n","982:\tlearn: 0.5421696\ttotal: 2m 38s\tremaining: 2.74s\n","983:\tlearn: 0.5421155\ttotal: 2m 38s\tremaining: 2.58s\n","984:\tlearn: 0.5420853\ttotal: 2m 38s\tremaining: 2.41s\n","985:\tlearn: 0.5420526\ttotal: 2m 38s\tremaining: 2.25s\n","986:\tlearn: 0.5420134\ttotal: 2m 38s\tremaining: 2.09s\n","987:\tlearn: 0.5419887\ttotal: 2m 38s\tremaining: 1.93s\n","988:\tlearn: 0.5419481\ttotal: 2m 39s\tremaining: 1.77s\n","989:\tlearn: 0.5419155\ttotal: 2m 39s\tremaining: 1.61s\n","990:\tlearn: 0.5419150\ttotal: 2m 39s\tremaining: 1.45s\n","991:\tlearn: 0.5419137\ttotal: 2m 39s\tremaining: 1.28s\n","992:\tlearn: 0.5418959\ttotal: 2m 39s\tremaining: 1.12s\n","993:\tlearn: 0.5418439\ttotal: 2m 39s\tremaining: 964ms\n","994:\tlearn: 0.5418075\ttotal: 2m 39s\tremaining: 803ms\n","995:\tlearn: 0.5417696\ttotal: 2m 39s\tremaining: 642ms\n","996:\tlearn: 0.5417236\ttotal: 2m 40s\tremaining: 482ms\n","997:\tlearn: 0.5416926\ttotal: 2m 40s\tremaining: 321ms\n","998:\tlearn: 0.5416588\ttotal: 2m 40s\tremaining: 160ms\n","999:\tlearn: 0.5416274\ttotal: 2m 40s\tremaining: 0us\n","train: 0.7298146666083433\n","test: 0.6886213928316278\n","test conf matrix: \n"," [[21609 10344]\n"," [ 9543 22370]]\n"]}]},{"cell_type":"code","source":["## попробую вероятности и подбор порога\n","model_catb = CatBoostClassifier()\n","model_catb.fit(x_train, y_train)\n","\n","#pred_train = model_catb.predict(x_train)\n","pred_proba = pd.DataFrame({'proba': model_catb.predict_proba(x_test)[:,1].T})"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wv9xBtJ6IsZA","executionInfo":{"status":"ok","timestamp":1708007221661,"user_tz":-240,"elapsed":160232,"user":{"displayName":"Евгений Малов","userId":"06257165098392198337"}},"outputId":"223be31f-5c62-4039-a421-a502773fb25c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Learning rate set to 0.087278\n","0:\tlearn: 0.6853203\ttotal: 231ms\tremaining: 3m 50s\n","1:\tlearn: 0.6784332\ttotal: 385ms\tremaining: 3m 11s\n","2:\tlearn: 0.6722734\ttotal: 558ms\tremaining: 3m 5s\n","3:\tlearn: 0.6668897\ttotal: 745ms\tremaining: 3m 5s\n","4:\tlearn: 0.6621721\ttotal: 907ms\tremaining: 3m\n","5:\tlearn: 0.6583644\ttotal: 1.07s\tremaining: 2m 57s\n","6:\tlearn: 0.6548527\ttotal: 1.24s\tremaining: 2m 56s\n","7:\tlearn: 0.6515997\ttotal: 1.41s\tremaining: 2m 54s\n","8:\tlearn: 0.6486987\ttotal: 1.55s\tremaining: 2m 50s\n","9:\tlearn: 0.6458337\ttotal: 1.73s\tremaining: 2m 51s\n","10:\tlearn: 0.6435745\ttotal: 1.86s\tremaining: 2m 47s\n","11:\tlearn: 0.6411898\ttotal: 2s\tremaining: 2m 45s\n","12:\tlearn: 0.6391037\ttotal: 2.17s\tremaining: 2m 45s\n","13:\tlearn: 0.6372205\ttotal: 2.33s\tremaining: 2m 44s\n","14:\tlearn: 0.6354741\ttotal: 2.49s\tremaining: 2m 43s\n","15:\tlearn: 0.6339281\ttotal: 2.65s\tremaining: 2m 42s\n","16:\tlearn: 0.6324966\ttotal: 2.82s\tremaining: 2m 43s\n","17:\tlearn: 0.6312105\ttotal: 2.96s\tremaining: 2m 41s\n","18:\tlearn: 0.6297366\ttotal: 3.2s\tremaining: 2m 45s\n","19:\tlearn: 0.6283756\ttotal: 3.48s\tremaining: 2m 50s\n","20:\tlearn: 0.6270470\ttotal: 3.82s\tremaining: 2m 58s\n","21:\tlearn: 0.6259955\ttotal: 4.09s\tremaining: 3m 2s\n","22:\tlearn: 0.6251003\ttotal: 4.29s\tremaining: 3m 2s\n","23:\tlearn: 0.6240241\ttotal: 4.57s\tremaining: 3m 5s\n","24:\tlearn: 0.6230403\ttotal: 4.87s\tremaining: 3m 9s\n","25:\tlearn: 0.6220473\ttotal: 5.17s\tremaining: 3m 13s\n","26:\tlearn: 0.6212786\ttotal: 5.44s\tremaining: 3m 16s\n","27:\tlearn: 0.6204698\ttotal: 5.71s\tremaining: 3m 18s\n","28:\tlearn: 0.6197485\ttotal: 5.97s\tremaining: 3m 19s\n","29:\tlearn: 0.6190729\ttotal: 6.24s\tremaining: 3m 21s\n","30:\tlearn: 0.6182226\ttotal: 6.54s\tremaining: 3m 24s\n","31:\tlearn: 0.6176202\ttotal: 6.79s\tremaining: 3m 25s\n","32:\tlearn: 0.6169877\ttotal: 6.96s\tremaining: 3m 23s\n","33:\tlearn: 0.6162964\ttotal: 7.11s\tremaining: 3m 22s\n","34:\tlearn: 0.6157414\ttotal: 7.24s\tremaining: 3m 19s\n","35:\tlearn: 0.6151353\ttotal: 7.58s\tremaining: 3m 22s\n","36:\tlearn: 0.6144736\ttotal: 8.01s\tremaining: 3m 28s\n","37:\tlearn: 0.6139149\ttotal: 8.29s\tremaining: 3m 29s\n","38:\tlearn: 0.6134219\ttotal: 8.44s\tremaining: 3m 27s\n","39:\tlearn: 0.6128850\ttotal: 8.58s\tremaining: 3m 25s\n","40:\tlearn: 0.6122752\ttotal: 8.75s\tremaining: 3m 24s\n","41:\tlearn: 0.6118384\ttotal: 8.87s\tremaining: 3m 22s\n","42:\tlearn: 0.6113904\ttotal: 9.04s\tremaining: 3m 21s\n","43:\tlearn: 0.6109074\ttotal: 9.21s\tremaining: 3m 20s\n","44:\tlearn: 0.6104551\ttotal: 9.37s\tremaining: 3m 18s\n","45:\tlearn: 0.6099486\ttotal: 9.53s\tremaining: 3m 17s\n","46:\tlearn: 0.6094380\ttotal: 9.66s\tremaining: 3m 15s\n","47:\tlearn: 0.6090024\ttotal: 9.81s\tremaining: 3m 14s\n","48:\tlearn: 0.6086525\ttotal: 9.95s\tremaining: 3m 13s\n","49:\tlearn: 0.6083133\ttotal: 10.1s\tremaining: 3m 11s\n","50:\tlearn: 0.6078785\ttotal: 10.2s\tremaining: 3m 10s\n","51:\tlearn: 0.6075098\ttotal: 10.4s\tremaining: 3m 9s\n","52:\tlearn: 0.6071912\ttotal: 10.5s\tremaining: 3m 8s\n","53:\tlearn: 0.6068191\ttotal: 10.7s\tremaining: 3m 7s\n","54:\tlearn: 0.6065556\ttotal: 10.8s\tremaining: 3m 6s\n","55:\tlearn: 0.6062771\ttotal: 11s\tremaining: 3m 4s\n","56:\tlearn: 0.6059925\ttotal: 11.1s\tremaining: 3m 3s\n","57:\tlearn: 0.6057459\ttotal: 11.2s\tremaining: 3m 2s\n","58:\tlearn: 0.6054378\ttotal: 11.4s\tremaining: 3m 1s\n","59:\tlearn: 0.6051938\ttotal: 11.5s\tremaining: 2m 59s\n","60:\tlearn: 0.6048908\ttotal: 11.6s\tremaining: 2m 59s\n","61:\tlearn: 0.6046331\ttotal: 11.8s\tremaining: 2m 58s\n","62:\tlearn: 0.6043254\ttotal: 11.9s\tremaining: 2m 57s\n","63:\tlearn: 0.6039572\ttotal: 12.1s\tremaining: 2m 56s\n","64:\tlearn: 0.6036944\ttotal: 12.2s\tremaining: 2m 55s\n","65:\tlearn: 0.6033729\ttotal: 12.4s\tremaining: 2m 55s\n","66:\tlearn: 0.6031156\ttotal: 12.5s\tremaining: 2m 54s\n","67:\tlearn: 0.6028700\ttotal: 12.6s\tremaining: 2m 53s\n","68:\tlearn: 0.6025331\ttotal: 12.8s\tremaining: 2m 52s\n","69:\tlearn: 0.6022922\ttotal: 13s\tremaining: 2m 52s\n","70:\tlearn: 0.6020400\ttotal: 13.1s\tremaining: 2m 51s\n","71:\tlearn: 0.6016383\ttotal: 13.3s\tremaining: 2m 51s\n","72:\tlearn: 0.6014343\ttotal: 13.4s\tremaining: 2m 50s\n","73:\tlearn: 0.6012354\ttotal: 13.6s\tremaining: 2m 49s\n","74:\tlearn: 0.6009852\ttotal: 13.7s\tremaining: 2m 48s\n","75:\tlearn: 0.6007512\ttotal: 13.8s\tremaining: 2m 48s\n","76:\tlearn: 0.6005347\ttotal: 14s\tremaining: 2m 47s\n","77:\tlearn: 0.6003331\ttotal: 14.1s\tremaining: 2m 46s\n","78:\tlearn: 0.6000966\ttotal: 14.3s\tremaining: 2m 46s\n","79:\tlearn: 0.5997198\ttotal: 14.4s\tremaining: 2m 46s\n","80:\tlearn: 0.5994801\ttotal: 14.6s\tremaining: 2m 45s\n","81:\tlearn: 0.5992782\ttotal: 14.7s\tremaining: 2m 44s\n","82:\tlearn: 0.5989645\ttotal: 14.9s\tremaining: 2m 44s\n","83:\tlearn: 0.5987868\ttotal: 15.1s\tremaining: 2m 44s\n","84:\tlearn: 0.5985435\ttotal: 15.3s\tremaining: 2m 44s\n","85:\tlearn: 0.5982448\ttotal: 15.4s\tremaining: 2m 43s\n","86:\tlearn: 0.5980524\ttotal: 15.5s\tremaining: 2m 43s\n","87:\tlearn: 0.5978589\ttotal: 15.7s\tremaining: 2m 42s\n","88:\tlearn: 0.5976705\ttotal: 15.8s\tremaining: 2m 42s\n","89:\tlearn: 0.5975146\ttotal: 15.9s\tremaining: 2m 41s\n","90:\tlearn: 0.5973618\ttotal: 16.1s\tremaining: 2m 40s\n","91:\tlearn: 0.5972047\ttotal: 16.2s\tremaining: 2m 40s\n","92:\tlearn: 0.5970373\ttotal: 16.4s\tremaining: 2m 39s\n","93:\tlearn: 0.5968973\ttotal: 16.5s\tremaining: 2m 39s\n","94:\tlearn: 0.5967316\ttotal: 16.7s\tremaining: 2m 38s\n","95:\tlearn: 0.5965777\ttotal: 16.8s\tremaining: 2m 38s\n","96:\tlearn: 0.5963900\ttotal: 17s\tremaining: 2m 38s\n","97:\tlearn: 0.5962612\ttotal: 17.2s\tremaining: 2m 38s\n","98:\tlearn: 0.5961371\ttotal: 17.5s\tremaining: 2m 38s\n","99:\tlearn: 0.5958901\ttotal: 17.8s\tremaining: 2m 39s\n","100:\tlearn: 0.5957768\ttotal: 18s\tremaining: 2m 40s\n","101:\tlearn: 0.5956978\ttotal: 18.2s\tremaining: 2m 40s\n","102:\tlearn: 0.5954547\ttotal: 18.5s\tremaining: 2m 41s\n","103:\tlearn: 0.5953300\ttotal: 18.8s\tremaining: 2m 41s\n","104:\tlearn: 0.5952163\ttotal: 19s\tremaining: 2m 42s\n","105:\tlearn: 0.5950753\ttotal: 19.3s\tremaining: 2m 43s\n","106:\tlearn: 0.5949197\ttotal: 19.7s\tremaining: 2m 44s\n","107:\tlearn: 0.5947860\ttotal: 19.9s\tremaining: 2m 44s\n","108:\tlearn: 0.5946757\ttotal: 20.1s\tremaining: 2m 44s\n","109:\tlearn: 0.5944816\ttotal: 20.4s\tremaining: 2m 44s\n","110:\tlearn: 0.5943173\ttotal: 20.6s\tremaining: 2m 44s\n","111:\tlearn: 0.5942315\ttotal: 20.7s\tremaining: 2m 44s\n","112:\tlearn: 0.5939592\ttotal: 20.9s\tremaining: 2m 43s\n","113:\tlearn: 0.5938170\ttotal: 21s\tremaining: 2m 43s\n","114:\tlearn: 0.5936994\ttotal: 21.1s\tremaining: 2m 42s\n","115:\tlearn: 0.5935636\ttotal: 21.3s\tremaining: 2m 42s\n","116:\tlearn: 0.5934232\ttotal: 21.4s\tremaining: 2m 41s\n","117:\tlearn: 0.5932865\ttotal: 21.5s\tremaining: 2m 41s\n","118:\tlearn: 0.5931494\ttotal: 21.7s\tremaining: 2m 40s\n","119:\tlearn: 0.5930380\ttotal: 21.8s\tremaining: 2m 40s\n","120:\tlearn: 0.5928830\ttotal: 22s\tremaining: 2m 39s\n","121:\tlearn: 0.5926478\ttotal: 22.1s\tremaining: 2m 39s\n","122:\tlearn: 0.5925399\ttotal: 22.3s\tremaining: 2m 38s\n","123:\tlearn: 0.5924225\ttotal: 22.4s\tremaining: 2m 38s\n","124:\tlearn: 0.5923318\ttotal: 22.5s\tremaining: 2m 37s\n","125:\tlearn: 0.5921459\ttotal: 22.7s\tremaining: 2m 37s\n","126:\tlearn: 0.5919693\ttotal: 22.8s\tremaining: 2m 36s\n","127:\tlearn: 0.5918396\ttotal: 23s\tremaining: 2m 36s\n","128:\tlearn: 0.5917317\ttotal: 23.2s\tremaining: 2m 36s\n","129:\tlearn: 0.5916015\ttotal: 23.3s\tremaining: 2m 35s\n","130:\tlearn: 0.5914779\ttotal: 23.4s\tremaining: 2m 35s\n","131:\tlearn: 0.5913950\ttotal: 23.6s\tremaining: 2m 35s\n","132:\tlearn: 0.5912766\ttotal: 23.7s\tremaining: 2m 34s\n","133:\tlearn: 0.5911610\ttotal: 23.9s\tremaining: 2m 34s\n","134:\tlearn: 0.5910695\ttotal: 24s\tremaining: 2m 33s\n","135:\tlearn: 0.5908838\ttotal: 24.1s\tremaining: 2m 33s\n","136:\tlearn: 0.5907224\ttotal: 24.3s\tremaining: 2m 32s\n","137:\tlearn: 0.5905940\ttotal: 24.4s\tremaining: 2m 32s\n","138:\tlearn: 0.5904257\ttotal: 24.6s\tremaining: 2m 32s\n","139:\tlearn: 0.5902844\ttotal: 24.7s\tremaining: 2m 31s\n","140:\tlearn: 0.5901587\ttotal: 24.9s\tremaining: 2m 31s\n","141:\tlearn: 0.5900083\ttotal: 25s\tremaining: 2m 31s\n","142:\tlearn: 0.5899136\ttotal: 25.2s\tremaining: 2m 30s\n","143:\tlearn: 0.5898012\ttotal: 25.3s\tremaining: 2m 30s\n","144:\tlearn: 0.5896715\ttotal: 25.4s\tremaining: 2m 29s\n","145:\tlearn: 0.5895151\ttotal: 25.6s\tremaining: 2m 29s\n","146:\tlearn: 0.5893781\ttotal: 25.7s\tremaining: 2m 29s\n","147:\tlearn: 0.5892376\ttotal: 25.9s\tremaining: 2m 29s\n","148:\tlearn: 0.5891321\ttotal: 26s\tremaining: 2m 28s\n","149:\tlearn: 0.5889958\ttotal: 26.2s\tremaining: 2m 28s\n","150:\tlearn: 0.5888668\ttotal: 26.3s\tremaining: 2m 27s\n","151:\tlearn: 0.5887210\ttotal: 26.5s\tremaining: 2m 27s\n","152:\tlearn: 0.5885791\ttotal: 26.6s\tremaining: 2m 27s\n","153:\tlearn: 0.5884507\ttotal: 26.8s\tremaining: 2m 27s\n","154:\tlearn: 0.5883164\ttotal: 26.9s\tremaining: 2m 26s\n","155:\tlearn: 0.5881869\ttotal: 27.1s\tremaining: 2m 26s\n","156:\tlearn: 0.5880541\ttotal: 27.2s\tremaining: 2m 25s\n","157:\tlearn: 0.5879328\ttotal: 27.3s\tremaining: 2m 25s\n","158:\tlearn: 0.5877862\ttotal: 27.5s\tremaining: 2m 25s\n","159:\tlearn: 0.5876786\ttotal: 27.7s\tremaining: 2m 25s\n","160:\tlearn: 0.5875611\ttotal: 27.8s\tremaining: 2m 24s\n","161:\tlearn: 0.5874152\ttotal: 27.9s\tremaining: 2m 24s\n","162:\tlearn: 0.5872912\ttotal: 28.1s\tremaining: 2m 24s\n","163:\tlearn: 0.5871630\ttotal: 28.2s\tremaining: 2m 23s\n","164:\tlearn: 0.5870474\ttotal: 28.3s\tremaining: 2m 23s\n","165:\tlearn: 0.5869529\ttotal: 28.4s\tremaining: 2m 22s\n","166:\tlearn: 0.5868397\ttotal: 28.6s\tremaining: 2m 22s\n","167:\tlearn: 0.5867436\ttotal: 28.7s\tremaining: 2m 22s\n","168:\tlearn: 0.5866171\ttotal: 28.9s\tremaining: 2m 22s\n","169:\tlearn: 0.5864610\ttotal: 29.1s\tremaining: 2m 21s\n","170:\tlearn: 0.5863614\ttotal: 29.2s\tremaining: 2m 21s\n","171:\tlearn: 0.5862414\ttotal: 29.3s\tremaining: 2m 21s\n","172:\tlearn: 0.5861483\ttotal: 29.5s\tremaining: 2m 20s\n","173:\tlearn: 0.5860298\ttotal: 29.6s\tremaining: 2m 20s\n","174:\tlearn: 0.5859084\ttotal: 29.8s\tremaining: 2m 20s\n","175:\tlearn: 0.5857676\ttotal: 29.9s\tremaining: 2m 20s\n","176:\tlearn: 0.5856522\ttotal: 30.1s\tremaining: 2m 19s\n","177:\tlearn: 0.5855775\ttotal: 30.2s\tremaining: 2m 19s\n","178:\tlearn: 0.5854850\ttotal: 30.3s\tremaining: 2m 19s\n","179:\tlearn: 0.5853772\ttotal: 30.5s\tremaining: 2m 18s\n","180:\tlearn: 0.5852833\ttotal: 30.7s\tremaining: 2m 18s\n","181:\tlearn: 0.5851788\ttotal: 30.9s\tremaining: 2m 18s\n","182:\tlearn: 0.5850580\ttotal: 31.2s\tremaining: 2m 19s\n","183:\tlearn: 0.5849215\ttotal: 31.4s\tremaining: 2m 19s\n","184:\tlearn: 0.5848163\ttotal: 31.7s\tremaining: 2m 19s\n","185:\tlearn: 0.5846742\ttotal: 31.9s\tremaining: 2m 19s\n","186:\tlearn: 0.5845542\ttotal: 32.3s\tremaining: 2m 20s\n","187:\tlearn: 0.5844443\ttotal: 32.6s\tremaining: 2m 20s\n","188:\tlearn: 0.5843171\ttotal: 32.8s\tremaining: 2m 20s\n","189:\tlearn: 0.5842227\ttotal: 33.1s\tremaining: 2m 21s\n","190:\tlearn: 0.5840979\ttotal: 33.4s\tremaining: 2m 21s\n","191:\tlearn: 0.5840206\ttotal: 33.6s\tremaining: 2m 21s\n","192:\tlearn: 0.5838907\ttotal: 33.9s\tremaining: 2m 21s\n","193:\tlearn: 0.5837640\ttotal: 34.2s\tremaining: 2m 21s\n","194:\tlearn: 0.5836288\ttotal: 34.3s\tremaining: 2m 21s\n","195:\tlearn: 0.5835444\ttotal: 34.5s\tremaining: 2m 21s\n","196:\tlearn: 0.5834589\ttotal: 34.6s\tremaining: 2m 21s\n","197:\tlearn: 0.5833822\ttotal: 34.7s\tremaining: 2m 20s\n","198:\tlearn: 0.5832492\ttotal: 34.9s\tremaining: 2m 20s\n","199:\tlearn: 0.5831241\ttotal: 35.1s\tremaining: 2m 20s\n","200:\tlearn: 0.5830375\ttotal: 35.2s\tremaining: 2m 20s\n","201:\tlearn: 0.5829635\ttotal: 35.3s\tremaining: 2m 19s\n","202:\tlearn: 0.5828718\ttotal: 35.5s\tremaining: 2m 19s\n","203:\tlearn: 0.5827677\ttotal: 35.6s\tremaining: 2m 18s\n","204:\tlearn: 0.5826442\ttotal: 35.8s\tremaining: 2m 18s\n","205:\tlearn: 0.5825342\ttotal: 36s\tremaining: 2m 18s\n","206:\tlearn: 0.5824467\ttotal: 36.1s\tremaining: 2m 18s\n","207:\tlearn: 0.5823614\ttotal: 36.3s\tremaining: 2m 18s\n","208:\tlearn: 0.5822523\ttotal: 36.4s\tremaining: 2m 17s\n","209:\tlearn: 0.5821437\ttotal: 36.6s\tremaining: 2m 17s\n","210:\tlearn: 0.5820418\ttotal: 36.7s\tremaining: 2m 17s\n","211:\tlearn: 0.5819519\ttotal: 36.9s\tremaining: 2m 17s\n","212:\tlearn: 0.5818691\ttotal: 37s\tremaining: 2m 16s\n","213:\tlearn: 0.5817650\ttotal: 37.2s\tremaining: 2m 16s\n","214:\tlearn: 0.5816792\ttotal: 37.3s\tremaining: 2m 16s\n","215:\tlearn: 0.5815724\ttotal: 37.5s\tremaining: 2m 16s\n","216:\tlearn: 0.5814782\ttotal: 37.6s\tremaining: 2m 15s\n","217:\tlearn: 0.5813995\ttotal: 37.8s\tremaining: 2m 15s\n","218:\tlearn: 0.5813242\ttotal: 37.9s\tremaining: 2m 15s\n","219:\tlearn: 0.5812406\ttotal: 38s\tremaining: 2m 14s\n","220:\tlearn: 0.5811470\ttotal: 38.2s\tremaining: 2m 14s\n","221:\tlearn: 0.5810635\ttotal: 38.3s\tremaining: 2m 14s\n","222:\tlearn: 0.5809912\ttotal: 38.4s\tremaining: 2m 13s\n","223:\tlearn: 0.5809287\ttotal: 38.5s\tremaining: 2m 13s\n","224:\tlearn: 0.5808228\ttotal: 38.7s\tremaining: 2m 13s\n","225:\tlearn: 0.5807412\ttotal: 38.8s\tremaining: 2m 12s\n","226:\tlearn: 0.5806542\ttotal: 38.9s\tremaining: 2m 12s\n","227:\tlearn: 0.5805597\ttotal: 39.1s\tremaining: 2m 12s\n","228:\tlearn: 0.5804923\ttotal: 39.2s\tremaining: 2m 11s\n","229:\tlearn: 0.5804077\ttotal: 39.3s\tremaining: 2m 11s\n","230:\tlearn: 0.5803580\ttotal: 39.4s\tremaining: 2m 11s\n","231:\tlearn: 0.5802732\ttotal: 39.6s\tremaining: 2m 10s\n","232:\tlearn: 0.5801954\ttotal: 39.7s\tremaining: 2m 10s\n","233:\tlearn: 0.5801087\ttotal: 39.8s\tremaining: 2m 10s\n","234:\tlearn: 0.5800056\ttotal: 40s\tremaining: 2m 10s\n","235:\tlearn: 0.5798770\ttotal: 40.1s\tremaining: 2m 9s\n","236:\tlearn: 0.5797919\ttotal: 40.3s\tremaining: 2m 9s\n","237:\tlearn: 0.5796970\ttotal: 40.4s\tremaining: 2m 9s\n","238:\tlearn: 0.5796476\ttotal: 40.5s\tremaining: 2m 9s\n","239:\tlearn: 0.5795920\ttotal: 40.7s\tremaining: 2m 8s\n","240:\tlearn: 0.5795258\ttotal: 40.8s\tremaining: 2m 8s\n","241:\tlearn: 0.5794360\ttotal: 40.9s\tremaining: 2m 8s\n","242:\tlearn: 0.5793316\ttotal: 41s\tremaining: 2m 7s\n","243:\tlearn: 0.5792513\ttotal: 41.2s\tremaining: 2m 7s\n","244:\tlearn: 0.5791474\ttotal: 41.8s\tremaining: 2m 8s\n","245:\tlearn: 0.5790958\ttotal: 41.9s\tremaining: 2m 8s\n","246:\tlearn: 0.5790109\ttotal: 42.1s\tremaining: 2m 8s\n","247:\tlearn: 0.5789243\ttotal: 42.2s\tremaining: 2m 7s\n","248:\tlearn: 0.5788618\ttotal: 42.3s\tremaining: 2m 7s\n","249:\tlearn: 0.5787665\ttotal: 42.9s\tremaining: 2m 8s\n","250:\tlearn: 0.5786871\ttotal: 43.1s\tremaining: 2m 8s\n","251:\tlearn: 0.5786470\ttotal: 43.2s\tremaining: 2m 8s\n","252:\tlearn: 0.5785757\ttotal: 43.3s\tremaining: 2m 7s\n","253:\tlearn: 0.5784820\ttotal: 43.5s\tremaining: 2m 7s\n","254:\tlearn: 0.5783645\ttotal: 44s\tremaining: 2m 8s\n","255:\tlearn: 0.5782921\ttotal: 44.2s\tremaining: 2m 8s\n","256:\tlearn: 0.5782200\ttotal: 44.5s\tremaining: 2m 8s\n","257:\tlearn: 0.5781731\ttotal: 44.7s\tremaining: 2m 8s\n","258:\tlearn: 0.5780906\ttotal: 45s\tremaining: 2m 8s\n","259:\tlearn: 0.5780214\ttotal: 45.3s\tremaining: 2m 8s\n","260:\tlearn: 0.5779405\ttotal: 45.5s\tremaining: 2m 8s\n","261:\tlearn: 0.5778669\ttotal: 45.7s\tremaining: 2m 8s\n","262:\tlearn: 0.5777819\ttotal: 46s\tremaining: 2m 8s\n","263:\tlearn: 0.5776818\ttotal: 46.3s\tremaining: 2m 9s\n","264:\tlearn: 0.5775997\ttotal: 46.5s\tremaining: 2m 9s\n","265:\tlearn: 0.5775586\ttotal: 46.7s\tremaining: 2m 8s\n","266:\tlearn: 0.5775090\ttotal: 46.9s\tremaining: 2m 8s\n","267:\tlearn: 0.5774353\ttotal: 47.2s\tremaining: 2m 8s\n","268:\tlearn: 0.5773520\ttotal: 47.4s\tremaining: 2m 8s\n","269:\tlearn: 0.5772707\ttotal: 47.7s\tremaining: 2m 8s\n","270:\tlearn: 0.5771989\ttotal: 47.8s\tremaining: 2m 8s\n","271:\tlearn: 0.5771337\ttotal: 48s\tremaining: 2m 8s\n","272:\tlearn: 0.5770616\ttotal: 48.1s\tremaining: 2m 8s\n","273:\tlearn: 0.5769963\ttotal: 48.2s\tremaining: 2m 7s\n","274:\tlearn: 0.5769035\ttotal: 48.4s\tremaining: 2m 7s\n","275:\tlearn: 0.5768305\ttotal: 48.5s\tremaining: 2m 7s\n","276:\tlearn: 0.5767798\ttotal: 48.6s\tremaining: 2m 6s\n","277:\tlearn: 0.5766874\ttotal: 48.8s\tremaining: 2m 6s\n","278:\tlearn: 0.5766140\ttotal: 48.9s\tremaining: 2m 6s\n","279:\tlearn: 0.5765400\ttotal: 49.1s\tremaining: 2m 6s\n","280:\tlearn: 0.5764707\ttotal: 49.2s\tremaining: 2m 5s\n","281:\tlearn: 0.5764069\ttotal: 49.3s\tremaining: 2m 5s\n","282:\tlearn: 0.5763325\ttotal: 49.5s\tremaining: 2m 5s\n","283:\tlearn: 0.5762622\ttotal: 49.6s\tremaining: 2m 5s\n","284:\tlearn: 0.5762104\ttotal: 49.8s\tremaining: 2m 4s\n","285:\tlearn: 0.5761206\ttotal: 49.9s\tremaining: 2m 4s\n","286:\tlearn: 0.5760448\ttotal: 50.1s\tremaining: 2m 4s\n","287:\tlearn: 0.5759358\ttotal: 50.2s\tremaining: 2m 4s\n","288:\tlearn: 0.5758991\ttotal: 50.3s\tremaining: 2m 3s\n","289:\tlearn: 0.5758126\ttotal: 50.4s\tremaining: 2m 3s\n","290:\tlearn: 0.5757067\ttotal: 50.6s\tremaining: 2m 3s\n","291:\tlearn: 0.5756133\ttotal: 50.7s\tremaining: 2m 3s\n","292:\tlearn: 0.5755377\ttotal: 50.9s\tremaining: 2m 2s\n","293:\tlearn: 0.5754742\ttotal: 51s\tremaining: 2m 2s\n","294:\tlearn: 0.5754405\ttotal: 51.1s\tremaining: 2m 2s\n","295:\tlearn: 0.5753610\ttotal: 51.3s\tremaining: 2m 1s\n","296:\tlearn: 0.5752798\ttotal: 51.4s\tremaining: 2m 1s\n","297:\tlearn: 0.5751820\ttotal: 51.6s\tremaining: 2m 1s\n","298:\tlearn: 0.5751182\ttotal: 51.7s\tremaining: 2m 1s\n","299:\tlearn: 0.5750701\ttotal: 51.8s\tremaining: 2m\n","300:\tlearn: 0.5749804\ttotal: 52s\tremaining: 2m\n","301:\tlearn: 0.5749180\ttotal: 52.1s\tremaining: 2m\n","302:\tlearn: 0.5748869\ttotal: 52.2s\tremaining: 2m\n","303:\tlearn: 0.5748430\ttotal: 52.4s\tremaining: 1m 59s\n","304:\tlearn: 0.5747946\ttotal: 52.5s\tremaining: 1m 59s\n","305:\tlearn: 0.5747347\ttotal: 52.6s\tremaining: 1m 59s\n","306:\tlearn: 0.5746561\ttotal: 52.7s\tremaining: 1m 59s\n","307:\tlearn: 0.5745604\ttotal: 52.9s\tremaining: 1m 58s\n","308:\tlearn: 0.5744880\ttotal: 53s\tremaining: 1m 58s\n","309:\tlearn: 0.5744355\ttotal: 53.2s\tremaining: 1m 58s\n","310:\tlearn: 0.5743679\ttotal: 53.3s\tremaining: 1m 58s\n","311:\tlearn: 0.5742885\ttotal: 53.5s\tremaining: 1m 57s\n","312:\tlearn: 0.5742237\ttotal: 53.6s\tremaining: 1m 57s\n","313:\tlearn: 0.5741608\ttotal: 53.7s\tremaining: 1m 57s\n","314:\tlearn: 0.5740927\ttotal: 53.9s\tremaining: 1m 57s\n","315:\tlearn: 0.5740396\ttotal: 54s\tremaining: 1m 56s\n","316:\tlearn: 0.5739809\ttotal: 54.1s\tremaining: 1m 56s\n","317:\tlearn: 0.5739137\ttotal: 54.2s\tremaining: 1m 56s\n","318:\tlearn: 0.5738162\ttotal: 54.3s\tremaining: 1m 56s\n","319:\tlearn: 0.5737373\ttotal: 54.5s\tremaining: 1m 55s\n","320:\tlearn: 0.5736788\ttotal: 54.7s\tremaining: 1m 55s\n","321:\tlearn: 0.5736078\ttotal: 54.8s\tremaining: 1m 55s\n","322:\tlearn: 0.5735829\ttotal: 54.9s\tremaining: 1m 55s\n","323:\tlearn: 0.5734960\ttotal: 55.1s\tremaining: 1m 54s\n","324:\tlearn: 0.5734450\ttotal: 55.2s\tremaining: 1m 54s\n","325:\tlearn: 0.5733665\ttotal: 55.3s\tremaining: 1m 54s\n","326:\tlearn: 0.5733008\ttotal: 55.4s\tremaining: 1m 54s\n","327:\tlearn: 0.5732365\ttotal: 55.6s\tremaining: 1m 53s\n","328:\tlearn: 0.5731647\ttotal: 55.7s\tremaining: 1m 53s\n","329:\tlearn: 0.5730947\ttotal: 55.9s\tremaining: 1m 53s\n","330:\tlearn: 0.5730229\ttotal: 56s\tremaining: 1m 53s\n","331:\tlearn: 0.5729663\ttotal: 56.2s\tremaining: 1m 52s\n","332:\tlearn: 0.5729025\ttotal: 56.3s\tremaining: 1m 52s\n","333:\tlearn: 0.5728297\ttotal: 56.4s\tremaining: 1m 52s\n","334:\tlearn: 0.5727797\ttotal: 56.5s\tremaining: 1m 52s\n","335:\tlearn: 0.5727330\ttotal: 56.7s\tremaining: 1m 52s\n","336:\tlearn: 0.5726802\ttotal: 56.8s\tremaining: 1m 51s\n","337:\tlearn: 0.5726216\ttotal: 56.9s\tremaining: 1m 51s\n","338:\tlearn: 0.5725214\ttotal: 57.1s\tremaining: 1m 51s\n","339:\tlearn: 0.5724796\ttotal: 57.2s\tremaining: 1m 51s\n","340:\tlearn: 0.5723953\ttotal: 57.3s\tremaining: 1m 50s\n","341:\tlearn: 0.5723428\ttotal: 57.5s\tremaining: 1m 50s\n","342:\tlearn: 0.5722928\ttotal: 57.6s\tremaining: 1m 50s\n","343:\tlearn: 0.5722394\ttotal: 57.7s\tremaining: 1m 50s\n","344:\tlearn: 0.5721698\ttotal: 57.9s\tremaining: 1m 49s\n","345:\tlearn: 0.5721124\ttotal: 58.2s\tremaining: 1m 49s\n","346:\tlearn: 0.5720274\ttotal: 58.4s\tremaining: 1m 49s\n","347:\tlearn: 0.5719704\ttotal: 58.6s\tremaining: 1m 49s\n","348:\tlearn: 0.5719096\ttotal: 58.9s\tremaining: 1m 49s\n","349:\tlearn: 0.5718412\ttotal: 59.2s\tremaining: 1m 49s\n","350:\tlearn: 0.5717927\ttotal: 59.3s\tremaining: 1m 49s\n","351:\tlearn: 0.5717444\ttotal: 59.6s\tremaining: 1m 49s\n","352:\tlearn: 0.5717369\ttotal: 59.8s\tremaining: 1m 49s\n","353:\tlearn: 0.5716641\ttotal: 60s\tremaining: 1m 49s\n","354:\tlearn: 0.5715906\ttotal: 1m\tremaining: 1m 49s\n","355:\tlearn: 0.5715449\ttotal: 1m\tremaining: 1m 49s\n","356:\tlearn: 0.5714866\ttotal: 1m\tremaining: 1m 49s\n","357:\tlearn: 0.5714399\ttotal: 1m\tremaining: 1m 49s\n","358:\tlearn: 0.5713801\ttotal: 1m 1s\tremaining: 1m 49s\n","359:\tlearn: 0.5713187\ttotal: 1m 1s\tremaining: 1m 49s\n","360:\tlearn: 0.5712668\ttotal: 1m 1s\tremaining: 1m 48s\n","361:\tlearn: 0.5711936\ttotal: 1m 1s\tremaining: 1m 48s\n","362:\tlearn: 0.5711407\ttotal: 1m 1s\tremaining: 1m 48s\n","363:\tlearn: 0.5710718\ttotal: 1m 1s\tremaining: 1m 48s\n","364:\tlearn: 0.5710333\ttotal: 1m 2s\tremaining: 1m 47s\n","365:\tlearn: 0.5709774\ttotal: 1m 2s\tremaining: 1m 47s\n","366:\tlearn: 0.5708821\ttotal: 1m 2s\tremaining: 1m 47s\n","367:\tlearn: 0.5708182\ttotal: 1m 2s\tremaining: 1m 47s\n","368:\tlearn: 0.5707751\ttotal: 1m 2s\tremaining: 1m 46s\n","369:\tlearn: 0.5706874\ttotal: 1m 2s\tremaining: 1m 46s\n","370:\tlearn: 0.5706124\ttotal: 1m 2s\tremaining: 1m 46s\n","371:\tlearn: 0.5705696\ttotal: 1m 2s\tremaining: 1m 46s\n","372:\tlearn: 0.5704999\ttotal: 1m 3s\tremaining: 1m 46s\n","373:\tlearn: 0.5704458\ttotal: 1m 3s\tremaining: 1m 45s\n","374:\tlearn: 0.5703748\ttotal: 1m 3s\tremaining: 1m 45s\n","375:\tlearn: 0.5702881\ttotal: 1m 3s\tremaining: 1m 45s\n","376:\tlearn: 0.5702088\ttotal: 1m 3s\tremaining: 1m 45s\n","377:\tlearn: 0.5701378\ttotal: 1m 3s\tremaining: 1m 44s\n","378:\tlearn: 0.5700597\ttotal: 1m 3s\tremaining: 1m 44s\n","379:\tlearn: 0.5699869\ttotal: 1m 4s\tremaining: 1m 44s\n","380:\tlearn: 0.5699348\ttotal: 1m 4s\tremaining: 1m 44s\n","381:\tlearn: 0.5698576\ttotal: 1m 4s\tremaining: 1m 44s\n","382:\tlearn: 0.5697820\ttotal: 1m 4s\tremaining: 1m 43s\n","383:\tlearn: 0.5696785\ttotal: 1m 4s\tremaining: 1m 43s\n","384:\tlearn: 0.5696301\ttotal: 1m 4s\tremaining: 1m 43s\n","385:\tlearn: 0.5695598\ttotal: 1m 4s\tremaining: 1m 43s\n","386:\tlearn: 0.5694953\ttotal: 1m 5s\tremaining: 1m 43s\n","387:\tlearn: 0.5694252\ttotal: 1m 5s\tremaining: 1m 42s\n","388:\tlearn: 0.5693493\ttotal: 1m 5s\tremaining: 1m 42s\n","389:\tlearn: 0.5692866\ttotal: 1m 5s\tremaining: 1m 42s\n","390:\tlearn: 0.5692283\ttotal: 1m 5s\tremaining: 1m 42s\n","391:\tlearn: 0.5691674\ttotal: 1m 5s\tremaining: 1m 42s\n","392:\tlearn: 0.5691337\ttotal: 1m 5s\tremaining: 1m 41s\n","393:\tlearn: 0.5690877\ttotal: 1m 6s\tremaining: 1m 41s\n","394:\tlearn: 0.5690287\ttotal: 1m 6s\tremaining: 1m 41s\n","395:\tlearn: 0.5689770\ttotal: 1m 6s\tremaining: 1m 41s\n","396:\tlearn: 0.5689017\ttotal: 1m 6s\tremaining: 1m 40s\n","397:\tlearn: 0.5688404\ttotal: 1m 6s\tremaining: 1m 40s\n","398:\tlearn: 0.5687682\ttotal: 1m 6s\tremaining: 1m 40s\n","399:\tlearn: 0.5687539\ttotal: 1m 6s\tremaining: 1m 40s\n","400:\tlearn: 0.5686525\ttotal: 1m 7s\tremaining: 1m 40s\n","401:\tlearn: 0.5685605\ttotal: 1m 7s\tremaining: 1m 40s\n","402:\tlearn: 0.5685362\ttotal: 1m 7s\tremaining: 1m 39s\n","403:\tlearn: 0.5684648\ttotal: 1m 7s\tremaining: 1m 39s\n","404:\tlearn: 0.5684165\ttotal: 1m 7s\tremaining: 1m 39s\n","405:\tlearn: 0.5683591\ttotal: 1m 7s\tremaining: 1m 39s\n","406:\tlearn: 0.5683120\ttotal: 1m 7s\tremaining: 1m 38s\n","407:\tlearn: 0.5682390\ttotal: 1m 7s\tremaining: 1m 38s\n","408:\tlearn: 0.5681830\ttotal: 1m 8s\tremaining: 1m 38s\n","409:\tlearn: 0.5681251\ttotal: 1m 8s\tremaining: 1m 38s\n","410:\tlearn: 0.5680553\ttotal: 1m 8s\tremaining: 1m 37s\n","411:\tlearn: 0.5679998\ttotal: 1m 8s\tremaining: 1m 37s\n","412:\tlearn: 0.5679259\ttotal: 1m 8s\tremaining: 1m 37s\n","413:\tlearn: 0.5678576\ttotal: 1m 8s\tremaining: 1m 37s\n","414:\tlearn: 0.5677857\ttotal: 1m 8s\tremaining: 1m 37s\n","415:\tlearn: 0.5677264\ttotal: 1m 9s\tremaining: 1m 36s\n","416:\tlearn: 0.5677207\ttotal: 1m 9s\tremaining: 1m 36s\n","417:\tlearn: 0.5676466\ttotal: 1m 9s\tremaining: 1m 36s\n","418:\tlearn: 0.5676176\ttotal: 1m 9s\tremaining: 1m 36s\n","419:\tlearn: 0.5676130\ttotal: 1m 9s\tremaining: 1m 35s\n","420:\tlearn: 0.5676058\ttotal: 1m 9s\tremaining: 1m 35s\n","421:\tlearn: 0.5675290\ttotal: 1m 9s\tremaining: 1m 35s\n","422:\tlearn: 0.5674605\ttotal: 1m 9s\tremaining: 1m 35s\n","423:\tlearn: 0.5674013\ttotal: 1m 10s\tremaining: 1m 35s\n","424:\tlearn: 0.5673460\ttotal: 1m 10s\tremaining: 1m 34s\n","425:\tlearn: 0.5672903\ttotal: 1m 10s\tremaining: 1m 34s\n","426:\tlearn: 0.5672133\ttotal: 1m 10s\tremaining: 1m 34s\n","427:\tlearn: 0.5671611\ttotal: 1m 10s\tremaining: 1m 34s\n","428:\tlearn: 0.5670684\ttotal: 1m 10s\tremaining: 1m 34s\n","429:\tlearn: 0.5669955\ttotal: 1m 10s\tremaining: 1m 34s\n","430:\tlearn: 0.5669255\ttotal: 1m 11s\tremaining: 1m 33s\n","431:\tlearn: 0.5668690\ttotal: 1m 11s\tremaining: 1m 33s\n","432:\tlearn: 0.5668185\ttotal: 1m 11s\tremaining: 1m 33s\n","433:\tlearn: 0.5667444\ttotal: 1m 11s\tremaining: 1m 33s\n","434:\tlearn: 0.5667034\ttotal: 1m 11s\tremaining: 1m 33s\n","435:\tlearn: 0.5666531\ttotal: 1m 12s\tremaining: 1m 33s\n","436:\tlearn: 0.5666000\ttotal: 1m 12s\tremaining: 1m 33s\n","437:\tlearn: 0.5665333\ttotal: 1m 12s\tremaining: 1m 33s\n","438:\tlearn: 0.5664705\ttotal: 1m 12s\tremaining: 1m 33s\n","439:\tlearn: 0.5664118\ttotal: 1m 13s\tremaining: 1m 33s\n","440:\tlearn: 0.5663747\ttotal: 1m 13s\tremaining: 1m 32s\n","441:\tlearn: 0.5663203\ttotal: 1m 13s\tremaining: 1m 32s\n","442:\tlearn: 0.5662568\ttotal: 1m 13s\tremaining: 1m 32s\n","443:\tlearn: 0.5661998\ttotal: 1m 14s\tremaining: 1m 32s\n","444:\tlearn: 0.5661512\ttotal: 1m 14s\tremaining: 1m 32s\n","445:\tlearn: 0.5660935\ttotal: 1m 14s\tremaining: 1m 32s\n","446:\tlearn: 0.5660467\ttotal: 1m 14s\tremaining: 1m 32s\n","447:\tlearn: 0.5660010\ttotal: 1m 15s\tremaining: 1m 32s\n","448:\tlearn: 0.5659278\ttotal: 1m 15s\tremaining: 1m 32s\n","449:\tlearn: 0.5658799\ttotal: 1m 15s\tremaining: 1m 32s\n","450:\tlearn: 0.5658147\ttotal: 1m 15s\tremaining: 1m 31s\n","451:\tlearn: 0.5657804\ttotal: 1m 15s\tremaining: 1m 31s\n","452:\tlearn: 0.5657073\ttotal: 1m 15s\tremaining: 1m 31s\n","453:\tlearn: 0.5656412\ttotal: 1m 15s\tremaining: 1m 31s\n","454:\tlearn: 0.5655727\ttotal: 1m 16s\tremaining: 1m 31s\n","455:\tlearn: 0.5655019\ttotal: 1m 16s\tremaining: 1m 30s\n","456:\tlearn: 0.5654421\ttotal: 1m 16s\tremaining: 1m 30s\n","457:\tlearn: 0.5653750\ttotal: 1m 16s\tremaining: 1m 30s\n","458:\tlearn: 0.5653175\ttotal: 1m 16s\tremaining: 1m 30s\n","459:\tlearn: 0.5652647\ttotal: 1m 16s\tremaining: 1m 30s\n","460:\tlearn: 0.5652064\ttotal: 1m 16s\tremaining: 1m 29s\n","461:\tlearn: 0.5651436\ttotal: 1m 17s\tremaining: 1m 29s\n","462:\tlearn: 0.5651071\ttotal: 1m 17s\tremaining: 1m 29s\n","463:\tlearn: 0.5650244\ttotal: 1m 17s\tremaining: 1m 29s\n","464:\tlearn: 0.5650201\ttotal: 1m 17s\tremaining: 1m 29s\n","465:\tlearn: 0.5649784\ttotal: 1m 17s\tremaining: 1m 28s\n","466:\tlearn: 0.5649305\ttotal: 1m 17s\tremaining: 1m 28s\n","467:\tlearn: 0.5648899\ttotal: 1m 17s\tremaining: 1m 28s\n","468:\tlearn: 0.5648384\ttotal: 1m 17s\tremaining: 1m 28s\n","469:\tlearn: 0.5647869\ttotal: 1m 18s\tremaining: 1m 28s\n","470:\tlearn: 0.5647399\ttotal: 1m 18s\tremaining: 1m 27s\n","471:\tlearn: 0.5646739\ttotal: 1m 18s\tremaining: 1m 27s\n","472:\tlearn: 0.5646084\ttotal: 1m 18s\tremaining: 1m 27s\n","473:\tlearn: 0.5645476\ttotal: 1m 18s\tremaining: 1m 27s\n","474:\tlearn: 0.5644955\ttotal: 1m 18s\tremaining: 1m 27s\n","475:\tlearn: 0.5644244\ttotal: 1m 18s\tremaining: 1m 26s\n","476:\tlearn: 0.5643407\ttotal: 1m 19s\tremaining: 1m 26s\n","477:\tlearn: 0.5642689\ttotal: 1m 19s\tremaining: 1m 26s\n","478:\tlearn: 0.5642249\ttotal: 1m 19s\tremaining: 1m 26s\n","479:\tlearn: 0.5641571\ttotal: 1m 19s\tremaining: 1m 26s\n","480:\tlearn: 0.5641515\ttotal: 1m 19s\tremaining: 1m 25s\n","481:\tlearn: 0.5641189\ttotal: 1m 19s\tremaining: 1m 25s\n","482:\tlearn: 0.5640614\ttotal: 1m 19s\tremaining: 1m 25s\n","483:\tlearn: 0.5639787\ttotal: 1m 20s\tremaining: 1m 25s\n","484:\tlearn: 0.5639104\ttotal: 1m 20s\tremaining: 1m 25s\n","485:\tlearn: 0.5638726\ttotal: 1m 20s\tremaining: 1m 25s\n","486:\tlearn: 0.5638241\ttotal: 1m 20s\tremaining: 1m 24s\n","487:\tlearn: 0.5637373\ttotal: 1m 20s\tremaining: 1m 24s\n","488:\tlearn: 0.5636644\ttotal: 1m 20s\tremaining: 1m 24s\n","489:\tlearn: 0.5636099\ttotal: 1m 21s\tremaining: 1m 24s\n","490:\tlearn: 0.5635620\ttotal: 1m 21s\tremaining: 1m 24s\n","491:\tlearn: 0.5635432\ttotal: 1m 21s\tremaining: 1m 23s\n","492:\tlearn: 0.5634737\ttotal: 1m 21s\tremaining: 1m 23s\n","493:\tlearn: 0.5634236\ttotal: 1m 21s\tremaining: 1m 23s\n","494:\tlearn: 0.5633590\ttotal: 1m 21s\tremaining: 1m 23s\n","495:\tlearn: 0.5632977\ttotal: 1m 21s\tremaining: 1m 23s\n","496:\tlearn: 0.5632514\ttotal: 1m 21s\tremaining: 1m 22s\n","497:\tlearn: 0.5632206\ttotal: 1m 21s\tremaining: 1m 22s\n","498:\tlearn: 0.5632014\ttotal: 1m 22s\tremaining: 1m 22s\n","499:\tlearn: 0.5631457\ttotal: 1m 22s\tremaining: 1m 22s\n","500:\tlearn: 0.5631032\ttotal: 1m 22s\tremaining: 1m 22s\n","501:\tlearn: 0.5630635\ttotal: 1m 22s\tremaining: 1m 21s\n","502:\tlearn: 0.5630096\ttotal: 1m 22s\tremaining: 1m 21s\n","503:\tlearn: 0.5629551\ttotal: 1m 22s\tremaining: 1m 21s\n","504:\tlearn: 0.5628996\ttotal: 1m 22s\tremaining: 1m 21s\n","505:\tlearn: 0.5628370\ttotal: 1m 23s\tremaining: 1m 21s\n","506:\tlearn: 0.5627980\ttotal: 1m 23s\tremaining: 1m 20s\n","507:\tlearn: 0.5627483\ttotal: 1m 23s\tremaining: 1m 20s\n","508:\tlearn: 0.5626956\ttotal: 1m 23s\tremaining: 1m 20s\n","509:\tlearn: 0.5626429\ttotal: 1m 23s\tremaining: 1m 20s\n","510:\tlearn: 0.5625985\ttotal: 1m 23s\tremaining: 1m 20s\n","511:\tlearn: 0.5625946\ttotal: 1m 23s\tremaining: 1m 19s\n","512:\tlearn: 0.5625906\ttotal: 1m 23s\tremaining: 1m 19s\n","513:\tlearn: 0.5625200\ttotal: 1m 23s\tremaining: 1m 19s\n","514:\tlearn: 0.5624733\ttotal: 1m 24s\tremaining: 1m 19s\n","515:\tlearn: 0.5624106\ttotal: 1m 24s\tremaining: 1m 19s\n","516:\tlearn: 0.5623552\ttotal: 1m 24s\tremaining: 1m 18s\n","517:\tlearn: 0.5623140\ttotal: 1m 24s\tremaining: 1m 18s\n","518:\tlearn: 0.5622691\ttotal: 1m 24s\tremaining: 1m 18s\n","519:\tlearn: 0.5622171\ttotal: 1m 24s\tremaining: 1m 18s\n","520:\tlearn: 0.5621620\ttotal: 1m 25s\tremaining: 1m 18s\n","521:\tlearn: 0.5621031\ttotal: 1m 25s\tremaining: 1m 18s\n","522:\tlearn: 0.5620403\ttotal: 1m 25s\tremaining: 1m 17s\n","523:\tlearn: 0.5619904\ttotal: 1m 25s\tremaining: 1m 17s\n","524:\tlearn: 0.5619303\ttotal: 1m 25s\tremaining: 1m 17s\n","525:\tlearn: 0.5618518\ttotal: 1m 26s\tremaining: 1m 17s\n","526:\tlearn: 0.5617968\ttotal: 1m 26s\tremaining: 1m 17s\n","527:\tlearn: 0.5617632\ttotal: 1m 26s\tremaining: 1m 17s\n","528:\tlearn: 0.5617297\ttotal: 1m 27s\tremaining: 1m 17s\n","529:\tlearn: 0.5617009\ttotal: 1m 27s\tremaining: 1m 17s\n","530:\tlearn: 0.5616347\ttotal: 1m 27s\tremaining: 1m 17s\n","531:\tlearn: 0.5616317\ttotal: 1m 27s\tremaining: 1m 17s\n","532:\tlearn: 0.5615816\ttotal: 1m 27s\tremaining: 1m 17s\n","533:\tlearn: 0.5615081\ttotal: 1m 28s\tremaining: 1m 16s\n","534:\tlearn: 0.5614597\ttotal: 1m 28s\tremaining: 1m 16s\n","535:\tlearn: 0.5614296\ttotal: 1m 28s\tremaining: 1m 16s\n","536:\tlearn: 0.5613836\ttotal: 1m 28s\tremaining: 1m 16s\n","537:\tlearn: 0.5613376\ttotal: 1m 28s\tremaining: 1m 16s\n","538:\tlearn: 0.5612730\ttotal: 1m 29s\tremaining: 1m 16s\n","539:\tlearn: 0.5612281\ttotal: 1m 29s\tremaining: 1m 15s\n","540:\tlearn: 0.5611784\ttotal: 1m 29s\tremaining: 1m 15s\n","541:\tlearn: 0.5611234\ttotal: 1m 29s\tremaining: 1m 15s\n","542:\tlearn: 0.5610455\ttotal: 1m 29s\tremaining: 1m 15s\n","543:\tlearn: 0.5610123\ttotal: 1m 29s\tremaining: 1m 15s\n","544:\tlearn: 0.5609836\ttotal: 1m 29s\tremaining: 1m 15s\n","545:\tlearn: 0.5609119\ttotal: 1m 30s\tremaining: 1m 14s\n","546:\tlearn: 0.5608218\ttotal: 1m 30s\tremaining: 1m 14s\n","547:\tlearn: 0.5608002\ttotal: 1m 30s\tremaining: 1m 14s\n","548:\tlearn: 0.5607893\ttotal: 1m 30s\tremaining: 1m 14s\n","549:\tlearn: 0.5607342\ttotal: 1m 30s\tremaining: 1m 14s\n","550:\tlearn: 0.5606890\ttotal: 1m 30s\tremaining: 1m 13s\n","551:\tlearn: 0.5606336\ttotal: 1m 30s\tremaining: 1m 13s\n","552:\tlearn: 0.5605674\ttotal: 1m 30s\tremaining: 1m 13s\n","553:\tlearn: 0.5605106\ttotal: 1m 31s\tremaining: 1m 13s\n","554:\tlearn: 0.5604408\ttotal: 1m 31s\tremaining: 1m 13s\n","555:\tlearn: 0.5604210\ttotal: 1m 31s\tremaining: 1m 12s\n","556:\tlearn: 0.5603546\ttotal: 1m 31s\tremaining: 1m 12s\n","557:\tlearn: 0.5603424\ttotal: 1m 31s\tremaining: 1m 12s\n","558:\tlearn: 0.5602880\ttotal: 1m 31s\tremaining: 1m 12s\n","559:\tlearn: 0.5602203\ttotal: 1m 31s\tremaining: 1m 12s\n","560:\tlearn: 0.5601882\ttotal: 1m 32s\tremaining: 1m 12s\n","561:\tlearn: 0.5601208\ttotal: 1m 32s\tremaining: 1m 11s\n","562:\tlearn: 0.5600513\ttotal: 1m 32s\tremaining: 1m 11s\n","563:\tlearn: 0.5600034\ttotal: 1m 32s\tremaining: 1m 11s\n","564:\tlearn: 0.5599434\ttotal: 1m 32s\tremaining: 1m 11s\n","565:\tlearn: 0.5599293\ttotal: 1m 32s\tremaining: 1m 11s\n","566:\tlearn: 0.5598965\ttotal: 1m 32s\tremaining: 1m 10s\n","567:\tlearn: 0.5598413\ttotal: 1m 32s\tremaining: 1m 10s\n","568:\tlearn: 0.5597682\ttotal: 1m 33s\tremaining: 1m 10s\n","569:\tlearn: 0.5597144\ttotal: 1m 33s\tremaining: 1m 10s\n","570:\tlearn: 0.5596394\ttotal: 1m 33s\tremaining: 1m 10s\n","571:\tlearn: 0.5596217\ttotal: 1m 33s\tremaining: 1m 9s\n","572:\tlearn: 0.5596054\ttotal: 1m 33s\tremaining: 1m 9s\n","573:\tlearn: 0.5595533\ttotal: 1m 33s\tremaining: 1m 9s\n","574:\tlearn: 0.5595508\ttotal: 1m 33s\tremaining: 1m 9s\n","575:\tlearn: 0.5594852\ttotal: 1m 34s\tremaining: 1m 9s\n","576:\tlearn: 0.5594323\ttotal: 1m 34s\tremaining: 1m 9s\n","577:\tlearn: 0.5593700\ttotal: 1m 34s\tremaining: 1m 8s\n","578:\tlearn: 0.5593148\ttotal: 1m 34s\tremaining: 1m 8s\n","579:\tlearn: 0.5592279\ttotal: 1m 34s\tremaining: 1m 8s\n","580:\tlearn: 0.5592251\ttotal: 1m 34s\tremaining: 1m 8s\n","581:\tlearn: 0.5592234\ttotal: 1m 34s\tremaining: 1m 8s\n","582:\tlearn: 0.5591837\ttotal: 1m 34s\tremaining: 1m 7s\n","583:\tlearn: 0.5591268\ttotal: 1m 35s\tremaining: 1m 7s\n","584:\tlearn: 0.5590934\ttotal: 1m 35s\tremaining: 1m 7s\n","585:\tlearn: 0.5590896\ttotal: 1m 35s\tremaining: 1m 7s\n","586:\tlearn: 0.5590461\ttotal: 1m 35s\tremaining: 1m 7s\n","587:\tlearn: 0.5589921\ttotal: 1m 35s\tremaining: 1m 6s\n","588:\tlearn: 0.5589459\ttotal: 1m 35s\tremaining: 1m 6s\n","589:\tlearn: 0.5588899\ttotal: 1m 35s\tremaining: 1m 6s\n","590:\tlearn: 0.5588558\ttotal: 1m 35s\tremaining: 1m 6s\n","591:\tlearn: 0.5587850\ttotal: 1m 36s\tremaining: 1m 6s\n","592:\tlearn: 0.5587695\ttotal: 1m 36s\tremaining: 1m 5s\n","593:\tlearn: 0.5587030\ttotal: 1m 36s\tremaining: 1m 5s\n","594:\tlearn: 0.5586753\ttotal: 1m 36s\tremaining: 1m 5s\n","595:\tlearn: 0.5586353\ttotal: 1m 36s\tremaining: 1m 5s\n","596:\tlearn: 0.5585693\ttotal: 1m 36s\tremaining: 1m 5s\n","597:\tlearn: 0.5584972\ttotal: 1m 36s\tremaining: 1m 5s\n","598:\tlearn: 0.5584436\ttotal: 1m 37s\tremaining: 1m 4s\n","599:\tlearn: 0.5583783\ttotal: 1m 37s\tremaining: 1m 4s\n","600:\tlearn: 0.5583410\ttotal: 1m 37s\tremaining: 1m 4s\n","601:\tlearn: 0.5583025\ttotal: 1m 37s\tremaining: 1m 4s\n","602:\tlearn: 0.5582275\ttotal: 1m 37s\tremaining: 1m 4s\n","603:\tlearn: 0.5581654\ttotal: 1m 37s\tremaining: 1m 4s\n","604:\tlearn: 0.5581122\ttotal: 1m 37s\tremaining: 1m 3s\n","605:\tlearn: 0.5580660\ttotal: 1m 38s\tremaining: 1m 3s\n","606:\tlearn: 0.5580086\ttotal: 1m 38s\tremaining: 1m 3s\n","607:\tlearn: 0.5579728\ttotal: 1m 38s\tremaining: 1m 3s\n","608:\tlearn: 0.5579231\ttotal: 1m 38s\tremaining: 1m 3s\n","609:\tlearn: 0.5578880\ttotal: 1m 38s\tremaining: 1m 2s\n","610:\tlearn: 0.5578469\ttotal: 1m 38s\tremaining: 1m 2s\n","611:\tlearn: 0.5577929\ttotal: 1m 38s\tremaining: 1m 2s\n","612:\tlearn: 0.5577331\ttotal: 1m 39s\tremaining: 1m 2s\n","613:\tlearn: 0.5576723\ttotal: 1m 39s\tremaining: 1m 2s\n","614:\tlearn: 0.5576170\ttotal: 1m 39s\tremaining: 1m 2s\n","615:\tlearn: 0.5575790\ttotal: 1m 39s\tremaining: 1m 2s\n","616:\tlearn: 0.5575465\ttotal: 1m 40s\tremaining: 1m 2s\n","617:\tlearn: 0.5574808\ttotal: 1m 40s\tremaining: 1m 2s\n","618:\tlearn: 0.5574135\ttotal: 1m 40s\tremaining: 1m 1s\n","619:\tlearn: 0.5573648\ttotal: 1m 40s\tremaining: 1m 1s\n","620:\tlearn: 0.5573267\ttotal: 1m 41s\tremaining: 1m 1s\n","621:\tlearn: 0.5572757\ttotal: 1m 41s\tremaining: 1m 1s\n","622:\tlearn: 0.5572304\ttotal: 1m 41s\tremaining: 1m 1s\n","623:\tlearn: 0.5571782\ttotal: 1m 41s\tremaining: 1m 1s\n","624:\tlearn: 0.5571395\ttotal: 1m 42s\tremaining: 1m 1s\n","625:\tlearn: 0.5571064\ttotal: 1m 42s\tremaining: 1m 1s\n","626:\tlearn: 0.5570427\ttotal: 1m 42s\tremaining: 1m\n","627:\tlearn: 0.5570124\ttotal: 1m 42s\tremaining: 1m\n","628:\tlearn: 0.5569730\ttotal: 1m 42s\tremaining: 1m\n","629:\tlearn: 0.5569291\ttotal: 1m 42s\tremaining: 1m\n","630:\tlearn: 0.5569263\ttotal: 1m 42s\tremaining: 1m\n","631:\tlearn: 0.5568803\ttotal: 1m 43s\tremaining: 1m\n","632:\tlearn: 0.5568322\ttotal: 1m 43s\tremaining: 59.9s\n","633:\tlearn: 0.5567698\ttotal: 1m 43s\tremaining: 59.7s\n","634:\tlearn: 0.5567140\ttotal: 1m 43s\tremaining: 59.5s\n","635:\tlearn: 0.5566684\ttotal: 1m 43s\tremaining: 59.3s\n","636:\tlearn: 0.5566116\ttotal: 1m 43s\tremaining: 59.2s\n","637:\tlearn: 0.5565659\ttotal: 1m 43s\tremaining: 59s\n","638:\tlearn: 0.5564914\ttotal: 1m 44s\tremaining: 58.8s\n","639:\tlearn: 0.5564360\ttotal: 1m 44s\tremaining: 58.6s\n","640:\tlearn: 0.5563776\ttotal: 1m 44s\tremaining: 58.4s\n","641:\tlearn: 0.5563375\ttotal: 1m 44s\tremaining: 58.3s\n","642:\tlearn: 0.5563357\ttotal: 1m 44s\tremaining: 58.1s\n","643:\tlearn: 0.5563216\ttotal: 1m 44s\tremaining: 57.9s\n","644:\tlearn: 0.5562683\ttotal: 1m 44s\tremaining: 57.7s\n","645:\tlearn: 0.5562064\ttotal: 1m 44s\tremaining: 57.5s\n","646:\tlearn: 0.5561533\ttotal: 1m 45s\tremaining: 57.3s\n","647:\tlearn: 0.5560847\ttotal: 1m 45s\tremaining: 57.2s\n","648:\tlearn: 0.5560290\ttotal: 1m 45s\tremaining: 57s\n","649:\tlearn: 0.5559770\ttotal: 1m 45s\tremaining: 56.8s\n","650:\tlearn: 0.5559042\ttotal: 1m 45s\tremaining: 56.7s\n","651:\tlearn: 0.5558627\ttotal: 1m 45s\tremaining: 56.5s\n","652:\tlearn: 0.5558100\ttotal: 1m 45s\tremaining: 56.3s\n","653:\tlearn: 0.5558086\ttotal: 1m 46s\tremaining: 56.1s\n","654:\tlearn: 0.5557571\ttotal: 1m 46s\tremaining: 56s\n","655:\tlearn: 0.5556887\ttotal: 1m 46s\tremaining: 55.8s\n","656:\tlearn: 0.5556389\ttotal: 1m 46s\tremaining: 55.6s\n","657:\tlearn: 0.5555872\ttotal: 1m 46s\tremaining: 55.4s\n","658:\tlearn: 0.5555270\ttotal: 1m 46s\tremaining: 55.3s\n","659:\tlearn: 0.5554747\ttotal: 1m 46s\tremaining: 55.1s\n","660:\tlearn: 0.5554417\ttotal: 1m 47s\tremaining: 54.9s\n","661:\tlearn: 0.5554294\ttotal: 1m 47s\tremaining: 54.7s\n","662:\tlearn: 0.5553567\ttotal: 1m 47s\tremaining: 54.5s\n","663:\tlearn: 0.5552847\ttotal: 1m 47s\tremaining: 54.4s\n","664:\tlearn: 0.5552312\ttotal: 1m 47s\tremaining: 54.2s\n","665:\tlearn: 0.5551468\ttotal: 1m 47s\tremaining: 54s\n","666:\tlearn: 0.5551308\ttotal: 1m 47s\tremaining: 53.9s\n","667:\tlearn: 0.5550858\ttotal: 1m 48s\tremaining: 53.7s\n","668:\tlearn: 0.5550442\ttotal: 1m 48s\tremaining: 53.5s\n","669:\tlearn: 0.5549878\ttotal: 1m 48s\tremaining: 53.3s\n","670:\tlearn: 0.5549249\ttotal: 1m 48s\tremaining: 53.2s\n","671:\tlearn: 0.5548817\ttotal: 1m 48s\tremaining: 53s\n","672:\tlearn: 0.5548449\ttotal: 1m 48s\tremaining: 52.8s\n","673:\tlearn: 0.5548043\ttotal: 1m 48s\tremaining: 52.6s\n","674:\tlearn: 0.5547657\ttotal: 1m 48s\tremaining: 52.4s\n","675:\tlearn: 0.5547347\ttotal: 1m 49s\tremaining: 52.2s\n","676:\tlearn: 0.5546738\ttotal: 1m 49s\tremaining: 52.1s\n","677:\tlearn: 0.5546305\ttotal: 1m 49s\tremaining: 51.9s\n","678:\tlearn: 0.5545838\ttotal: 1m 49s\tremaining: 51.7s\n","679:\tlearn: 0.5545218\ttotal: 1m 49s\tremaining: 51.6s\n","680:\tlearn: 0.5544854\ttotal: 1m 49s\tremaining: 51.4s\n","681:\tlearn: 0.5544237\ttotal: 1m 49s\tremaining: 51.2s\n","682:\tlearn: 0.5544012\ttotal: 1m 49s\tremaining: 51s\n","683:\tlearn: 0.5543867\ttotal: 1m 50s\tremaining: 50.8s\n","684:\tlearn: 0.5543433\ttotal: 1m 50s\tremaining: 50.7s\n","685:\tlearn: 0.5542986\ttotal: 1m 50s\tremaining: 50.5s\n","686:\tlearn: 0.5542501\ttotal: 1m 50s\tremaining: 50.3s\n","687:\tlearn: 0.5541806\ttotal: 1m 50s\tremaining: 50.1s\n","688:\tlearn: 0.5541561\ttotal: 1m 50s\tremaining: 50s\n","689:\tlearn: 0.5540987\ttotal: 1m 50s\tremaining: 49.8s\n","690:\tlearn: 0.5540301\ttotal: 1m 50s\tremaining: 49.6s\n","691:\tlearn: 0.5539902\ttotal: 1m 51s\tremaining: 49.5s\n","692:\tlearn: 0.5539557\ttotal: 1m 51s\tremaining: 49.3s\n","693:\tlearn: 0.5538866\ttotal: 1m 51s\tremaining: 49.1s\n","694:\tlearn: 0.5538490\ttotal: 1m 51s\tremaining: 49s\n","695:\tlearn: 0.5537827\ttotal: 1m 51s\tremaining: 48.8s\n","696:\tlearn: 0.5537573\ttotal: 1m 51s\tremaining: 48.6s\n","697:\tlearn: 0.5536829\ttotal: 1m 51s\tremaining: 48.4s\n","698:\tlearn: 0.5536591\ttotal: 1m 52s\tremaining: 48.3s\n","699:\tlearn: 0.5536577\ttotal: 1m 52s\tremaining: 48.1s\n","700:\tlearn: 0.5536114\ttotal: 1m 52s\tremaining: 47.9s\n","701:\tlearn: 0.5535758\ttotal: 1m 52s\tremaining: 47.7s\n","702:\tlearn: 0.5535383\ttotal: 1m 52s\tremaining: 47.6s\n","703:\tlearn: 0.5534926\ttotal: 1m 52s\tremaining: 47.5s\n","704:\tlearn: 0.5534488\ttotal: 1m 53s\tremaining: 47.4s\n","705:\tlearn: 0.5534457\ttotal: 1m 53s\tremaining: 47.2s\n","706:\tlearn: 0.5533926\ttotal: 1m 53s\tremaining: 47.1s\n","707:\tlearn: 0.5533738\ttotal: 1m 53s\tremaining: 46.9s\n","708:\tlearn: 0.5533202\ttotal: 1m 54s\tremaining: 46.8s\n","709:\tlearn: 0.5532635\ttotal: 1m 54s\tremaining: 46.7s\n","710:\tlearn: 0.5532090\ttotal: 1m 54s\tremaining: 46.6s\n","711:\tlearn: 0.5531625\ttotal: 1m 54s\tremaining: 46.5s\n","712:\tlearn: 0.5531413\ttotal: 1m 55s\tremaining: 46.3s\n","713:\tlearn: 0.5530856\ttotal: 1m 55s\tremaining: 46.2s\n","714:\tlearn: 0.5530415\ttotal: 1m 55s\tremaining: 46.1s\n","715:\tlearn: 0.5529910\ttotal: 1m 55s\tremaining: 45.9s\n","716:\tlearn: 0.5529378\ttotal: 1m 56s\tremaining: 45.8s\n","717:\tlearn: 0.5528940\ttotal: 1m 56s\tremaining: 45.6s\n","718:\tlearn: 0.5528228\ttotal: 1m 56s\tremaining: 45.4s\n","719:\tlearn: 0.5527676\ttotal: 1m 56s\tremaining: 45.3s\n","720:\tlearn: 0.5527340\ttotal: 1m 56s\tremaining: 45.1s\n","721:\tlearn: 0.5526933\ttotal: 1m 56s\tremaining: 44.9s\n","722:\tlearn: 0.5526362\ttotal: 1m 56s\tremaining: 44.8s\n","723:\tlearn: 0.5525722\ttotal: 1m 57s\tremaining: 44.6s\n","724:\tlearn: 0.5525438\ttotal: 1m 57s\tremaining: 44.4s\n","725:\tlearn: 0.5524856\ttotal: 1m 57s\tremaining: 44.3s\n","726:\tlearn: 0.5524352\ttotal: 1m 57s\tremaining: 44.1s\n","727:\tlearn: 0.5523807\ttotal: 1m 57s\tremaining: 44s\n","728:\tlearn: 0.5523579\ttotal: 1m 57s\tremaining: 43.8s\n","729:\tlearn: 0.5523560\ttotal: 1m 57s\tremaining: 43.6s\n","730:\tlearn: 0.5523128\ttotal: 1m 57s\tremaining: 43.4s\n","731:\tlearn: 0.5522616\ttotal: 1m 58s\tremaining: 43.2s\n","732:\tlearn: 0.5522064\ttotal: 1m 58s\tremaining: 43.1s\n","733:\tlearn: 0.5521300\ttotal: 1m 58s\tremaining: 42.9s\n","734:\tlearn: 0.5520919\ttotal: 1m 58s\tremaining: 42.7s\n","735:\tlearn: 0.5520566\ttotal: 1m 58s\tremaining: 42.6s\n","736:\tlearn: 0.5519906\ttotal: 1m 58s\tremaining: 42.4s\n","737:\tlearn: 0.5519653\ttotal: 1m 58s\tremaining: 42.2s\n","738:\tlearn: 0.5519210\ttotal: 1m 59s\tremaining: 42s\n","739:\tlearn: 0.5518561\ttotal: 1m 59s\tremaining: 41.9s\n","740:\tlearn: 0.5518059\ttotal: 1m 59s\tremaining: 41.7s\n","741:\tlearn: 0.5517569\ttotal: 1m 59s\tremaining: 41.5s\n","742:\tlearn: 0.5517137\ttotal: 1m 59s\tremaining: 41.4s\n","743:\tlearn: 0.5516796\ttotal: 1m 59s\tremaining: 41.2s\n","744:\tlearn: 0.5516324\ttotal: 1m 59s\tremaining: 41s\n","745:\tlearn: 0.5516309\ttotal: 1m 59s\tremaining: 40.8s\n","746:\tlearn: 0.5516003\ttotal: 2m\tremaining: 40.7s\n","747:\tlearn: 0.5515296\ttotal: 2m\tremaining: 40.5s\n","748:\tlearn: 0.5515273\ttotal: 2m\tremaining: 40.3s\n","749:\tlearn: 0.5514979\ttotal: 2m\tremaining: 40.1s\n","750:\tlearn: 0.5514370\ttotal: 2m\tremaining: 40s\n","751:\tlearn: 0.5514064\ttotal: 2m\tremaining: 39.8s\n","752:\tlearn: 0.5513580\ttotal: 2m\tremaining: 39.6s\n","753:\tlearn: 0.5513233\ttotal: 2m\tremaining: 39.5s\n","754:\tlearn: 0.5512859\ttotal: 2m 1s\tremaining: 39.3s\n","755:\tlearn: 0.5512295\ttotal: 2m 1s\tremaining: 39.1s\n","756:\tlearn: 0.5511833\ttotal: 2m 1s\tremaining: 39s\n","757:\tlearn: 0.5511322\ttotal: 2m 1s\tremaining: 38.8s\n","758:\tlearn: 0.5510895\ttotal: 2m 1s\tremaining: 38.6s\n","759:\tlearn: 0.5510171\ttotal: 2m 1s\tremaining: 38.5s\n","760:\tlearn: 0.5509761\ttotal: 2m 1s\tremaining: 38.3s\n","761:\tlearn: 0.5509468\ttotal: 2m 2s\tremaining: 38.1s\n","762:\tlearn: 0.5509021\ttotal: 2m 2s\tremaining: 37.9s\n","763:\tlearn: 0.5508909\ttotal: 2m 2s\tremaining: 37.8s\n","764:\tlearn: 0.5508338\ttotal: 2m 2s\tremaining: 37.6s\n","765:\tlearn: 0.5507709\ttotal: 2m 2s\tremaining: 37.4s\n","766:\tlearn: 0.5507191\ttotal: 2m 2s\tremaining: 37.3s\n","767:\tlearn: 0.5506914\ttotal: 2m 2s\tremaining: 37.1s\n","768:\tlearn: 0.5506540\ttotal: 2m 2s\tremaining: 36.9s\n","769:\tlearn: 0.5505896\ttotal: 2m 3s\tremaining: 36.8s\n","770:\tlearn: 0.5505341\ttotal: 2m 3s\tremaining: 36.6s\n","771:\tlearn: 0.5504710\ttotal: 2m 3s\tremaining: 36.4s\n","772:\tlearn: 0.5504402\ttotal: 2m 3s\tremaining: 36.3s\n","773:\tlearn: 0.5503875\ttotal: 2m 3s\tremaining: 36.1s\n","774:\tlearn: 0.5503848\ttotal: 2m 3s\tremaining: 35.9s\n","775:\tlearn: 0.5503827\ttotal: 2m 3s\tremaining: 35.7s\n","776:\tlearn: 0.5503799\ttotal: 2m 3s\tremaining: 35.6s\n","777:\tlearn: 0.5503456\ttotal: 2m 4s\tremaining: 35.4s\n","778:\tlearn: 0.5503004\ttotal: 2m 4s\tremaining: 35.2s\n","779:\tlearn: 0.5502521\ttotal: 2m 4s\tremaining: 35.1s\n","780:\tlearn: 0.5501965\ttotal: 2m 4s\tremaining: 34.9s\n","781:\tlearn: 0.5501513\ttotal: 2m 4s\tremaining: 34.7s\n","782:\tlearn: 0.5501138\ttotal: 2m 4s\tremaining: 34.6s\n","783:\tlearn: 0.5500561\ttotal: 2m 4s\tremaining: 34.4s\n","784:\tlearn: 0.5499885\ttotal: 2m 4s\tremaining: 34.2s\n","785:\tlearn: 0.5499442\ttotal: 2m 5s\tremaining: 34.1s\n","786:\tlearn: 0.5499093\ttotal: 2m 5s\tremaining: 33.9s\n","787:\tlearn: 0.5498562\ttotal: 2m 5s\tremaining: 33.7s\n","788:\tlearn: 0.5498085\ttotal: 2m 5s\tremaining: 33.6s\n","789:\tlearn: 0.5497329\ttotal: 2m 5s\tremaining: 33.4s\n","790:\tlearn: 0.5496769\ttotal: 2m 5s\tremaining: 33.2s\n","791:\tlearn: 0.5496458\ttotal: 2m 5s\tremaining: 33.1s\n","792:\tlearn: 0.5495849\ttotal: 2m 6s\tremaining: 32.9s\n","793:\tlearn: 0.5495296\ttotal: 2m 6s\tremaining: 32.8s\n","794:\tlearn: 0.5494662\ttotal: 2m 6s\tremaining: 32.7s\n","795:\tlearn: 0.5494247\ttotal: 2m 6s\tremaining: 32.5s\n","796:\tlearn: 0.5493825\ttotal: 2m 7s\tremaining: 32.4s\n","797:\tlearn: 0.5493346\ttotal: 2m 7s\tremaining: 32.2s\n","798:\tlearn: 0.5493061\ttotal: 2m 7s\tremaining: 32.1s\n","799:\tlearn: 0.5492695\ttotal: 2m 7s\tremaining: 31.9s\n","800:\tlearn: 0.5492312\ttotal: 2m 7s\tremaining: 31.8s\n","801:\tlearn: 0.5491874\ttotal: 2m 8s\tremaining: 31.7s\n","802:\tlearn: 0.5491592\ttotal: 2m 8s\tremaining: 31.5s\n","803:\tlearn: 0.5491358\ttotal: 2m 8s\tremaining: 31.4s\n","804:\tlearn: 0.5490726\ttotal: 2m 8s\tremaining: 31.2s\n","805:\tlearn: 0.5490285\ttotal: 2m 9s\tremaining: 31.1s\n","806:\tlearn: 0.5489810\ttotal: 2m 9s\tremaining: 31s\n","807:\tlearn: 0.5489274\ttotal: 2m 9s\tremaining: 30.8s\n","808:\tlearn: 0.5488824\ttotal: 2m 9s\tremaining: 30.7s\n","809:\tlearn: 0.5488808\ttotal: 2m 9s\tremaining: 30.5s\n","810:\tlearn: 0.5488430\ttotal: 2m 10s\tremaining: 30.3s\n","811:\tlearn: 0.5488002\ttotal: 2m 10s\tremaining: 30.1s\n","812:\tlearn: 0.5487724\ttotal: 2m 10s\tremaining: 30s\n","813:\tlearn: 0.5487496\ttotal: 2m 10s\tremaining: 29.8s\n","814:\tlearn: 0.5487213\ttotal: 2m 10s\tremaining: 29.6s\n","815:\tlearn: 0.5486641\ttotal: 2m 10s\tremaining: 29.5s\n","816:\tlearn: 0.5486315\ttotal: 2m 10s\tremaining: 29.3s\n","817:\tlearn: 0.5485720\ttotal: 2m 10s\tremaining: 29.1s\n","818:\tlearn: 0.5485696\ttotal: 2m 11s\tremaining: 29s\n","819:\tlearn: 0.5485094\ttotal: 2m 11s\tremaining: 28.8s\n","820:\tlearn: 0.5485046\ttotal: 2m 11s\tremaining: 28.6s\n","821:\tlearn: 0.5484595\ttotal: 2m 11s\tremaining: 28.5s\n","822:\tlearn: 0.5484106\ttotal: 2m 11s\tremaining: 28.3s\n","823:\tlearn: 0.5483554\ttotal: 2m 11s\tremaining: 28.1s\n","824:\tlearn: 0.5483175\ttotal: 2m 11s\tremaining: 28s\n","825:\tlearn: 0.5482576\ttotal: 2m 11s\tremaining: 27.8s\n","826:\tlearn: 0.5481942\ttotal: 2m 12s\tremaining: 27.6s\n","827:\tlearn: 0.5481369\ttotal: 2m 12s\tremaining: 27.5s\n","828:\tlearn: 0.5480980\ttotal: 2m 12s\tremaining: 27.3s\n","829:\tlearn: 0.5480431\ttotal: 2m 12s\tremaining: 27.1s\n","830:\tlearn: 0.5480219\ttotal: 2m 12s\tremaining: 27s\n","831:\tlearn: 0.5479899\ttotal: 2m 12s\tremaining: 26.8s\n","832:\tlearn: 0.5479887\ttotal: 2m 12s\tremaining: 26.6s\n","833:\tlearn: 0.5479618\ttotal: 2m 13s\tremaining: 26.5s\n","834:\tlearn: 0.5479547\ttotal: 2m 13s\tremaining: 26.3s\n","835:\tlearn: 0.5479147\ttotal: 2m 13s\tremaining: 26.1s\n","836:\tlearn: 0.5478867\ttotal: 2m 13s\tremaining: 26s\n","837:\tlearn: 0.5478455\ttotal: 2m 13s\tremaining: 25.8s\n","838:\tlearn: 0.5478005\ttotal: 2m 13s\tremaining: 25.6s\n","839:\tlearn: 0.5477351\ttotal: 2m 13s\tremaining: 25.5s\n","840:\tlearn: 0.5476679\ttotal: 2m 13s\tremaining: 25.3s\n","841:\tlearn: 0.5476620\ttotal: 2m 13s\tremaining: 25.1s\n","842:\tlearn: 0.5476172\ttotal: 2m 14s\tremaining: 25s\n","843:\tlearn: 0.5475685\ttotal: 2m 14s\tremaining: 24.8s\n","844:\tlearn: 0.5474936\ttotal: 2m 14s\tremaining: 24.7s\n","845:\tlearn: 0.5474424\ttotal: 2m 14s\tremaining: 24.5s\n","846:\tlearn: 0.5474136\ttotal: 2m 14s\tremaining: 24.3s\n","847:\tlearn: 0.5473706\ttotal: 2m 14s\tremaining: 24.2s\n","848:\tlearn: 0.5473149\ttotal: 2m 14s\tremaining: 24s\n","849:\tlearn: 0.5472828\ttotal: 2m 15s\tremaining: 23.8s\n","850:\tlearn: 0.5472536\ttotal: 2m 15s\tremaining: 23.7s\n","851:\tlearn: 0.5472108\ttotal: 2m 15s\tremaining: 23.5s\n","852:\tlearn: 0.5471759\ttotal: 2m 15s\tremaining: 23.3s\n","853:\tlearn: 0.5471334\ttotal: 2m 15s\tremaining: 23.2s\n","854:\tlearn: 0.5470968\ttotal: 2m 15s\tremaining: 23s\n","855:\tlearn: 0.5470685\ttotal: 2m 15s\tremaining: 22.8s\n","856:\tlearn: 0.5470266\ttotal: 2m 15s\tremaining: 22.7s\n","857:\tlearn: 0.5469907\ttotal: 2m 16s\tremaining: 22.5s\n","858:\tlearn: 0.5469503\ttotal: 2m 16s\tremaining: 22.4s\n","859:\tlearn: 0.5469249\ttotal: 2m 16s\tremaining: 22.2s\n","860:\tlearn: 0.5468831\ttotal: 2m 16s\tremaining: 22s\n","861:\tlearn: 0.5468507\ttotal: 2m 16s\tremaining: 21.9s\n","862:\tlearn: 0.5468490\ttotal: 2m 16s\tremaining: 21.7s\n","863:\tlearn: 0.5468242\ttotal: 2m 16s\tremaining: 21.5s\n","864:\tlearn: 0.5467626\ttotal: 2m 16s\tremaining: 21.4s\n","865:\tlearn: 0.5466792\ttotal: 2m 17s\tremaining: 21.2s\n","866:\tlearn: 0.5466237\ttotal: 2m 17s\tremaining: 21s\n","867:\tlearn: 0.5465632\ttotal: 2m 17s\tremaining: 20.9s\n","868:\tlearn: 0.5465162\ttotal: 2m 17s\tremaining: 20.7s\n","869:\tlearn: 0.5465105\ttotal: 2m 17s\tremaining: 20.6s\n","870:\tlearn: 0.5464571\ttotal: 2m 17s\tremaining: 20.4s\n","871:\tlearn: 0.5464071\ttotal: 2m 17s\tremaining: 20.2s\n","872:\tlearn: 0.5463676\ttotal: 2m 18s\tremaining: 20.1s\n","873:\tlearn: 0.5463462\ttotal: 2m 18s\tremaining: 19.9s\n","874:\tlearn: 0.5463359\ttotal: 2m 18s\tremaining: 19.7s\n","875:\tlearn: 0.5463041\ttotal: 2m 18s\tremaining: 19.6s\n","876:\tlearn: 0.5462502\ttotal: 2m 18s\tremaining: 19.4s\n","877:\tlearn: 0.5461933\ttotal: 2m 18s\tremaining: 19.3s\n","878:\tlearn: 0.5461518\ttotal: 2m 18s\tremaining: 19.1s\n","879:\tlearn: 0.5461129\ttotal: 2m 18s\tremaining: 18.9s\n","880:\tlearn: 0.5460736\ttotal: 2m 18s\tremaining: 18.8s\n","881:\tlearn: 0.5460345\ttotal: 2m 19s\tremaining: 18.6s\n","882:\tlearn: 0.5459940\ttotal: 2m 19s\tremaining: 18.5s\n","883:\tlearn: 0.5459464\ttotal: 2m 19s\tremaining: 18.3s\n","884:\tlearn: 0.5459095\ttotal: 2m 19s\tremaining: 18.1s\n","885:\tlearn: 0.5458798\ttotal: 2m 19s\tremaining: 18s\n","886:\tlearn: 0.5458590\ttotal: 2m 19s\tremaining: 17.8s\n","887:\tlearn: 0.5458031\ttotal: 2m 20s\tremaining: 17.7s\n","888:\tlearn: 0.5457677\ttotal: 2m 20s\tremaining: 17.5s\n","889:\tlearn: 0.5457018\ttotal: 2m 20s\tremaining: 17.4s\n","890:\tlearn: 0.5456994\ttotal: 2m 20s\tremaining: 17.2s\n","891:\tlearn: 0.5456454\ttotal: 2m 21s\tremaining: 17.1s\n","892:\tlearn: 0.5456054\ttotal: 2m 21s\tremaining: 16.9s\n","893:\tlearn: 0.5455906\ttotal: 2m 21s\tremaining: 16.8s\n","894:\tlearn: 0.5455404\ttotal: 2m 21s\tremaining: 16.6s\n","895:\tlearn: 0.5455382\ttotal: 2m 22s\tremaining: 16.5s\n","896:\tlearn: 0.5455039\ttotal: 2m 22s\tremaining: 16.3s\n","897:\tlearn: 0.5454659\ttotal: 2m 22s\tremaining: 16.2s\n","898:\tlearn: 0.5454264\ttotal: 2m 22s\tremaining: 16s\n","899:\tlearn: 0.5453857\ttotal: 2m 23s\tremaining: 15.9s\n","900:\tlearn: 0.5453642\ttotal: 2m 23s\tremaining: 15.7s\n","901:\tlearn: 0.5452945\ttotal: 2m 23s\tremaining: 15.6s\n","902:\tlearn: 0.5452425\ttotal: 2m 23s\tremaining: 15.4s\n","903:\tlearn: 0.5452120\ttotal: 2m 23s\tremaining: 15.3s\n","904:\tlearn: 0.5452103\ttotal: 2m 23s\tremaining: 15.1s\n","905:\tlearn: 0.5451751\ttotal: 2m 23s\tremaining: 14.9s\n","906:\tlearn: 0.5451502\ttotal: 2m 24s\tremaining: 14.8s\n","907:\tlearn: 0.5451056\ttotal: 2m 24s\tremaining: 14.6s\n","908:\tlearn: 0.5450680\ttotal: 2m 24s\tremaining: 14.4s\n","909:\tlearn: 0.5450313\ttotal: 2m 24s\tremaining: 14.3s\n","910:\tlearn: 0.5450065\ttotal: 2m 24s\tremaining: 14.1s\n","911:\tlearn: 0.5449654\ttotal: 2m 24s\tremaining: 14s\n","912:\tlearn: 0.5449401\ttotal: 2m 24s\tremaining: 13.8s\n","913:\tlearn: 0.5448827\ttotal: 2m 24s\tremaining: 13.6s\n","914:\tlearn: 0.5448498\ttotal: 2m 24s\tremaining: 13.5s\n","915:\tlearn: 0.5448113\ttotal: 2m 25s\tremaining: 13.3s\n","916:\tlearn: 0.5447811\ttotal: 2m 25s\tremaining: 13.1s\n","917:\tlearn: 0.5447798\ttotal: 2m 25s\tremaining: 13s\n","918:\tlearn: 0.5447478\ttotal: 2m 25s\tremaining: 12.8s\n","919:\tlearn: 0.5447296\ttotal: 2m 25s\tremaining: 12.7s\n","920:\tlearn: 0.5446865\ttotal: 2m 25s\tremaining: 12.5s\n","921:\tlearn: 0.5446526\ttotal: 2m 25s\tremaining: 12.3s\n","922:\tlearn: 0.5446064\ttotal: 2m 25s\tremaining: 12.2s\n","923:\tlearn: 0.5445464\ttotal: 2m 26s\tremaining: 12s\n","924:\tlearn: 0.5444954\ttotal: 2m 26s\tremaining: 11.9s\n","925:\tlearn: 0.5444346\ttotal: 2m 26s\tremaining: 11.7s\n","926:\tlearn: 0.5443881\ttotal: 2m 26s\tremaining: 11.5s\n","927:\tlearn: 0.5443356\ttotal: 2m 26s\tremaining: 11.4s\n","928:\tlearn: 0.5442894\ttotal: 2m 26s\tremaining: 11.2s\n","929:\tlearn: 0.5442047\ttotal: 2m 26s\tremaining: 11.1s\n","930:\tlearn: 0.5441683\ttotal: 2m 27s\tremaining: 10.9s\n","931:\tlearn: 0.5441255\ttotal: 2m 27s\tremaining: 10.7s\n","932:\tlearn: 0.5440836\ttotal: 2m 27s\tremaining: 10.6s\n","933:\tlearn: 0.5440269\ttotal: 2m 27s\tremaining: 10.4s\n","934:\tlearn: 0.5440005\ttotal: 2m 27s\tremaining: 10.3s\n","935:\tlearn: 0.5439583\ttotal: 2m 27s\tremaining: 10.1s\n","936:\tlearn: 0.5439170\ttotal: 2m 27s\tremaining: 9.94s\n","937:\tlearn: 0.5438753\ttotal: 2m 28s\tremaining: 9.78s\n","938:\tlearn: 0.5438484\ttotal: 2m 28s\tremaining: 9.62s\n","939:\tlearn: 0.5438196\ttotal: 2m 28s\tremaining: 9.46s\n","940:\tlearn: 0.5437717\ttotal: 2m 28s\tremaining: 9.31s\n","941:\tlearn: 0.5437141\ttotal: 2m 28s\tremaining: 9.15s\n","942:\tlearn: 0.5436850\ttotal: 2m 28s\tremaining: 8.99s\n","943:\tlearn: 0.5436821\ttotal: 2m 28s\tremaining: 8.83s\n","944:\tlearn: 0.5436410\ttotal: 2m 28s\tremaining: 8.67s\n","945:\tlearn: 0.5436203\ttotal: 2m 29s\tremaining: 8.51s\n","946:\tlearn: 0.5435757\ttotal: 2m 29s\tremaining: 8.35s\n","947:\tlearn: 0.5435424\ttotal: 2m 29s\tremaining: 8.19s\n","948:\tlearn: 0.5435022\ttotal: 2m 29s\tremaining: 8.03s\n","949:\tlearn: 0.5434532\ttotal: 2m 29s\tremaining: 7.87s\n","950:\tlearn: 0.5434045\ttotal: 2m 29s\tremaining: 7.71s\n","951:\tlearn: 0.5433655\ttotal: 2m 29s\tremaining: 7.55s\n","952:\tlearn: 0.5433067\ttotal: 2m 29s\tremaining: 7.4s\n","953:\tlearn: 0.5432524\ttotal: 2m 30s\tremaining: 7.24s\n","954:\tlearn: 0.5432154\ttotal: 2m 30s\tremaining: 7.08s\n","955:\tlearn: 0.5431632\ttotal: 2m 30s\tremaining: 6.92s\n","956:\tlearn: 0.5431379\ttotal: 2m 30s\tremaining: 6.76s\n","957:\tlearn: 0.5431227\ttotal: 2m 30s\tremaining: 6.6s\n","958:\tlearn: 0.5430713\ttotal: 2m 30s\tremaining: 6.44s\n","959:\tlearn: 0.5430212\ttotal: 2m 30s\tremaining: 6.28s\n","960:\tlearn: 0.5429789\ttotal: 2m 30s\tremaining: 6.13s\n","961:\tlearn: 0.5429489\ttotal: 2m 31s\tremaining: 5.97s\n","962:\tlearn: 0.5429473\ttotal: 2m 31s\tremaining: 5.81s\n","963:\tlearn: 0.5428855\ttotal: 2m 31s\tremaining: 5.65s\n","964:\tlearn: 0.5428439\ttotal: 2m 31s\tremaining: 5.49s\n","965:\tlearn: 0.5427877\ttotal: 2m 31s\tremaining: 5.34s\n","966:\tlearn: 0.5427485\ttotal: 2m 31s\tremaining: 5.18s\n","967:\tlearn: 0.5427086\ttotal: 2m 31s\tremaining: 5.02s\n","968:\tlearn: 0.5426712\ttotal: 2m 32s\tremaining: 4.86s\n","969:\tlearn: 0.5426209\ttotal: 2m 32s\tremaining: 4.71s\n","970:\tlearn: 0.5425721\ttotal: 2m 32s\tremaining: 4.55s\n","971:\tlearn: 0.5425708\ttotal: 2m 32s\tremaining: 4.39s\n","972:\tlearn: 0.5425227\ttotal: 2m 32s\tremaining: 4.23s\n","973:\tlearn: 0.5424707\ttotal: 2m 32s\tremaining: 4.08s\n","974:\tlearn: 0.5424372\ttotal: 2m 32s\tremaining: 3.92s\n","975:\tlearn: 0.5423955\ttotal: 2m 32s\tremaining: 3.76s\n","976:\tlearn: 0.5423572\ttotal: 2m 33s\tremaining: 3.6s\n","977:\tlearn: 0.5423211\ttotal: 2m 33s\tremaining: 3.45s\n","978:\tlearn: 0.5422834\ttotal: 2m 33s\tremaining: 3.29s\n","979:\tlearn: 0.5422533\ttotal: 2m 33s\tremaining: 3.13s\n","980:\tlearn: 0.5422230\ttotal: 2m 33s\tremaining: 2.98s\n","981:\tlearn: 0.5422209\ttotal: 2m 33s\tremaining: 2.82s\n","982:\tlearn: 0.5421696\ttotal: 2m 34s\tremaining: 2.67s\n","983:\tlearn: 0.5421155\ttotal: 2m 34s\tremaining: 2.51s\n","984:\tlearn: 0.5420853\ttotal: 2m 34s\tremaining: 2.35s\n","985:\tlearn: 0.5420526\ttotal: 2m 34s\tremaining: 2.2s\n","986:\tlearn: 0.5420134\ttotal: 2m 35s\tremaining: 2.04s\n","987:\tlearn: 0.5419887\ttotal: 2m 35s\tremaining: 1.89s\n","988:\tlearn: 0.5419481\ttotal: 2m 35s\tremaining: 1.73s\n","989:\tlearn: 0.5419155\ttotal: 2m 35s\tremaining: 1.57s\n","990:\tlearn: 0.5419150\ttotal: 2m 36s\tremaining: 1.42s\n","991:\tlearn: 0.5419137\ttotal: 2m 36s\tremaining: 1.26s\n","992:\tlearn: 0.5418959\ttotal: 2m 36s\tremaining: 1.1s\n","993:\tlearn: 0.5418439\ttotal: 2m 36s\tremaining: 946ms\n","994:\tlearn: 0.5418075\ttotal: 2m 36s\tremaining: 789ms\n","995:\tlearn: 0.5417696\ttotal: 2m 37s\tremaining: 631ms\n","996:\tlearn: 0.5417236\ttotal: 2m 37s\tremaining: 473ms\n","997:\tlearn: 0.5416926\ttotal: 2m 37s\tremaining: 315ms\n","998:\tlearn: 0.5416588\ttotal: 2m 37s\tremaining: 158ms\n","999:\tlearn: 0.5416274\ttotal: 2m 37s\tremaining: 0us\n"]}]},{"cell_type":"code","source":["treshold = 0\n","best_res = 0\n","for i in np.arange(0.05, 0.95, 0.05):\n","    res = pred_proba['proba'].apply(lambda x:0 if x < i else 1)\n","    tmp_score = round(roc_auc_score(y_test, res), 4)\n","    if tmp_score > best_res:\n","        best_res = tmp_score\n","        treshold = i\n","    print(f\"i - {i}, res - {tmp_score}\")\n","print(treshold)\n","print(best_res)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oTyNWl2yJpuC","executionInfo":{"status":"ok","timestamp":1708007235262,"user_tz":-240,"elapsed":1445,"user":{"displayName":"Евгений Малов","userId":"06257165098392198337"}},"outputId":"f6a2515a-9957-48ff-8a16-d2ef62360135"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["i - 0.05, res - 0.5021\n","i - 0.1, res - 0.5207\n","i - 0.15000000000000002, res - 0.5509\n","i - 0.2, res - 0.5831\n","i - 0.25, res - 0.6141\n","i - 0.3, res - 0.6413\n","i - 0.35000000000000003, res - 0.6619\n","i - 0.4, res - 0.6771\n","i - 0.45, res - 0.6871\n","i - 0.5, res - 0.6886\n","i - 0.55, res - 0.6827\n","i - 0.6000000000000001, res - 0.6707\n","i - 0.6500000000000001, res - 0.6502\n","i - 0.7000000000000001, res - 0.623\n","i - 0.7500000000000001, res - 0.5942\n","i - 0.8, res - 0.5617\n","i - 0.8500000000000001, res - 0.5328\n","i - 0.9000000000000001, res - 0.5111\n","0.5\n","0.6886\n"]}]},{"cell_type":"code","source":["def objective_lgbm(trial):\n","    max_depth = trial.suggest_int(\"max_depth\", 2, 15)\n","    learning_rate = trial.suggest_float(\"learning_rate\", 1e-5, 1, log=True)\n","    n_estimators = trial.suggest_int(\"n_estimators\", 10, 700)\n","\n","    score = cross_val_score(LGBMClassifier(max_depth=max_depth, learning_rate=learning_rate, n_estimators=n_estimators),\n","                            x_train, y_train, cv=3, scoring='roc_auc', n_jobs=-1).mean()\n","    return score\n","\n","\n","study_lgbm = optuna.create_study(direction=\"maximize\")\n","study_lgbm.optimize(objective_lgbm, n_trials=50)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e5V3BDzPbvxx","executionInfo":{"status":"ok","timestamp":1707831780799,"user_tz":-240,"elapsed":3988929,"user":{"displayName":"Евгений Малов","userId":"06257165098392198337"}},"outputId":"c585a3a8-d167-44ad-91e1-8d9037a2d441"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[I 2024-02-13 12:36:31,472] A new study created in memory with name: no-name-1880a6e1-b227-4a25-a480-86d81b3c5cfe\n","[I 2024-02-13 12:37:09,660] Trial 0 finished with value: 0.6812840715383398 and parameters: {'max_depth': 6, 'learning_rate': 0.00011859471033414236, 'n_estimators': 140}. Best is trial 0 with value: 0.6812840715383398.\n","[I 2024-02-13 12:37:36,292] Trial 1 finished with value: 0.6102473752179339 and parameters: {'max_depth': 2, 'learning_rate': 1.0800540338210664e-05, 'n_estimators': 222}. Best is trial 0 with value: 0.6812840715383398.\n","[I 2024-02-13 12:39:00,935] Trial 2 finished with value: 0.6879447534206401 and parameters: {'max_depth': 11, 'learning_rate': 6.251357097363783e-05, 'n_estimators': 396}. Best is trial 2 with value: 0.6879447534206401.\n","[I 2024-02-13 12:40:06,021] Trial 3 finished with value: 0.6805921457740766 and parameters: {'max_depth': 7, 'learning_rate': 0.9694155722043523, 'n_estimators': 544}. Best is trial 2 with value: 0.6879447534206401.\n","[I 2024-02-13 12:40:48,415] Trial 4 finished with value: 0.7514152515997695 and parameters: {'max_depth': 10, 'learning_rate': 0.08407431672299592, 'n_estimators': 240}. Best is trial 4 with value: 0.7514152515997695.\n","[I 2024-02-13 12:41:25,130] Trial 5 finished with value: 0.7140326343487712 and parameters: {'max_depth': 5, 'learning_rate': 0.006452866244052312, 'n_estimators': 171}. Best is trial 4 with value: 0.7514152515997695.\n","[I 2024-02-13 12:41:59,314] Trial 6 finished with value: 0.702623717750626 and parameters: {'max_depth': 7, 'learning_rate': 0.0021511784748028374, 'n_estimators': 140}. Best is trial 4 with value: 0.7514152515997695.\n","[I 2024-02-13 12:42:27,721] Trial 7 finished with value: 0.7475590499338121 and parameters: {'max_depth': 5, 'learning_rate': 0.23368199329985004, 'n_estimators': 177}. Best is trial 4 with value: 0.7514152515997695.\n","[I 2024-02-13 12:43:18,540] Trial 8 finished with value: 0.691598641833307 and parameters: {'max_depth': 12, 'learning_rate': 0.0002751849689615351, 'n_estimators': 199}. Best is trial 4 with value: 0.7514152515997695.\n","[I 2024-02-13 12:43:31,088] Trial 9 finished with value: 0.7325525392291521 and parameters: {'max_depth': 4, 'learning_rate': 0.9325318069580143, 'n_estimators': 27}. Best is trial 4 with value: 0.7514152515997695.\n","[I 2024-02-13 12:45:09,511] Trial 10 finished with value: 0.7529788525987781 and parameters: {'max_depth': 15, 'learning_rate': 0.037411732809586755, 'n_estimators': 669}. Best is trial 10 with value: 0.7529788525987781.\n","[I 2024-02-13 12:46:49,692] Trial 11 finished with value: 0.7528818335358912 and parameters: {'max_depth': 15, 'learning_rate': 0.041872654910131785, 'n_estimators': 690}. Best is trial 10 with value: 0.7529788525987781.\n","[I 2024-02-13 12:48:55,596] Trial 12 finished with value: 0.7513343361293358 and parameters: {'max_depth': 15, 'learning_rate': 0.013700593223265004, 'n_estimators': 692}. Best is trial 10 with value: 0.7529788525987781.\n","[I 2024-02-13 12:50:38,055] Trial 13 finished with value: 0.7527847651995213 and parameters: {'max_depth': 15, 'learning_rate': 0.038175073214563045, 'n_estimators': 687}. Best is trial 10 with value: 0.7529788525987781.\n","[I 2024-02-13 12:52:23,535] Trial 14 finished with value: 0.7066737007677885 and parameters: {'max_depth': 13, 'learning_rate': 0.0007419634474887491, 'n_estimators': 530}. Best is trial 10 with value: 0.7529788525987781.\n","[I 2024-02-13 12:53:56,153] Trial 15 finished with value: 0.7527668789885795 and parameters: {'max_depth': 13, 'learning_rate': 0.029693571257174176, 'n_estimators': 575}. Best is trial 10 with value: 0.7529788525987781.\n","[I 2024-02-13 12:54:53,182] Trial 16 finished with value: 0.7485791307087796 and parameters: {'max_depth': 15, 'learning_rate': 0.1370522184473232, 'n_estimators': 429}. Best is trial 10 with value: 0.7529788525987781.\n","[I 2024-02-13 12:56:56,641] Trial 17 finished with value: 0.7224257838684744 and parameters: {'max_depth': 9, 'learning_rate': 0.002018750689346509, 'n_estimators': 621}. Best is trial 10 with value: 0.7529788525987781.\n","[I 2024-02-13 12:58:29,250] Trial 18 finished with value: 0.7452559466431309 and parameters: {'max_depth': 13, 'learning_rate': 0.010160281091704677, 'n_estimators': 471}. Best is trial 10 with value: 0.7529788525987781.\n","[I 2024-02-13 12:59:11,614] Trial 19 finished with value: 0.7418634616804143 and parameters: {'max_depth': 14, 'learning_rate': 0.2318189270215018, 'n_estimators': 324}. Best is trial 10 with value: 0.7529788525987781.\n","[I 2024-02-13 13:00:39,928] Trial 20 finished with value: 0.7528321474556922 and parameters: {'max_depth': 11, 'learning_rate': 0.04530348288447809, 'n_estimators': 640}. Best is trial 10 with value: 0.7529788525987781.\n","[I 2024-02-13 13:02:21,297] Trial 21 finished with value: 0.7526239661482413 and parameters: {'max_depth': 11, 'learning_rate': 0.03362981728146362, 'n_estimators': 626}. Best is trial 10 with value: 0.7529788525987781.\n","[I 2024-02-13 13:03:39,513] Trial 22 finished with value: 0.7508527666149195 and parameters: {'max_depth': 14, 'learning_rate': 0.08307799753189692, 'n_estimators': 644}. Best is trial 10 with value: 0.7529788525987781.\n","[I 2024-02-13 13:05:19,062] Trial 23 finished with value: 0.7339294204261665 and parameters: {'max_depth': 9, 'learning_rate': 0.005021125748286379, 'n_estimators': 495}. Best is trial 10 with value: 0.7529788525987781.\n","[I 2024-02-13 13:06:24,100] Trial 24 finished with value: 0.7204543714553138 and parameters: {'max_depth': 12, 'learning_rate': 0.4000844523076273, 'n_estimators': 595}. Best is trial 10 with value: 0.7529788525987781.\n","[I 2024-02-13 13:08:11,238] Trial 25 finished with value: 0.752734480286876 and parameters: {'max_depth': 14, 'learning_rate': 0.023384136760660403, 'n_estimators': 681}. Best is trial 10 with value: 0.7529788525987781.\n","[I 2024-02-13 13:09:27,619] Trial 26 finished with value: 0.7520845438596341 and parameters: {'max_depth': 11, 'learning_rate': 0.05940677627509613, 'n_estimators': 572}. Best is trial 10 with value: 0.7529788525987781.\n","[I 2024-02-13 13:11:25,807] Trial 27 finished with value: 0.7511747574058143 and parameters: {'max_depth': 12, 'learning_rate': 0.013973685526288969, 'n_estimators': 653}. Best is trial 10 with value: 0.7529788525987781.\n","[I 2024-02-13 13:12:30,316] Trial 28 finished with value: 0.7213625424433601 and parameters: {'max_depth': 10, 'learning_rate': 0.003940288071613578, 'n_estimators': 295}. Best is trial 10 with value: 0.7529788525987781.\n","[I 2024-02-13 13:14:08,834] Trial 29 finished with value: 0.7091971571646735 and parameters: {'max_depth': 15, 'learning_rate': 0.000981089904279583, 'n_estimators': 489}. Best is trial 10 with value: 0.7529788525987781.\n","[I 2024-02-13 13:15:02,421] Trial 30 finished with value: 0.7482287268930449 and parameters: {'max_depth': 14, 'learning_rate': 0.1435653024852825, 'n_estimators': 423}. Best is trial 10 with value: 0.7529788525987781.\n","[I 2024-02-13 13:16:32,496] Trial 31 finished with value: 0.7525730373706331 and parameters: {'max_depth': 15, 'learning_rate': 0.04855232213682884, 'n_estimators': 681}. Best is trial 10 with value: 0.7529788525987781.\n","[I 2024-02-13 13:18:25,084] Trial 32 finished with value: 0.7524081706982034 and parameters: {'max_depth': 13, 'learning_rate': 0.02021031675277774, 'n_estimators': 691}. Best is trial 10 with value: 0.7529788525987781.\n","[I 2024-02-13 13:19:31,544] Trial 33 finished with value: 0.7232580324813668 and parameters: {'max_depth': 15, 'learning_rate': 0.368333064355129, 'n_estimators': 620}. Best is trial 10 with value: 0.7529788525987781.\n","[I 2024-02-13 13:20:20,233] Trial 34 finished with value: 0.618745577418319 and parameters: {'max_depth': 2, 'learning_rate': 5.0815066723697924e-05, 'n_estimators': 530}. Best is trial 10 with value: 0.7529788525987781.\n","[I 2024-02-13 13:22:17,754] Trial 35 finished with value: 0.7453169376560602 and parameters: {'max_depth': 14, 'learning_rate': 0.00812119004201519, 'n_estimators': 594}. Best is trial 10 with value: 0.7529788525987781.\n","[I 2024-02-13 13:23:45,845] Trial 36 finished with value: 0.7526154021098327 and parameters: {'max_depth': 8, 'learning_rate': 0.04910042387224353, 'n_estimators': 660}. Best is trial 10 with value: 0.7529788525987781.\n","[I 2024-02-13 13:25:08,875] Trial 37 finished with value: 0.7505616843427241 and parameters: {'max_depth': 11, 'learning_rate': 0.09098975061013151, 'n_estimators': 700}. Best is trial 10 with value: 0.7529788525987781.\n","[I 2024-02-13 13:26:47,259] Trial 38 finished with value: 0.7519007335624407 and parameters: {'max_depth': 12, 'learning_rate': 0.01990442178099446, 'n_estimators': 561}. Best is trial 10 with value: 0.7529788525987781.\n","[I 2024-02-13 13:27:05,502] Trial 39 finished with value: 0.7484178206836961 and parameters: {'max_depth': 10, 'learning_rate': 0.1725419839500609, 'n_estimators': 52}. Best is trial 10 with value: 0.7529788525987781.\n","[I 2024-02-13 13:27:49,538] Trial 40 finished with value: 0.7108883061786679 and parameters: {'max_depth': 13, 'learning_rate': 0.5552298968105668, 'n_estimators': 371}. Best is trial 10 with value: 0.7529788525987781.\n","[I 2024-02-13 13:29:22,442] Trial 41 finished with value: 0.7526906085817755 and parameters: {'max_depth': 13, 'learning_rate': 0.028286703394778526, 'n_estimators': 588}. Best is trial 10 with value: 0.7529788525987781.\n","[I 2024-02-13 13:30:53,174] Trial 42 finished with value: 0.752459998851334 and parameters: {'max_depth': 14, 'learning_rate': 0.04147948882499701, 'n_estimators': 654}. Best is trial 10 with value: 0.7529788525987781.\n","[I 2024-02-13 13:32:08,322] Trial 43 finished with value: 0.7506020462995195 and parameters: {'max_depth': 15, 'learning_rate': 0.08908762209717459, 'n_estimators': 611}. Best is trial 10 with value: 0.7529788525987781.\n","[I 2024-02-13 13:33:51,881] Trial 44 finished with value: 0.7504070829022712 and parameters: {'max_depth': 14, 'learning_rate': 0.014566427718609894, 'n_estimators': 548}. Best is trial 10 with value: 0.7529788525987781.\n","[I 2024-02-13 13:36:00,690] Trial 45 finished with value: 0.7422232943719255 and parameters: {'max_depth': 15, 'learning_rate': 0.005958221639012722, 'n_estimators': 651}. Best is trial 10 with value: 0.7529788525987781.\n","[I 2024-02-13 13:38:15,050] Trial 46 finished with value: 0.7229450578390025 and parameters: {'max_depth': 13, 'learning_rate': 0.0019115996781266706, 'n_estimators': 667}. Best is trial 10 with value: 0.7529788525987781.\n","[I 2024-02-13 13:39:34,585] Trial 47 finished with value: 0.7518817431137107 and parameters: {'max_depth': 12, 'learning_rate': 0.06571754742557435, 'n_estimators': 627}. Best is trial 10 with value: 0.7529788525987781.\n","[I 2024-02-13 13:41:16,224] Trial 48 finished with value: 0.6836037767050577 and parameters: {'max_depth': 15, 'learning_rate': 1.3261401993234142e-05, 'n_estimators': 518}. Best is trial 10 with value: 0.7529788525987781.\n","[I 2024-02-13 13:42:59,978] Trial 49 finished with value: 0.7528565526652384 and parameters: {'max_depth': 14, 'learning_rate': 0.03139567766229434, 'n_estimators': 700}. Best is trial 10 with value: 0.7529788525987781.\n"]}]},{"cell_type":"code","source":["study_lgbm.best_params"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IIE06l5wbv1W","executionInfo":{"status":"ok","timestamp":1707831864790,"user_tz":-240,"elapsed":289,"user":{"displayName":"Евгений Малов","userId":"06257165098392198337"}},"outputId":"2407629c-0ebb-4125-d3bd-5ecb8a08fe19"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'max_depth': 15, 'learning_rate': 0.037411732809586755, 'n_estimators': 669}"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":["opt_model_lgbm = LGBMClassifier(max_depth=15, learning_rate=0.037411732809586755, n_estimators=669)\n","opt_model_lgbm.fit(x_train, y_train)\n","\n","pred_train = opt_model_lgbm.predict(x_train)\n","pred_test = opt_model_lgbm.predict(x_test)\n","\n","print(f'train: {roc_auc_score(y_train, pred_train)}')\n","print(f'test: {roc_auc_score(y_test, pred_test)}')\n","print(f'test conf matrix: \\n {confusion_matrix(y_test, pred_test)}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TBmKdsTrcOAN","executionInfo":{"status":"ok","timestamp":1707852636256,"user_tz":-240,"elapsed":66654,"user":{"displayName":"Евгений Малов","userId":"06257165098392198337"}},"outputId":"1baf7ee4-e947-47ed-97b5-a1d27a02f3b3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 74529, number of negative: 74489\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.638769 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 4670\n","[LightGBM] [Info] Number of data points in the train set: 149018, number of used features: 306\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500134 -> initscore=0.000537\n","[LightGBM] [Info] Start training from score 0.000537\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","train: 0.7240271363586864\n","test: 0.6873445737110458\n","test conf matrix: \n"," [[21205 10748]\n"," [ 9221 22692]]\n"]}]},{"cell_type":"code","source":["def objective_xgb(trial):\n","    max_depth = trial.suggest_int(\"max_depth\", 2, 15)\n","    learning_rate = trial.suggest_float(\"learning_rate\", 1e-5, 1, log=True)\n","    n_estimators = trial.suggest_int(\"n_estimators\", 10, 700)\n","\n","    score = cross_val_score(XGBClassifier(max_depth=max_depth, n_estimators=n_estimators,\n","                                              learning_rate=learning_rate),\n","                            x_train, y_train, cv=3, scoring='roc_auc', n_jobs=-1).mean()\n","    return score\n","\n","\n","study_xgb = optuna.create_study(direction=\"maximize\")\n","study_xgb.optimize(objective_xgb, n_trials=50)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Jv1ISGV3cOD6","executionInfo":{"status":"ok","timestamp":1707840644619,"user_tz":-240,"elapsed":8709791,"user":{"displayName":"Евгений Малов","userId":"06257165098392198337"}},"outputId":"cc9f2365-8f85-4717-c068-9c243e8d0e8e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[I 2024-02-13 13:45:34,350] A new study created in memory with name: no-name-e5b16c2b-d2d3-47a4-aa1b-1780a5a33c64\n","[I 2024-02-13 13:46:33,092] Trial 0 finished with value: 0.6884904588336352 and parameters: {'max_depth': 6, 'learning_rate': 0.00036612120307004284, 'n_estimators': 142}. Best is trial 0 with value: 0.6884904588336352.\n","[I 2024-02-13 13:47:00,801] Trial 1 finished with value: 0.6996296860616534 and parameters: {'max_depth': 9, 'learning_rate': 0.0010526765485588928, 'n_estimators': 30}. Best is trial 1 with value: 0.6996296860616534.\n","[I 2024-02-13 14:03:43,953] Trial 2 finished with value: 0.6968232593405891 and parameters: {'max_depth': 15, 'learning_rate': 0.00020431488837946692, 'n_estimators': 605}. Best is trial 1 with value: 0.6996296860616534.\n","[I 2024-02-13 14:06:54,214] Trial 3 finished with value: 0.6852691931136303 and parameters: {'max_depth': 5, 'learning_rate': 0.00023997566802554714, 'n_estimators': 638}. Best is trial 1 with value: 0.6996296860616534.\n","[I 2024-02-13 14:09:22,160] Trial 4 finished with value: 0.749209804395163 and parameters: {'max_depth': 10, 'learning_rate': 0.07480475956849739, 'n_estimators': 385}. Best is trial 4 with value: 0.749209804395163.\n","[I 2024-02-13 14:11:20,477] Trial 5 finished with value: 0.7506779596657371 and parameters: {'max_depth': 11, 'learning_rate': 0.056675671190086055, 'n_estimators': 233}. Best is trial 5 with value: 0.7506779596657371.\n","[I 2024-02-13 14:16:44,687] Trial 6 finished with value: 0.6866001827938312 and parameters: {'max_depth': 13, 'learning_rate': 0.00010667229990976323, 'n_estimators': 284}. Best is trial 5 with value: 0.7506779596657371.\n","[I 2024-02-13 14:24:15,166] Trial 7 finished with value: 0.7421731887517818 and parameters: {'max_depth': 12, 'learning_rate': 0.004253101260424451, 'n_estimators': 528}. Best is trial 5 with value: 0.7506779596657371.\n","[I 2024-02-13 14:28:46,152] Trial 8 finished with value: 0.726443563995661 and parameters: {'max_depth': 7, 'learning_rate': 0.001903824632269958, 'n_estimators': 700}. Best is trial 5 with value: 0.7506779596657371.\n","[I 2024-02-13 14:30:16,937] Trial 9 finished with value: 0.6714135899450687 and parameters: {'max_depth': 5, 'learning_rate': 5.808043551774659e-05, 'n_estimators': 276}. Best is trial 5 with value: 0.7506779596657371.\n","[I 2024-02-13 14:31:32,888] Trial 10 finished with value: 0.7439477758397349 and parameters: {'max_depth': 2, 'learning_rate': 0.6361177355157799, 'n_estimators': 449}. Best is trial 5 with value: 0.7506779596657371.\n","[I 2024-02-13 14:34:18,864] Trial 11 finished with value: 0.7485051915168385 and parameters: {'max_depth': 11, 'learning_rate': 0.07555329672956046, 'n_estimators': 381}. Best is trial 5 with value: 0.7506779596657371.\n","[I 2024-02-13 14:36:10,270] Trial 12 finished with value: 0.7485944345975812 and parameters: {'max_depth': 10, 'learning_rate': 0.02265463997944676, 'n_estimators': 193}. Best is trial 5 with value: 0.7506779596657371.\n","[I 2024-02-13 14:38:01,595] Trial 13 finished with value: 0.7369066916811762 and parameters: {'max_depth': 8, 'learning_rate': 0.21539390422517912, 'n_estimators': 397}. Best is trial 5 with value: 0.7506779596657371.\n","[I 2024-02-13 14:42:48,875] Trial 14 finished with value: 0.7489851163195594 and parameters: {'max_depth': 14, 'learning_rate': 0.01893992711974615, 'n_estimators': 284}. Best is trial 5 with value: 0.7506779596657371.\n","[I 2024-02-13 14:44:21,506] Trial 15 finished with value: 0.7406922651460235 and parameters: {'max_depth': 11, 'learning_rate': 0.017372584567647717, 'n_estimators': 117}. Best is trial 5 with value: 0.7506779596657371.\n","[I 2024-02-13 14:45:42,555] Trial 16 finished with value: 0.7002899465296976 and parameters: {'max_depth': 9, 'learning_rate': 0.7321452646933816, 'n_estimators': 220}. Best is trial 5 with value: 0.7506779596657371.\n","[I 2024-02-13 14:54:41,998] Trial 17 finished with value: 0.6769814617153815 and parameters: {'max_depth': 13, 'learning_rate': 1.55270111143935e-05, 'n_estimators': 476}. Best is trial 5 with value: 0.7506779596657371.\n","[I 2024-02-13 14:57:10,143] Trial 18 finished with value: 0.7452260979762896 and parameters: {'max_depth': 11, 'learning_rate': 0.11109668902114474, 'n_estimators': 345}. Best is trial 5 with value: 0.7506779596657371.\n","[I 2024-02-13 14:57:28,749] Trial 19 finished with value: 0.6539024078613161 and parameters: {'max_depth': 2, 'learning_rate': 0.007069832183272979, 'n_estimators': 32}. Best is trial 5 with value: 0.7506779596657371.\n","[I 2024-02-13 14:59:15,419] Trial 20 finished with value: 0.751511812810255 and parameters: {'max_depth': 8, 'learning_rate': 0.06189464819976403, 'n_estimators': 331}. Best is trial 20 with value: 0.751511812810255.\n","[I 2024-02-13 15:01:07,324] Trial 21 finished with value: 0.7518394558814983 and parameters: {'max_depth': 8, 'learning_rate': 0.06086398253417569, 'n_estimators': 347}. Best is trial 21 with value: 0.7518394558814983.\n","[I 2024-02-13 15:02:28,987] Trial 22 finished with value: 0.7384676114499379 and parameters: {'max_depth': 7, 'learning_rate': 0.24092423458802956, 'n_estimators': 309}. Best is trial 21 with value: 0.7518394558814983.\n","[I 2024-02-13 15:03:51,401] Trial 23 finished with value: 0.7502434145171953 and parameters: {'max_depth': 8, 'learning_rate': 0.038962593065939535, 'n_estimators': 197}. Best is trial 21 with value: 0.7518394558814983.\n","[I 2024-02-13 15:05:10,346] Trial 24 finished with value: 0.7261291503932968 and parameters: {'max_depth': 5, 'learning_rate': 0.00923312261023915, 'n_estimators': 247}. Best is trial 21 with value: 0.7518394558814983.\n","[I 2024-02-13 15:07:04,680] Trial 25 finished with value: 0.7445548011516142 and parameters: {'max_depth': 7, 'learning_rate': 0.16413626923075714, 'n_estimators': 457}. Best is trial 21 with value: 0.7518394558814983.\n","[I 2024-02-13 15:08:22,527] Trial 26 finished with value: 0.7494329222356934 and parameters: {'max_depth': 10, 'learning_rate': 0.042284911134309724, 'n_estimators': 131}. Best is trial 21 with value: 0.7518394558814983.\n","[I 2024-02-13 15:09:31,391] Trial 27 finished with value: 0.7395926742311908 and parameters: {'max_depth': 4, 'learning_rate': 0.4472831093363471, 'n_estimators': 334}. Best is trial 21 with value: 0.7518394558814983.\n","[I 2024-02-13 15:14:02,441] Trial 28 finished with value: 0.7226854627042115 and parameters: {'max_depth': 9, 'learning_rate': 0.0011204119233259216, 'n_estimators': 518}. Best is trial 21 with value: 0.7518394558814983.\n","[I 2024-02-13 15:14:45,040] Trial 29 finished with value: 0.7382820616964176 and parameters: {'max_depth': 6, 'learning_rate': 0.03847514412833203, 'n_estimators': 95}. Best is trial 21 with value: 0.7518394558814983.\n","[I 2024-02-13 15:17:22,465] Trial 30 finished with value: 0.7386994299293188 and parameters: {'max_depth': 12, 'learning_rate': 0.010029260463316666, 'n_estimators': 173}. Best is trial 21 with value: 0.7518394558814983.\n","[I 2024-02-13 15:18:51,198] Trial 31 finished with value: 0.7513869094751602 and parameters: {'max_depth': 8, 'learning_rate': 0.04850168894469306, 'n_estimators': 237}. Best is trial 21 with value: 0.7518394558814983.\n","[I 2024-02-13 15:20:06,099] Trial 32 finished with value: 0.7257103746545696 and parameters: {'max_depth': 8, 'learning_rate': 0.3643511063425365, 'n_estimators': 243}. Best is trial 21 with value: 0.7518394558814983.\n","[I 2024-02-13 15:21:49,946] Trial 33 finished with value: 0.7516135823456885 and parameters: {'max_depth': 6, 'learning_rate': 0.08135639525543499, 'n_estimators': 422}. Best is trial 21 with value: 0.7518394558814983.\n","[I 2024-02-13 15:23:32,210] Trial 34 finished with value: 0.7509643156807765 and parameters: {'max_depth': 6, 'learning_rate': 0.1040192565494262, 'n_estimators': 420}. Best is trial 21 with value: 0.7518394558814983.\n","[I 2024-02-13 15:25:05,038] Trial 35 finished with value: 0.7037217810314279 and parameters: {'max_depth': 4, 'learning_rate': 0.002716325792566156, 'n_estimators': 332}. Best is trial 21 with value: 0.7518394558814983.\n","[I 2024-02-13 15:27:43,715] Trial 36 finished with value: 0.7520214075851729 and parameters: {'max_depth': 7, 'learning_rate': 0.02632811650515188, 'n_estimators': 517}. Best is trial 36 with value: 0.7520214075851729.\n","[I 2024-02-13 15:30:33,567] Trial 37 finished with value: 0.7516037545261023 and parameters: {'max_depth': 7, 'learning_rate': 0.021094146128027267, 'n_estimators': 540}. Best is trial 36 with value: 0.7520214075851729.\n","[I 2024-02-13 15:33:00,699] Trial 38 finished with value: 0.7255283112344769 and parameters: {'max_depth': 4, 'learning_rate': 0.005550061103486764, 'n_estimators': 587}. Best is trial 36 with value: 0.7520214075851729.\n","[I 2024-02-13 15:35:41,834] Trial 39 finished with value: 0.7485802923063568 and parameters: {'max_depth': 6, 'learning_rate': 0.01569751553641998, 'n_estimators': 546}. Best is trial 36 with value: 0.7520214075851729.\n","[I 2024-02-13 15:38:44,847] Trial 40 finished with value: 0.7525661057599794 and parameters: {'max_depth': 7, 'learning_rate': 0.02709631435444296, 'n_estimators': 642}. Best is trial 40 with value: 0.7525661057599794.\n","[I 2024-02-13 15:41:51,693] Trial 41 finished with value: 0.7526730720607482 and parameters: {'max_depth': 7, 'learning_rate': 0.027180381875281077, 'n_estimators': 651}. Best is trial 41 with value: 0.7526730720607482.\n","[I 2024-02-13 15:44:11,668] Trial 42 finished with value: 0.7487671251365723 and parameters: {'max_depth': 6, 'learning_rate': 0.1184104106754602, 'n_estimators': 634}. Best is trial 41 with value: 0.7526730720607482.\n","[I 2024-02-13 15:47:17,836] Trial 43 finished with value: 0.7525868662529156 and parameters: {'max_depth': 7, 'learning_rate': 0.03257818778046196, 'n_estimators': 691}. Best is trial 41 with value: 0.7526730720607482.\n","[I 2024-02-13 15:50:36,584] Trial 44 finished with value: 0.7525089985185119 and parameters: {'max_depth': 7, 'learning_rate': 0.02853339082997904, 'n_estimators': 681}. Best is trial 41 with value: 0.7526730720607482.\n","[I 2024-02-13 15:53:40,215] Trial 45 finished with value: 0.7453076824499032 and parameters: {'max_depth': 5, 'learning_rate': 0.012026533937706281, 'n_estimators': 699}. Best is trial 41 with value: 0.7526730720607482.\n","[I 2024-02-13 15:57:52,157] Trial 46 finished with value: 0.7353341716126867 and parameters: {'max_depth': 7, 'learning_rate': 0.0035110775918617758, 'n_estimators': 678}. Best is trial 41 with value: 0.7526730720607482.\n","[I 2024-02-13 16:01:36,756] Trial 47 finished with value: 0.7525647834244739 and parameters: {'max_depth': 9, 'learning_rate': 0.027302561531645012, 'n_estimators': 645}. Best is trial 41 with value: 0.7526730720607482.\n","[I 2024-02-13 16:07:14,462] Trial 48 finished with value: 0.7172574585359303 and parameters: {'max_depth': 9, 'learning_rate': 0.000524805791328753, 'n_estimators': 636}. Best is trial 41 with value: 0.7526730720607482.\n","[I 2024-02-13 16:10:43,605] Trial 49 finished with value: 0.7527496825498021 and parameters: {'max_depth': 9, 'learning_rate': 0.03213090007171616, 'n_estimators': 588}. Best is trial 49 with value: 0.7527496825498021.\n"]}]},{"cell_type":"code","source":["study_xgb.best_params"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_auuui1acOHa","executionInfo":{"status":"ok","timestamp":1707840921381,"user_tz":-240,"elapsed":342,"user":{"displayName":"Евгений Малов","userId":"06257165098392198337"}},"outputId":"17bfa07f-45cc-40dd-fa56-edfa3b2883ff"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'max_depth': 9, 'learning_rate': 0.03213090007171616, 'n_estimators': 588}"]},"metadata":{},"execution_count":17}]},{"cell_type":"code","source":["opt_model_xgb = XGBClassifier(max_depth=9, learning_rate=0.03213090007171616, n_estimators=588)\n","opt_model_xgb.fit(x_train, y_train)\n","\n","pred_train = opt_model_xgb.predict(x_train)\n","pred_test = opt_model_xgb.predict(x_test)\n","\n","print(f'train: {roc_auc_score(y_train, pred_train)}')\n","print(f'test: {roc_auc_score(y_test, pred_test)}')\n","print(f'test conf matrix: \\n {confusion_matrix(y_test, pred_test)}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"txJt6qCxcOK9","executionInfo":{"status":"ok","timestamp":1707852536032,"user_tz":-240,"elapsed":146129,"user":{"displayName":"Евгений Малов","userId":"06257165098392198337"}},"outputId":"5f88843e-7a17-49e7-b8fb-4380f0a35a15"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["train: 0.8094509775152494\n","test: 0.688546330271739\n","test conf matrix: \n"," [[21442 10511]\n"," [ 9381 22532]]\n"]}]},{"cell_type":"code","source":["def objective_catboost(trial):\n","    max_depth = trial.suggest_int(\"max_depth\", 2, 15)\n","    learning_rate = trial.suggest_float(\"learning_rate\", 1e-3, 1, log=True)\n","    n_estimators = trial.suggest_int(\"n_estimators\", 10, 150)\n","    l2_leaf_reg = trial.suggest_int('l2_leaf_reg', 1, 5)\n","\n","    score = cross_val_score(CatBoostClassifier(max_depth=max_depth, n_estimators=n_estimators,\n","                                              learning_rate=learning_rate, l2_leaf_reg=l2_leaf_reg),\n","                            x_train, y_train, cv=3, scoring='roc_auc', n_jobs=-1).mean()\n","    return score\n","\n","\n","study_catboost = optuna.create_study(direction=\"maximize\")\n","study_catboost.optimize(objective_catboost, n_trials=50)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lBVlNpJTcOOS","executionInfo":{"status":"ok","timestamp":1707850926184,"user_tz":-240,"elapsed":5249056,"user":{"displayName":"Евгений Малов","userId":"06257165098392198337"}},"outputId":"f22c8c0d-c68d-4e1f-db82-bc7e91440b64"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[I 2024-02-13 16:17:58,779] A new study created in memory with name: no-name-e696c4a1-4670-4b4b-80cf-634f97f4b115\n","[I 2024-02-13 16:18:14,993] Trial 0 finished with value: 0.682279111256123 and parameters: {'max_depth': 5, 'learning_rate': 0.003364582064735686, 'n_estimators': 27, 'l2_leaf_reg': 4}. Best is trial 0 with value: 0.682279111256123.\n","[I 2024-02-13 16:23:13,067] Trial 1 finished with value: 0.7438903232621872 and parameters: {'max_depth': 11, 'learning_rate': 0.1802378466835114, 'n_estimators': 143, 'l2_leaf_reg': 4}. Best is trial 1 with value: 0.7438903232621872.\n","[I 2024-02-13 16:24:17,571] Trial 2 finished with value: 0.7093068052998905 and parameters: {'max_depth': 9, 'learning_rate': 0.004202020576118888, 'n_estimators': 99, 'l2_leaf_reg': 4}. Best is trial 1 with value: 0.7438903232621872.\n","[I 2024-02-13 16:24:37,357] Trial 3 finished with value: 0.7039452502906091 and parameters: {'max_depth': 3, 'learning_rate': 0.03451008110058443, 'n_estimators': 58, 'l2_leaf_reg': 1}. Best is trial 1 with value: 0.7438903232621872.\n","[I 2024-02-13 16:27:21,781] Trial 4 finished with value: 0.7222812041521774 and parameters: {'max_depth': 10, 'learning_rate': 0.5020575602147997, 'n_estimators': 98, 'l2_leaf_reg': 3}. Best is trial 1 with value: 0.7438903232621872.\n","[I 2024-02-13 16:29:57,315] Trial 5 finished with value: 0.7380119623998868 and parameters: {'max_depth': 13, 'learning_rate': 0.12227713031394793, 'n_estimators': 42, 'l2_leaf_reg': 2}. Best is trial 1 with value: 0.7438903232621872.\n","[I 2024-02-13 16:30:17,253] Trial 6 finished with value: 0.7139878624055868 and parameters: {'max_depth': 4, 'learning_rate': 0.04540467670824229, 'n_estimators': 52, 'l2_leaf_reg': 1}. Best is trial 1 with value: 0.7438903232621872.\n","[I 2024-02-13 16:35:52,451] Trial 7 finished with value: 0.7130733733103921 and parameters: {'max_depth': 12, 'learning_rate': 0.0013289825213372616, 'n_estimators': 128, 'l2_leaf_reg': 2}. Best is trial 1 with value: 0.7438903232621872.\n","[I 2024-02-13 16:36:44,818] Trial 8 finished with value: 0.7341449521497999 and parameters: {'max_depth': 8, 'learning_rate': 0.5126340671266475, 'n_estimators': 104, 'l2_leaf_reg': 3}. Best is trial 1 with value: 0.7438903232621872.\n","[I 2024-02-13 16:37:39,557] Trial 9 finished with value: 0.7034707834350463 and parameters: {'max_depth': 9, 'learning_rate': 0.0010489506889694163, 'n_estimators': 82, 'l2_leaf_reg': 3}. Best is trial 1 with value: 0.7438903232621872.\n","[I 2024-02-13 16:59:59,664] Trial 10 finished with value: 0.7387506316436725 and parameters: {'max_depth': 15, 'learning_rate': 0.14968260208115733, 'n_estimators': 145, 'l2_leaf_reg': 5}. Best is trial 1 with value: 0.7438903232621872.\n","[I 2024-02-13 17:23:05,945] Trial 11 finished with value: 0.7383639023185479 and parameters: {'max_depth': 15, 'learning_rate': 0.14824563496168858, 'n_estimators': 149, 'l2_leaf_reg': 5}. Best is trial 1 with value: 0.7438903232621872.\n","[I 2024-02-13 17:46:05,057] Trial 12 finished with value: 0.7387283183003236 and parameters: {'max_depth': 15, 'learning_rate': 0.14526830126241264, 'n_estimators': 150, 'l2_leaf_reg': 5}. Best is trial 1 with value: 0.7438903232621872.\n","[I 2024-02-13 17:51:37,587] Trial 13 finished with value: 0.6824478593880791 and parameters: {'max_depth': 12, 'learning_rate': 0.8533156312895319, 'n_estimators': 127, 'l2_leaf_reg': 4}. Best is trial 1 with value: 0.7438903232621872.\n","[I 2024-02-13 17:52:26,630] Trial 14 finished with value: 0.7412099528734015 and parameters: {'max_depth': 6, 'learning_rate': 0.06815936722073981, 'n_estimators': 126, 'l2_leaf_reg': 5}. Best is trial 1 with value: 0.7438903232621872.\n","[I 2024-02-13 17:53:16,439] Trial 15 finished with value: 0.7199894981041736 and parameters: {'max_depth': 6, 'learning_rate': 0.015679966362743568, 'n_estimators': 122, 'l2_leaf_reg': 4}. Best is trial 1 with value: 0.7438903232621872.\n","[I 2024-02-13 17:54:11,730] Trial 16 finished with value: 0.7175645657054295 and parameters: {'max_depth': 7, 'learning_rate': 0.011468991456196164, 'n_estimators': 116, 'l2_leaf_reg': 5}. Best is trial 1 with value: 0.7438903232621872.\n","[I 2024-02-13 17:56:47,803] Trial 17 finished with value: 0.7410424956991909 and parameters: {'max_depth': 11, 'learning_rate': 0.05950385277627144, 'n_estimators': 77, 'l2_leaf_reg': 4}. Best is trial 1 with value: 0.7438903232621872.\n","[I 2024-02-13 17:57:19,258] Trial 18 finished with value: 0.7413148539930337 and parameters: {'max_depth': 2, 'learning_rate': 0.2889999218903594, 'n_estimators': 135, 'l2_leaf_reg': 5}. Best is trial 1 with value: 0.7438903232621872.\n","[I 2024-02-13 17:57:25,067] Trial 19 finished with value: 0.7123352233824649 and parameters: {'max_depth': 3, 'learning_rate': 0.3186503527268087, 'n_estimators': 11, 'l2_leaf_reg': 3}. Best is trial 1 with value: 0.7438903232621872.\n","[I 2024-02-13 17:57:54,976] Trial 20 finished with value: 0.7415358158644261 and parameters: {'max_depth': 2, 'learning_rate': 0.29095269314300976, 'n_estimators': 134, 'l2_leaf_reg': 4}. Best is trial 1 with value: 0.7438903232621872.\n","[I 2024-02-13 17:58:25,148] Trial 21 finished with value: 0.7402192123767527 and parameters: {'max_depth': 2, 'learning_rate': 0.2672235921273691, 'n_estimators': 137, 'l2_leaf_reg': 4}. Best is trial 1 with value: 0.7438903232621872.\n","[I 2024-02-13 17:58:57,081] Trial 22 finished with value: 0.7427937033415329 and parameters: {'max_depth': 2, 'learning_rate': 0.7908320728688331, 'n_estimators': 136, 'l2_leaf_reg': 4}. Best is trial 1 with value: 0.7438903232621872.\n","[I 2024-02-13 17:59:29,153] Trial 23 finished with value: 0.7400310513647094 and parameters: {'max_depth': 4, 'learning_rate': 0.8816139778283383, 'n_estimators': 111, 'l2_leaf_reg': 4}. Best is trial 1 with value: 0.7438903232621872.\n","[I 2024-02-13 17:59:48,767] Trial 24 finished with value: 0.7404661697542451 and parameters: {'max_depth': 2, 'learning_rate': 0.5727496169185227, 'n_estimators': 83, 'l2_leaf_reg': 2}. Best is trial 1 with value: 0.7438903232621872.\n","[I 2024-02-13 18:00:30,022] Trial 25 finished with value: 0.7393772122256866 and parameters: {'max_depth': 4, 'learning_rate': 0.08734237901314887, 'n_estimators': 138, 'l2_leaf_reg': 4}. Best is trial 1 with value: 0.7438903232621872.\n","[I 2024-02-13 18:07:30,454] Trial 26 finished with value: 0.7230692855936405 and parameters: {'max_depth': 13, 'learning_rate': 0.29122136020873696, 'n_estimators': 114, 'l2_leaf_reg': 3}. Best is trial 1 with value: 0.7438903232621872.\n","[I 2024-02-13 18:08:32,898] Trial 27 finished with value: 0.7288185180441603 and parameters: {'max_depth': 7, 'learning_rate': 0.020338616240860984, 'n_estimators': 139, 'l2_leaf_reg': 4}. Best is trial 1 with value: 0.7438903232621872.\n","[I 2024-02-13 18:12:13,161] Trial 28 finished with value: 0.7419826247733244 and parameters: {'max_depth': 11, 'learning_rate': 0.20766701136626714, 'n_estimators': 107, 'l2_leaf_reg': 3}. Best is trial 1 with value: 0.7438903232621872.\n","[I 2024-02-13 18:14:52,087] Trial 29 finished with value: 0.6811042364554013 and parameters: {'max_depth': 10, 'learning_rate': 0.9949629034996135, 'n_estimators': 94, 'l2_leaf_reg': 2}. Best is trial 1 with value: 0.7438903232621872.\n","[I 2024-02-13 18:18:40,578] Trial 30 finished with value: 0.7156208802407328 and parameters: {'max_depth': 11, 'learning_rate': 0.4749423823402486, 'n_estimators': 108, 'l2_leaf_reg': 3}. Best is trial 1 with value: 0.7438903232621872.\n","[I 2024-02-13 18:27:05,608] Trial 31 finished with value: 0.7317037483868648 and parameters: {'max_depth': 13, 'learning_rate': 0.22802832010246674, 'n_estimators': 134, 'l2_leaf_reg': 4}. Best is trial 1 with value: 0.7438903232621872.\n","[I 2024-02-13 18:30:28,780] Trial 32 finished with value: 0.7463401350371859 and parameters: {'max_depth': 10, 'learning_rate': 0.19783352287461753, 'n_estimators': 121, 'l2_leaf_reg': 4}. Best is trial 32 with value: 0.7463401350371859.\n","[I 2024-02-13 18:33:48,415] Trial 33 finished with value: 0.7477445516280193 and parameters: {'max_depth': 10, 'learning_rate': 0.10709160401244221, 'n_estimators': 119, 'l2_leaf_reg': 3}. Best is trial 33 with value: 0.7477445516280193.\n","[I 2024-02-13 18:37:07,340] Trial 34 finished with value: 0.746441561465793 and parameters: {'max_depth': 10, 'learning_rate': 0.08085569180743075, 'n_estimators': 118, 'l2_leaf_reg': 3}. Best is trial 33 with value: 0.7477445516280193.\n","[I 2024-02-13 18:39:41,556] Trial 35 finished with value: 0.7452628612001654 and parameters: {'max_depth': 10, 'learning_rate': 0.09287601201990682, 'n_estimators': 92, 'l2_leaf_reg': 3}. Best is trial 33 with value: 0.7477445516280193.\n","[I 2024-02-13 18:42:17,395] Trial 36 finished with value: 0.7363421212042067 and parameters: {'max_depth': 10, 'learning_rate': 0.033224382302118, 'n_estimators': 92, 'l2_leaf_reg': 2}. Best is trial 33 with value: 0.7477445516280193.\n","[I 2024-02-13 18:43:02,953] Trial 37 finished with value: 0.7420233512303285 and parameters: {'max_depth': 9, 'learning_rate': 0.08882443594239174, 'n_estimators': 72, 'l2_leaf_reg': 3}. Best is trial 33 with value: 0.7477445516280193.\n","[I 2024-02-13 18:43:38,980] Trial 38 finished with value: 0.7411787424926407 and parameters: {'max_depth': 8, 'learning_rate': 0.09758986883048974, 'n_estimators': 66, 'l2_leaf_reg': 2}. Best is trial 33 with value: 0.7477445516280193.\n","[I 2024-02-13 18:47:00,356] Trial 39 finished with value: 0.7422290199119175 and parameters: {'max_depth': 10, 'learning_rate': 0.04297735960014373, 'n_estimators': 120, 'l2_leaf_reg': 3}. Best is trial 33 with value: 0.7477445516280193.\n","[I 2024-02-13 18:51:21,467] Trial 40 finished with value: 0.7358813749441996 and parameters: {'max_depth': 12, 'learning_rate': 0.024867309812312596, 'n_estimators': 100, 'l2_leaf_reg': 3}. Best is trial 33 with value: 0.7477445516280193.\n","[I 2024-02-13 18:52:16,590] Trial 41 finished with value: 0.7402898780268874 and parameters: {'max_depth': 9, 'learning_rate': 0.05311610112519094, 'n_estimators': 90, 'l2_leaf_reg': 3}. Best is trial 33 with value: 0.7477445516280193.\n","[I 2024-02-13 18:53:49,441] Trial 42 finished with value: 0.7406717013959443 and parameters: {'max_depth': 11, 'learning_rate': 0.1165709385577975, 'n_estimators': 44, 'l2_leaf_reg': 3}. Best is trial 33 with value: 0.7477445516280193.\n","[I 2024-02-13 18:54:48,698] Trial 43 finished with value: 0.7438904294687978 and parameters: {'max_depth': 8, 'learning_rate': 0.0691870676701852, 'n_estimators': 120, 'l2_leaf_reg': 2}. Best is trial 33 with value: 0.7477445516280193.\n","[I 2024-02-13 18:55:46,818] Trial 44 finished with value: 0.7443491667438885 and parameters: {'max_depth': 8, 'learning_rate': 0.07646130767669149, 'n_estimators': 118, 'l2_leaf_reg': 1}. Best is trial 33 with value: 0.7477445516280193.\n","[I 2024-02-13 18:58:37,422] Trial 45 finished with value: 0.72121036158283 and parameters: {'max_depth': 10, 'learning_rate': 0.009160440981552855, 'n_estimators': 102, 'l2_leaf_reg': 1}. Best is trial 33 with value: 0.7477445516280193.\n","[I 2024-02-13 18:59:27,226] Trial 46 finished with value: 0.7480696917812337 and parameters: {'max_depth': 7, 'learning_rate': 0.16858814571572392, 'n_estimators': 114, 'l2_leaf_reg': 1}. Best is trial 46 with value: 0.7480696917812337.\n","[I 2024-02-13 19:00:23,876] Trial 47 finished with value: 0.748774218856504 and parameters: {'max_depth': 7, 'learning_rate': 0.1825404169073286, 'n_estimators': 129, 'l2_leaf_reg': 2}. Best is trial 47 with value: 0.748774218856504.\n","[I 2024-02-13 19:01:18,623] Trial 48 finished with value: 0.7488640427031227 and parameters: {'max_depth': 7, 'learning_rate': 0.16066064531182833, 'n_estimators': 128, 'l2_leaf_reg': 1}. Best is trial 48 with value: 0.7488640427031227.\n","[I 2024-02-13 19:02:05,481] Trial 49 finished with value: 0.7477505641242672 and parameters: {'max_depth': 6, 'learning_rate': 0.14639072968716543, 'n_estimators': 125, 'l2_leaf_reg': 1}. Best is trial 48 with value: 0.7488640427031227.\n"]}]},{"cell_type":"code","source":["study_catboost.best_params"],"metadata":{"id":"2dnkwANicORQ","colab":{"base_uri":"https://localhost:8080/","height":175},"executionInfo":{"status":"error","timestamp":1707851952962,"user_tz":-240,"elapsed":321,"user":{"displayName":"Евгений Малов","userId":"06257165098392198337"}},"outputId":"c3991fbf-c53d-45d3-ecce-6532e6776b01"},"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'study_catboost' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-5636397f39e1>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mstudy_catboost\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'study_catboost' is not defined"]}]},{"cell_type":"markdown","source":["value: 0.7488640427031227 and parameters: {'max_depth': 7, 'learning_rate': 0.16066064531182833, 'n_estimators': 128, 'l2_leaf_reg': 1}. Best is trial 48 with value: 0.7488640427031227."],"metadata":{"id":"ue2g2YJm4nWW"}},{"cell_type":"code","source":["opt_model_catb = CatBoostClassifier(max_depth=7, learning_rate=0.16066064531182833, n_estimators=128, l2_leaf_reg=1)\n","opt_model_catb.fit(x_train, y_train)\n","\n","pred_train = opt_model_catb.predict(x_train)\n","pred_test = opt_model_catb.predict(x_test)\n","\n","print(f'train: {roc_auc_score(y_train, pred_train)}')\n","print(f'test: {roc_auc_score(y_test, pred_test)}')\n","print(f'test conf matrix: \\n {confusion_matrix(y_test, pred_test)}')"],"metadata":{"id":"otrC-6zkbAFM","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1707852162138,"user_tz":-240,"elapsed":28201,"user":{"displayName":"Евгений Малов","userId":"06257165098392198337"}},"outputId":"5c8c751f-dd17-409c-9ea9-f60a07dab2e1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0:\tlearn: 0.6775661\ttotal: 257ms\tremaining: 32.6s\n","1:\tlearn: 0.6649475\ttotal: 441ms\tremaining: 27.8s\n","2:\tlearn: 0.6559733\ttotal: 645ms\tremaining: 26.9s\n","3:\tlearn: 0.6489057\ttotal: 815ms\tremaining: 25.3s\n","4:\tlearn: 0.6434606\ttotal: 1.03s\tremaining: 25.3s\n","5:\tlearn: 0.6387325\ttotal: 1.23s\tremaining: 25s\n","6:\tlearn: 0.6349607\ttotal: 1.41s\tremaining: 24.3s\n","7:\tlearn: 0.6312718\ttotal: 1.6s\tremaining: 24s\n","8:\tlearn: 0.6282846\ttotal: 1.77s\tremaining: 23.4s\n","9:\tlearn: 0.6257069\ttotal: 1.96s\tremaining: 23.2s\n","10:\tlearn: 0.6230501\ttotal: 2.17s\tremaining: 23.1s\n","11:\tlearn: 0.6208669\ttotal: 2.36s\tremaining: 22.8s\n","12:\tlearn: 0.6192317\ttotal: 2.56s\tremaining: 22.6s\n","13:\tlearn: 0.6175728\ttotal: 2.72s\tremaining: 22.1s\n","14:\tlearn: 0.6161139\ttotal: 2.87s\tremaining: 21.6s\n","15:\tlearn: 0.6148583\ttotal: 3.03s\tremaining: 21.2s\n","16:\tlearn: 0.6136796\ttotal: 3.23s\tremaining: 21.1s\n","17:\tlearn: 0.6123554\ttotal: 3.4s\tremaining: 20.8s\n","18:\tlearn: 0.6114286\ttotal: 3.53s\tremaining: 20.3s\n","19:\tlearn: 0.6102979\ttotal: 3.71s\tremaining: 20s\n","20:\tlearn: 0.6092805\ttotal: 3.88s\tremaining: 19.8s\n","21:\tlearn: 0.6085106\ttotal: 4.03s\tremaining: 19.4s\n","22:\tlearn: 0.6076009\ttotal: 4.24s\tremaining: 19.3s\n","23:\tlearn: 0.6068082\ttotal: 4.37s\tremaining: 19s\n","24:\tlearn: 0.6060445\ttotal: 4.52s\tremaining: 18.6s\n","25:\tlearn: 0.6053172\ttotal: 4.67s\tremaining: 18.3s\n","26:\tlearn: 0.6047079\ttotal: 4.82s\tremaining: 18s\n","27:\tlearn: 0.6036639\ttotal: 5s\tremaining: 17.9s\n","28:\tlearn: 0.6027885\ttotal: 5.21s\tremaining: 17.8s\n","29:\tlearn: 0.6022301\ttotal: 5.36s\tremaining: 17.5s\n","30:\tlearn: 0.6017265\ttotal: 5.51s\tremaining: 17.2s\n","31:\tlearn: 0.6009759\ttotal: 5.68s\tremaining: 17s\n","32:\tlearn: 0.6003476\ttotal: 5.84s\tremaining: 16.8s\n","33:\tlearn: 0.5997759\ttotal: 5.99s\tremaining: 16.6s\n","34:\tlearn: 0.5993521\ttotal: 6.12s\tremaining: 16.3s\n","35:\tlearn: 0.5987961\ttotal: 6.31s\tremaining: 16.1s\n","36:\tlearn: 0.5979861\ttotal: 6.49s\tremaining: 16s\n","37:\tlearn: 0.5974562\ttotal: 6.66s\tremaining: 15.8s\n","38:\tlearn: 0.5970328\ttotal: 6.89s\tremaining: 15.7s\n","39:\tlearn: 0.5966022\ttotal: 7.17s\tremaining: 15.8s\n","40:\tlearn: 0.5962080\ttotal: 7.41s\tremaining: 15.7s\n","41:\tlearn: 0.5959109\ttotal: 7.69s\tremaining: 15.7s\n","42:\tlearn: 0.5954158\ttotal: 8.04s\tremaining: 15.9s\n","43:\tlearn: 0.5950291\ttotal: 8.34s\tremaining: 15.9s\n","44:\tlearn: 0.5945610\ttotal: 8.61s\tremaining: 15.9s\n","45:\tlearn: 0.5940763\ttotal: 8.95s\tremaining: 16s\n","46:\tlearn: 0.5935697\ttotal: 9.26s\tremaining: 16s\n","47:\tlearn: 0.5930198\ttotal: 9.64s\tremaining: 16.1s\n","48:\tlearn: 0.5926603\ttotal: 9.99s\tremaining: 16.1s\n","49:\tlearn: 0.5923661\ttotal: 10.3s\tremaining: 16s\n","50:\tlearn: 0.5919069\ttotal: 10.6s\tremaining: 16.1s\n","51:\tlearn: 0.5916088\ttotal: 10.8s\tremaining: 15.8s\n","52:\tlearn: 0.5914005\ttotal: 11s\tremaining: 15.5s\n","53:\tlearn: 0.5910898\ttotal: 11.1s\tremaining: 15.2s\n","54:\tlearn: 0.5907713\ttotal: 11.2s\tremaining: 14.9s\n","55:\tlearn: 0.5904525\ttotal: 11.4s\tremaining: 14.7s\n","56:\tlearn: 0.5901144\ttotal: 11.6s\tremaining: 14.4s\n","57:\tlearn: 0.5898739\ttotal: 11.7s\tremaining: 14.1s\n","58:\tlearn: 0.5896293\ttotal: 11.9s\tremaining: 13.9s\n","59:\tlearn: 0.5893100\ttotal: 12s\tremaining: 13.6s\n","60:\tlearn: 0.5890232\ttotal: 12.2s\tremaining: 13.4s\n","61:\tlearn: 0.5888251\ttotal: 12.3s\tremaining: 13.1s\n","62:\tlearn: 0.5884622\ttotal: 12.5s\tremaining: 12.9s\n","63:\tlearn: 0.5881992\ttotal: 12.7s\tremaining: 12.7s\n","64:\tlearn: 0.5878665\ttotal: 12.8s\tremaining: 12.5s\n","65:\tlearn: 0.5875059\ttotal: 13s\tremaining: 12.2s\n","66:\tlearn: 0.5872035\ttotal: 13.2s\tremaining: 12s\n","67:\tlearn: 0.5869363\ttotal: 13.3s\tremaining: 11.8s\n","68:\tlearn: 0.5865605\ttotal: 13.5s\tremaining: 11.6s\n","69:\tlearn: 0.5863237\ttotal: 13.7s\tremaining: 11.4s\n","70:\tlearn: 0.5859368\ttotal: 13.9s\tremaining: 11.1s\n","71:\tlearn: 0.5856789\ttotal: 14s\tremaining: 10.9s\n","72:\tlearn: 0.5854546\ttotal: 14.2s\tremaining: 10.7s\n","73:\tlearn: 0.5851963\ttotal: 14.3s\tremaining: 10.5s\n","74:\tlearn: 0.5848254\ttotal: 14.6s\tremaining: 10.3s\n","75:\tlearn: 0.5845100\ttotal: 14.7s\tremaining: 10.1s\n","76:\tlearn: 0.5842806\ttotal: 14.9s\tremaining: 9.85s\n","77:\tlearn: 0.5839338\ttotal: 15.1s\tremaining: 9.65s\n","78:\tlearn: 0.5836342\ttotal: 15.2s\tremaining: 9.42s\n","79:\tlearn: 0.5832781\ttotal: 15.4s\tremaining: 9.23s\n","80:\tlearn: 0.5829467\ttotal: 15.5s\tremaining: 9s\n","81:\tlearn: 0.5826622\ttotal: 15.7s\tremaining: 8.81s\n","82:\tlearn: 0.5824661\ttotal: 15.8s\tremaining: 8.58s\n","83:\tlearn: 0.5821925\ttotal: 16s\tremaining: 8.37s\n","84:\tlearn: 0.5818931\ttotal: 16.1s\tremaining: 8.17s\n","85:\tlearn: 0.5814761\ttotal: 16.3s\tremaining: 7.98s\n","86:\tlearn: 0.5811887\ttotal: 16.5s\tremaining: 7.77s\n","87:\tlearn: 0.5809362\ttotal: 16.6s\tremaining: 7.56s\n","88:\tlearn: 0.5807143\ttotal: 16.8s\tremaining: 7.36s\n","89:\tlearn: 0.5804355\ttotal: 17s\tremaining: 7.17s\n","90:\tlearn: 0.5799780\ttotal: 17.1s\tremaining: 6.96s\n","91:\tlearn: 0.5796451\ttotal: 17.3s\tremaining: 6.79s\n","92:\tlearn: 0.5793884\ttotal: 17.5s\tremaining: 6.58s\n","93:\tlearn: 0.5790314\ttotal: 17.7s\tremaining: 6.41s\n","94:\tlearn: 0.5787818\ttotal: 17.9s\tremaining: 6.23s\n","95:\tlearn: 0.5785371\ttotal: 18.1s\tremaining: 6.02s\n","96:\tlearn: 0.5782559\ttotal: 18.3s\tremaining: 5.83s\n","97:\tlearn: 0.5780325\ttotal: 18.4s\tremaining: 5.63s\n","98:\tlearn: 0.5777491\ttotal: 18.6s\tremaining: 5.45s\n","99:\tlearn: 0.5774117\ttotal: 18.8s\tremaining: 5.27s\n","100:\tlearn: 0.5771919\ttotal: 19s\tremaining: 5.07s\n","101:\tlearn: 0.5768973\ttotal: 19.1s\tremaining: 4.87s\n","102:\tlearn: 0.5765511\ttotal: 19.3s\tremaining: 4.68s\n","103:\tlearn: 0.5763033\ttotal: 19.5s\tremaining: 4.49s\n","104:\tlearn: 0.5760011\ttotal: 19.6s\tremaining: 4.3s\n","105:\tlearn: 0.5757514\ttotal: 19.8s\tremaining: 4.12s\n","106:\tlearn: 0.5755317\ttotal: 20s\tremaining: 3.93s\n","107:\tlearn: 0.5753367\ttotal: 20.2s\tremaining: 3.74s\n","108:\tlearn: 0.5750030\ttotal: 20.4s\tremaining: 3.56s\n","109:\tlearn: 0.5747897\ttotal: 20.6s\tremaining: 3.36s\n","110:\tlearn: 0.5745909\ttotal: 20.8s\tremaining: 3.18s\n","111:\tlearn: 0.5743051\ttotal: 21.1s\tremaining: 3.02s\n","112:\tlearn: 0.5741447\ttotal: 21.4s\tremaining: 2.84s\n","113:\tlearn: 0.5739215\ttotal: 21.7s\tremaining: 2.67s\n","114:\tlearn: 0.5736875\ttotal: 22s\tremaining: 2.49s\n","115:\tlearn: 0.5735355\ttotal: 22.3s\tremaining: 2.31s\n","116:\tlearn: 0.5732203\ttotal: 22.7s\tremaining: 2.13s\n","117:\tlearn: 0.5729817\ttotal: 23s\tremaining: 1.95s\n","118:\tlearn: 0.5728832\ttotal: 23.3s\tremaining: 1.76s\n","119:\tlearn: 0.5726514\ttotal: 23.6s\tremaining: 1.57s\n","120:\tlearn: 0.5724262\ttotal: 23.9s\tremaining: 1.38s\n","121:\tlearn: 0.5721539\ttotal: 24.1s\tremaining: 1.19s\n","122:\tlearn: 0.5719653\ttotal: 24.4s\tremaining: 991ms\n","123:\tlearn: 0.5717508\ttotal: 24.5s\tremaining: 791ms\n","124:\tlearn: 0.5715461\ttotal: 24.7s\tremaining: 592ms\n","125:\tlearn: 0.5714139\ttotal: 24.8s\tremaining: 393ms\n","126:\tlearn: 0.5712819\ttotal: 24.9s\tremaining: 196ms\n","127:\tlearn: 0.5710627\ttotal: 25.1s\tremaining: 0us\n","train: 0.7035890504982999\n","test: 0.6841120867124026\n","test conf matrix: \n"," [[21458 10495]\n"," [ 9680 22233]]\n"]}]},{"cell_type":"code","source":["estimators = [\n","    ('lgbm', opt_model_lgbm),\n","    ('xgb', opt_model_xgb),\n","    ('cb', opt_model_catb)\n","    ]\n","\n","reg = StackingClassifier(\n","    estimators=estimators,\n","    final_estimator=GradientBoostingClassifier(learning_rate = 0.02, n_estimators = 100, random_state=42))\n","\n","reg.fit(x_train, y_train)\n","pred_train = reg.predict(x_train)\n","pred_test = reg.predict(x_test)\n","\n","print(f'train: {roc_auc_score(y_train, pred_train)}')\n","print(f'test: {roc_auc_score(y_test, pred_test)}')\n","print(f'test conf matrix: \\n {confusion_matrix(y_test, pred_test)}')"],"metadata":{"id":"cNpQg8JactBB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1707853680376,"user_tz":-240,"elapsed":1029337,"user":{"displayName":"Евгений Малов","userId":"06257165098392198337"}},"outputId":"11c9d8d3-5f2a-4d20-abcb-c02425c47e5a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 74529, number of negative: 74489\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.545347 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 4670\n","[LightGBM] [Info] Number of data points in the train set: 149018, number of used features: 306\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500134 -> initscore=0.000537\n","[LightGBM] [Info] Start training from score 0.000537\n","0:\tlearn: 0.6775661\ttotal: 203ms\tremaining: 25.8s\n","1:\tlearn: 0.6649475\ttotal: 391ms\tremaining: 24.6s\n","2:\tlearn: 0.6559733\ttotal: 606ms\tremaining: 25.3s\n","3:\tlearn: 0.6489057\ttotal: 782ms\tremaining: 24.3s\n","4:\tlearn: 0.6434606\ttotal: 985ms\tremaining: 24.2s\n","5:\tlearn: 0.6387325\ttotal: 1.18s\tremaining: 24s\n","6:\tlearn: 0.6349607\ttotal: 1.36s\tremaining: 23.6s\n","7:\tlearn: 0.6312718\ttotal: 1.58s\tremaining: 23.7s\n","8:\tlearn: 0.6282846\ttotal: 1.75s\tremaining: 23.1s\n","9:\tlearn: 0.6257069\ttotal: 1.94s\tremaining: 22.9s\n","10:\tlearn: 0.6230501\ttotal: 2.13s\tremaining: 22.7s\n","11:\tlearn: 0.6208669\ttotal: 2.32s\tremaining: 22.4s\n","12:\tlearn: 0.6192317\ttotal: 2.53s\tremaining: 22.4s\n","13:\tlearn: 0.6175728\ttotal: 2.71s\tremaining: 22s\n","14:\tlearn: 0.6161139\ttotal: 2.87s\tremaining: 21.6s\n","15:\tlearn: 0.6148583\ttotal: 3.03s\tremaining: 21.2s\n","16:\tlearn: 0.6136796\ttotal: 3.22s\tremaining: 21s\n","17:\tlearn: 0.6123554\ttotal: 3.39s\tremaining: 20.7s\n","18:\tlearn: 0.6114286\ttotal: 3.53s\tremaining: 20.2s\n","19:\tlearn: 0.6102979\ttotal: 3.72s\tremaining: 20.1s\n","20:\tlearn: 0.6092805\ttotal: 3.9s\tremaining: 19.9s\n","21:\tlearn: 0.6085106\ttotal: 4.04s\tremaining: 19.5s\n","22:\tlearn: 0.6076009\ttotal: 4.25s\tremaining: 19.4s\n","23:\tlearn: 0.6068082\ttotal: 4.39s\tremaining: 19s\n","24:\tlearn: 0.6060445\ttotal: 4.54s\tremaining: 18.7s\n","25:\tlearn: 0.6053172\ttotal: 4.71s\tremaining: 18.5s\n","26:\tlearn: 0.6047079\ttotal: 4.95s\tremaining: 18.5s\n","27:\tlearn: 0.6036639\ttotal: 5.25s\tremaining: 18.8s\n","28:\tlearn: 0.6027885\ttotal: 5.63s\tremaining: 19.2s\n","29:\tlearn: 0.6022301\ttotal: 5.93s\tremaining: 19.4s\n","30:\tlearn: 0.6017265\ttotal: 6.16s\tremaining: 19.3s\n","31:\tlearn: 0.6009759\ttotal: 6.48s\tremaining: 19.5s\n","32:\tlearn: 0.6003476\ttotal: 6.8s\tremaining: 19.6s\n","33:\tlearn: 0.5997759\ttotal: 7.09s\tremaining: 19.6s\n","34:\tlearn: 0.5993521\ttotal: 7.35s\tremaining: 19.5s\n","35:\tlearn: 0.5987961\ttotal: 7.67s\tremaining: 19.6s\n","36:\tlearn: 0.5979861\ttotal: 8.03s\tremaining: 19.8s\n","37:\tlearn: 0.5974562\ttotal: 8.33s\tremaining: 19.7s\n","38:\tlearn: 0.5970328\ttotal: 8.62s\tremaining: 19.7s\n","39:\tlearn: 0.5966022\ttotal: 8.77s\tremaining: 19.3s\n","40:\tlearn: 0.5962080\ttotal: 8.93s\tremaining: 19s\n","41:\tlearn: 0.5959109\ttotal: 9.07s\tremaining: 18.6s\n","42:\tlearn: 0.5954158\ttotal: 9.26s\tremaining: 18.3s\n","43:\tlearn: 0.5950291\ttotal: 9.43s\tremaining: 18s\n","44:\tlearn: 0.5945610\ttotal: 9.57s\tremaining: 17.7s\n","45:\tlearn: 0.5940763\ttotal: 9.75s\tremaining: 17.4s\n","46:\tlearn: 0.5935697\ttotal: 9.94s\tremaining: 17.1s\n","47:\tlearn: 0.5930198\ttotal: 10.1s\tremaining: 16.9s\n","48:\tlearn: 0.5926603\ttotal: 10.3s\tremaining: 16.6s\n","49:\tlearn: 0.5923661\ttotal: 10.5s\tremaining: 16.4s\n","50:\tlearn: 0.5919069\ttotal: 10.7s\tremaining: 16.2s\n","51:\tlearn: 0.5916088\ttotal: 10.9s\tremaining: 16s\n","52:\tlearn: 0.5914005\ttotal: 11.1s\tremaining: 15.6s\n","53:\tlearn: 0.5910898\ttotal: 11.2s\tremaining: 15.3s\n","54:\tlearn: 0.5907713\ttotal: 11.3s\tremaining: 15s\n","55:\tlearn: 0.5904525\ttotal: 11.5s\tremaining: 14.8s\n","56:\tlearn: 0.5901144\ttotal: 11.7s\tremaining: 14.5s\n","57:\tlearn: 0.5898739\ttotal: 11.8s\tremaining: 14.2s\n","58:\tlearn: 0.5896293\ttotal: 12s\tremaining: 14s\n","59:\tlearn: 0.5893100\ttotal: 12.1s\tremaining: 13.7s\n","60:\tlearn: 0.5890232\ttotal: 12.3s\tremaining: 13.5s\n","61:\tlearn: 0.5888251\ttotal: 12.4s\tremaining: 13.2s\n","62:\tlearn: 0.5884622\ttotal: 12.6s\tremaining: 13s\n","63:\tlearn: 0.5881992\ttotal: 12.8s\tremaining: 12.8s\n","64:\tlearn: 0.5878665\ttotal: 13s\tremaining: 12.6s\n","65:\tlearn: 0.5875059\ttotal: 13.2s\tremaining: 12.4s\n","66:\tlearn: 0.5872035\ttotal: 13.3s\tremaining: 12.1s\n","67:\tlearn: 0.5869363\ttotal: 13.5s\tremaining: 11.9s\n","68:\tlearn: 0.5865605\ttotal: 13.7s\tremaining: 11.7s\n","69:\tlearn: 0.5863237\ttotal: 13.8s\tremaining: 11.5s\n","70:\tlearn: 0.5859368\ttotal: 14s\tremaining: 11.3s\n","71:\tlearn: 0.5856789\ttotal: 14.2s\tremaining: 11s\n","72:\tlearn: 0.5854546\ttotal: 14.4s\tremaining: 10.8s\n","73:\tlearn: 0.5851963\ttotal: 14.5s\tremaining: 10.6s\n","74:\tlearn: 0.5848254\ttotal: 14.7s\tremaining: 10.4s\n","75:\tlearn: 0.5845100\ttotal: 14.9s\tremaining: 10.2s\n","76:\tlearn: 0.5842806\ttotal: 15s\tremaining: 9.96s\n","77:\tlearn: 0.5839338\ttotal: 15.2s\tremaining: 9.76s\n","78:\tlearn: 0.5836342\ttotal: 15.4s\tremaining: 9.53s\n","79:\tlearn: 0.5832781\ttotal: 15.6s\tremaining: 9.33s\n","80:\tlearn: 0.5829467\ttotal: 15.7s\tremaining: 9.1s\n","81:\tlearn: 0.5826622\ttotal: 15.9s\tremaining: 8.9s\n","82:\tlearn: 0.5824661\ttotal: 16s\tremaining: 8.68s\n","83:\tlearn: 0.5821925\ttotal: 16.2s\tremaining: 8.47s\n","84:\tlearn: 0.5818931\ttotal: 16.3s\tremaining: 8.27s\n","85:\tlearn: 0.5814761\ttotal: 16.5s\tremaining: 8.08s\n","86:\tlearn: 0.5811887\ttotal: 16.7s\tremaining: 7.87s\n","87:\tlearn: 0.5809362\ttotal: 16.8s\tremaining: 7.65s\n","88:\tlearn: 0.5807143\ttotal: 17s\tremaining: 7.45s\n","89:\tlearn: 0.5804355\ttotal: 17.2s\tremaining: 7.26s\n","90:\tlearn: 0.5799780\ttotal: 17.4s\tremaining: 7.06s\n","91:\tlearn: 0.5796451\ttotal: 17.6s\tremaining: 6.88s\n","92:\tlearn: 0.5793884\ttotal: 17.7s\tremaining: 6.67s\n","93:\tlearn: 0.5790314\ttotal: 17.9s\tremaining: 6.49s\n","94:\tlearn: 0.5787818\ttotal: 18.2s\tremaining: 6.31s\n","95:\tlearn: 0.5785371\ttotal: 18.3s\tremaining: 6.1s\n","96:\tlearn: 0.5782559\ttotal: 18.5s\tremaining: 5.91s\n","97:\tlearn: 0.5780325\ttotal: 18.7s\tremaining: 5.73s\n","98:\tlearn: 0.5777491\ttotal: 19.1s\tremaining: 5.59s\n","99:\tlearn: 0.5774117\ttotal: 19.5s\tremaining: 5.45s\n","100:\tlearn: 0.5771919\ttotal: 19.7s\tremaining: 5.27s\n","101:\tlearn: 0.5768973\ttotal: 20s\tremaining: 5.1s\n","102:\tlearn: 0.5765511\ttotal: 20.3s\tremaining: 4.94s\n","103:\tlearn: 0.5763033\ttotal: 20.7s\tremaining: 4.77s\n","104:\tlearn: 0.5760011\ttotal: 21s\tremaining: 4.61s\n","105:\tlearn: 0.5757514\ttotal: 21.4s\tremaining: 4.43s\n","106:\tlearn: 0.5755317\ttotal: 21.7s\tremaining: 4.27s\n","107:\tlearn: 0.5753367\ttotal: 22s\tremaining: 4.08s\n","108:\tlearn: 0.5750030\ttotal: 22.4s\tremaining: 3.91s\n","109:\tlearn: 0.5747897\ttotal: 22.6s\tremaining: 3.69s\n","110:\tlearn: 0.5745909\ttotal: 22.7s\tremaining: 3.48s\n","111:\tlearn: 0.5743051\ttotal: 22.9s\tremaining: 3.27s\n","112:\tlearn: 0.5741447\ttotal: 23s\tremaining: 3.06s\n","113:\tlearn: 0.5739215\ttotal: 23.2s\tremaining: 2.85s\n","114:\tlearn: 0.5736875\ttotal: 23.4s\tremaining: 2.65s\n","115:\tlearn: 0.5735355\ttotal: 23.6s\tremaining: 2.44s\n","116:\tlearn: 0.5732203\ttotal: 23.8s\tremaining: 2.23s\n","117:\tlearn: 0.5729817\ttotal: 23.9s\tremaining: 2.03s\n","118:\tlearn: 0.5728832\ttotal: 24s\tremaining: 1.82s\n","119:\tlearn: 0.5726514\ttotal: 24.2s\tremaining: 1.61s\n","120:\tlearn: 0.5724262\ttotal: 24.4s\tremaining: 1.41s\n","121:\tlearn: 0.5721539\ttotal: 24.5s\tremaining: 1.21s\n","122:\tlearn: 0.5719653\ttotal: 24.7s\tremaining: 1s\n","123:\tlearn: 0.5717508\ttotal: 24.8s\tremaining: 800ms\n","124:\tlearn: 0.5715461\ttotal: 25s\tremaining: 599ms\n","125:\tlearn: 0.5714139\ttotal: 25.1s\tremaining: 398ms\n","126:\tlearn: 0.5712819\ttotal: 25.2s\tremaining: 199ms\n","127:\tlearn: 0.5710627\ttotal: 25.4s\tremaining: 0us\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 59623, number of negative: 59591\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.438629 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 4594\n","[LightGBM] [Info] Number of data points in the train set: 119214, number of used features: 306\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500134 -> initscore=0.000537\n","[LightGBM] [Info] Start training from score 0.000537\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 59623, number of negative: 59591\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.438000 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 4583\n","[LightGBM] [Info] Number of data points in the train set: 119214, number of used features: 305\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500134 -> initscore=0.000537\n","[LightGBM] [Info] Start training from score 0.000537\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 59623, number of negative: 59591\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.441751 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 4560\n","[LightGBM] [Info] Number of data points in the train set: 119214, number of used features: 304\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500134 -> initscore=0.000537\n","[LightGBM] [Info] Start training from score 0.000537\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 59624, number of negative: 59591\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.542581 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 4582\n","[LightGBM] [Info] Number of data points in the train set: 119215, number of used features: 304\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500138 -> initscore=0.000554\n","[LightGBM] [Info] Start training from score 0.000554\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 59623, number of negative: 59592\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.577423 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 4608\n","[LightGBM] [Info] Number of data points in the train set: 119215, number of used features: 305\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500130 -> initscore=0.000520\n","[LightGBM] [Info] Start training from score 0.000520\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","0:\tlearn: 0.6776267\ttotal: 159ms\tremaining: 20.2s\n","1:\tlearn: 0.6660706\ttotal: 302ms\tremaining: 19s\n","2:\tlearn: 0.6572758\ttotal: 456ms\tremaining: 19s\n","3:\tlearn: 0.6499088\ttotal: 608ms\tremaining: 18.8s\n","4:\tlearn: 0.6438027\ttotal: 766ms\tremaining: 18.8s\n","5:\tlearn: 0.6386625\ttotal: 943ms\tremaining: 19.2s\n","6:\tlearn: 0.6345104\ttotal: 1.1s\tremaining: 19s\n","7:\tlearn: 0.6308941\ttotal: 1.26s\tremaining: 18.9s\n","8:\tlearn: 0.6278262\ttotal: 1.42s\tremaining: 18.8s\n","9:\tlearn: 0.6250921\ttotal: 1.57s\tremaining: 18.5s\n","10:\tlearn: 0.6230100\ttotal: 1.71s\tremaining: 18.2s\n","11:\tlearn: 0.6207992\ttotal: 1.85s\tremaining: 17.9s\n","12:\tlearn: 0.6192070\ttotal: 2s\tremaining: 17.7s\n","13:\tlearn: 0.6174687\ttotal: 2.14s\tremaining: 17.4s\n","14:\tlearn: 0.6158539\ttotal: 2.26s\tremaining: 17.1s\n","15:\tlearn: 0.6142782\ttotal: 2.43s\tremaining: 17s\n","16:\tlearn: 0.6130470\ttotal: 2.57s\tremaining: 16.8s\n","17:\tlearn: 0.6120066\ttotal: 2.73s\tremaining: 16.7s\n","18:\tlearn: 0.6109955\ttotal: 2.94s\tremaining: 16.9s\n","19:\tlearn: 0.6100465\ttotal: 3.19s\tremaining: 17.2s\n","20:\tlearn: 0.6085185\ttotal: 3.48s\tremaining: 17.8s\n","21:\tlearn: 0.6075683\ttotal: 3.7s\tremaining: 17.8s\n","22:\tlearn: 0.6066265\ttotal: 4.01s\tremaining: 18.3s\n","23:\tlearn: 0.6058691\ttotal: 4.26s\tremaining: 18.5s\n","24:\tlearn: 0.6051206\ttotal: 4.55s\tremaining: 18.8s\n","25:\tlearn: 0.6044273\ttotal: 4.81s\tremaining: 18.9s\n","26:\tlearn: 0.6035651\ttotal: 5.1s\tremaining: 19.1s\n","27:\tlearn: 0.6029255\ttotal: 5.3s\tremaining: 18.9s\n","28:\tlearn: 0.6023110\ttotal: 5.52s\tremaining: 18.8s\n","29:\tlearn: 0.6017328\ttotal: 5.82s\tremaining: 19s\n","30:\tlearn: 0.6011516\ttotal: 6.04s\tremaining: 18.9s\n","31:\tlearn: 0.6005919\ttotal: 6.27s\tremaining: 18.8s\n","32:\tlearn: 0.5998895\ttotal: 6.47s\tremaining: 18.6s\n","33:\tlearn: 0.5991706\ttotal: 6.63s\tremaining: 18.3s\n","34:\tlearn: 0.5986107\ttotal: 6.78s\tremaining: 18s\n","35:\tlearn: 0.5979056\ttotal: 6.92s\tremaining: 17.7s\n","36:\tlearn: 0.5974149\ttotal: 7.03s\tremaining: 17.3s\n","37:\tlearn: 0.5968896\ttotal: 7.16s\tremaining: 16.9s\n","38:\tlearn: 0.5961044\ttotal: 7.32s\tremaining: 16.7s\n","39:\tlearn: 0.5956524\ttotal: 7.45s\tremaining: 16.4s\n","40:\tlearn: 0.5952134\ttotal: 7.58s\tremaining: 16.1s\n","41:\tlearn: 0.5945586\ttotal: 7.72s\tremaining: 15.8s\n","42:\tlearn: 0.5940319\ttotal: 7.88s\tremaining: 15.6s\n","43:\tlearn: 0.5933395\ttotal: 8.03s\tremaining: 15.3s\n","44:\tlearn: 0.5929671\ttotal: 8.16s\tremaining: 15s\n","45:\tlearn: 0.5925843\ttotal: 8.27s\tremaining: 14.7s\n","46:\tlearn: 0.5922290\ttotal: 8.4s\tremaining: 14.5s\n","47:\tlearn: 0.5919016\ttotal: 8.52s\tremaining: 14.2s\n","48:\tlearn: 0.5914702\ttotal: 8.64s\tremaining: 13.9s\n","49:\tlearn: 0.5910458\ttotal: 8.82s\tremaining: 13.8s\n","50:\tlearn: 0.5906904\ttotal: 8.94s\tremaining: 13.5s\n","51:\tlearn: 0.5902428\ttotal: 9.09s\tremaining: 13.3s\n","52:\tlearn: 0.5899383\ttotal: 9.2s\tremaining: 13s\n","53:\tlearn: 0.5895953\ttotal: 9.34s\tremaining: 12.8s\n","54:\tlearn: 0.5892303\ttotal: 9.48s\tremaining: 12.6s\n","55:\tlearn: 0.5888559\ttotal: 9.61s\tremaining: 12.4s\n","56:\tlearn: 0.5884967\ttotal: 9.75s\tremaining: 12.2s\n","57:\tlearn: 0.5881993\ttotal: 9.88s\tremaining: 11.9s\n","58:\tlearn: 0.5879099\ttotal: 10s\tremaining: 11.7s\n","59:\tlearn: 0.5874688\ttotal: 10.2s\tremaining: 11.5s\n","60:\tlearn: 0.5872321\ttotal: 10.3s\tremaining: 11.3s\n","61:\tlearn: 0.5869587\ttotal: 10.4s\tremaining: 11.1s\n","62:\tlearn: 0.5866318\ttotal: 10.5s\tremaining: 10.9s\n","63:\tlearn: 0.5863582\ttotal: 10.7s\tremaining: 10.7s\n","64:\tlearn: 0.5858933\ttotal: 10.8s\tremaining: 10.5s\n","65:\tlearn: 0.5853787\ttotal: 11s\tremaining: 10.3s\n","66:\tlearn: 0.5849709\ttotal: 11.1s\tremaining: 10.1s\n","67:\tlearn: 0.5847115\ttotal: 11.2s\tremaining: 9.91s\n","68:\tlearn: 0.5844640\ttotal: 11.4s\tremaining: 9.73s\n","69:\tlearn: 0.5840891\ttotal: 11.6s\tremaining: 9.57s\n","70:\tlearn: 0.5838196\ttotal: 11.7s\tremaining: 9.37s\n","71:\tlearn: 0.5834470\ttotal: 11.8s\tremaining: 9.2s\n","72:\tlearn: 0.5830527\ttotal: 12s\tremaining: 9.04s\n","73:\tlearn: 0.5825444\ttotal: 12.1s\tremaining: 8.86s\n","74:\tlearn: 0.5822679\ttotal: 12.3s\tremaining: 8.69s\n","75:\tlearn: 0.5819300\ttotal: 12.4s\tremaining: 8.51s\n","76:\tlearn: 0.5815819\ttotal: 12.6s\tremaining: 8.35s\n","77:\tlearn: 0.5812332\ttotal: 12.7s\tremaining: 8.17s\n","78:\tlearn: 0.5808714\ttotal: 12.9s\tremaining: 7.98s\n","79:\tlearn: 0.5805164\ttotal: 13s\tremaining: 7.8s\n","80:\tlearn: 0.5802661\ttotal: 13.1s\tremaining: 7.62s\n","81:\tlearn: 0.5800097\ttotal: 13.3s\tremaining: 7.43s\n","82:\tlearn: 0.5796893\ttotal: 13.4s\tremaining: 7.25s\n","83:\tlearn: 0.5793173\ttotal: 13.6s\tremaining: 7.12s\n","84:\tlearn: 0.5789942\ttotal: 13.7s\tremaining: 6.95s\n","85:\tlearn: 0.5786885\ttotal: 13.9s\tremaining: 6.78s\n","86:\tlearn: 0.5783473\ttotal: 14s\tremaining: 6.6s\n","87:\tlearn: 0.5780666\ttotal: 14.1s\tremaining: 6.42s\n","88:\tlearn: 0.5777262\ttotal: 14.3s\tremaining: 6.25s\n","89:\tlearn: 0.5773683\ttotal: 14.4s\tremaining: 6.08s\n","90:\tlearn: 0.5770472\ttotal: 14.5s\tremaining: 5.9s\n","91:\tlearn: 0.5766740\ttotal: 14.7s\tremaining: 5.75s\n","92:\tlearn: 0.5762673\ttotal: 14.9s\tremaining: 5.59s\n","93:\tlearn: 0.5760287\ttotal: 15s\tremaining: 5.42s\n","94:\tlearn: 0.5757422\ttotal: 15.1s\tremaining: 5.26s\n","95:\tlearn: 0.5754287\ttotal: 15.3s\tremaining: 5.09s\n","96:\tlearn: 0.5750951\ttotal: 15.4s\tremaining: 4.92s\n","97:\tlearn: 0.5748987\ttotal: 15.5s\tremaining: 4.75s\n","98:\tlearn: 0.5747417\ttotal: 15.6s\tremaining: 4.58s\n","99:\tlearn: 0.5743660\ttotal: 15.8s\tremaining: 4.42s\n","100:\tlearn: 0.5740109\ttotal: 16s\tremaining: 4.27s\n","101:\tlearn: 0.5737755\ttotal: 16.1s\tremaining: 4.1s\n","102:\tlearn: 0.5735186\ttotal: 16.2s\tremaining: 3.93s\n","103:\tlearn: 0.5732770\ttotal: 16.3s\tremaining: 3.77s\n","104:\tlearn: 0.5728238\ttotal: 16.5s\tremaining: 3.62s\n","105:\tlearn: 0.5724197\ttotal: 16.8s\tremaining: 3.49s\n","106:\tlearn: 0.5721322\ttotal: 17s\tremaining: 3.34s\n","107:\tlearn: 0.5718062\ttotal: 17.3s\tremaining: 3.2s\n","108:\tlearn: 0.5714729\ttotal: 17.5s\tremaining: 3.06s\n","109:\tlearn: 0.5711322\ttotal: 17.8s\tremaining: 2.91s\n","110:\tlearn: 0.5709730\ttotal: 18s\tremaining: 2.76s\n","111:\tlearn: 0.5706767\ttotal: 18.2s\tremaining: 2.6s\n","112:\tlearn: 0.5703146\ttotal: 18.5s\tremaining: 2.46s\n","113:\tlearn: 0.5700605\ttotal: 18.7s\tremaining: 2.3s\n","114:\tlearn: 0.5698040\ttotal: 19s\tremaining: 2.15s\n","115:\tlearn: 0.5696451\ttotal: 19.2s\tremaining: 1.99s\n","116:\tlearn: 0.5694543\ttotal: 19.4s\tremaining: 1.82s\n","117:\tlearn: 0.5691573\ttotal: 19.6s\tremaining: 1.66s\n","118:\tlearn: 0.5688499\ttotal: 19.9s\tremaining: 1.51s\n","119:\tlearn: 0.5686608\ttotal: 20.1s\tremaining: 1.34s\n","120:\tlearn: 0.5683350\ttotal: 20.3s\tremaining: 1.17s\n","121:\tlearn: 0.5680786\ttotal: 20.4s\tremaining: 1s\n","122:\tlearn: 0.5677763\ttotal: 20.6s\tremaining: 838ms\n","123:\tlearn: 0.5675448\ttotal: 20.8s\tremaining: 670ms\n","124:\tlearn: 0.5672988\ttotal: 21s\tremaining: 503ms\n","125:\tlearn: 0.5670291\ttotal: 21.1s\tremaining: 335ms\n","126:\tlearn: 0.5667115\ttotal: 21.3s\tremaining: 167ms\n","127:\tlearn: 0.5664571\ttotal: 21.4s\tremaining: 0us\n","0:\tlearn: 0.6773214\ttotal: 148ms\tremaining: 18.8s\n","1:\tlearn: 0.6654286\ttotal: 323ms\tremaining: 20.4s\n","2:\tlearn: 0.6572179\ttotal: 481ms\tremaining: 20.1s\n","3:\tlearn: 0.6499319\ttotal: 632ms\tremaining: 19.6s\n","4:\tlearn: 0.6438468\ttotal: 778ms\tremaining: 19.1s\n","5:\tlearn: 0.6392720\ttotal: 926ms\tremaining: 18.8s\n","6:\tlearn: 0.6353792\ttotal: 1.09s\tremaining: 18.9s\n","7:\tlearn: 0.6323454\ttotal: 1.25s\tremaining: 18.7s\n","8:\tlearn: 0.6293511\ttotal: 1.41s\tremaining: 18.6s\n","9:\tlearn: 0.6268937\ttotal: 1.54s\tremaining: 18.2s\n","10:\tlearn: 0.6243653\ttotal: 1.69s\tremaining: 18s\n","11:\tlearn: 0.6222067\ttotal: 1.81s\tremaining: 17.5s\n","12:\tlearn: 0.6202885\ttotal: 1.96s\tremaining: 17.3s\n","13:\tlearn: 0.6184808\ttotal: 2.1s\tremaining: 17.1s\n","14:\tlearn: 0.6169727\ttotal: 2.25s\tremaining: 17s\n","15:\tlearn: 0.6156470\ttotal: 2.39s\tremaining: 16.7s\n","16:\tlearn: 0.6141916\ttotal: 2.55s\tremaining: 16.6s\n","17:\tlearn: 0.6127190\ttotal: 2.65s\tremaining: 16.2s\n","18:\tlearn: 0.6114879\ttotal: 2.82s\tremaining: 16.2s\n","19:\tlearn: 0.6104636\ttotal: 2.93s\tremaining: 15.8s\n","20:\tlearn: 0.6095239\ttotal: 3.05s\tremaining: 15.5s\n","21:\tlearn: 0.6086635\ttotal: 3.17s\tremaining: 15.3s\n","22:\tlearn: 0.6076415\ttotal: 3.31s\tremaining: 15.1s\n","23:\tlearn: 0.6067402\ttotal: 3.48s\tremaining: 15.1s\n","24:\tlearn: 0.6055079\ttotal: 3.65s\tremaining: 15s\n","25:\tlearn: 0.6047163\ttotal: 3.81s\tremaining: 14.9s\n","26:\tlearn: 0.6040401\ttotal: 3.93s\tremaining: 14.7s\n","27:\tlearn: 0.6032834\ttotal: 4.04s\tremaining: 14.4s\n","28:\tlearn: 0.6026464\ttotal: 4.18s\tremaining: 14.3s\n","29:\tlearn: 0.6019781\ttotal: 4.31s\tremaining: 14.1s\n","30:\tlearn: 0.6013803\ttotal: 4.46s\tremaining: 13.9s\n","31:\tlearn: 0.6007716\ttotal: 4.56s\tremaining: 13.7s\n","32:\tlearn: 0.6001346\ttotal: 4.71s\tremaining: 13.6s\n","33:\tlearn: 0.5995661\ttotal: 4.84s\tremaining: 13.4s\n","34:\tlearn: 0.5991216\ttotal: 4.96s\tremaining: 13.2s\n","35:\tlearn: 0.5986056\ttotal: 5.07s\tremaining: 13s\n","36:\tlearn: 0.5981918\ttotal: 5.2s\tremaining: 12.8s\n","37:\tlearn: 0.5976241\ttotal: 5.36s\tremaining: 12.7s\n","38:\tlearn: 0.5969737\ttotal: 5.54s\tremaining: 12.6s\n","39:\tlearn: 0.5965279\ttotal: 5.66s\tremaining: 12.4s\n","40:\tlearn: 0.5960030\ttotal: 5.78s\tremaining: 12.3s\n","41:\tlearn: 0.5955638\ttotal: 5.9s\tremaining: 12.1s\n","42:\tlearn: 0.5950844\ttotal: 6.05s\tremaining: 12s\n","43:\tlearn: 0.5946167\ttotal: 6.21s\tremaining: 11.8s\n","44:\tlearn: 0.5941946\ttotal: 6.33s\tremaining: 11.7s\n","45:\tlearn: 0.5938878\ttotal: 6.45s\tremaining: 11.5s\n","46:\tlearn: 0.5934504\ttotal: 6.61s\tremaining: 11.4s\n","47:\tlearn: 0.5928808\ttotal: 6.78s\tremaining: 11.3s\n","48:\tlearn: 0.5925476\ttotal: 6.9s\tremaining: 11.1s\n","49:\tlearn: 0.5921224\ttotal: 7.02s\tremaining: 11s\n","50:\tlearn: 0.5916991\ttotal: 7.16s\tremaining: 10.8s\n","51:\tlearn: 0.5912910\ttotal: 7.3s\tremaining: 10.7s\n","52:\tlearn: 0.5909193\ttotal: 7.41s\tremaining: 10.5s\n","53:\tlearn: 0.5905049\ttotal: 7.59s\tremaining: 10.4s\n","54:\tlearn: 0.5900852\ttotal: 7.85s\tremaining: 10.4s\n","55:\tlearn: 0.5897664\ttotal: 8.08s\tremaining: 10.4s\n","56:\tlearn: 0.5892437\ttotal: 8.37s\tremaining: 10.4s\n","57:\tlearn: 0.5889938\ttotal: 8.6s\tremaining: 10.4s\n","58:\tlearn: 0.5885764\ttotal: 8.87s\tremaining: 10.4s\n","59:\tlearn: 0.5882993\ttotal: 9.09s\tremaining: 10.3s\n","60:\tlearn: 0.5879165\ttotal: 9.35s\tremaining: 10.3s\n","61:\tlearn: 0.5876112\ttotal: 9.59s\tremaining: 10.2s\n","62:\tlearn: 0.5873494\ttotal: 9.82s\tremaining: 10.1s\n","63:\tlearn: 0.5870884\ttotal: 10s\tremaining: 10s\n","64:\tlearn: 0.5867875\ttotal: 10.3s\tremaining: 9.95s\n","65:\tlearn: 0.5865241\ttotal: 10.5s\tremaining: 9.87s\n","66:\tlearn: 0.5862696\ttotal: 10.8s\tremaining: 9.81s\n","67:\tlearn: 0.5859917\ttotal: 11s\tremaining: 9.68s\n","68:\tlearn: 0.5857401\ttotal: 11.2s\tremaining: 9.57s\n","69:\tlearn: 0.5853344\ttotal: 11.3s\tremaining: 9.4s\n","70:\tlearn: 0.5848780\ttotal: 11.5s\tremaining: 9.22s\n","71:\tlearn: 0.5843671\ttotal: 11.6s\tremaining: 9.04s\n","72:\tlearn: 0.5841643\ttotal: 11.8s\tremaining: 8.85s\n","73:\tlearn: 0.5837461\ttotal: 11.9s\tremaining: 8.7s\n","74:\tlearn: 0.5833733\ttotal: 12.1s\tremaining: 8.52s\n","75:\tlearn: 0.5830603\ttotal: 12.2s\tremaining: 8.34s\n","76:\tlearn: 0.5827429\ttotal: 12.3s\tremaining: 8.16s\n","77:\tlearn: 0.5824606\ttotal: 12.4s\tremaining: 7.97s\n","78:\tlearn: 0.5820491\ttotal: 12.6s\tremaining: 7.81s\n","79:\tlearn: 0.5815808\ttotal: 12.8s\tremaining: 7.68s\n","80:\tlearn: 0.5811480\ttotal: 12.9s\tremaining: 7.5s\n","81:\tlearn: 0.5807416\ttotal: 13.1s\tremaining: 7.33s\n","82:\tlearn: 0.5802942\ttotal: 13.2s\tremaining: 7.17s\n","83:\tlearn: 0.5800118\ttotal: 13.4s\tremaining: 7.01s\n","84:\tlearn: 0.5797193\ttotal: 13.5s\tremaining: 6.83s\n","85:\tlearn: 0.5793834\ttotal: 13.6s\tremaining: 6.65s\n","86:\tlearn: 0.5790451\ttotal: 13.8s\tremaining: 6.48s\n","87:\tlearn: 0.5787278\ttotal: 13.9s\tremaining: 6.31s\n","88:\tlearn: 0.5783805\ttotal: 14s\tremaining: 6.14s\n","89:\tlearn: 0.5780158\ttotal: 14.2s\tremaining: 5.98s\n","90:\tlearn: 0.5776623\ttotal: 14.3s\tremaining: 5.81s\n","91:\tlearn: 0.5773513\ttotal: 14.4s\tremaining: 5.65s\n","92:\tlearn: 0.5769348\ttotal: 14.6s\tremaining: 5.49s\n","93:\tlearn: 0.5766312\ttotal: 14.7s\tremaining: 5.33s\n","94:\tlearn: 0.5763093\ttotal: 14.9s\tremaining: 5.17s\n","95:\tlearn: 0.5760993\ttotal: 15s\tremaining: 5s\n","96:\tlearn: 0.5758463\ttotal: 15.1s\tremaining: 4.83s\n","97:\tlearn: 0.5756030\ttotal: 15.2s\tremaining: 4.66s\n","98:\tlearn: 0.5752967\ttotal: 15.3s\tremaining: 4.49s\n","99:\tlearn: 0.5749893\ttotal: 15.5s\tremaining: 4.33s\n","100:\tlearn: 0.5746572\ttotal: 15.6s\tremaining: 4.17s\n","101:\tlearn: 0.5742836\ttotal: 15.7s\tremaining: 4.01s\n","102:\tlearn: 0.5740025\ttotal: 15.9s\tremaining: 3.85s\n","103:\tlearn: 0.5736941\ttotal: 16s\tremaining: 3.7s\n","104:\tlearn: 0.5734390\ttotal: 16.2s\tremaining: 3.54s\n","105:\tlearn: 0.5731008\ttotal: 16.3s\tremaining: 3.39s\n","106:\tlearn: 0.5728115\ttotal: 16.5s\tremaining: 3.23s\n","107:\tlearn: 0.5726068\ttotal: 16.6s\tremaining: 3.07s\n","108:\tlearn: 0.5723510\ttotal: 16.7s\tremaining: 2.91s\n","109:\tlearn: 0.5721126\ttotal: 16.8s\tremaining: 2.75s\n","110:\tlearn: 0.5718597\ttotal: 16.9s\tremaining: 2.59s\n","111:\tlearn: 0.5716836\ttotal: 17s\tremaining: 2.43s\n","112:\tlearn: 0.5714014\ttotal: 17.2s\tremaining: 2.28s\n","113:\tlearn: 0.5710941\ttotal: 17.3s\tremaining: 2.13s\n","114:\tlearn: 0.5708112\ttotal: 17.4s\tremaining: 1.97s\n","115:\tlearn: 0.5705317\ttotal: 17.6s\tremaining: 1.82s\n","116:\tlearn: 0.5701802\ttotal: 17.8s\tremaining: 1.67s\n","117:\tlearn: 0.5699188\ttotal: 17.9s\tremaining: 1.52s\n","118:\tlearn: 0.5696785\ttotal: 18s\tremaining: 1.36s\n","119:\tlearn: 0.5694307\ttotal: 18.2s\tremaining: 1.21s\n","120:\tlearn: 0.5691201\ttotal: 18.3s\tremaining: 1.06s\n","121:\tlearn: 0.5688904\ttotal: 18.5s\tremaining: 909ms\n","122:\tlearn: 0.5686441\ttotal: 18.6s\tremaining: 756ms\n","123:\tlearn: 0.5684083\ttotal: 18.7s\tremaining: 604ms\n","124:\tlearn: 0.5681359\ttotal: 18.9s\tremaining: 453ms\n","125:\tlearn: 0.5679074\ttotal: 19s\tremaining: 302ms\n","126:\tlearn: 0.5677346\ttotal: 19.1s\tremaining: 151ms\n","127:\tlearn: 0.5674745\ttotal: 19.2s\tremaining: 0us\n","0:\tlearn: 0.6771393\ttotal: 160ms\tremaining: 20.4s\n","1:\tlearn: 0.6653461\ttotal: 303ms\tremaining: 19.1s\n","2:\tlearn: 0.6567232\ttotal: 465ms\tremaining: 19.4s\n","3:\tlearn: 0.6493290\ttotal: 609ms\tremaining: 18.9s\n","4:\tlearn: 0.6434178\ttotal: 874ms\tremaining: 21.5s\n","5:\tlearn: 0.6386127\ttotal: 1.14s\tremaining: 23.3s\n","6:\tlearn: 0.6344669\ttotal: 1.47s\tremaining: 25.4s\n","7:\tlearn: 0.6310198\ttotal: 1.77s\tremaining: 26.5s\n","8:\tlearn: 0.6276935\ttotal: 2.02s\tremaining: 26.7s\n","9:\tlearn: 0.6249106\ttotal: 2.29s\tremaining: 27.1s\n","10:\tlearn: 0.6225509\ttotal: 2.57s\tremaining: 27.4s\n","11:\tlearn: 0.6205146\ttotal: 2.88s\tremaining: 27.9s\n","12:\tlearn: 0.6184113\ttotal: 3.14s\tremaining: 27.7s\n","13:\tlearn: 0.6167633\ttotal: 3.44s\tremaining: 28s\n","14:\tlearn: 0.6152857\ttotal: 3.72s\tremaining: 28s\n","15:\tlearn: 0.6137069\ttotal: 4.01s\tremaining: 28s\n","16:\tlearn: 0.6124658\ttotal: 4.25s\tremaining: 27.8s\n","17:\tlearn: 0.6112873\ttotal: 4.47s\tremaining: 27.4s\n","18:\tlearn: 0.6102059\ttotal: 4.63s\tremaining: 26.5s\n","19:\tlearn: 0.6091482\ttotal: 4.75s\tremaining: 25.7s\n","20:\tlearn: 0.6082795\ttotal: 4.89s\tremaining: 24.9s\n","21:\tlearn: 0.6073630\ttotal: 5.02s\tremaining: 24.2s\n","22:\tlearn: 0.6063350\ttotal: 5.15s\tremaining: 23.5s\n","23:\tlearn: 0.6054273\ttotal: 5.35s\tremaining: 23.2s\n","24:\tlearn: 0.6047738\ttotal: 5.47s\tremaining: 22.5s\n","25:\tlearn: 0.6040676\ttotal: 5.62s\tremaining: 22s\n","26:\tlearn: 0.6032909\ttotal: 5.76s\tremaining: 21.6s\n","27:\tlearn: 0.6025817\ttotal: 5.9s\tremaining: 21.1s\n","28:\tlearn: 0.6017015\ttotal: 6.03s\tremaining: 20.6s\n","29:\tlearn: 0.6011614\ttotal: 6.16s\tremaining: 20.1s\n","30:\tlearn: 0.6003469\ttotal: 6.31s\tremaining: 19.8s\n","31:\tlearn: 0.5998894\ttotal: 6.44s\tremaining: 19.3s\n","32:\tlearn: 0.5992948\ttotal: 6.55s\tremaining: 18.9s\n","33:\tlearn: 0.5987597\ttotal: 6.69s\tremaining: 18.5s\n","34:\tlearn: 0.5979723\ttotal: 6.83s\tremaining: 18.2s\n","35:\tlearn: 0.5975624\ttotal: 6.94s\tremaining: 17.7s\n","36:\tlearn: 0.5968989\ttotal: 7.09s\tremaining: 17.4s\n","37:\tlearn: 0.5964908\ttotal: 7.21s\tremaining: 17.1s\n","38:\tlearn: 0.5960973\ttotal: 7.37s\tremaining: 16.8s\n","39:\tlearn: 0.5955716\ttotal: 7.5s\tremaining: 16.5s\n","40:\tlearn: 0.5950068\ttotal: 7.64s\tremaining: 16.2s\n","41:\tlearn: 0.5941815\ttotal: 7.82s\tremaining: 16s\n","42:\tlearn: 0.5935303\ttotal: 7.98s\tremaining: 15.8s\n","43:\tlearn: 0.5930229\ttotal: 8.12s\tremaining: 15.5s\n","44:\tlearn: 0.5926517\ttotal: 8.24s\tremaining: 15.2s\n","45:\tlearn: 0.5922942\ttotal: 8.36s\tremaining: 14.9s\n","46:\tlearn: 0.5918565\ttotal: 8.49s\tremaining: 14.6s\n","47:\tlearn: 0.5914940\ttotal: 8.65s\tremaining: 14.4s\n","48:\tlearn: 0.5911487\ttotal: 8.79s\tremaining: 14.2s\n","49:\tlearn: 0.5908135\ttotal: 8.92s\tremaining: 13.9s\n","50:\tlearn: 0.5904236\ttotal: 9.03s\tremaining: 13.6s\n","51:\tlearn: 0.5900606\ttotal: 9.18s\tremaining: 13.4s\n","52:\tlearn: 0.5897772\ttotal: 9.3s\tremaining: 13.2s\n","53:\tlearn: 0.5894422\ttotal: 9.45s\tremaining: 12.9s\n","54:\tlearn: 0.5890811\ttotal: 9.59s\tremaining: 12.7s\n","55:\tlearn: 0.5886923\ttotal: 9.75s\tremaining: 12.5s\n","56:\tlearn: 0.5882050\ttotal: 9.9s\tremaining: 12.3s\n","57:\tlearn: 0.5878887\ttotal: 10s\tremaining: 12.1s\n","58:\tlearn: 0.5875725\ttotal: 10.2s\tremaining: 11.9s\n","59:\tlearn: 0.5873166\ttotal: 10.3s\tremaining: 11.6s\n","60:\tlearn: 0.5869931\ttotal: 10.4s\tremaining: 11.4s\n","61:\tlearn: 0.5867795\ttotal: 10.5s\tremaining: 11.2s\n","62:\tlearn: 0.5863777\ttotal: 10.7s\tremaining: 11s\n","63:\tlearn: 0.5859344\ttotal: 10.8s\tremaining: 10.8s\n","64:\tlearn: 0.5853891\ttotal: 11s\tremaining: 10.7s\n","65:\tlearn: 0.5850206\ttotal: 11.2s\tremaining: 10.5s\n","66:\tlearn: 0.5847614\ttotal: 11.3s\tremaining: 10.3s\n","67:\tlearn: 0.5844682\ttotal: 11.4s\tremaining: 10.1s\n","68:\tlearn: 0.5840473\ttotal: 11.6s\tremaining: 9.88s\n","69:\tlearn: 0.5836310\ttotal: 11.7s\tremaining: 9.69s\n","70:\tlearn: 0.5832794\ttotal: 11.8s\tremaining: 9.49s\n","71:\tlearn: 0.5828940\ttotal: 12s\tremaining: 9.33s\n","72:\tlearn: 0.5825081\ttotal: 12.2s\tremaining: 9.16s\n","73:\tlearn: 0.5821359\ttotal: 12.3s\tremaining: 8.96s\n","74:\tlearn: 0.5818213\ttotal: 12.4s\tremaining: 8.78s\n","75:\tlearn: 0.5815181\ttotal: 12.6s\tremaining: 8.6s\n","76:\tlearn: 0.5812994\ttotal: 12.7s\tremaining: 8.41s\n","77:\tlearn: 0.5809675\ttotal: 12.9s\tremaining: 8.25s\n","78:\tlearn: 0.5807145\ttotal: 13s\tremaining: 8.05s\n","79:\tlearn: 0.5803213\ttotal: 13.1s\tremaining: 7.88s\n","80:\tlearn: 0.5799768\ttotal: 13.3s\tremaining: 7.7s\n","81:\tlearn: 0.5796391\ttotal: 13.4s\tremaining: 7.52s\n","82:\tlearn: 0.5792851\ttotal: 13.5s\tremaining: 7.34s\n","83:\tlearn: 0.5789594\ttotal: 13.7s\tremaining: 7.17s\n","84:\tlearn: 0.5785836\ttotal: 13.8s\tremaining: 6.98s\n","85:\tlearn: 0.5783039\ttotal: 13.9s\tremaining: 6.81s\n","86:\tlearn: 0.5779290\ttotal: 14.1s\tremaining: 6.64s\n","87:\tlearn: 0.5776551\ttotal: 14.2s\tremaining: 6.46s\n","88:\tlearn: 0.5773243\ttotal: 14.4s\tremaining: 6.3s\n","89:\tlearn: 0.5769692\ttotal: 14.6s\tremaining: 6.16s\n","90:\tlearn: 0.5765198\ttotal: 14.9s\tremaining: 6.04s\n","91:\tlearn: 0.5762032\ttotal: 15.2s\tremaining: 5.94s\n","92:\tlearn: 0.5758446\ttotal: 15.5s\tremaining: 5.82s\n","93:\tlearn: 0.5755610\ttotal: 15.7s\tremaining: 5.68s\n","94:\tlearn: 0.5752348\ttotal: 16s\tremaining: 5.54s\n","95:\tlearn: 0.5749108\ttotal: 16.3s\tremaining: 5.42s\n","96:\tlearn: 0.5745405\ttotal: 16.6s\tremaining: 5.3s\n","97:\tlearn: 0.5742048\ttotal: 16.8s\tremaining: 5.14s\n","98:\tlearn: 0.5738931\ttotal: 17.1s\tremaining: 5s\n","99:\tlearn: 0.5737121\ttotal: 17.3s\tremaining: 4.84s\n","100:\tlearn: 0.5734593\ttotal: 17.5s\tremaining: 4.69s\n","101:\tlearn: 0.5732517\ttotal: 17.8s\tremaining: 4.53s\n","102:\tlearn: 0.5729836\ttotal: 18.1s\tremaining: 4.38s\n","103:\tlearn: 0.5727547\ttotal: 18.2s\tremaining: 4.21s\n","104:\tlearn: 0.5725191\ttotal: 18.4s\tremaining: 4.03s\n","105:\tlearn: 0.5722808\ttotal: 18.5s\tremaining: 3.84s\n","106:\tlearn: 0.5720398\ttotal: 18.6s\tremaining: 3.65s\n","107:\tlearn: 0.5717746\ttotal: 18.7s\tremaining: 3.47s\n","108:\tlearn: 0.5714741\ttotal: 18.9s\tremaining: 3.29s\n","109:\tlearn: 0.5712050\ttotal: 19s\tremaining: 3.11s\n","110:\tlearn: 0.5709926\ttotal: 19.1s\tremaining: 2.92s\n","111:\tlearn: 0.5707785\ttotal: 19.2s\tremaining: 2.75s\n","112:\tlearn: 0.5704758\ttotal: 19.4s\tremaining: 2.57s\n","113:\tlearn: 0.5702007\ttotal: 19.5s\tremaining: 2.39s\n","114:\tlearn: 0.5699788\ttotal: 19.6s\tremaining: 2.22s\n","115:\tlearn: 0.5696869\ttotal: 19.8s\tremaining: 2.04s\n","116:\tlearn: 0.5694288\ttotal: 19.9s\tremaining: 1.87s\n","117:\tlearn: 0.5691293\ttotal: 20.1s\tremaining: 1.7s\n","118:\tlearn: 0.5688705\ttotal: 20.2s\tremaining: 1.53s\n","119:\tlearn: 0.5686098\ttotal: 20.4s\tremaining: 1.36s\n","120:\tlearn: 0.5684239\ttotal: 20.5s\tremaining: 1.19s\n","121:\tlearn: 0.5681590\ttotal: 20.6s\tremaining: 1.01s\n","122:\tlearn: 0.5678818\ttotal: 20.8s\tremaining: 844ms\n","123:\tlearn: 0.5675761\ttotal: 20.9s\tremaining: 674ms\n","124:\tlearn: 0.5673341\ttotal: 21s\tremaining: 504ms\n","125:\tlearn: 0.5671135\ttotal: 21.1s\tremaining: 335ms\n","126:\tlearn: 0.5667644\ttotal: 21.3s\tremaining: 168ms\n","127:\tlearn: 0.5666188\ttotal: 21.4s\tremaining: 0us\n","0:\tlearn: 0.6776988\ttotal: 157ms\tremaining: 19.9s\n","1:\tlearn: 0.6652271\ttotal: 309ms\tremaining: 19.5s\n","2:\tlearn: 0.6565857\ttotal: 451ms\tremaining: 18.8s\n","3:\tlearn: 0.6498916\ttotal: 618ms\tremaining: 19.2s\n","4:\tlearn: 0.6439501\ttotal: 773ms\tremaining: 19s\n","5:\tlearn: 0.6389101\ttotal: 913ms\tremaining: 18.6s\n","6:\tlearn: 0.6346406\ttotal: 1.08s\tremaining: 18.7s\n","7:\tlearn: 0.6316480\ttotal: 1.22s\tremaining: 18.4s\n","8:\tlearn: 0.6283422\ttotal: 1.4s\tremaining: 18.5s\n","9:\tlearn: 0.6258453\ttotal: 1.54s\tremaining: 18.1s\n","10:\tlearn: 0.6232663\ttotal: 1.7s\tremaining: 18.1s\n","11:\tlearn: 0.6210035\ttotal: 1.87s\tremaining: 18.1s\n","12:\tlearn: 0.6187769\ttotal: 2.03s\tremaining: 18s\n","13:\tlearn: 0.6171359\ttotal: 2.15s\tremaining: 17.6s\n","14:\tlearn: 0.6154940\ttotal: 2.3s\tremaining: 17.3s\n","15:\tlearn: 0.6141575\ttotal: 2.43s\tremaining: 17s\n","16:\tlearn: 0.6130838\ttotal: 2.57s\tremaining: 16.8s\n","17:\tlearn: 0.6117467\ttotal: 2.71s\tremaining: 16.6s\n","18:\tlearn: 0.6106489\ttotal: 2.85s\tremaining: 16.3s\n","19:\tlearn: 0.6096824\ttotal: 2.96s\tremaining: 16s\n","20:\tlearn: 0.6087085\ttotal: 3.09s\tremaining: 15.7s\n","21:\tlearn: 0.6078465\ttotal: 3.21s\tremaining: 15.4s\n","22:\tlearn: 0.6069499\ttotal: 3.34s\tremaining: 15.2s\n","23:\tlearn: 0.6059457\ttotal: 3.5s\tremaining: 15.1s\n","24:\tlearn: 0.6049499\ttotal: 3.66s\tremaining: 15.1s\n","25:\tlearn: 0.6041226\ttotal: 3.81s\tremaining: 14.9s\n","26:\tlearn: 0.6034360\ttotal: 3.93s\tremaining: 14.7s\n","27:\tlearn: 0.6027687\ttotal: 4.03s\tremaining: 14.4s\n","28:\tlearn: 0.6021081\ttotal: 4.16s\tremaining: 14.2s\n","29:\tlearn: 0.6014530\ttotal: 4.29s\tremaining: 14s\n","30:\tlearn: 0.6008110\ttotal: 4.45s\tremaining: 13.9s\n","31:\tlearn: 0.6001752\ttotal: 4.57s\tremaining: 13.7s\n","32:\tlearn: 0.5995502\ttotal: 4.73s\tremaining: 13.6s\n","33:\tlearn: 0.5991210\ttotal: 4.84s\tremaining: 13.4s\n","34:\tlearn: 0.5985657\ttotal: 4.97s\tremaining: 13.2s\n","35:\tlearn: 0.5981090\ttotal: 5.1s\tremaining: 13s\n","36:\tlearn: 0.5976275\ttotal: 5.25s\tremaining: 12.9s\n","37:\tlearn: 0.5971725\ttotal: 5.39s\tremaining: 12.8s\n","38:\tlearn: 0.5967682\ttotal: 5.56s\tremaining: 12.7s\n","39:\tlearn: 0.5962497\ttotal: 5.83s\tremaining: 12.8s\n","40:\tlearn: 0.5957649\ttotal: 6.09s\tremaining: 12.9s\n","41:\tlearn: 0.5953293\ttotal: 6.33s\tremaining: 13s\n","42:\tlearn: 0.5948112\ttotal: 6.57s\tremaining: 13s\n","43:\tlearn: 0.5943428\ttotal: 6.83s\tremaining: 13s\n","44:\tlearn: 0.5938672\ttotal: 7.09s\tremaining: 13.1s\n","45:\tlearn: 0.5935933\ttotal: 7.3s\tremaining: 13s\n","46:\tlearn: 0.5931672\ttotal: 7.53s\tremaining: 13s\n","47:\tlearn: 0.5927139\ttotal: 7.84s\tremaining: 13.1s\n","48:\tlearn: 0.5923638\ttotal: 8.08s\tremaining: 13s\n","49:\tlearn: 0.5919959\ttotal: 8.33s\tremaining: 13s\n","50:\tlearn: 0.5917429\ttotal: 8.52s\tremaining: 12.9s\n","51:\tlearn: 0.5911370\ttotal: 8.81s\tremaining: 12.9s\n","52:\tlearn: 0.5908914\ttotal: 9.04s\tremaining: 12.8s\n","53:\tlearn: 0.5904149\ttotal: 9.26s\tremaining: 12.7s\n","54:\tlearn: 0.5899688\ttotal: 9.4s\tremaining: 12.5s\n","55:\tlearn: 0.5895956\ttotal: 9.54s\tremaining: 12.3s\n","56:\tlearn: 0.5893965\ttotal: 9.67s\tremaining: 12s\n","57:\tlearn: 0.5890143\ttotal: 9.78s\tremaining: 11.8s\n","58:\tlearn: 0.5887306\ttotal: 9.92s\tremaining: 11.6s\n","59:\tlearn: 0.5882928\ttotal: 10.1s\tremaining: 11.5s\n","60:\tlearn: 0.5879301\ttotal: 10.2s\tremaining: 11.3s\n","61:\tlearn: 0.5876450\ttotal: 10.4s\tremaining: 11s\n","62:\tlearn: 0.5873190\ttotal: 10.5s\tremaining: 10.8s\n","63:\tlearn: 0.5870909\ttotal: 10.6s\tremaining: 10.6s\n","64:\tlearn: 0.5865668\ttotal: 10.8s\tremaining: 10.4s\n","65:\tlearn: 0.5862708\ttotal: 10.9s\tremaining: 10.2s\n","66:\tlearn: 0.5859348\ttotal: 11s\tremaining: 10.1s\n","67:\tlearn: 0.5856114\ttotal: 11.2s\tremaining: 9.87s\n","68:\tlearn: 0.5853106\ttotal: 11.3s\tremaining: 9.66s\n","69:\tlearn: 0.5851126\ttotal: 11.4s\tremaining: 9.45s\n","70:\tlearn: 0.5848325\ttotal: 11.5s\tremaining: 9.25s\n","71:\tlearn: 0.5845060\ttotal: 11.7s\tremaining: 9.08s\n","72:\tlearn: 0.5841733\ttotal: 11.8s\tremaining: 8.89s\n","73:\tlearn: 0.5838685\ttotal: 11.9s\tremaining: 8.71s\n","74:\tlearn: 0.5836272\ttotal: 12.1s\tremaining: 8.53s\n","75:\tlearn: 0.5832230\ttotal: 12.2s\tremaining: 8.35s\n","76:\tlearn: 0.5828901\ttotal: 12.3s\tremaining: 8.16s\n","77:\tlearn: 0.5825542\ttotal: 12.5s\tremaining: 7.99s\n","78:\tlearn: 0.5822512\ttotal: 12.6s\tremaining: 7.82s\n","79:\tlearn: 0.5819503\ttotal: 12.8s\tremaining: 7.65s\n","80:\tlearn: 0.5816510\ttotal: 12.9s\tremaining: 7.47s\n","81:\tlearn: 0.5813818\ttotal: 13s\tremaining: 7.3s\n","82:\tlearn: 0.5810480\ttotal: 13.2s\tremaining: 7.14s\n","83:\tlearn: 0.5806774\ttotal: 13.3s\tremaining: 6.96s\n","84:\tlearn: 0.5803110\ttotal: 13.5s\tremaining: 6.8s\n","85:\tlearn: 0.5799283\ttotal: 13.6s\tremaining: 6.64s\n","86:\tlearn: 0.5796004\ttotal: 13.8s\tremaining: 6.49s\n","87:\tlearn: 0.5791431\ttotal: 13.9s\tremaining: 6.34s\n","88:\tlearn: 0.5788254\ttotal: 14.1s\tremaining: 6.18s\n","89:\tlearn: 0.5784584\ttotal: 14.2s\tremaining: 6.01s\n","90:\tlearn: 0.5781300\ttotal: 14.4s\tremaining: 5.84s\n","91:\tlearn: 0.5778109\ttotal: 14.5s\tremaining: 5.67s\n","92:\tlearn: 0.5774931\ttotal: 14.6s\tremaining: 5.51s\n","93:\tlearn: 0.5772134\ttotal: 14.8s\tremaining: 5.34s\n","94:\tlearn: 0.5769065\ttotal: 14.9s\tremaining: 5.18s\n","95:\tlearn: 0.5766353\ttotal: 15.1s\tremaining: 5.02s\n","96:\tlearn: 0.5764210\ttotal: 15.2s\tremaining: 4.86s\n","97:\tlearn: 0.5760812\ttotal: 15.3s\tremaining: 4.7s\n","98:\tlearn: 0.5758049\ttotal: 15.5s\tremaining: 4.54s\n","99:\tlearn: 0.5754965\ttotal: 15.6s\tremaining: 4.38s\n","100:\tlearn: 0.5752166\ttotal: 15.7s\tremaining: 4.21s\n","101:\tlearn: 0.5749378\ttotal: 15.9s\tremaining: 4.05s\n","102:\tlearn: 0.5746183\ttotal: 16s\tremaining: 3.89s\n","103:\tlearn: 0.5743883\ttotal: 16.2s\tremaining: 3.73s\n","104:\tlearn: 0.5740055\ttotal: 16.4s\tremaining: 3.58s\n","105:\tlearn: 0.5738271\ttotal: 16.5s\tremaining: 3.42s\n","106:\tlearn: 0.5735797\ttotal: 16.6s\tremaining: 3.25s\n","107:\tlearn: 0.5733789\ttotal: 16.7s\tremaining: 3.09s\n","108:\tlearn: 0.5730370\ttotal: 16.9s\tremaining: 2.94s\n","109:\tlearn: 0.5728223\ttotal: 17s\tremaining: 2.78s\n","110:\tlearn: 0.5725634\ttotal: 17.1s\tremaining: 2.62s\n","111:\tlearn: 0.5723206\ttotal: 17.2s\tremaining: 2.46s\n","112:\tlearn: 0.5720037\ttotal: 17.4s\tremaining: 2.31s\n","113:\tlearn: 0.5718308\ttotal: 17.5s\tremaining: 2.15s\n","114:\tlearn: 0.5715081\ttotal: 17.6s\tremaining: 1.99s\n","115:\tlearn: 0.5712782\ttotal: 17.8s\tremaining: 1.84s\n","116:\tlearn: 0.5709845\ttotal: 17.9s\tremaining: 1.68s\n","117:\tlearn: 0.5707253\ttotal: 18s\tremaining: 1.53s\n","118:\tlearn: 0.5705113\ttotal: 18.2s\tremaining: 1.37s\n","119:\tlearn: 0.5702755\ttotal: 18.3s\tremaining: 1.22s\n","120:\tlearn: 0.5701359\ttotal: 18.4s\tremaining: 1.07s\n","121:\tlearn: 0.5698322\ttotal: 18.6s\tremaining: 913ms\n","122:\tlearn: 0.5694779\ttotal: 18.7s\tremaining: 761ms\n","123:\tlearn: 0.5692968\ttotal: 18.8s\tremaining: 607ms\n","124:\tlearn: 0.5690552\ttotal: 19s\tremaining: 455ms\n","125:\tlearn: 0.5688838\ttotal: 19.1s\tremaining: 303ms\n","126:\tlearn: 0.5686160\ttotal: 19.2s\tremaining: 151ms\n","127:\tlearn: 0.5683517\ttotal: 19.4s\tremaining: 0us\n","0:\tlearn: 0.6771034\ttotal: 278ms\tremaining: 35.4s\n","1:\tlearn: 0.6658956\ttotal: 549ms\tremaining: 34.6s\n","2:\tlearn: 0.6569854\ttotal: 794ms\tremaining: 33.1s\n","3:\tlearn: 0.6495572\ttotal: 1.11s\tremaining: 34.4s\n","4:\tlearn: 0.6435320\ttotal: 1.36s\tremaining: 33.4s\n","5:\tlearn: 0.6388644\ttotal: 1.65s\tremaining: 33.5s\n","6:\tlearn: 0.6345888\ttotal: 1.83s\tremaining: 31.6s\n","7:\tlearn: 0.6312058\ttotal: 2s\tremaining: 30.1s\n","8:\tlearn: 0.6279863\ttotal: 2.17s\tremaining: 28.7s\n","9:\tlearn: 0.6253426\ttotal: 2.31s\tremaining: 27.3s\n","10:\tlearn: 0.6233540\ttotal: 2.46s\tremaining: 26.2s\n","11:\tlearn: 0.6214602\ttotal: 2.62s\tremaining: 25.3s\n","12:\tlearn: 0.6194917\ttotal: 2.75s\tremaining: 24.4s\n","13:\tlearn: 0.6180632\ttotal: 2.88s\tremaining: 23.5s\n","14:\tlearn: 0.6164813\ttotal: 3.03s\tremaining: 22.8s\n","15:\tlearn: 0.6145504\ttotal: 3.21s\tremaining: 22.4s\n","16:\tlearn: 0.6133757\ttotal: 3.32s\tremaining: 21.7s\n","17:\tlearn: 0.6121928\ttotal: 3.46s\tremaining: 21.1s\n","18:\tlearn: 0.6109912\ttotal: 3.58s\tremaining: 20.5s\n","19:\tlearn: 0.6098027\ttotal: 3.73s\tremaining: 20.2s\n","20:\tlearn: 0.6088284\ttotal: 3.86s\tremaining: 19.7s\n","21:\tlearn: 0.6080692\ttotal: 4s\tremaining: 19.3s\n","22:\tlearn: 0.6073277\ttotal: 4.12s\tremaining: 18.8s\n","23:\tlearn: 0.6066019\ttotal: 4.26s\tremaining: 18.5s\n","24:\tlearn: 0.6057871\ttotal: 4.39s\tremaining: 18.1s\n","25:\tlearn: 0.6051617\ttotal: 4.53s\tremaining: 17.8s\n","26:\tlearn: 0.6043189\ttotal: 4.67s\tremaining: 17.5s\n","27:\tlearn: 0.6033298\ttotal: 4.82s\tremaining: 17.2s\n","28:\tlearn: 0.6022764\ttotal: 4.98s\tremaining: 17s\n","29:\tlearn: 0.6012069\ttotal: 5.13s\tremaining: 16.8s\n","30:\tlearn: 0.6005790\ttotal: 5.25s\tremaining: 16.4s\n","31:\tlearn: 0.5999531\ttotal: 5.4s\tremaining: 16.2s\n","32:\tlearn: 0.5993213\ttotal: 5.51s\tremaining: 15.9s\n","33:\tlearn: 0.5985907\ttotal: 5.65s\tremaining: 15.6s\n","34:\tlearn: 0.5981058\ttotal: 5.76s\tremaining: 15.3s\n","35:\tlearn: 0.5975403\ttotal: 5.9s\tremaining: 15.1s\n","36:\tlearn: 0.5970351\ttotal: 6.03s\tremaining: 14.8s\n","37:\tlearn: 0.5965612\ttotal: 6.16s\tremaining: 14.6s\n","38:\tlearn: 0.5959375\ttotal: 6.33s\tremaining: 14.4s\n","39:\tlearn: 0.5955451\ttotal: 6.45s\tremaining: 14.2s\n","40:\tlearn: 0.5951261\ttotal: 6.58s\tremaining: 14s\n","41:\tlearn: 0.5947783\ttotal: 6.71s\tremaining: 13.7s\n","42:\tlearn: 0.5943127\ttotal: 6.84s\tremaining: 13.5s\n","43:\tlearn: 0.5938071\ttotal: 6.98s\tremaining: 13.3s\n","44:\tlearn: 0.5933545\ttotal: 7.12s\tremaining: 13.1s\n","45:\tlearn: 0.5928266\ttotal: 7.28s\tremaining: 13s\n","46:\tlearn: 0.5925214\ttotal: 7.38s\tremaining: 12.7s\n","47:\tlearn: 0.5921893\ttotal: 7.53s\tremaining: 12.5s\n","48:\tlearn: 0.5918363\ttotal: 7.68s\tremaining: 12.4s\n","49:\tlearn: 0.5913985\ttotal: 7.84s\tremaining: 12.2s\n","50:\tlearn: 0.5910050\ttotal: 7.98s\tremaining: 12s\n","51:\tlearn: 0.5906744\ttotal: 8.14s\tremaining: 11.9s\n","52:\tlearn: 0.5903500\ttotal: 8.25s\tremaining: 11.7s\n","53:\tlearn: 0.5897847\ttotal: 8.42s\tremaining: 11.5s\n","54:\tlearn: 0.5895099\ttotal: 8.54s\tremaining: 11.3s\n","55:\tlearn: 0.5891429\ttotal: 8.65s\tremaining: 11.1s\n","56:\tlearn: 0.5889203\ttotal: 8.75s\tremaining: 10.9s\n","57:\tlearn: 0.5886387\ttotal: 8.86s\tremaining: 10.7s\n","58:\tlearn: 0.5883320\ttotal: 8.99s\tremaining: 10.5s\n","59:\tlearn: 0.5880986\ttotal: 9.12s\tremaining: 10.3s\n","60:\tlearn: 0.5878060\ttotal: 9.24s\tremaining: 10.1s\n","61:\tlearn: 0.5875238\ttotal: 9.37s\tremaining: 9.97s\n","62:\tlearn: 0.5872395\ttotal: 9.5s\tremaining: 9.8s\n","63:\tlearn: 0.5868991\ttotal: 9.64s\tremaining: 9.64s\n","64:\tlearn: 0.5865857\ttotal: 9.76s\tremaining: 9.46s\n","65:\tlearn: 0.5862361\ttotal: 9.92s\tremaining: 9.32s\n","66:\tlearn: 0.5858861\ttotal: 10s\tremaining: 9.14s\n","67:\tlearn: 0.5856244\ttotal: 10.2s\tremaining: 8.97s\n","68:\tlearn: 0.5853674\ttotal: 10.3s\tremaining: 8.82s\n","69:\tlearn: 0.5850829\ttotal: 10.4s\tremaining: 8.64s\n","70:\tlearn: 0.5846568\ttotal: 10.6s\tremaining: 8.5s\n","71:\tlearn: 0.5842881\ttotal: 10.7s\tremaining: 8.36s\n","72:\tlearn: 0.5839634\ttotal: 10.9s\tremaining: 8.21s\n","73:\tlearn: 0.5835694\ttotal: 11.1s\tremaining: 8.07s\n","74:\tlearn: 0.5834029\ttotal: 11.2s\tremaining: 7.9s\n","75:\tlearn: 0.5830983\ttotal: 11.3s\tremaining: 7.74s\n","76:\tlearn: 0.5828006\ttotal: 11.5s\tremaining: 7.59s\n","77:\tlearn: 0.5823961\ttotal: 11.6s\tremaining: 7.45s\n","78:\tlearn: 0.5820235\ttotal: 11.9s\tremaining: 7.36s\n","79:\tlearn: 0.5817159\ttotal: 12.1s\tremaining: 7.26s\n","80:\tlearn: 0.5813969\ttotal: 12.4s\tremaining: 7.17s\n","81:\tlearn: 0.5810363\ttotal: 12.6s\tremaining: 7.07s\n","82:\tlearn: 0.5806132\ttotal: 12.9s\tremaining: 6.98s\n","83:\tlearn: 0.5801968\ttotal: 13.2s\tremaining: 6.9s\n","84:\tlearn: 0.5798746\ttotal: 13.5s\tremaining: 6.81s\n","85:\tlearn: 0.5795062\ttotal: 13.7s\tremaining: 6.71s\n","86:\tlearn: 0.5792067\ttotal: 14s\tremaining: 6.6s\n","87:\tlearn: 0.5788377\ttotal: 14.2s\tremaining: 6.47s\n","88:\tlearn: 0.5785824\ttotal: 14.5s\tremaining: 6.35s\n","89:\tlearn: 0.5782434\ttotal: 14.7s\tremaining: 6.22s\n","90:\tlearn: 0.5778728\ttotal: 15s\tremaining: 6.1s\n","91:\tlearn: 0.5776021\ttotal: 15.2s\tremaining: 5.96s\n","92:\tlearn: 0.5772294\ttotal: 15.4s\tremaining: 5.81s\n","93:\tlearn: 0.5769168\ttotal: 15.7s\tremaining: 5.67s\n","94:\tlearn: 0.5765581\ttotal: 15.8s\tremaining: 5.49s\n","95:\tlearn: 0.5762339\ttotal: 15.9s\tremaining: 5.32s\n","96:\tlearn: 0.5759058\ttotal: 16.1s\tremaining: 5.14s\n","97:\tlearn: 0.5755879\ttotal: 16.2s\tremaining: 4.96s\n","98:\tlearn: 0.5753829\ttotal: 16.3s\tremaining: 4.79s\n","99:\tlearn: 0.5751273\ttotal: 16.5s\tremaining: 4.61s\n","100:\tlearn: 0.5747820\ttotal: 16.6s\tremaining: 4.44s\n","101:\tlearn: 0.5743944\ttotal: 16.8s\tremaining: 4.28s\n","102:\tlearn: 0.5742032\ttotal: 16.9s\tremaining: 4.1s\n","103:\tlearn: 0.5739607\ttotal: 17s\tremaining: 3.92s\n","104:\tlearn: 0.5737024\ttotal: 17.1s\tremaining: 3.75s\n","105:\tlearn: 0.5734075\ttotal: 17.3s\tremaining: 3.58s\n","106:\tlearn: 0.5731584\ttotal: 17.4s\tremaining: 3.41s\n","107:\tlearn: 0.5728851\ttotal: 17.5s\tremaining: 3.25s\n","108:\tlearn: 0.5725356\ttotal: 17.7s\tremaining: 3.08s\n","109:\tlearn: 0.5722057\ttotal: 17.8s\tremaining: 2.92s\n","110:\tlearn: 0.5718968\ttotal: 18s\tremaining: 2.75s\n","111:\tlearn: 0.5715489\ttotal: 18.1s\tremaining: 2.59s\n","112:\tlearn: 0.5711621\ttotal: 18.3s\tremaining: 2.43s\n","113:\tlearn: 0.5708705\ttotal: 18.5s\tremaining: 2.27s\n","114:\tlearn: 0.5706007\ttotal: 18.7s\tremaining: 2.11s\n","115:\tlearn: 0.5702822\ttotal: 18.8s\tremaining: 1.94s\n","116:\tlearn: 0.5699984\ttotal: 18.9s\tremaining: 1.78s\n","117:\tlearn: 0.5697191\ttotal: 19.1s\tremaining: 1.61s\n","118:\tlearn: 0.5694690\ttotal: 19.2s\tremaining: 1.45s\n","119:\tlearn: 0.5691906\ttotal: 19.3s\tremaining: 1.29s\n","120:\tlearn: 0.5689034\ttotal: 19.5s\tremaining: 1.13s\n","121:\tlearn: 0.5686589\ttotal: 19.6s\tremaining: 965ms\n","122:\tlearn: 0.5683670\ttotal: 19.7s\tremaining: 803ms\n","123:\tlearn: 0.5681445\ttotal: 19.9s\tremaining: 642ms\n","124:\tlearn: 0.5679136\ttotal: 20s\tremaining: 480ms\n","125:\tlearn: 0.5676482\ttotal: 20.2s\tremaining: 320ms\n","126:\tlearn: 0.5674225\ttotal: 20.3s\tremaining: 160ms\n","127:\tlearn: 0.5671884\ttotal: 20.4s\tremaining: 0us\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","train: 0.778890642964533\n","test: 0.6886239459932656\n","test conf matrix: \n"," [[20680 11273]\n"," [ 8615 23298]]\n"]}]},{"cell_type":"markdown","source":["## Down_upsampling in 338 feat"],"metadata":{"id":"20KVqeno4WXF"}},{"cell_type":"code","source":["x_train = pd.read_parquet(path + '/up_ds_x_train.parquet').drop('id', axis=1)\n","x_test = pd.read_parquet(path + '/up_ds_x_test.parquet').drop('id', axis=1)\n","y_train = pd.read_parquet(path + '/up_ds_y_train.parquet').drop('id', axis=1)\n","y_test = pd.read_parquet(path + '/up_ds_y_test.parquet').drop('id', axis=1)"],"metadata":{"id":"JcynO9J34nE0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["x_train.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1708100838028,"user_tz":-240,"elapsed":267,"user":{"displayName":"Евгений Малов","userId":"06257165098392198337"}},"outputId":"05320851-1d60-44c3-d498-406164681a5d","id":"kfTOSsC84nE1"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(745094, 337)"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["model_log_reg = LogisticRegression()\n","model_log_reg.fit(x_train, y_train)\n","\n","pred_train = model_log_reg.predict(x_train)\n","pred_test = model_log_reg.predict(x_test)\n","\n","print(f'train: {roc_auc_score(y_train, pred_train)}')\n","print(f'test: {roc_auc_score(y_test, pred_test)}')\n","print(f'test conf matrix: \\n {confusion_matrix(y_test, pred_test)}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1708019555758,"user_tz":-240,"elapsed":64255,"user":{"displayName":"Евгений Малов","userId":"06257165098392198337"}},"outputId":"9293e402-9fed-4c41-ef8e-8c264745bd29","id":"ihesFI4o4nE2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["train: 0.6755299082102137\n","test: 0.6746205765486564\n","test conf matrix: \n"," [[106285  53116]\n"," [ 50782 109143]]\n"]}]},{"cell_type":"code","source":["model_lgbm = LGBMClassifier()\n","model_lgbm.fit(x_train, y_train)\n","\n","pred_train = model_lgbm.predict(x_train)\n","pred_test = model_lgbm.predict(x_test)\n","\n","print(f'train: {roc_auc_score(y_train, pred_train)}')\n","print(f'test: {roc_auc_score(y_test, pred_test)}')\n","print(f'test conf matrix: \\n {confusion_matrix(y_test, pred_test)}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1708019867755,"user_tz":-240,"elapsed":92602,"user":{"displayName":"Евгений Малов","userId":"06257165098392198337"}},"outputId":"5788a73c-e4b0-4dc2-98cc-3a335c78903a","id":"lP349NQp4nE3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[LightGBM] [Info] Number of positive: 372285, number of negative: 372809\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 4.059392 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 4777\n","[LightGBM] [Info] Number of data points in the train set: 745094, number of used features: 318\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499648 -> initscore=-0.001407\n","[LightGBM] [Info] Start training from score -0.001407\n","train: 0.6956991992455455\n","test: 0.6927982603097641\n","test conf matrix: \n"," [[106021  53380]\n"," [ 44703 115222]]\n"]}]},{"cell_type":"code","source":["model_xbm = XGBClassifier()\n","model_xbm.fit(x_train, y_train)\n","\n","pred_train = model_xbm.predict(x_train)\n","pred_test = model_xbm.predict(x_test)\n","\n","print(f'train: {roc_auc_score(y_train, pred_train)}')\n","print(f'test: {roc_auc_score(y_test, pred_test)}')\n","print(f'test conf matrix: \\n {confusion_matrix(y_test, pred_test)}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1708019995884,"user_tz":-240,"elapsed":100233,"user":{"displayName":"Евгений Малов","userId":"06257165098392198337"}},"outputId":"da387172-fe11-4161-dede-f5747d425c35","id":"3BlQxy6f4nE5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["train: 0.7191655272740818\n","test: 0.7081758457188457\n","test conf matrix: \n"," [[110134  49267]\n"," [ 43911 116014]]\n"]}]},{"cell_type":"code","source":["model_catb = CatBoostClassifier(verbose=False)\n","model_catb.fit(x_train, y_train)\n","\n","pred_train = model_catb.predict(x_train)\n","pred_test = model_catb.predict(x_test)\n","\n","print(f'train: {roc_auc_score(y_train, pred_train)}')\n","print(f'test: {roc_auc_score(y_test, pred_test)}')\n","print(f'test conf matrix: \\n {confusion_matrix(y_test, pred_test)}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1708020812802,"user_tz":-240,"elapsed":54829,"user":{"displayName":"Евгений Малов","userId":"06257165098392198337"}},"outputId":"407ddfdb-3d94-4db7-f13e-361439f06740","id":"LfAdNVNz4nE7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["train: 0.7371837784013591\n","test: 0.7213253588930185\n","test conf matrix: \n"," [[111616  47785]\n"," [ 41192 118733]]\n"]}]},{"cell_type":"code","source":["def objective_lgbm(trial):\n","    max_depth = trial.suggest_int(\"max_depth\", 2, 15)\n","    learning_rate = trial.suggest_float(\"learning_rate\", 1e-5, 1, log=True)\n","    n_estimators = trial.suggest_int(\"n_estimators\", 10, 700)\n","\n","    score = cross_val_score(LGBMClassifier(max_depth=max_depth, learning_rate=learning_rate, n_estimators=n_estimators),\n","                            x_train, y_train, cv=3, scoring='roc_auc', n_jobs=-1).mean()\n","    return score\n","\n","\n","study_lgbm = optuna.create_study(direction=\"maximize\")\n","study_lgbm.optimize(objective_lgbm, n_trials=50)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1708091646454,"user_tz":-240,"elapsed":12914,"user":{"displayName":"Евгений Малов","userId":"06257165098392198337"}},"outputId":"014be5a9-6f41-4ca6-9922-a5631f50fd34","id":"tjFtT8Y24nE_"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[I 2024-02-16 09:25:51,335] A new study created in memory with name: no-name-5c2e4993-2a4b-4633-a0b3-5c39fdfb0107\n","[I 2024-02-16 09:34:18,579] Trial 0 finished with value: 0.684351358157481 and parameters: {'max_depth': 11, 'learning_rate': 1.455839641282559e-05, 'n_estimators': 503}. Best is trial 0 with value: 0.684351358157481.\n","[I 2024-02-16 09:35:35,185] Trial 1 finished with value: 0.7570539376868993 and parameters: {'max_depth': 7, 'learning_rate': 0.23773400650016965, 'n_estimators': 47}. Best is trial 1 with value: 0.7570539376868993.\n","[I 2024-02-16 09:46:34,127] Trial 2 finished with value: 0.7075279977181284 and parameters: {'max_depth': 8, 'learning_rate': 0.0005461974417169861, 'n_estimators': 700}. Best is trial 1 with value: 0.7570539376868993.\n","[I 2024-02-16 09:48:37,803] Trial 3 finished with value: 0.7693521236873982 and parameters: {'max_depth': 10, 'learning_rate': 0.20132851535164106, 'n_estimators': 126}. Best is trial 3 with value: 0.7693521236873982.\n","[I 2024-02-16 09:49:34,342] Trial 4 finished with value: 0.7402838589958393 and parameters: {'max_depth': 13, 'learning_rate': 0.25847406506441645, 'n_estimators': 14}. Best is trial 3 with value: 0.7693521236873982.\n","[I 2024-02-16 09:50:38,357] Trial 5 finished with value: 0.6887539173282805 and parameters: {'max_depth': 14, 'learning_rate': 0.0012970835912283563, 'n_estimators': 26}. Best is trial 3 with value: 0.7693521236873982.\n","[I 2024-02-16 09:59:40,612] Trial 6 finished with value: 0.7685386097807688 and parameters: {'max_depth': 13, 'learning_rate': 0.02733825551306619, 'n_estimators': 696}. Best is trial 3 with value: 0.7693521236873982.\n","[I 2024-02-16 10:01:53,060] Trial 7 finished with value: 0.7830671713344074 and parameters: {'max_depth': 6, 'learning_rate': 0.5428268617857805, 'n_estimators': 184}. Best is trial 7 with value: 0.7830671713344074.\n","[I 2024-02-16 10:06:39,332] Trial 8 finished with value: 0.705432568906831 and parameters: {'max_depth': 7, 'learning_rate': 0.0011978875804154476, 'n_estimators': 289}. Best is trial 7 with value: 0.7830671713344074.\n","[I 2024-02-16 10:09:17,473] Trial 9 finished with value: 0.6995257132335313 and parameters: {'max_depth': 9, 'learning_rate': 0.001514899693658405, 'n_estimators': 134}. Best is trial 7 with value: 0.7830671713344074.\n","[I 2024-02-16 10:11:59,206] Trial 10 finished with value: 0.7279622115351344 and parameters: {'max_depth': 2, 'learning_rate': 0.03020200652963631, 'n_estimators': 321}. Best is trial 7 with value: 0.7830671713344074.\n","[I 2024-02-16 10:13:48,850] Trial 11 finished with value: 0.7577042951825588 and parameters: {'max_depth': 3, 'learning_rate': 0.8275029623229487, 'n_estimators': 171}. Best is trial 7 with value: 0.7830671713344074.\n","[I 2024-02-16 10:17:18,785] Trial 12 finished with value: 0.7412520333082852 and parameters: {'max_depth': 5, 'learning_rate': 0.020713561996012788, 'n_estimators': 219}. Best is trial 7 with value: 0.7830671713344074.\n","[I 2024-02-16 10:20:58,080] Trial 13 finished with value: 0.8120296478814889 and parameters: {'max_depth': 10, 'learning_rate': 0.9592853349970412, 'n_estimators': 417}. Best is trial 13 with value: 0.8120296478814889.\n","[I 2024-02-16 10:25:12,316] Trial 14 finished with value: 0.8043084635891531 and parameters: {'max_depth': 5, 'learning_rate': 0.9285811716340623, 'n_estimators': 449}. Best is trial 13 with value: 0.8120296478814889.\n","[I 2024-02-16 10:29:44,223] Trial 15 finished with value: 0.76313794472523 and parameters: {'max_depth': 4, 'learning_rate': 0.07431551195244325, 'n_estimators': 480}. Best is trial 13 with value: 0.8120296478814889.\n","[I 2024-02-16 10:36:43,998] Trial 16 finished with value: 0.6914967684178283 and parameters: {'max_depth': 11, 'learning_rate': 0.000130194429439569, 'n_estimators': 432}. Best is trial 13 with value: 0.8120296478814889.\n","[I 2024-02-16 10:42:56,732] Trial 17 finished with value: 0.7230207336010173 and parameters: {'max_depth': 4, 'learning_rate': 0.004616081433080839, 'n_estimators': 565}. Best is trial 13 with value: 0.8120296478814889.\n","[I 2024-02-16 10:46:24,751] Trial 18 finished with value: 0.8101246053226979 and parameters: {'max_depth': 15, 'learning_rate': 0.9586514074620299, 'n_estimators': 388}. Best is trial 13 with value: 0.8120296478814889.\n","[I 2024-02-16 10:53:18,508] Trial 19 finished with value: 0.7399110689326802 and parameters: {'max_depth': 15, 'learning_rate': 0.007226706019760914, 'n_estimators': 406}. Best is trial 13 with value: 0.8120296478814889.\n","[I 2024-02-16 10:59:33,458] Trial 20 finished with value: 0.7862460977670823 and parameters: {'max_depth': 12, 'learning_rate': 0.08525428924623261, 'n_estimators': 609}. Best is trial 13 with value: 0.8120296478814889.\n","[I 2024-02-16 11:03:00,099] Trial 21 finished with value: 0.8107300085905993 and parameters: {'max_depth': 15, 'learning_rate': 0.7585009362487486, 'n_estimators': 379}. Best is trial 13 with value: 0.8120296478814889.\n","[I 2024-02-16 11:07:04,335] Trial 22 finished with value: 0.781494609458974 and parameters: {'max_depth': 15, 'learning_rate': 0.11838341893315059, 'n_estimators': 368}. Best is trial 13 with value: 0.8120296478814889.\n","[I 2024-02-16 11:09:56,977] Trial 23 finished with value: 0.7969866150057149 and parameters: {'max_depth': 14, 'learning_rate': 0.4643477398610561, 'n_estimators': 284}. Best is trial 13 with value: 0.8120296478814889.\n","[I 2024-02-16 11:14:30,879] Trial 24 finished with value: 0.826432220567495 and parameters: {'max_depth': 13, 'learning_rate': 0.8397098004862189, 'n_estimators': 525}. Best is trial 24 with value: 0.826432220567495.\n","[I 2024-02-16 11:20:59,689] Trial 25 finished with value: 0.773463822174563 and parameters: {'max_depth': 12, 'learning_rate': 0.04911031004472646, 'n_estimators': 547}. Best is trial 24 with value: 0.826432220567495.\n","[I 2024-02-16 11:26:08,418] Trial 26 finished with value: 0.8180678198418293 and parameters: {'max_depth': 10, 'learning_rate': 0.3081222745571771, 'n_estimators': 607}. Best is trial 24 with value: 0.826432220567495.\n","[I 2024-02-16 11:37:25,610] Trial 27 finished with value: 0.7531705022016454 and parameters: {'max_depth': 9, 'learning_rate': 0.009803850332450383, 'n_estimators': 642}. Best is trial 24 with value: 0.826432220567495.\n","[I 2024-02-16 11:42:13,150] Trial 28 finished with value: 0.8078889138654187 and parameters: {'max_depth': 10, 'learning_rate': 0.24128282030614157, 'n_estimators': 545}. Best is trial 24 with value: 0.826432220567495.\n","[I 2024-02-16 11:47:02,798] Trial 29 finished with value: 0.7930435244887498 and parameters: {'max_depth': 11, 'learning_rate': 0.14552037933337075, 'n_estimators': 498}. Best is trial 24 with value: 0.826432220567495.\n","[I 2024-02-16 11:56:54,893] Trial 30 finished with value: 0.6891968932784117 and parameters: {'max_depth': 10, 'learning_rate': 5.544739499982066e-05, 'n_estimators': 623}. Best is trial 24 with value: 0.826432220567495.\n","[I 2024-02-16 12:00:54,862] Trial 31 finished with value: 0.8136388380860753 and parameters: {'max_depth': 13, 'learning_rate': 0.4082557615486357, 'n_estimators': 467}. Best is trial 24 with value: 0.826432220567495.\n","[I 2024-02-16 12:04:59,263] Trial 32 finished with value: 0.8176841893575468 and parameters: {'max_depth': 12, 'learning_rate': 0.5101104728396997, 'n_estimators': 470}. Best is trial 24 with value: 0.826432220567495.\n","[I 2024-02-16 12:09:55,848] Trial 33 finished with value: 0.8206446039696451 and parameters: {'max_depth': 12, 'learning_rate': 0.3653260162013677, 'n_estimators': 578}. Best is trial 24 with value: 0.826432220567495.\n","[I 2024-02-16 12:15:28,166] Trial 34 finished with value: 0.8148005996704207 and parameters: {'max_depth': 12, 'learning_rate': 0.28028538407467357, 'n_estimators': 588}. Best is trial 24 with value: 0.826432220567495.\n","[I 2024-02-16 12:20:24,997] Trial 35 finished with value: 0.794478108207786 and parameters: {'max_depth': 8, 'learning_rate': 0.15522983395851606, 'n_estimators': 519}. Best is trial 24 with value: 0.826432220567495.\n","[I 2024-02-16 12:25:37,821] Trial 36 finished with value: 0.8219116947842684 and parameters: {'max_depth': 11, 'learning_rate': 0.3281266776188269, 'n_estimators': 637}. Best is trial 24 with value: 0.826432220567495.\n","[I 2024-02-16 12:33:02,671] Trial 37 finished with value: 0.776857727254814 and parameters: {'max_depth': 11, 'learning_rate': 0.048608137467008934, 'n_estimators': 670}. Best is trial 24 with value: 0.826432220567495.\n","[I 2024-02-16 12:43:22,532] Trial 38 finished with value: 0.7612483060329792 and parameters: {'max_depth': 13, 'learning_rate': 0.016011188466259478, 'n_estimators': 673}. Best is trial 24 with value: 0.826432220567495.\n","[I 2024-02-16 12:48:41,918] Trial 39 finished with value: 0.8099481241514783 and parameters: {'max_depth': 14, 'learning_rate': 0.2258701847197041, 'n_estimators': 589}. Best is trial 24 with value: 0.826432220567495.\n","[I 2024-02-16 12:59:08,596] Trial 40 finished with value: 0.6863823666465864 and parameters: {'max_depth': 9, 'learning_rate': 1.964147290438719e-05, 'n_estimators': 655}. Best is trial 24 with value: 0.826432220567495.\n","[I 2024-02-16 13:03:58,373] Trial 41 finished with value: 0.8178005495893889 and parameters: {'max_depth': 12, 'learning_rate': 0.3965408346033027, 'n_estimators': 519}. Best is trial 24 with value: 0.826432220567495.\n","[I 2024-02-16 13:08:48,524] Trial 42 finished with value: 0.8168437826229882 and parameters: {'max_depth': 11, 'learning_rate': 0.3663837211083437, 'n_estimators': 532}. Best is trial 24 with value: 0.826432220567495.\n","[I 2024-02-16 13:15:20,981] Trial 43 finished with value: 0.783402601162531 and parameters: {'max_depth': 13, 'learning_rate': 0.08065799081200001, 'n_estimators': 573}. Best is trial 24 with value: 0.826432220567495.\n","[I 2024-02-16 13:20:28,297] Trial 44 finished with value: 0.8202738551412835 and parameters: {'max_depth': 12, 'learning_rate': 0.32604135309488924, 'n_estimators': 608}. Best is trial 24 with value: 0.826432220567495.\n","[I 2024-02-16 13:27:51,713] Trial 45 finished with value: 0.7740281070860887 and parameters: {'max_depth': 14, 'learning_rate': 0.04431738237599864, 'n_estimators': 621}. Best is trial 24 with value: 0.826432220567495.\n","[I 2024-02-16 13:34:01,423] Trial 46 finished with value: 0.8044129179741017 and parameters: {'max_depth': 10, 'learning_rate': 0.15440599158636403, 'n_estimators': 697}. Best is trial 24 with value: 0.826432220567495.\n","[I 2024-02-16 13:38:58,551] Trial 47 finished with value: 0.8308859414109042 and parameters: {'max_depth': 11, 'learning_rate': 0.6034033282351656, 'n_estimators': 605}. Best is trial 47 with value: 0.8308859414109042.\n","[I 2024-02-16 13:49:33,929] Trial 48 finished with value: 0.7063447968586299 and parameters: {'max_depth': 13, 'learning_rate': 0.000545484296131659, 'n_estimators': 642}. Best is trial 47 with value: 0.8308859414109042.\n","[I 2024-02-16 13:54:05,522] Trial 49 finished with value: 0.8272109203343302 and parameters: {'max_depth': 11, 'learning_rate': 0.5750552237449779, 'n_estimators': 559}. Best is trial 47 with value: 0.8308859414109042.\n"]}]},{"cell_type":"code","source":["study_lgbm.best_params"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1708092068973,"user_tz":-240,"elapsed":305,"user":{"displayName":"Евгений Малов","userId":"06257165098392198337"}},"outputId":"110b9412-d253-4718-cebf-b839286f6a73","id":"g8hD2nyY4nFA"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'max_depth': 11, 'learning_rate': 0.6034033282351656, 'n_estimators': 605}"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["opt_model_lgbm = LGBMClassifier(max_depth=11, learning_rate=0.6034033282351656, n_estimators=605)\n","opt_model_lgbm.fit(x_train, y_train)\n","\n","pred_train = opt_model_lgbm.predict(x_train)\n","pred_test = opt_model_lgbm.predict(x_test)\n","\n","print(f'train: {roc_auc_score(y_train, pred_train)}')\n","print(f'test: {roc_auc_score(y_test, pred_test)}')\n","print(f'test conf matrix: \\n {confusion_matrix(y_test, pred_test)}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1708172961935,"user_tz":-240,"elapsed":119610,"user":{"displayName":"Евгений Малов","userId":"06257165098392198337"}},"outputId":"94b47d32-466f-4e06-f574-9713859147f9","id":"uzTre_JQ4nFB"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 372285, number of negative: 372809\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 4.943093 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 4777\n","[LightGBM] [Info] Number of data points in the train set: 745094, number of used features: 318\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499648 -> initscore=-0.001407\n","[LightGBM] [Info] Start training from score -0.001407\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","train: 0.808015166552359\n","test: 0.7616731056660452\n","test conf matrix: \n"," [[116248  43153]\n"," [ 32934 126991]]\n"]}]},{"cell_type":"code","source":["def objective_xgb(trial):\n","    max_depth = trial.suggest_int(\"max_depth\", 2, 15)\n","    learning_rate = trial.suggest_float(\"learning_rate\", 1e-5, 1, log=True)\n","    n_estimators = trial.suggest_int(\"n_estimators\", 10, 700)\n","\n","    score = cross_val_score(XGBClassifier(max_depth=max_depth, n_estimators=n_estimators,\n","                                              learning_rate=learning_rate),\n","                            x_train, y_train, cv=3, scoring='roc_auc', n_jobs=-1).mean()\n","    return score\n","\n","\n","study_xgb = optuna.create_study(direction=\"maximize\")\n","study_xgb.optimize(objective_xgb, n_trials=50)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"12e10559-50fd-4a70-bc2d-4436c0f524b1","id":"jWWCDQEM4nFC"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[I 2024-02-16 16:27:46,547] A new study created in memory with name: no-name-7e4ba8f2-4ab2-4d8a-896e-2671b53d3abd\n","[I 2024-02-16 16:40:35,789] Trial 0 finished with value: 0.9542581583118661 and parameters: {'max_depth': 13, 'learning_rate': 0.3432994402068103, 'n_estimators': 318}. Best is trial 0 with value: 0.9542581583118661.\n","[I 2024-02-16 16:48:16,414] Trial 1 finished with value: 0.7079673236146614 and parameters: {'max_depth': 7, 'learning_rate': 0.0008987567326865373, 'n_estimators': 224}. Best is trial 0 with value: 0.9542581583118661.\n","[I 2024-02-16 16:53:52,985] Trial 2 finished with value: 0.8950233397984078 and parameters: {'max_depth': 14, 'learning_rate': 0.09864294533105011, 'n_estimators': 85}. Best is trial 0 with value: 0.9542581583118661.\n","[I 2024-02-16 16:59:52,204] Trial 3 finished with value: 0.6933734952086298 and parameters: {'max_depth': 7, 'learning_rate': 2.959850017508347e-05, 'n_estimators': 166}. Best is trial 0 with value: 0.9542581583118661.\n","[I 2024-02-16 17:10:01,549] Trial 4 finished with value: 0.932588478349709 and parameters: {'max_depth': 10, 'learning_rate': 0.981433034685477, 'n_estimators': 326}. Best is trial 0 with value: 0.9542581583118661.\n","[I 2024-02-16 17:16:28,408] Trial 5 finished with value: 0.627700223932386 and parameters: {'max_depth': 2, 'learning_rate': 0.00015285752601776285, 'n_estimators': 378}. Best is trial 0 with value: 0.9542581583118661.\n","[I 2024-02-16 17:21:53,145] Trial 6 finished with value: 0.7402405761186137 and parameters: {'max_depth': 2, 'learning_rate': 0.0673655642454137, 'n_estimators': 329}. Best is trial 0 with value: 0.9542581583118661.\n","[I 2024-02-16 17:29:43,505] Trial 7 finished with value: 0.780370261672648 and parameters: {'max_depth': 12, 'learning_rate': 0.006875795853497208, 'n_estimators': 124}. Best is trial 0 with value: 0.9542581583118661.\n","[I 2024-02-16 18:08:54,756] Trial 8 finished with value: 0.816126392553969 and parameters: {'max_depth': 15, 'learning_rate': 0.0009454798545494328, 'n_estimators': 434}. Best is trial 0 with value: 0.9542581583118661.\n","[I 2024-02-16 18:44:32,563] Trial 9 finished with value: 0.7745448216142631 and parameters: {'max_depth': 12, 'learning_rate': 0.0010432836116962291, 'n_estimators': 611}. Best is trial 0 with value: 0.9542581583118661.\n","[I 2024-02-16 19:00:07,688] Trial 10 finished with value: 0.935945699853658 and parameters: {'max_depth': 9, 'learning_rate': 0.9299078836779641, 'n_estimators': 564}. Best is trial 0 with value: 0.9542581583118661.\n","[I 2024-02-16 19:18:57,353] Trial 11 finished with value: 0.9404013154750915 and parameters: {'max_depth': 9, 'learning_rate': 0.9575605936178612, 'n_estimators': 694}. Best is trial 0 with value: 0.9542581583118661.\n","[I 2024-02-16 19:32:08,236] Trial 12 finished with value: 0.7977545008316543 and parameters: {'max_depth': 6, 'learning_rate': 0.09051985558467364, 'n_estimators': 684}. Best is trial 0 with value: 0.9542581583118661.\n","[I 2024-02-16 19:54:59,238] Trial 13 finished with value: 0.8538567240065024 and parameters: {'max_depth': 12, 'learning_rate': 0.01520868404655083, 'n_estimators': 471}. Best is trial 0 with value: 0.9542581583118661.\n","[I 2024-02-16 20:00:13,720] Trial 14 finished with value: 0.7794000553463917 and parameters: {'max_depth': 5, 'learning_rate': 0.2547115852197114, 'n_estimators': 255}. Best is trial 0 with value: 0.9542581583118661.\n","[I 2024-02-16 20:02:09,721] Trial 15 finished with value: 0.7976968881116379 and parameters: {'max_depth': 10, 'learning_rate': 0.32462989456899777, 'n_estimators': 22}. Best is trial 0 with value: 0.9542581583118661.\n","[I 2024-02-16 20:26:31,848] Trial 16 finished with value: 0.8921132827700857 and parameters: {'max_depth': 13, 'learning_rate': 0.02294036184500839, 'n_estimators': 518}. Best is trial 0 with value: 0.9542581583118661.\n","[I 2024-02-16 20:37:29,217] Trial 17 finished with value: 0.785490138652574 and parameters: {'max_depth': 4, 'learning_rate': 0.27392610937212286, 'n_estimators': 696}. Best is trial 0 with value: 0.9542581583118661.\n","[I 2024-02-16 20:52:36,065] Trial 18 finished with value: 0.8231676478490219 and parameters: {'max_depth': 10, 'learning_rate': 0.02439935467170152, 'n_estimators': 410}. Best is trial 0 with value: 0.9542581583118661.\n","[I 2024-02-16 21:02:10,032] Trial 19 finished with value: 0.7005977528202526 and parameters: {'max_depth': 8, 'learning_rate': 1.1559988954341942e-05, 'n_estimators': 241}. Best is trial 0 with value: 0.9542581583118661.\n","[I 2024-02-16 21:55:36,577] Trial 20 finished with value: 0.8616511321053512 and parameters: {'max_depth': 15, 'learning_rate': 0.0030940896365431484, 'n_estimators': 602}. Best is trial 0 with value: 0.9542581583118661.\n","[I 2024-02-16 22:11:03,094] Trial 21 finished with value: 0.9357348205999395 and parameters: {'max_depth': 9, 'learning_rate': 0.9177051824052117, 'n_estimators': 569}. Best is trial 0 with value: 0.9542581583118661.\n","[I 2024-02-16 22:28:08,738] Trial 22 finished with value: 0.9539852007075561 and parameters: {'max_depth': 11, 'learning_rate': 0.6246169633376519, 'n_estimators': 526}. Best is trial 0 with value: 0.9542581583118661.\n","[I 2024-02-16 22:42:31,303] Trial 23 finished with value: 0.941452118679242 and parameters: {'max_depth': 11, 'learning_rate': 0.2791027027157458, 'n_estimators': 483}. Best is trial 0 with value: 0.9542581583118661.\n","[I 2024-02-16 22:56:41,115] Trial 24 finished with value: 0.9283044026845486 and parameters: {'max_depth': 11, 'learning_rate': 0.18166308129467432, 'n_estimators': 495}. Best is trial 0 with value: 0.9542581583118661.\n"]}]},{"cell_type":"code","source":["study_xgb.best_params"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1707840921381,"user_tz":-240,"elapsed":342,"user":{"displayName":"Евгений Малов","userId":"06257165098392198337"}},"outputId":"17bfa07f-45cc-40dd-fa56-edfa3b2883ff","id":"ddzBiBPM4nFD"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'max_depth': 9, 'learning_rate': 0.03213090007171616, 'n_estimators': 588}"]},"metadata":{},"execution_count":17}]},{"cell_type":"markdown","source":["Trial 3 finished with value: 0.9588921870299 and parameters: {'max_depth': 12, 'learning_rate': 0.47555557015719635, 'n_estimators': 539}. Best is trial 3 with value: 0.9588921870299."],"metadata":{"id":"fZsu3oMPvKez"}},{"cell_type":"markdown","source":["Trial 0 finished with value: 0.9542581583118661 and parameters: {'max_depth': 13, 'learning_rate': 0.3432994402068103, 'n_estimators': 318}. Best is trial 0 with value: 0.9542581583118661"],"metadata":{"id":"APXzHWvKkJ7O"}},{"cell_type":"code","source":["opt_model_xgb = XGBClassifier(max_depth=12, learning_rate=0.47555557015719635, n_estimators=539)\n","opt_model_xgb.fit(x_train, y_train)\n","\n","pred_train = opt_model_xgb.predict(x_train)\n","pred_test = opt_model_xgb.predict(x_test)\n","\n","print(f'train: {roc_auc_score(y_train, pred_train)}')\n","print(f'test: {roc_auc_score(y_test, pred_test)}')\n","print(f'test conf matrix: \\n {confusion_matrix(y_test, pred_test)}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1708173447606,"user_tz":-240,"elapsed":428989,"user":{"displayName":"Евгений Малов","userId":"06257165098392198337"}},"outputId":"ef57c85b-28a8-493d-819d-7a25348b9510","id":"eJ2p5w5o4nFE"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["train: 0.9918892523147078\n","test: 0.9306357385246855\n","test conf matrix: \n"," [[141709  17692]\n"," [  4436 155489]]\n"]}]},{"cell_type":"code","source":["def objective_catboost(trial):\n","    max_depth = trial.suggest_int(\"max_depth\", 2, 15)\n","    learning_rate = trial.suggest_float(\"learning_rate\", 1e-3, 1, log=True)\n","    n_estimators = trial.suggest_int(\"n_estimators\", 10, 700)\n","    l2_leaf_reg = trial.suggest_int('l2_leaf_reg', 1, 5)\n","\n","    score = cross_val_score(CatBoostClassifier(max_depth=max_depth, n_estimators=n_estimators,\n","                                              learning_rate=learning_rate, l2_leaf_reg=l2_leaf_reg),\n","                            x_train, y_train, cv=3, scoring='roc_auc', n_jobs=-1).mean()\n","    return score\n","\n","\n","study_catboost = optuna.create_study(direction=\"maximize\")\n","study_catboost.optimize(objective_catboost, n_trials=50)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"3266cacb-256e-4de5-c3cc-d5b367597c0b","id":"nOKKHsu34nFF"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[I 2024-02-17 09:49:52,615] A new study created in memory with name: no-name-a3a6ccc0-6ac7-445f-aa67-8e0c4d5525d7\n","[I 2024-02-17 09:55:53,757] Trial 0 finished with value: 0.7464693290135433 and parameters: {'max_depth': 5, 'learning_rate': 0.03995865295667124, 'n_estimators': 318, 'l2_leaf_reg': 3}. Best is trial 0 with value: 0.7464693290135433.\n","[I 2024-02-17 10:00:39,327] Trial 1 finished with value: 0.7678605975285326 and parameters: {'max_depth': 5, 'learning_rate': 0.34394516285884064, 'n_estimators': 265, 'l2_leaf_reg': 2}. Best is trial 1 with value: 0.7678605975285326.\n","[I 2024-02-17 10:03:22,550] Trial 2 finished with value: 0.7569219268910091 and parameters: {'max_depth': 3, 'learning_rate': 0.6272387432095053, 'n_estimators': 183, 'l2_leaf_reg': 3}. Best is trial 1 with value: 0.7678605975285326.\n","[I 2024-02-17 10:10:02,664] Trial 3 finished with value: 0.7411036388616038 and parameters: {'max_depth': 14, 'learning_rate': 0.010761621533003076, 'n_estimators': 39, 'l2_leaf_reg': 1}. Best is trial 1 with value: 0.7678605975285326.\n","[I 2024-02-17 10:12:47,771] Trial 4 finished with value: 0.7079775972743324 and parameters: {'max_depth': 2, 'learning_rate': 0.019977559835355346, 'n_estimators': 200, 'l2_leaf_reg': 2}. Best is trial 1 with value: 0.7678605975285326.\n","[I 2024-02-17 10:22:33,582] Trial 5 finished with value: 0.7935776726618927 and parameters: {'max_depth': 6, 'learning_rate': 0.709389404689928, 'n_estimators': 511, 'l2_leaf_reg': 2}. Best is trial 5 with value: 0.7935776726618927.\n","[I 2024-02-17 10:29:09,256] Trial 6 finished with value: 0.746682100995906 and parameters: {'max_depth': 4, 'learning_rate': 0.04351006013402569, 'n_estimators': 398, 'l2_leaf_reg': 3}. Best is trial 5 with value: 0.7935776726618927.\n","[I 2024-02-17 12:11:23,951] Trial 7 finished with value: 0.7597104434247939 and parameters: {'max_depth': 14, 'learning_rate': 0.0019648251369964185, 'n_estimators': 618, 'l2_leaf_reg': 1}. Best is trial 5 with value: 0.7935776726618927.\n"]}]},{"cell_type":"code","source":["study_catboost.best_params"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":175},"executionInfo":{"status":"error","timestamp":1707851952962,"user_tz":-240,"elapsed":321,"user":{"displayName":"Евгений Малов","userId":"06257165098392198337"}},"outputId":"c3991fbf-c53d-45d3-ecce-6532e6776b01","id":"6v66YGql4nFG"},"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'study_catboost' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-5636397f39e1>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mstudy_catboost\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'study_catboost' is not defined"]}]},{"cell_type":"markdown","source":["Trial 5 finished with value: 0.7935776726618927 and parameters: {'max_depth': 6, 'learning_rate': 0.709389404689928, 'n_estimators': 511, 'l2_leaf_reg': 2}. Best is trial 5 with value: 0.7935776726618927."],"metadata":{"id":"tzyM0-7D4nFH"}},{"cell_type":"code","source":["opt_model_catb = CatBoostClassifier(max_depth=6, learning_rate=0.709389404689928, n_estimators=511, l2_leaf_reg=2, verbose=False)\n","opt_model_catb.fit(x_train, y_train)\n","\n","pred_train = opt_model_catb.predict(x_train)\n","pred_test = opt_model_catb.predict(x_test)\n","\n","print(f'train: {roc_auc_score(y_train, pred_train)}')\n","print(f'test: {roc_auc_score(y_test, pred_test)}')\n","print(f'test conf matrix: \\n {confusion_matrix(y_test, pred_test)}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1708173781421,"user_tz":-240,"elapsed":297332,"user":{"displayName":"Евгений Малов","userId":"06257165098392198337"}},"outputId":"d164d112-1557-4848-8d0c-8336f927a182","id":"qEVffVeh4nFI"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["train: 0.7521043415235962\n","test: 0.7267705641786496\n","test conf matrix: \n"," [[112726  46675]\n"," [ 40564 119361]]\n"]}]},{"cell_type":"code","source":["# обучение дефолтных моделей\n","estimators = [\n","    ('lgbm', model_lgbm),\n","    ('xgb', model_xbm),\n","    ('cb', model_catb)\n","    ]\n","\n","reg = StackingClassifier(\n","    estimators=estimators,\n","    final_estimator=GradientBoostingClassifier(learning_rate = 0.02, n_estimators = 100, random_state=42))\n","\n","reg.fit(x_train, y_train)\n","pred_train = reg.predict(x_train)\n","pred_test = reg.predict(x_test)\n","\n","print(f'train: {roc_auc_score(y_train, pred_train)}')\n","print(f'test: {roc_auc_score(y_test, pred_test)}')\n","print(f'test conf matrix: \\n {confusion_matrix(y_test, pred_test)}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VY-UeTTMA2hN","executionInfo":{"status":"ok","timestamp":1708026371431,"user_tz":-240,"elapsed":13193,"user":{"displayName":"Евгений Малов","userId":"06257165098392198337"}},"outputId":"4bc17f81-5bec-4097-84ba-9ba4c8065ddc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[LightGBM] [Info] Number of positive: 372285, number of negative: 372809\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 2.796399 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 4777\n","[LightGBM] [Info] Number of data points in the train set: 745094, number of used features: 318\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499648 -> initscore=-0.001407\n","[LightGBM] [Info] Start training from score -0.001407\n","[LightGBM] [Info] Number of positive: 297828, number of negative: 298247\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 2.789601 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 4741\n","[LightGBM] [Info] Number of data points in the train set: 596075, number of used features: 317\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499649 -> initscore=-0.001406\n","[LightGBM] [Info] Start training from score -0.001406\n","[LightGBM] [Info] Number of positive: 297828, number of negative: 298247\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 3.003478 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 4745\n","[LightGBM] [Info] Number of data points in the train set: 596075, number of used features: 317\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499649 -> initscore=-0.001406\n","[LightGBM] [Info] Start training from score -0.001406\n","[LightGBM] [Info] Number of positive: 297828, number of negative: 298247\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 2.911425 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 4758\n","[LightGBM] [Info] Number of data points in the train set: 596075, number of used features: 317\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499649 -> initscore=-0.001406\n","[LightGBM] [Info] Start training from score -0.001406\n","[LightGBM] [Info] Number of positive: 297828, number of negative: 298247\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 2.703793 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 4763\n","[LightGBM] [Info] Number of data points in the train set: 596075, number of used features: 316\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499649 -> initscore=-0.001406\n","[LightGBM] [Info] Start training from score -0.001406\n","[LightGBM] [Info] Number of positive: 297828, number of negative: 298248\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 2.399994 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 4762\n","[LightGBM] [Info] Number of data points in the train set: 596076, number of used features: 316\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499648 -> initscore=-0.001409\n","[LightGBM] [Info] Start training from score -0.001409\n","train: 0.7410592224104986\n","test: 0.7241814129383317\n","test conf matrix: \n"," [[109033  50368]\n"," [ 37687 122238]]\n"]}]},{"cell_type":"code","source":["# обучение моделей с подобранными гиперпараметрами, все 3 модели\n","estimators = [\n","    ('lgbm', opt_model_lgbm),\n","    ('xgb', opt_model_xgb),\n","    ('cb', opt_model_catb)\n","    ]\n","\n","reg = StackingClassifier(\n","    estimators=estimators,\n","    final_estimator=GradientBoostingClassifier(learning_rate = 0.02, n_estimators = 100, random_state=42))\n","\n","reg.fit(x_train, y_train)\n","pred_train = reg.predict(x_train)\n","pred_test = reg.predict(x_test)\n","\n","print(f'train: {roc_auc_score(y_train, pred_train)}')\n","print(f'test: {roc_auc_score(y_test, pred_test)}')\n","print(f'test conf matrix: \\n {confusion_matrix(y_test, pred_test)}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1708178220732,"user_tz":-240,"elapsed":4147579,"user":{"displayName":"Евгений Малов","userId":"06257165098392198337"}},"outputId":"1e07bf38-4181-4fc1-b9c4-9295c17385e7","id":"dTRAga5g4nFJ"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 372285, number of negative: 372809\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 2.022611 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 4777\n","[LightGBM] [Info] Number of data points in the train set: 745094, number of used features: 318\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499648 -> initscore=-0.001407\n","[LightGBM] [Info] Start training from score -0.001407\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 297828, number of negative: 298247\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.624810 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 4741\n","[LightGBM] [Info] Number of data points in the train set: 596075, number of used features: 317\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499649 -> initscore=-0.001406\n","[LightGBM] [Info] Start training from score -0.001406\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 297828, number of negative: 298247\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.744717 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 4745\n","[LightGBM] [Info] Number of data points in the train set: 596075, number of used features: 317\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499649 -> initscore=-0.001406\n","[LightGBM] [Info] Start training from score -0.001406\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 297828, number of negative: 298247\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.668507 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 4758\n","[LightGBM] [Info] Number of data points in the train set: 596075, number of used features: 317\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499649 -> initscore=-0.001406\n","[LightGBM] [Info] Start training from score -0.001406\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 297828, number of negative: 298247\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.650238 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 4763\n","[LightGBM] [Info] Number of data points in the train set: 596075, number of used features: 316\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499649 -> initscore=-0.001406\n","[LightGBM] [Info] Start training from score -0.001406\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 297828, number of negative: 298248\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.639613 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 4762\n","[LightGBM] [Info] Number of data points in the train set: 596076, number of used features: 316\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499648 -> initscore=-0.001409\n","[LightGBM] [Info] Start training from score -0.001409\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","train: 0.983871778022353\n","test: 0.943056030744661\n","test conf matrix: \n"," [[151331   8070]\n"," [ 10117 149808]]\n"]}]},{"cell_type":"code","source":["with open(os.path.join(path, f'up_ds_3_models.pkl'), 'wb') as file:\n","    dill.dump(reg, file)"],"metadata":{"id":"7aMW3w1pXCca"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["with open(path + '/up_ds_3_models.pkl', 'rb') as file:\n","    model = dill.load(file)\n","model"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":164},"id":"vpyAG0sEXCpX","executionInfo":{"status":"ok","timestamp":1708178791158,"user_tz":-240,"elapsed":297,"user":{"displayName":"Евгений Малов","userId":"06257165098392198337"}},"outputId":"5d6a27e5-38d5-48af-af08-f9e324481f54"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["StackingClassifier(estimators=[('lgbm',\n","                                LGBMClassifier(learning_rate=0.6034033282351656,\n","                                               max_depth=11,\n","                                               n_estimators=605)),\n","                               ('xgb',\n","                                XGBClassifier(base_score=None, booster=None,\n","                                              callbacks=None,\n","                                              colsample_bylevel=None,\n","                                              colsample_bynode=None,\n","                                              colsample_bytree=None,\n","                                              device=None,\n","                                              early_stopping_rounds=None,\n","                                              enable_categorical=False,\n","                                              eval_metric=None,\n","                                              feature_types=None...\n","                                              max_cat_to_onehot=None,\n","                                              max_delta_step=None, max_depth=12,\n","                                              max_leaves=None,\n","                                              min_child_weight=None,\n","                                              missing=nan,\n","                                              monotone_constraints=None,\n","                                              multi_strategy=None,\n","                                              n_estimators=539, n_jobs=None,\n","                                              num_parallel_tree=None,\n","                                              random_state=None, ...)),\n","                               ('cb',\n","                                <catboost.core.CatBoostClassifier object at 0x783d83a96410>)],\n","                   final_estimator=GradientBoostingClassifier(learning_rate=0.02,\n","                                                              random_state=42))"],"text/html":["<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>StackingClassifier(estimators=[(&#x27;lgbm&#x27;,\n","                                LGBMClassifier(learning_rate=0.6034033282351656,\n","                                               max_depth=11,\n","                                               n_estimators=605)),\n","                               (&#x27;xgb&#x27;,\n","                                XGBClassifier(base_score=None, booster=None,\n","                                              callbacks=None,\n","                                              colsample_bylevel=None,\n","                                              colsample_bynode=None,\n","                                              colsample_bytree=None,\n","                                              device=None,\n","                                              early_stopping_rounds=None,\n","                                              enable_categorical=False,\n","                                              eval_metric=None,\n","                                              feature_types=None...\n","                                              max_cat_to_onehot=None,\n","                                              max_delta_step=None, max_depth=12,\n","                                              max_leaves=None,\n","                                              min_child_weight=None,\n","                                              missing=nan,\n","                                              monotone_constraints=None,\n","                                              multi_strategy=None,\n","                                              n_estimators=539, n_jobs=None,\n","                                              num_parallel_tree=None,\n","                                              random_state=None, ...)),\n","                               (&#x27;cb&#x27;,\n","                                &lt;catboost.core.CatBoostClassifier object at 0x783d83a96410&gt;)],\n","                   final_estimator=GradientBoostingClassifier(learning_rate=0.02,\n","                                                              random_state=42))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StackingClassifier</label><div class=\"sk-toggleable__content\"><pre>StackingClassifier(estimators=[(&#x27;lgbm&#x27;,\n","                                LGBMClassifier(learning_rate=0.6034033282351656,\n","                                               max_depth=11,\n","                                               n_estimators=605)),\n","                               (&#x27;xgb&#x27;,\n","                                XGBClassifier(base_score=None, booster=None,\n","                                              callbacks=None,\n","                                              colsample_bylevel=None,\n","                                              colsample_bynode=None,\n","                                              colsample_bytree=None,\n","                                              device=None,\n","                                              early_stopping_rounds=None,\n","                                              enable_categorical=False,\n","                                              eval_metric=None,\n","                                              feature_types=None...\n","                                              max_cat_to_onehot=None,\n","                                              max_delta_step=None, max_depth=12,\n","                                              max_leaves=None,\n","                                              min_child_weight=None,\n","                                              missing=nan,\n","                                              monotone_constraints=None,\n","                                              multi_strategy=None,\n","                                              n_estimators=539, n_jobs=None,\n","                                              num_parallel_tree=None,\n","                                              random_state=None, ...)),\n","                               (&#x27;cb&#x27;,\n","                                &lt;catboost.core.CatBoostClassifier object at 0x783d83a96410&gt;)],\n","                   final_estimator=GradientBoostingClassifier(learning_rate=0.02,\n","                                                              random_state=42))</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>lgbm</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(learning_rate=0.6034033282351656, max_depth=11, n_estimators=605)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>xgb</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n","              colsample_bylevel=None, colsample_bynode=None,\n","              colsample_bytree=None, device=None, early_stopping_rounds=None,\n","              enable_categorical=False, eval_metric=None, feature_types=None,\n","              gamma=None, grow_policy=None, importance_type=None,\n","              interaction_constraints=None, learning_rate=0.47555557015719635,\n","              max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n","              max_delta_step=None, max_depth=12, max_leaves=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              multi_strategy=None, n_estimators=539, n_jobs=None,\n","              num_parallel_tree=None, random_state=None, ...)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>cb</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CatBoostClassifier</label><div class=\"sk-toggleable__content\"><pre>&lt;catboost.core.CatBoostClassifier object at 0x783d83a96410&gt;</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>final_estimator</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier(learning_rate=0.02, random_state=42)</pre></div></div></div></div></div></div></div></div></div></div></div></div>"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","source":["# обучение моделей с подобранными гиперпараметрами, ТОЛЬКО lgbm + xgb\n","estimators = [\n","    ('lgbm', opt_model_lgbm),\n","    ('xgb', opt_model_xgb)\n","    ]\n","\n","reg = StackingClassifier(\n","    estimators=estimators,\n","    final_estimator=GradientBoostingClassifier(learning_rate = 0.02, n_estimators = 100, random_state=42))\n","\n","reg.fit(x_train, y_train)\n","pred_train = reg.predict(x_train)\n","pred_test = reg.predict(x_test)\n","\n","print(f'train: {roc_auc_score(y_train, pred_train)}')\n","print(f'test: {roc_auc_score(y_test, pred_test)}')\n","print(f'test conf matrix: \\n {confusion_matrix(y_test, pred_test)}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2YkRYj2kaXc1","executionInfo":{"status":"ok","timestamp":1708181816503,"user_tz":-240,"elapsed":1167855,"user":{"displayName":"Евгений Малов","userId":"06257165098392198337"}},"outputId":"fb5ac2a6-836a-4b37-d84c-27b36bbcbe1e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 372285, number of negative: 372809\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 2.004785 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 4777\n","[LightGBM] [Info] Number of data points in the train set: 745094, number of used features: 318\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499648 -> initscore=-0.001407\n","[LightGBM] [Info] Start training from score -0.001407\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 297828, number of negative: 298247\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.648818 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 4741\n","[LightGBM] [Info] Number of data points in the train set: 596075, number of used features: 317\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499649 -> initscore=-0.001406\n","[LightGBM] [Info] Start training from score -0.001406\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 297828, number of negative: 298247\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.985949 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 4745\n","[LightGBM] [Info] Number of data points in the train set: 596075, number of used features: 317\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499649 -> initscore=-0.001406\n","[LightGBM] [Info] Start training from score -0.001406\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 297828, number of negative: 298247\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.678743 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 4758\n","[LightGBM] [Info] Number of data points in the train set: 596075, number of used features: 317\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499649 -> initscore=-0.001406\n","[LightGBM] [Info] Start training from score -0.001406\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 297828, number of negative: 298247\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.668545 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 4763\n","[LightGBM] [Info] Number of data points in the train set: 596075, number of used features: 316\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499649 -> initscore=-0.001406\n","[LightGBM] [Info] Start training from score -0.001406\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 297828, number of negative: 298248\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.959254 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 4762\n","[LightGBM] [Info] Number of data points in the train set: 596076, number of used features: 316\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499648 -> initscore=-0.001409\n","[LightGBM] [Info] Start training from score -0.001409\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","train: 0.9846536429973801\n","test: 0.9432536373469469\n","test conf matrix: \n"," [[151089   8312]\n"," [  9811 150114]]\n"]}]},{"cell_type":"code","source":["with open(os.path.join(path, f'up_ds_ONLY2_models.pkl'), 'wb') as file:\n","    dill.dump(reg, file)"],"metadata":{"id":"VzD2hndodWnl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["with open(path + '/up_ds_ONLY2_models.pkl', 'rb') as file:\n","    model_xgb_lgbm = dill.load(file)\n","model_xgb_lgbm"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":164},"executionInfo":{"status":"ok","timestamp":1708181921271,"user_tz":-240,"elapsed":729,"user":{"displayName":"Евгений Малов","userId":"06257165098392198337"}},"outputId":"af102dd3-0b9e-4043-f129-3470bbf56714","id":"QBo80HFNdWnl"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["StackingClassifier(estimators=[('lgbm',\n","                                LGBMClassifier(learning_rate=0.6034033282351656,\n","                                               max_depth=11,\n","                                               n_estimators=605)),\n","                               ('xgb',\n","                                XGBClassifier(base_score=None, booster=None,\n","                                              callbacks=None,\n","                                              colsample_bylevel=None,\n","                                              colsample_bynode=None,\n","                                              colsample_bytree=None,\n","                                              device=None,\n","                                              early_stopping_rounds=None,\n","                                              enable_categorical=False,\n","                                              eval_metric=None,\n","                                              feature_types=None...\n","                                              learning_rate=0.47555557015719635,\n","                                              max_bin=None,\n","                                              max_cat_threshold=None,\n","                                              max_cat_to_onehot=None,\n","                                              max_delta_step=None, max_depth=12,\n","                                              max_leaves=None,\n","                                              min_child_weight=None,\n","                                              missing=nan,\n","                                              monotone_constraints=None,\n","                                              multi_strategy=None,\n","                                              n_estimators=539, n_jobs=None,\n","                                              num_parallel_tree=None,\n","                                              random_state=None, ...))],\n","                   final_estimator=GradientBoostingClassifier(learning_rate=0.02,\n","                                                              random_state=42))"],"text/html":["<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>StackingClassifier(estimators=[(&#x27;lgbm&#x27;,\n","                                LGBMClassifier(learning_rate=0.6034033282351656,\n","                                               max_depth=11,\n","                                               n_estimators=605)),\n","                               (&#x27;xgb&#x27;,\n","                                XGBClassifier(base_score=None, booster=None,\n","                                              callbacks=None,\n","                                              colsample_bylevel=None,\n","                                              colsample_bynode=None,\n","                                              colsample_bytree=None,\n","                                              device=None,\n","                                              early_stopping_rounds=None,\n","                                              enable_categorical=False,\n","                                              eval_metric=None,\n","                                              feature_types=None...\n","                                              learning_rate=0.47555557015719635,\n","                                              max_bin=None,\n","                                              max_cat_threshold=None,\n","                                              max_cat_to_onehot=None,\n","                                              max_delta_step=None, max_depth=12,\n","                                              max_leaves=None,\n","                                              min_child_weight=None,\n","                                              missing=nan,\n","                                              monotone_constraints=None,\n","                                              multi_strategy=None,\n","                                              n_estimators=539, n_jobs=None,\n","                                              num_parallel_tree=None,\n","                                              random_state=None, ...))],\n","                   final_estimator=GradientBoostingClassifier(learning_rate=0.02,\n","                                                              random_state=42))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StackingClassifier</label><div class=\"sk-toggleable__content\"><pre>StackingClassifier(estimators=[(&#x27;lgbm&#x27;,\n","                                LGBMClassifier(learning_rate=0.6034033282351656,\n","                                               max_depth=11,\n","                                               n_estimators=605)),\n","                               (&#x27;xgb&#x27;,\n","                                XGBClassifier(base_score=None, booster=None,\n","                                              callbacks=None,\n","                                              colsample_bylevel=None,\n","                                              colsample_bynode=None,\n","                                              colsample_bytree=None,\n","                                              device=None,\n","                                              early_stopping_rounds=None,\n","                                              enable_categorical=False,\n","                                              eval_metric=None,\n","                                              feature_types=None...\n","                                              learning_rate=0.47555557015719635,\n","                                              max_bin=None,\n","                                              max_cat_threshold=None,\n","                                              max_cat_to_onehot=None,\n","                                              max_delta_step=None, max_depth=12,\n","                                              max_leaves=None,\n","                                              min_child_weight=None,\n","                                              missing=nan,\n","                                              monotone_constraints=None,\n","                                              multi_strategy=None,\n","                                              n_estimators=539, n_jobs=None,\n","                                              num_parallel_tree=None,\n","                                              random_state=None, ...))],\n","                   final_estimator=GradientBoostingClassifier(learning_rate=0.02,\n","                                                              random_state=42))</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>lgbm</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(learning_rate=0.6034033282351656, max_depth=11, n_estimators=605)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>xgb</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n","              colsample_bylevel=None, colsample_bynode=None,\n","              colsample_bytree=None, device=None, early_stopping_rounds=None,\n","              enable_categorical=False, eval_metric=None, feature_types=None,\n","              gamma=None, grow_policy=None, importance_type=None,\n","              interaction_constraints=None, learning_rate=0.47555557015719635,\n","              max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n","              max_delta_step=None, max_depth=12, max_leaves=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              multi_strategy=None, n_estimators=539, n_jobs=None,\n","              num_parallel_tree=None, random_state=None, ...)</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>final_estimator</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier(learning_rate=0.02, random_state=42)</pre></div></div></div></div></div></div></div></div></div></div></div></div>"]},"metadata":{},"execution_count":20}]},{"cell_type":"markdown","source":["## Downsampl + SMOTE"],"metadata":{"id":"Rylp2PwJlHG2"}},{"cell_type":"code","source":["x_train = pd.read_parquet(path + '/smote_x_train.parquet').drop('id', axis=1)\n","x_test = pd.read_parquet(path + '/smote_x_test.parquet').drop('id', axis=1)\n","y_train = pd.read_parquet(path + '/smote_y_train.parquet').drop('id', axis=1)\n","y_test = pd.read_parquet(path + '/smote_y_test.parquet').drop('id', axis=1)"],"metadata":{"id":"k8JQKhE8Ki5k"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["x_train.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1708275797080,"user_tz":-240,"elapsed":271,"user":{"displayName":"Евгений Малов","userId":"06257165098392198337"}},"outputId":"056f8f25-eff6-4d50-f316-c11ed02ea52c","id":"9ye02gZvKi5o"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(447056, 337)"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["model_log_reg = LogisticRegression()\n","model_log_reg.fit(x_train, y_train)\n","\n","pred_train = model_log_reg.predict(x_train)\n","pred_test = model_log_reg.predict(x_test)\n","\n","print(f'train: {roc_auc_score(y_train, pred_train)}')\n","print(f'test: {roc_auc_score(y_test, pred_test)}')\n","print(f'test conf matrix: \\n {confusion_matrix(y_test, pred_test)}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1708275857389,"user_tz":-240,"elapsed":51665,"user":{"displayName":"Евгений Малов","userId":"06257165098392198337"}},"outputId":"83c4674e-e644-4478-8108-9c7f8ac05302","id":"UttC5u72Ki5r"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["train: 0.8373166238289429\n","test: 0.8374553978508928\n","test conf matrix: \n"," [[91533  3959]\n"," [27258 68846]]\n"]}]},{"cell_type":"code","source":["model_lgbm = LGBMClassifier()\n","model_lgbm.fit(x_train, y_train)\n","\n","pred_train = model_lgbm.predict(x_train)\n","pred_test = model_lgbm.predict(x_test)\n","\n","print(f'train: {roc_auc_score(y_train, pred_train)}')\n","print(f'test: {roc_auc_score(y_test, pred_test)}')\n","print(f'test conf matrix: \\n {confusion_matrix(y_test, pred_test)}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1708275933110,"user_tz":-240,"elapsed":53963,"user":{"displayName":"Евгений Малов","userId":"06257165098392198337"}},"outputId":"8b8a94ed-f0cd-4a99-d17f-1fcd4b81744c","id":"EaP9nD5rKi5t"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[LightGBM] [Info] Number of positive: 223222, number of negative: 223834\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.436644 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 5108\n","[LightGBM] [Info] Number of data points in the train set: 447056, number of used features: 310\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499316 -> initscore=-0.002738\n","[LightGBM] [Info] Start training from score -0.002738\n","train: 0.8292421405073974\n","test: 0.8271749978762065\n","test conf matrix: \n"," [[87324  8168]\n"," [24998 71106]]\n"]}]},{"cell_type":"code","source":["model_xbm = XGBClassifier()\n","model_xbm.fit(x_train, y_train)\n","\n","pred_train = model_xbm.predict(x_train)\n","pred_test = model_xbm.predict(x_test)\n","\n","print(f'train: {roc_auc_score(y_train, pred_train)}')\n","print(f'test: {roc_auc_score(y_test, pred_test)}')\n","print(f'test conf matrix: \\n {confusion_matrix(y_test, pred_test)}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1708276017769,"user_tz":-240,"elapsed":70678,"user":{"displayName":"Евгений Малов","userId":"06257165098392198337"}},"outputId":"3737e740-6301-400e-dd62-724b678c8a7e","id":"hvvWTtpuKi5w"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["train: 0.8520549191605011\n","test: 0.8343065049445572\n","test conf matrix: \n"," [[85878  9614]\n"," [22172 73932]]\n"]}]},{"cell_type":"code","source":["model_catb = CatBoostClassifier(verbose=False)\n","model_catb.fit(x_train, y_train)\n","\n","pred_train = model_catb.predict(x_train)\n","pred_test = model_catb.predict(x_test)\n","\n","print(f'train: {roc_auc_score(y_train, pred_train)}')\n","print(f'test: {roc_auc_score(y_test, pred_test)}')\n","print(f'test conf matrix: \\n {confusion_matrix(y_test, pred_test)}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1708276577268,"user_tz":-240,"elapsed":547608,"user":{"displayName":"Евгений Малов","userId":"06257165098392198337"}},"outputId":"516af271-1109-427b-de72-35cdd6bebf6a","id":"LtNPYlrOKi5y"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["train: 0.8594988042210179\n","test: 0.8438834158473144\n","test conf matrix: \n"," [[88805  6687]\n"," [23277 72827]]\n"]}]},{"cell_type":"code","source":["def objective_lgbm(trial):\n","    max_depth = trial.suggest_int(\"max_depth\", 2, 15)\n","    learning_rate = trial.suggest_float(\"learning_rate\", 1e-5, 1, log=True)\n","    n_estimators = trial.suggest_int(\"n_estimators\", 10, 700)\n","\n","    score = cross_val_score(LGBMClassifier(max_depth=max_depth, learning_rate=learning_rate, n_estimators=n_estimators),\n","                            x_train, y_train, cv=3, scoring='roc_auc', n_jobs=-1).mean()\n","    return score\n","\n","\n","study_lgbm = optuna.create_study(direction=\"maximize\")\n","study_lgbm.optimize(objective_lgbm, n_trials=50)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1708294048508,"user_tz":-240,"elapsed":2308670,"user":{"displayName":"Евгений Малов","userId":"06257165098392198337"}},"outputId":"ad496e81-b818-404a-8381-e4b281a365dd","id":"lfZDbN4eKi50"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[I 2024-02-18 18:13:25,604] A new study created in memory with name: no-name-8b11fba2-57f0-49c6-8840-b232487e666e\n","[I 2024-02-18 18:16:50,706] Trial 0 finished with value: 0.9033066884256625 and parameters: {'max_depth': 8, 'learning_rate': 0.050659651556013804, 'n_estimators': 305}. Best is trial 0 with value: 0.9033066884256625.\n","[I 2024-02-18 18:17:36,904] Trial 1 finished with value: 0.6774602895396532 and parameters: {'max_depth': 2, 'learning_rate': 0.0023561395118358325, 'n_estimators': 81}. Best is trial 0 with value: 0.9033066884256625.\n","[I 2024-02-18 18:18:40,891] Trial 2 finished with value: 0.713330387682892 and parameters: {'max_depth': 2, 'learning_rate': 0.00436098905694216, 'n_estimators': 163}. Best is trial 0 with value: 0.9033066884256625.\n","[I 2024-02-18 18:23:09,503] Trial 3 finished with value: 0.7561589913063281 and parameters: {'max_depth': 15, 'learning_rate': 4.4720764855335824e-05, 'n_estimators': 410}. Best is trial 0 with value: 0.9033066884256625.\n","[I 2024-02-18 18:25:12,316] Trial 4 finished with value: 0.7585408672577317 and parameters: {'max_depth': 7, 'learning_rate': 0.0007874162320112293, 'n_estimators': 194}. Best is trial 0 with value: 0.9033066884256625.\n","[I 2024-02-18 18:26:15,069] Trial 5 finished with value: 0.7424966515077575 and parameters: {'max_depth': 9, 'learning_rate': 0.0004106586784869402, 'n_estimators': 61}. Best is trial 0 with value: 0.9033066884256625.\n","[I 2024-02-18 18:30:51,093] Trial 6 finished with value: 0.9116404744568251 and parameters: {'max_depth': 11, 'learning_rate': 0.07584533428122724, 'n_estimators': 445}. Best is trial 6 with value: 0.9116404744568251.\n","[I 2024-02-18 18:33:34,549] Trial 7 finished with value: 0.7578026801732594 and parameters: {'max_depth': 10, 'learning_rate': 0.00021090939296253378, 'n_estimators': 203}. Best is trial 6 with value: 0.9116404744568251.\n","[I 2024-02-18 18:40:54,757] Trial 8 finished with value: 0.8948369104738981 and parameters: {'max_depth': 12, 'learning_rate': 0.013003731909606905, 'n_estimators': 635}. Best is trial 6 with value: 0.9116404744568251.\n","[I 2024-02-18 18:41:57,741] Trial 9 finished with value: 0.6874194996418076 and parameters: {'max_depth': 3, 'learning_rate': 0.00021730491472234342, 'n_estimators': 124}. Best is trial 6 with value: 0.9116404744568251.\n","[I 2024-02-18 18:45:24,120] Trial 10 finished with value: 0.886824872697355 and parameters: {'max_depth': 15, 'learning_rate': 0.8824724411690622, 'n_estimators': 545}. Best is trial 6 with value: 0.9116404744568251.\n","[I 2024-02-18 18:49:05,792] Trial 11 finished with value: 0.9078182845918343 and parameters: {'max_depth': 6, 'learning_rate': 0.07567213410141631, 'n_estimators': 364}. Best is trial 6 with value: 0.9116404744568251.\n","[I 2024-02-18 18:52:35,270] Trial 12 finished with value: 0.9111450916725682 and parameters: {'max_depth': 5, 'learning_rate': 0.1517081619602805, 'n_estimators': 440}. Best is trial 6 with value: 0.9116404744568251.\n","[I 2024-02-18 18:55:43,347] Trial 13 finished with value: 0.8942967543929754 and parameters: {'max_depth': 5, 'learning_rate': 0.8506044343858681, 'n_estimators': 470}. Best is trial 6 with value: 0.9116404744568251.\n","[I 2024-02-18 19:00:32,308] Trial 14 finished with value: 0.912997154266666 and parameters: {'max_depth': 12, 'learning_rate': 0.10575560169571283, 'n_estimators': 524}. Best is trial 14 with value: 0.912997154266666.\n","[I 2024-02-18 19:07:48,363] Trial 15 finished with value: 0.9004016804897922 and parameters: {'max_depth': 12, 'learning_rate': 0.01574664449306907, 'n_estimators': 694}. Best is trial 14 with value: 0.912997154266666.\n","[I 2024-02-18 19:11:54,967] Trial 16 finished with value: 0.9106925377607906 and parameters: {'max_depth': 12, 'learning_rate': 0.2247129941442672, 'n_estimators': 544}. Best is trial 14 with value: 0.912997154266666.\n","[I 2024-02-18 19:15:21,411] Trial 17 finished with value: 0.8865831458445387 and parameters: {'max_depth': 11, 'learning_rate': 0.019496909900822024, 'n_estimators': 311}. Best is trial 14 with value: 0.912997154266666.\n","[I 2024-02-18 19:19:09,725] Trial 18 finished with value: 0.9084466787559404 and parameters: {'max_depth': 14, 'learning_rate': 0.28804729413608543, 'n_estimators': 525}. Best is trial 14 with value: 0.912997154266666.\n","[I 2024-02-18 19:25:25,879] Trial 19 finished with value: 0.9124480219866972 and parameters: {'max_depth': 13, 'learning_rate': 0.05919109674850971, 'n_estimators': 615}. Best is trial 14 with value: 0.912997154266666.\n","[I 2024-02-18 19:32:10,691] Trial 20 finished with value: 0.8634733197926376 and parameters: {'max_depth': 13, 'learning_rate': 0.004564016619617035, 'n_estimators': 620}. Best is trial 14 with value: 0.912997154266666.\n","[I 2024-02-18 19:38:32,404] Trial 21 finished with value: 0.9107672454031775 and parameters: {'max_depth': 10, 'learning_rate': 0.045966063813004485, 'n_estimators': 613}. Best is trial 14 with value: 0.912997154266666.\n","[I 2024-02-18 19:43:03,055] Trial 22 finished with value: 0.912986645274248 and parameters: {'max_depth': 13, 'learning_rate': 0.13487428762297896, 'n_estimators': 497}. Best is trial 14 with value: 0.912997154266666.\n","[I 2024-02-18 19:47:35,247] Trial 23 finished with value: 0.9031884665856532 and parameters: {'max_depth': 14, 'learning_rate': 0.40310045675768336, 'n_estimators': 697}. Best is trial 14 with value: 0.912997154266666.\n","[I 2024-02-18 19:53:09,369] Trial 24 finished with value: 0.9012845994023869 and parameters: {'max_depth': 13, 'learning_rate': 0.0229288592792187, 'n_estimators': 499}. Best is trial 14 with value: 0.912997154266666.\n","[I 2024-02-18 19:58:39,708] Trial 25 finished with value: 0.9132154695147531 and parameters: {'max_depth': 14, 'learning_rate': 0.09550124388045231, 'n_estimators': 585}. Best is trial 25 with value: 0.9132154695147531.\n","[I 2024-02-18 20:02:34,313] Trial 26 finished with value: 0.9037871045559172 and parameters: {'max_depth': 14, 'learning_rate': 0.40575014186538394, 'n_estimators': 571}. Best is trial 25 with value: 0.9132154695147531.\n","[I 2024-02-18 20:06:29,019] Trial 27 finished with value: 0.9121651837920638 and parameters: {'max_depth': 15, 'learning_rate': 0.15136569200634328, 'n_estimators': 393}. Best is trial 25 with value: 0.9132154695147531.\n","[I 2024-02-18 20:11:45,998] Trial 28 finished with value: 0.7362726880831255 and parameters: {'max_depth': 11, 'learning_rate': 1.1384580495743679e-05, 'n_estimators': 496}. Best is trial 25 with value: 0.9132154695147531.\n","[I 2024-02-18 20:15:09,995] Trial 29 finished with value: 0.8418305067013695 and parameters: {'max_depth': 8, 'learning_rate': 0.006251635194151361, 'n_estimators': 311}. Best is trial 25 with value: 0.9132154695147531.\n","[I 2024-02-18 20:18:27,017] Trial 30 finished with value: 0.8924681265968974 and parameters: {'max_depth': 9, 'learning_rate': 0.03160701634276224, 'n_estimators': 256}. Best is trial 25 with value: 0.9132154695147531.\n","[I 2024-02-18 20:24:08,108] Trial 31 finished with value: 0.9132969828254621 and parameters: {'max_depth': 13, 'learning_rate': 0.09171359811031285, 'n_estimators': 600}. Best is trial 31 with value: 0.9132969828254621.\n","[I 2024-02-18 20:30:06,973] Trial 32 finished with value: 0.9136025611832735 and parameters: {'max_depth': 13, 'learning_rate': 0.10258059179395394, 'n_estimators': 671}. Best is trial 32 with value: 0.9136025611832735.\n","[I 2024-02-18 20:37:21,883] Trial 33 finished with value: 0.8869398947821571 and parameters: {'max_depth': 12, 'learning_rate': 0.009064792149110426, 'n_estimators': 661}. Best is trial 32 with value: 0.9136025611832735.\n","[I 2024-02-18 20:42:47,467] Trial 34 finished with value: 0.9133154473111905 and parameters: {'max_depth': 14, 'learning_rate': 0.10516149275472851, 'n_estimators': 588}. Best is trial 32 with value: 0.9136025611832735.\n","[I 2024-02-18 20:49:03,702] Trial 35 finished with value: 0.9098572946441911 and parameters: {'max_depth': 14, 'learning_rate': 0.040726063555696024, 'n_estimators': 573}. Best is trial 32 with value: 0.9136025611832735.\n","[I 2024-02-18 20:57:05,863] Trial 36 finished with value: 0.824494457344528 and parameters: {'max_depth': 15, 'learning_rate': 0.001300713269379055, 'n_estimators': 659}. Best is trial 32 with value: 0.9136025611832735.\n","[I 2024-02-18 21:00:52,824] Trial 37 finished with value: 0.9002269889022326 and parameters: {'max_depth': 14, 'learning_rate': 0.4979578008590942, 'n_estimators': 567}. Best is trial 32 with value: 0.9136025611832735.\n","[I 2024-02-18 21:07:10,264] Trial 38 finished with value: 0.8366084491079558 and parameters: {'max_depth': 10, 'learning_rate': 0.0025313668822904904, 'n_estimators': 593}. Best is trial 32 with value: 0.9136025611832735.\n","[I 2024-02-18 21:12:28,335] Trial 39 finished with value: 0.9098626438442753 and parameters: {'max_depth': 15, 'learning_rate': 0.22786356970325009, 'n_estimators': 662}. Best is trial 32 with value: 0.9136025611832735.\n","[I 2024-02-18 21:18:51,888] Trial 40 finished with value: 0.91322034522269 and parameters: {'max_depth': 13, 'learning_rate': 0.07533355670026687, 'n_estimators': 648}. Best is trial 32 with value: 0.9136025611832735.\n","[I 2024-02-18 21:24:56,642] Trial 41 finished with value: 0.9132956294582447 and parameters: {'max_depth': 13, 'learning_rate': 0.07852315015332627, 'n_estimators': 640}. Best is trial 32 with value: 0.9136025611832735.\n","[I 2024-02-18 21:31:42,426] Trial 42 finished with value: 0.9109365182286203 and parameters: {'max_depth': 13, 'learning_rate': 0.042055908073998956, 'n_estimators': 646}. Best is trial 32 with value: 0.9136025611832735.\n","[I 2024-02-18 21:38:17,870] Trial 43 finished with value: 0.9131781324352884 and parameters: {'max_depth': 11, 'learning_rate': 0.06698963073678531, 'n_estimators': 681}. Best is trial 32 with value: 0.9136025611832735.\n","[I 2024-02-18 21:45:33,167] Trial 44 finished with value: 0.8884957682947311 and parameters: {'max_depth': 13, 'learning_rate': 0.010014224784404968, 'n_estimators': 627}. Best is trial 32 with value: 0.9136025611832735.\n","[I 2024-02-18 21:52:55,737] Trial 45 finished with value: 0.9084841603087419 and parameters: {'max_depth': 12, 'learning_rate': 0.02870545495450651, 'n_estimators': 700}. Best is trial 32 with value: 0.9136025611832735.\n","[I 2024-02-18 21:53:46,959] Trial 46 finished with value: 0.8965071488234293 and parameters: {'max_depth': 15, 'learning_rate': 0.6020486550748548, 'n_estimators': 39}. Best is trial 32 with value: 0.9136025611832735.\n","[I 2024-02-18 21:58:03,673] Trial 47 finished with value: 0.9079073377335177 and parameters: {'max_depth': 10, 'learning_rate': 0.29313102516524375, 'n_estimators': 597}. Best is trial 32 with value: 0.9136025611832735.\n","[I 2024-02-18 22:03:08,971] Trial 48 finished with value: 0.9120837727050657 and parameters: {'max_depth': 11, 'learning_rate': 0.16426939893061893, 'n_estimators': 641}. Best is trial 32 with value: 0.9136025611832735.\n","[I 2024-02-18 22:07:27,860] Trial 49 finished with value: 0.9099710993735552 and parameters: {'max_depth': 7, 'learning_rate': 0.07206440495002868, 'n_estimators': 446}. Best is trial 32 with value: 0.9136025611832735.\n"]}]},{"cell_type":"code","source":["study_lgbm.best_params"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1708294130492,"user_tz":-240,"elapsed":288,"user":{"displayName":"Евгений Малов","userId":"06257165098392198337"}},"outputId":"edf4188d-e64f-4a58-c79f-d1ff9c69af89","id":"EFN9jjAdKi51"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'max_depth': 13, 'learning_rate': 0.10258059179395394, 'n_estimators': 671}"]},"metadata":{},"execution_count":17}]},{"cell_type":"code","source":["opt_model_lgbm = LGBMClassifier(max_depth=13, learning_rate=0.10258059179395394, n_estimators=671)\n","opt_model_lgbm.fit(x_train, y_train)\n","\n","pred_train = opt_model_lgbm.predict(x_train)\n","pred_test = opt_model_lgbm.predict(x_test)\n","\n","print(f'train: {roc_auc_score(y_train, pred_train)}')\n","print(f'test: {roc_auc_score(y_test, pred_test)}')\n","print(f'test conf matrix: \\n {confusion_matrix(y_test, pred_test)}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1708448997319,"user_tz":-240,"elapsed":216966,"user":{"displayName":"Евгений Малов","userId":"06257165098392198337"}},"outputId":"606f7efa-4e72-4aa9-ccd5-67e6d136236c","id":"vqUZyAS-Ki52"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 223222, number of negative: 223834\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.517564 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 5108\n","[LightGBM] [Info] Number of data points in the train set: 447056, number of used features: 310\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499316 -> initscore=-0.002738\n","[LightGBM] [Info] Start training from score -0.002738\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","train: 0.8618250610276164\n","test: 0.8427172469774704\n","test conf matrix: \n"," [[88470  7022]\n"," [23164 72940]]\n"]}]},{"cell_type":"code","source":["def objective_xgb(trial):\n","    max_depth = trial.suggest_int(\"max_depth\", 2, 15)\n","    learning_rate = trial.suggest_float(\"learning_rate\", 1e-5, 1, log=True)\n","    n_estimators = trial.suggest_int(\"n_estimators\", 10, 700)\n","\n","    score = cross_val_score(XGBClassifier(max_depth=max_depth, n_estimators=n_estimators,\n","                                              learning_rate=learning_rate),\n","                            x_train, y_train, cv=3, scoring='roc_auc', n_jobs=-1).mean()\n","    return score\n","\n","\n","study_xgb = optuna.create_study(direction=\"maximize\")\n","study_xgb.optimize(objective_xgb, n_trials=50)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"3ab68edd-9a49-4749-906f-b6f750658ed3","id":"4G093IGiKi53"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[I 2024-02-19 09:53:05,845] A new study created in memory with name: no-name-fedbf42d-c815-4aed-b785-d357a60a249f\n","[I 2024-02-19 09:55:40,763] Trial 0 finished with value: 0.6755106223729456 and parameters: {'max_depth': 2, 'learning_rate': 0.00047018656128802055, 'n_estimators': 355}. Best is trial 0 with value: 0.6755106223729456.\n","[I 2024-02-19 09:56:06,785] Trial 1 finished with value: 0.6779151895895453 and parameters: {'max_depth': 4, 'learning_rate': 2.9686414638421047e-05, 'n_estimators': 11}. Best is trial 1 with value: 0.6779151895895453.\n","[I 2024-02-19 10:00:22,434] Trial 2 finished with value: 0.8445976677989459 and parameters: {'max_depth': 10, 'learning_rate': 0.0037532587673224176, 'n_estimators': 221}. Best is trial 2 with value: 0.8445976677989459.\n","[I 2024-02-19 10:07:59,781] Trial 3 finished with value: 0.9131727210582273 and parameters: {'max_depth': 11, 'learning_rate': 0.06324951022147739, 'n_estimators': 357}. Best is trial 3 with value: 0.9131727210582273.\n","[I 2024-02-19 10:20:41,297] Trial 4 finished with value: 0.9008933110957322 and parameters: {'max_depth': 14, 'learning_rate': 0.009033643408979216, 'n_estimators': 340}. Best is trial 3 with value: 0.9131727210582273.\n","[I 2024-02-19 10:23:36,930] Trial 5 finished with value: 0.7420631273466093 and parameters: {'max_depth': 6, 'learning_rate': 0.00046037157260625934, 'n_estimators': 237}. Best is trial 3 with value: 0.9131727210582273.\n","[I 2024-02-19 10:32:18,281] Trial 6 finished with value: 0.9042653946295457 and parameters: {'max_depth': 11, 'learning_rate': 0.49335755865077885, 'n_estimators': 502}. Best is trial 3 with value: 0.9131727210582273.\n","[I 2024-02-19 10:48:39,147] Trial 7 finished with value: 0.9110091069194914 and parameters: {'max_depth': 14, 'learning_rate': 0.014763020885623295, 'n_estimators': 452}. Best is trial 3 with value: 0.9131727210582273.\n","[I 2024-02-19 10:52:12,700] Trial 8 finished with value: 0.6465710293862929 and parameters: {'max_depth': 2, 'learning_rate': 1.0426049049528209e-05, 'n_estimators': 551}. Best is trial 3 with value: 0.9131727210582273.\n","[I 2024-02-19 10:57:13,001] Trial 9 finished with value: 0.9025603228915541 and parameters: {'max_depth': 11, 'learning_rate': 0.48898998802657184, 'n_estimators': 269}. Best is trial 3 with value: 0.9131727210582273.\n","[I 2024-02-19 11:05:40,642] Trial 10 finished with value: 0.9133205825873497 and parameters: {'max_depth': 7, 'learning_rate': 0.0679200914178317, 'n_estimators': 683}. Best is trial 10 with value: 0.9133205825873497.\n","[I 2024-02-19 11:13:45,512] Trial 11 finished with value: 0.9131526854956115 and parameters: {'max_depth': 7, 'learning_rate': 0.06673000358362047, 'n_estimators': 653}. Best is trial 10 with value: 0.9133205825873497.\n","[I 2024-02-19 11:23:03,431] Trial 12 finished with value: 0.9135121936848077 and parameters: {'max_depth': 8, 'learning_rate': 0.07291974997125054, 'n_estimators': 672}. Best is trial 12 with value: 0.9135121936848077.\n","[I 2024-02-19 11:33:16,406] Trial 13 finished with value: 0.9132172339251207 and parameters: {'max_depth': 8, 'learning_rate': 0.043200671501927974, 'n_estimators': 690}. Best is trial 12 with value: 0.9135121936848077.\n","[I 2024-02-19 11:38:58,846] Trial 14 finished with value: 0.9120869395903609 and parameters: {'max_depth': 5, 'learning_rate': 0.1939821555696708, 'n_estimators': 609}. Best is trial 12 with value: 0.9135121936848077.\n","[I 2024-02-19 11:48:30,229] Trial 15 finished with value: 0.822296546033033 and parameters: {'max_depth': 9, 'learning_rate': 0.0008634821880955975, 'n_estimators': 590}. Best is trial 12 with value: 0.9135121936848077.\n","[I 2024-02-19 11:54:05,757] Trial 16 finished with value: 0.889600264056558 and parameters: {'max_depth': 8, 'learning_rate': 0.9921877770584037, 'n_estimators': 455}. Best is trial 12 with value: 0.9135121936848077.\n","[I 2024-02-19 12:00:27,691] Trial 17 finished with value: 0.8894207806581944 and parameters: {'max_depth': 4, 'learning_rate': 0.02225082066525933, 'n_estimators': 679}. Best is trial 12 with value: 0.9135121936848077.\n","[I 2024-02-19 12:06:10,812] Trial 18 finished with value: 0.9119782901933525 and parameters: {'max_depth': 6, 'learning_rate': 0.16295536836866864, 'n_estimators': 540}. Best is trial 12 with value: 0.9135121936848077.\n","[I 2024-02-19 12:07:23,064] Trial 19 finished with value: 0.8046180558029651 and parameters: {'max_depth': 13, 'learning_rate': 0.0018450372166985245, 'n_estimators': 32}. Best is trial 12 with value: 0.9135121936848077.\n","[I 2024-02-19 12:09:10,167] Trial 20 finished with value: 0.7410207793810221 and parameters: {'max_depth': 9, 'learning_rate': 0.00010980859088500182, 'n_estimators': 94}. Best is trial 12 with value: 0.9135121936848077.\n","[I 2024-02-19 12:19:15,774] Trial 21 finished with value: 0.9135906199773512 and parameters: {'max_depth': 8, 'learning_rate': 0.05064004642135141, 'n_estimators': 696}. Best is trial 21 with value: 0.9135906199773512.\n","[I 2024-02-19 12:26:39,914] Trial 22 finished with value: 0.9116156265705834 and parameters: {'max_depth': 7, 'learning_rate': 0.15209960364182426, 'n_estimators': 624}. Best is trial 21 with value: 0.9135906199773512.\n","[I 2024-02-19 12:34:55,059] Trial 23 finished with value: 0.8768248226616415 and parameters: {'max_depth': 6, 'learning_rate': 0.007076267750089386, 'n_estimators': 690}. Best is trial 21 with value: 0.9135906199773512.\n","[I 2024-02-19 12:42:52,840] Trial 24 finished with value: 0.9087762873048377 and parameters: {'max_depth': 7, 'learning_rate': 0.030354417955806904, 'n_estimators': 577}. Best is trial 21 with value: 0.9135906199773512.\n","[I 2024-02-19 12:53:25,918] Trial 25 finished with value: 0.9119904056879866 and parameters: {'max_depth': 10, 'learning_rate': 0.10680475201839974, 'n_estimators': 641}. Best is trial 21 with value: 0.9135906199773512.\n","[I 2024-02-19 12:57:31,903] Trial 26 finished with value: 0.9102032342891834 and parameters: {'max_depth': 4, 'learning_rate': 0.3182501331460836, 'n_estimators': 488}. Best is trial 21 with value: 0.9135906199773512.\n","[I 2024-02-19 13:15:56,556] Trial 27 finished with value: 0.9126190689973002 and parameters: {'max_depth': 12, 'learning_rate': 0.014612058428688327, 'n_estimators': 696}. Best is trial 21 with value: 0.9135906199773512.\n","[I 2024-02-19 13:21:46,518] Trial 28 finished with value: 0.8657566688642708 and parameters: {'max_depth': 8, 'learning_rate': 0.005785325592725249, 'n_estimators': 406}. Best is trial 21 with value: 0.9135906199773512.\n","[I 2024-02-19 13:25:14,091] Trial 29 finished with value: 0.7177685261540723 and parameters: {'max_depth': 2, 'learning_rate': 0.0015911195480687373, 'n_estimators': 525}. Best is trial 21 with value: 0.9135906199773512.\n","[I 2024-02-19 13:35:44,894] Trial 30 finished with value: 0.913319348885318 and parameters: {'max_depth': 10, 'learning_rate': 0.07133854474940705, 'n_estimators': 591}. Best is trial 21 with value: 0.9135906199773512.\n","[I 2024-02-19 13:46:51,349] Trial 31 finished with value: 0.9129124143886562 and parameters: {'max_depth': 10, 'learning_rate': 0.08004876162414244, 'n_estimators': 647}. Best is trial 21 with value: 0.9135906199773512.\n","[I 2024-02-19 13:56:43,592] Trial 32 finished with value: 0.9124808972502269 and parameters: {'max_depth': 9, 'learning_rate': 0.030469185080647762, 'n_estimators': 596}. Best is trial 21 with value: 0.9135906199773512.\n","[I 2024-02-19 14:03:10,538] Trial 33 finished with value: 0.906367310219221 and parameters: {'max_depth': 7, 'learning_rate': 0.29797325523472556, 'n_estimators': 568}. Best is trial 21 with value: 0.9135906199773512.\n","[I 2024-02-19 14:15:01,326] Trial 34 finished with value: 0.9139274211662157 and parameters: {'max_depth': 10, 'learning_rate': 0.05503501331043618, 'n_estimators': 651}. Best is trial 34 with value: 0.9139274211662157.\n","[I 2024-02-19 14:20:26,185] Trial 35 finished with value: 0.890385442023022 and parameters: {'max_depth': 5, 'learning_rate': 0.9861125435388054, 'n_estimators': 651}. Best is trial 34 with value: 0.9139274211662157.\n","[I 2024-02-19 14:31:40,740] Trial 36 finished with value: 0.9084809808632475 and parameters: {'max_depth': 9, 'learning_rate': 0.015936369525818683, 'n_estimators': 630}. Best is trial 34 with value: 0.9139274211662157.\n","[I 2024-02-19 14:36:15,633] Trial 37 finished with value: 0.9080275853442071 and parameters: {'max_depth': 12, 'learning_rate': 0.03934831721637406, 'n_estimators': 164}. Best is trial 34 with value: 0.9139274211662157.\n","[I 2024-02-19 15:04:55,366] Trial 38 finished with value: 0.9026896820803678 and parameters: {'max_depth': 15, 'learning_rate': 0.0046215741535335555, 'n_estimators': 670}. Best is trial 34 with value: 0.9139274211662157.\n","[I 2024-02-19 15:09:27,973] Trial 39 finished with value: 0.878823952299244 and parameters: {'max_depth': 8, 'learning_rate': 0.011144004836747576, 'n_estimators': 296}. Best is trial 34 with value: 0.9139274211662157.\n","[I 2024-02-19 15:15:07,488] Trial 40 finished with value: 0.8236094381537548 and parameters: {'max_depth': 6, 'learning_rate': 0.0030781178305666086, 'n_estimators': 510}. Best is trial 34 with value: 0.9139274211662157.\n","[I 2024-02-19 15:25:39,459] Trial 41 finished with value: 0.9136028688514714 and parameters: {'max_depth': 10, 'learning_rate': 0.055911303025852815, 'n_estimators': 615}. Best is trial 34 with value: 0.9139274211662157.\n","[I 2024-02-19 15:38:40,299] Trial 42 finished with value: 0.9139869919141649 and parameters: {'max_depth': 11, 'learning_rate': 0.04924166876982857, 'n_estimators': 616}. Best is trial 42 with value: 0.9139869919141649.\n","[I 2024-02-19 15:50:21,204] Trial 43 finished with value: 0.912057107419952 and parameters: {'max_depth': 11, 'learning_rate': 0.11954320739512918, 'n_estimators': 616}. Best is trial 42 with value: 0.9139869919141649.\n","[I 2024-02-19 15:59:48,833] Trial 44 finished with value: 0.9136055416120555 and parameters: {'max_depth': 12, 'learning_rate': 0.04533313733210472, 'n_estimators': 406}. Best is trial 42 with value: 0.9139869919141649.\n","[I 2024-02-19 16:08:58,381] Trial 45 finished with value: 0.9112118127081147 and parameters: {'max_depth': 12, 'learning_rate': 0.022665515517805362, 'n_estimators': 362}. Best is trial 42 with value: 0.9139869919141649.\n","[I 2024-02-19 16:16:16,634] Trial 46 finished with value: 0.9078126163306314 and parameters: {'max_depth': 11, 'learning_rate': 0.2703585915537474, 'n_estimators': 419}. Best is trial 42 with value: 0.9139869919141649.\n","[I 2024-02-19 16:22:05,228] Trial 47 finished with value: 0.9105465547378494 and parameters: {'max_depth': 13, 'learning_rate': 0.04337610464198803, 'n_estimators': 187}. Best is trial 42 with value: 0.9139869919141649.\n","[I 2024-02-19 16:35:38,262] Trial 48 finished with value: 0.8138262385947149 and parameters: {'max_depth': 13, 'learning_rate': 0.000194775116177154, 'n_estimators': 478}. Best is trial 42 with value: 0.9139869919141649.\n"]}]},{"cell_type":"code","source":["study_xgb.best_params"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":141},"executionInfo":{"status":"error","timestamp":1708364613323,"user_tz":-240,"elapsed":908,"user":{"displayName":"Евгений Малов","userId":"06257165098392198337"}},"outputId":"4ce39b2d-3d98-4e9f-b38a-59d65cf45d8f","id":"oLNvdx0YKi54"},"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'study_xgb' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-9de1157c8fcd>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mstudy_xgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'study_xgb' is not defined"]}]},{"cell_type":"markdown","source":["Trial 42 finished with value: 0.9139869919141649 and parameters: {'max_depth': 11, 'learning_rate': 0.04924166876982857, 'n_estimators': 616}. Best is trial 42 with value: 0.9139869919141649."],"metadata":{"id":"sgGbtMued6tx"}},{"cell_type":"code","source":["opt_model_xgb = XGBClassifier(max_depth=11, learning_rate=0.04924166876982857, n_estimators=616)\n","opt_model_xgb.fit(x_train, y_train)\n","\n","pred_train = opt_model_xgb.predict(x_train)\n","pred_test = opt_model_xgb.predict(x_test)\n","\n","print(f'train: {roc_auc_score(y_train, pred_train)}')\n","print(f'test: {roc_auc_score(y_test, pred_test)}')\n","print(f'test conf matrix: \\n {confusion_matrix(y_test, pred_test)}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1708448765361,"user_tz":-240,"elapsed":552225,"user":{"displayName":"Евгений Малов","userId":"06257165098392198337"}},"outputId":"8922707a-d9ce-4238-b260-ef2e233fdceb","id":"bwiVdd4dKi57"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["train: 0.9673953610348954\n","test: 0.8445025411582613\n","test conf matrix: \n"," [[88181  7311]\n"," [22530 73574]]\n"]}]},{"cell_type":"code","source":["def objective_catboost(trial):\n","    max_depth = trial.suggest_int(\"max_depth\", 2, 15)\n","    learning_rate = trial.suggest_float(\"learning_rate\", 1e-3, 1, log=True)\n","    n_estimators = trial.suggest_int(\"n_estimators\", 10, 700)\n","    l2_leaf_reg = trial.suggest_int('l2_leaf_reg', 1, 5)\n","\n","    score = cross_val_score(CatBoostClassifier(max_depth=max_depth, n_estimators=n_estimators,\n","                                              learning_rate=learning_rate, l2_leaf_reg=l2_leaf_reg),\n","                            x_train, y_train, cv=3, scoring='roc_auc', n_jobs=-1).mean()\n","    return score\n","\n","\n","study_catboost = optuna.create_study(direction=\"maximize\")\n","study_catboost.optimize(objective_catboost, n_trials=50)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":966},"outputId":"ad919c7e-6574-46f8-c2cc-8102119b28d6","id":"XdXBo5IHKi58","executionInfo":{"status":"error","timestamp":1708446391535,"user_tz":-240,"elapsed":25658824,"user":{"displayName":"Евгений Малов","userId":"06257165098392198337"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[I 2024-02-20 09:18:52,591] A new study created in memory with name: no-name-0da4f96f-ae40-4d9f-bcac-8b29232743a6\n","[I 2024-02-20 09:33:12,036] Trial 0 finished with value: 0.9061162621984643 and parameters: {'max_depth': 11, 'learning_rate': 0.23925754688390824, 'n_estimators': 164, 'l2_leaf_reg': 3}. Best is trial 0 with value: 0.9061162621984643.\n","[I 2024-02-20 09:39:34,465] Trial 1 finished with value: 0.9097649862572817 and parameters: {'max_depth': 9, 'learning_rate': 0.19367108172650113, 'n_estimators': 278, 'l2_leaf_reg': 2}. Best is trial 1 with value: 0.9097649862572817.\n","[I 2024-02-20 09:46:24,024] Trial 2 finished with value: 0.80352361589638 and parameters: {'max_depth': 7, 'learning_rate': 0.0026499292483742405, 'n_estimators': 370, 'l2_leaf_reg': 5}. Best is trial 1 with value: 0.9097649862572817.\n","[I 2024-02-20 09:55:14,372] Trial 3 finished with value: 0.907851858992926 and parameters: {'max_depth': 5, 'learning_rate': 0.5729846240926912, 'n_estimators': 646, 'l2_leaf_reg': 3}. Best is trial 1 with value: 0.9097649862572817.\n","[I 2024-02-20 10:05:42,104] Trial 4 finished with value: 0.9107403957939472 and parameters: {'max_depth': 6, 'learning_rate': 0.10117440147740919, 'n_estimators': 629, 'l2_leaf_reg': 3}. Best is trial 4 with value: 0.9107403957939472.\n","[I 2024-02-20 10:23:18,092] Trial 5 finished with value: 0.8935300775802558 and parameters: {'max_depth': 10, 'learning_rate': 0.03996177023974978, 'n_estimators': 232, 'l2_leaf_reg': 3}. Best is trial 4 with value: 0.9107403957939472.\n","[I 2024-02-20 11:05:27,181] Trial 6 finished with value: 0.8567965387986337 and parameters: {'max_depth': 15, 'learning_rate': 0.007241224819459457, 'n_estimators': 161, 'l2_leaf_reg': 3}. Best is trial 4 with value: 0.9107403957939472.\n","[I 2024-02-20 11:59:35,047] Trial 7 finished with value: 0.9119434701873249 and parameters: {'max_depth': 11, 'learning_rate': 0.06065400574396137, 'n_estimators': 617, 'l2_leaf_reg': 5}. Best is trial 7 with value: 0.9119434701873249.\n","[I 2024-02-20 12:30:30,027] Trial 8 finished with value: 0.9056910170944138 and parameters: {'max_depth': 13, 'learning_rate': 0.07420224701820712, 'n_estimators': 235, 'l2_leaf_reg': 2}. Best is trial 7 with value: 0.9119434701873249.\n","[I 2024-02-20 12:41:21,806] Trial 9 finished with value: 0.911322844090086 and parameters: {'max_depth': 9, 'learning_rate': 0.1517861457670335, 'n_estimators': 468, 'l2_leaf_reg': 1}. Best is trial 7 with value: 0.9119434701873249.\n","[I 2024-02-20 12:41:51,078] Trial 10 finished with value: 0.7122202729790906 and parameters: {'max_depth': 3, 'learning_rate': 0.008881952070852657, 'n_estimators': 29, 'l2_leaf_reg': 5}. Best is trial 7 with value: 0.9119434701873249.\n","[I 2024-02-20 13:32:16,230] Trial 11 finished with value: 0.8868004397327396 and parameters: {'max_depth': 12, 'learning_rate': 0.8571603194418174, 'n_estimators': 490, 'l2_leaf_reg': 1}. Best is trial 7 with value: 0.9119434701873249.\n","[I 2024-02-20 13:42:50,233] Trial 12 finished with value: 0.8899353433072718 and parameters: {'max_depth': 8, 'learning_rate': 0.020676960915110884, 'n_estimators': 505, 'l2_leaf_reg': 1}. Best is trial 7 with value: 0.9119434701873249.\n","[I 2024-02-20 15:12:21,582] Trial 13 finished with value: 0.9040466857399827 and parameters: {'max_depth': 14, 'learning_rate': 0.02272457588137038, 'n_estimators': 515, 'l2_leaf_reg': 4}. Best is trial 7 with value: 0.9119434701873249.\n","[I 2024-02-20 16:04:19,333] Trial 14 finished with value: 0.905267205410068 and parameters: {'max_depth': 10, 'learning_rate': 0.3161112544930702, 'n_estimators': 695, 'l2_leaf_reg': 4}. Best is trial 7 with value: 0.9119434701873249.\n","[W 2024-02-20 16:26:30,154] Trial 15 failed with parameters: {'max_depth': 12, 'learning_rate': 0.10967275774281679, 'n_estimators': 397, 'l2_leaf_reg': 2} because of the following error: KeyboardInterrupt().\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n","    value_or_values = func(trial)\n","  File \"<ipython-input-8-a1ef236dc34d>\", line 7, in objective_catboost\n","    score = cross_val_score(CatBoostClassifier(max_depth=max_depth, n_estimators=n_estimators,\n","  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 515, in cross_val_score\n","    cv_results = cross_validate(\n","  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 266, in cross_validate\n","    results = parallel(\n","  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 63, in __call__\n","    return super().__call__(iterable_with_config)\n","  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 1952, in __call__\n","    return output if self.return_generator else list(output)\n","  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 1595, in _get_outputs\n","    yield from self._retrieve()\n","  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 1707, in _retrieve\n","    time.sleep(0.01)\n","KeyboardInterrupt\n","[W 2024-02-20 16:26:30,160] Trial 15 failed with value None.\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-8-a1ef236dc34d>\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mstudy_catboost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_study\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirection\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"maximize\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mstudy_catboost\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective_catboost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/optuna/study/study.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    449\u001b[0m                 \u001b[0mIf\u001b[0m \u001b[0mnested\u001b[0m \u001b[0minvocation\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0moccurs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m         \"\"\"\n\u001b[0;32m--> 451\u001b[0;31m         _optimize(\n\u001b[0m\u001b[1;32m    452\u001b[0m             \u001b[0mstudy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m             \u001b[0mfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m             _optimize_sequential(\n\u001b[0m\u001b[1;32m     67\u001b[0m                 \u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m                 \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m             \u001b[0mfrozen_trial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0;31m# The following line mitigates memory problems that can be occurred in some\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m     ):\n\u001b[0;32m--> 251\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mfunc_err\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfrozen_trial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mget_heartbeat_thread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trial_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_storage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m             \u001b[0mvalue_or_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m             \u001b[0;31m# TODO(mamu): Handle multi-objective cases.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-8-a1ef236dc34d>\u001b[0m in \u001b[0;36mobjective_catboost\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0ml2_leaf_reg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuggest_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'l2_leaf_reg'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     score = cross_val_score(CatBoostClassifier(max_depth=max_depth, n_estimators=n_estimators,\n\u001b[0m\u001b[1;32m      8\u001b[0m                                               learning_rate=learning_rate, l2_leaf_reg=l2_leaf_reg),\n\u001b[1;32m      9\u001b[0m                             x_train, y_train, cv=3, scoring='roc_auc', n_jobs=-1).mean()\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    513\u001b[0m     \u001b[0mscorer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_scoring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 515\u001b[0;31m     cv_results = cross_validate(\n\u001b[0m\u001b[1;32m    516\u001b[0m         \u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[0;31m# independent, and that it is pickle-able.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0mparallel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mParallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpre_dispatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpre_dispatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m     results = parallel(\n\u001b[0m\u001b[1;32m    267\u001b[0m         delayed(_fit_and_score)(\n\u001b[1;32m    268\u001b[0m             \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         )\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1950\u001b[0m         \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1952\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_generator\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1953\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1954\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1593\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1594\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1595\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_retrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1596\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1597\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mGeneratorExit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1705\u001b[0m                 (self._jobs[0].get_status(\n\u001b[1;32m   1706\u001b[0m                     timeout=self.timeout) == TASK_PENDING)):\n\u001b[0;32m-> 1707\u001b[0;31m                 \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1708\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["study_catboost.best_params"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1708446410858,"user_tz":-240,"elapsed":312,"user":{"displayName":"Евгений Малов","userId":"06257165098392198337"}},"outputId":"f325d93e-ecbc-44fe-920d-38a1d74a3a09","id":"Yl5FfrldKi59"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'max_depth': 11,\n"," 'learning_rate': 0.06065400574396137,\n"," 'n_estimators': 617,\n"," 'l2_leaf_reg': 5}"]},"metadata":{},"execution_count":9}]},{"cell_type":"markdown","source":["Trial 7 finished with value: 0.9119434701873249 and parameters: {'max_depth': 11, 'learning_rate': 0.06065400574396137, 'n_estimators': 617, 'l2_leaf_reg': 5}. Best is trial 7 with value: 0.9119434701873249."],"metadata":{"id":"aOjP4diOKi5-"}},{"cell_type":"code","source":["opt_model_catb = CatBoostClassifier(max_depth=11, learning_rate=0.06065400574396137, n_estimators=617, l2_leaf_reg=5, verbose=False)\n","opt_model_catb.fit(x_train, y_train)\n","\n","pred_train = opt_model_catb.predict(x_train)\n","pred_test = opt_model_catb.predict(x_test)\n","\n","print(f'train: {roc_auc_score(y_train, pred_train)}')\n","print(f'test: {roc_auc_score(y_test, pred_test)}')\n","print(f'test conf matrix: \\n {confusion_matrix(y_test, pred_test)}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1708448186731,"user_tz":-240,"elapsed":1714145,"user":{"displayName":"Евгений Малов","userId":"06257165098392198337"}},"outputId":"f6db320d-17fd-4d2a-beb1-a63319931b6f","id":"trArqeauKi5_"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["train: 0.8808575619544848\n","test: 0.8426670872503766\n","test conf matrix: \n"," [[88526  6966]\n"," [23230 72874]]\n"]}]},{"cell_type":"code","source":["# обучение дефолтных моделей\n","estimators = [\n","    ('lgbm', model_lgbm),\n","    ('xgb', model_xbm),\n","    ('cb', model_catb)\n","    ]\n","\n","reg = StackingClassifier(\n","    estimators=estimators,\n","    final_estimator=GradientBoostingClassifier(learning_rate = 0.02, n_estimators = 100, random_state=42))\n","\n","reg.fit(x_train, y_train)\n","pred_train = reg.predict(x_train)\n","pred_test = reg.predict(x_test)\n","\n","print(f'train: {roc_auc_score(y_train, pred_train)}')\n","print(f'test: {roc_auc_score(y_test, pred_test)}')\n","print(f'test conf matrix: \\n {confusion_matrix(y_test, pred_test)}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1708279946003,"user_tz":-240,"elapsed":3333931,"user":{"displayName":"Евгений Малов","userId":"06257165098392198337"}},"outputId":"9e274298-b2f3-4770-b2aa-8c5c58891598","id":"IRd77vsvKi6G"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[LightGBM] [Info] Number of positive: 223222, number of negative: 223834\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.457215 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 5108\n","[LightGBM] [Info] Number of data points in the train set: 447056, number of used features: 310\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499316 -> initscore=-0.002738\n","[LightGBM] [Info] Start training from score -0.002738\n","[LightGBM] [Info] Number of positive: 178577, number of negative: 179067\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.156188 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 5106\n","[LightGBM] [Info] Number of data points in the train set: 357644, number of used features: 309\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499315 -> initscore=-0.002740\n","[LightGBM] [Info] Start training from score -0.002740\n","[LightGBM] [Info] Number of positive: 178578, number of negative: 179067\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.410477 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 5154\n","[LightGBM] [Info] Number of data points in the train set: 357645, number of used features: 308\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499316 -> initscore=-0.002735\n","[LightGBM] [Info] Start training from score -0.002735\n","[LightGBM] [Info] Number of positive: 178578, number of negative: 179067\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.135339 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 5125\n","[LightGBM] [Info] Number of data points in the train set: 357645, number of used features: 308\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499316 -> initscore=-0.002735\n","[LightGBM] [Info] Start training from score -0.002735\n","[LightGBM] [Info] Number of positive: 178578, number of negative: 179067\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.132210 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 5125\n","[LightGBM] [Info] Number of data points in the train set: 357645, number of used features: 309\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499316 -> initscore=-0.002735\n","[LightGBM] [Info] Start training from score -0.002735\n","[LightGBM] [Info] Number of positive: 178577, number of negative: 179068\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.141551 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 5109\n","[LightGBM] [Info] Number of data points in the train set: 357645, number of used features: 309\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499314 -> initscore=-0.002746\n","[LightGBM] [Info] Start training from score -0.002746\n","train: 0.8581568527225782\n","test: 0.8441396019864249\n","test conf matrix: \n"," [[90715  4777]\n"," [25150 70954]]\n"]}]},{"cell_type":"code","source":["with open(os.path.join(path, f'smote_default_model.pkl'), 'wb') as file:\n","    dill.dump(reg, file)"],"metadata":{"id":"6CvbX-OUMlsQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["with open(path + '/smote_default_model.pkl', 'rb') as file:\n","    smote_default_model = dill.load(file)\n","smote_default_model"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":164},"executionInfo":{"status":"ok","timestamp":1708279976529,"user_tz":-240,"elapsed":304,"user":{"displayName":"Евгений Малов","userId":"06257165098392198337"}},"outputId":"fbe13d13-9600-4ac0-cfb4-dff8df5d9d96","id":"qBKLz2w_MlsR"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["StackingClassifier(estimators=[('lgbm', LGBMClassifier()),\n","                               ('xgb',\n","                                XGBClassifier(base_score=None, booster=None,\n","                                              callbacks=None,\n","                                              colsample_bylevel=None,\n","                                              colsample_bynode=None,\n","                                              colsample_bytree=None,\n","                                              device=None,\n","                                              early_stopping_rounds=None,\n","                                              enable_categorical=False,\n","                                              eval_metric=None,\n","                                              feature_types=None, gamma=None,\n","                                              grow_policy=None,\n","                                              importance_type=None,\n","                                              interaction_...\n","                                              max_delta_step=None,\n","                                              max_depth=None, max_leaves=None,\n","                                              min_child_weight=None,\n","                                              missing=nan,\n","                                              monotone_constraints=None,\n","                                              multi_strategy=None,\n","                                              n_estimators=None, n_jobs=None,\n","                                              num_parallel_tree=None,\n","                                              random_state=None, ...)),\n","                               ('cb',\n","                                <catboost.core.CatBoostClassifier object at 0x7d38094fbb80>)],\n","                   final_estimator=GradientBoostingClassifier(learning_rate=0.02,\n","                                                              random_state=42))"],"text/html":["<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>StackingClassifier(estimators=[(&#x27;lgbm&#x27;, LGBMClassifier()),\n","                               (&#x27;xgb&#x27;,\n","                                XGBClassifier(base_score=None, booster=None,\n","                                              callbacks=None,\n","                                              colsample_bylevel=None,\n","                                              colsample_bynode=None,\n","                                              colsample_bytree=None,\n","                                              device=None,\n","                                              early_stopping_rounds=None,\n","                                              enable_categorical=False,\n","                                              eval_metric=None,\n","                                              feature_types=None, gamma=None,\n","                                              grow_policy=None,\n","                                              importance_type=None,\n","                                              interaction_...\n","                                              max_delta_step=None,\n","                                              max_depth=None, max_leaves=None,\n","                                              min_child_weight=None,\n","                                              missing=nan,\n","                                              monotone_constraints=None,\n","                                              multi_strategy=None,\n","                                              n_estimators=None, n_jobs=None,\n","                                              num_parallel_tree=None,\n","                                              random_state=None, ...)),\n","                               (&#x27;cb&#x27;,\n","                                &lt;catboost.core.CatBoostClassifier object at 0x7d38094fbb80&gt;)],\n","                   final_estimator=GradientBoostingClassifier(learning_rate=0.02,\n","                                                              random_state=42))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StackingClassifier</label><div class=\"sk-toggleable__content\"><pre>StackingClassifier(estimators=[(&#x27;lgbm&#x27;, LGBMClassifier()),\n","                               (&#x27;xgb&#x27;,\n","                                XGBClassifier(base_score=None, booster=None,\n","                                              callbacks=None,\n","                                              colsample_bylevel=None,\n","                                              colsample_bynode=None,\n","                                              colsample_bytree=None,\n","                                              device=None,\n","                                              early_stopping_rounds=None,\n","                                              enable_categorical=False,\n","                                              eval_metric=None,\n","                                              feature_types=None, gamma=None,\n","                                              grow_policy=None,\n","                                              importance_type=None,\n","                                              interaction_...\n","                                              max_delta_step=None,\n","                                              max_depth=None, max_leaves=None,\n","                                              min_child_weight=None,\n","                                              missing=nan,\n","                                              monotone_constraints=None,\n","                                              multi_strategy=None,\n","                                              n_estimators=None, n_jobs=None,\n","                                              num_parallel_tree=None,\n","                                              random_state=None, ...)),\n","                               (&#x27;cb&#x27;,\n","                                &lt;catboost.core.CatBoostClassifier object at 0x7d38094fbb80&gt;)],\n","                   final_estimator=GradientBoostingClassifier(learning_rate=0.02,\n","                                                              random_state=42))</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>lgbm</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>xgb</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n","              colsample_bylevel=None, colsample_bynode=None,\n","              colsample_bytree=None, device=None, early_stopping_rounds=None,\n","              enable_categorical=False, eval_metric=None, feature_types=None,\n","              gamma=None, grow_policy=None, importance_type=None,\n","              interaction_constraints=None, learning_rate=None, max_bin=None,\n","              max_cat_threshold=None, max_cat_to_onehot=None,\n","              max_delta_step=None, max_depth=None, max_leaves=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              multi_strategy=None, n_estimators=None, n_jobs=None,\n","              num_parallel_tree=None, random_state=None, ...)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>cb</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CatBoostClassifier</label><div class=\"sk-toggleable__content\"><pre>&lt;catboost.core.CatBoostClassifier object at 0x7d38094fbb80&gt;</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>final_estimator</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier(learning_rate=0.02, random_state=42)</pre></div></div></div></div></div></div></div></div></div></div></div></div>"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","source":["# обучение моделей с подобранными гиперпараметрами, все 3 модели\n","estimators = [\n","    ('lgbm', opt_model_lgbm),\n","    ('xgb', opt_model_xgb),\n","    ('cb', opt_model_catb)\n","    ]\n","\n","reg = StackingClassifier(\n","    estimators=estimators,\n","    final_estimator=GradientBoostingClassifier(learning_rate = 0.02, n_estimators = 100, random_state=42))\n","\n","reg.fit(x_train, y_train)\n","pred_train = reg.predict(x_train)\n","pred_test = reg.predict(x_test)\n","\n","print(f'train: {roc_auc_score(y_train, pred_train)}')\n","print(f'test: {roc_auc_score(y_test, pred_test)}')\n","print(f'test conf matrix: \\n {confusion_matrix(y_test, pred_test)}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1708460307267,"user_tz":-240,"elapsed":8307876,"user":{"displayName":"Евгений Малов","userId":"06257165098392198337"}},"outputId":"4b1cc9b6-3eb7-4001-f4c2-7257a9f89eff","id":"qnR6TDEFKi6A"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 223222, number of negative: 223834\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.936380 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 5108\n","[LightGBM] [Info] Number of data points in the train set: 447056, number of used features: 310\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499316 -> initscore=-0.002738\n","[LightGBM] [Info] Start training from score -0.002738\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 178577, number of negative: 179067\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.448391 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 5106\n","[LightGBM] [Info] Number of data points in the train set: 357644, number of used features: 309\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499315 -> initscore=-0.002740\n","[LightGBM] [Info] Start training from score -0.002740\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 178578, number of negative: 179067\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.078033 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 5154\n","[LightGBM] [Info] Number of data points in the train set: 357645, number of used features: 308\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499316 -> initscore=-0.002735\n","[LightGBM] [Info] Start training from score -0.002735\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 178578, number of negative: 179067\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 2.364223 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 5125\n","[LightGBM] [Info] Number of data points in the train set: 357645, number of used features: 308\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499316 -> initscore=-0.002735\n","[LightGBM] [Info] Start training from score -0.002735\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 178578, number of negative: 179067\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.392467 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 5125\n","[LightGBM] [Info] Number of data points in the train set: 357645, number of used features: 309\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499316 -> initscore=-0.002735\n","[LightGBM] [Info] Start training from score -0.002735\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 178577, number of negative: 179068\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.069659 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 5109\n","[LightGBM] [Info] Number of data points in the train set: 357645, number of used features: 309\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499314 -> initscore=-0.002746\n","[LightGBM] [Info] Start training from score -0.002746\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","train: 0.940056165860861\n","test: 0.8454399772528922\n","test conf matrix: \n"," [[90550  4942]\n"," [24734 71370]]\n"]}]},{"cell_type":"code","source":["with open(os.path.join(path, f'smote_3_models.pkl'), 'wb') as file:\n","    dill.dump(reg, file)"],"metadata":{"id":"nTHCwRuoKi6B"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["with open(path + '/smote_3_models.pkl', 'rb') as file:\n","    smote_3_model = dill.load(file)\n","smote_3_model"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":164},"executionInfo":{"status":"ok","timestamp":1708460639740,"user_tz":-240,"elapsed":5675,"user":{"displayName":"Евгений Малов","userId":"06257165098392198337"}},"outputId":"5c25b059-41f5-4391-db66-61aa90bf291d","id":"oGOvSxHuKi6C"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["StackingClassifier(estimators=[('lgbm',\n","                                LGBMClassifier(learning_rate=0.10258059179395394,\n","                                               max_depth=13,\n","                                               n_estimators=671)),\n","                               ('xgb',\n","                                XGBClassifier(base_score=None, booster=None,\n","                                              callbacks=None,\n","                                              colsample_bylevel=None,\n","                                              colsample_bynode=None,\n","                                              colsample_bytree=None,\n","                                              device=None,\n","                                              early_stopping_rounds=None,\n","                                              enable_categorical=False,\n","                                              eval_metric=None,\n","                                              feature_types=Non...\n","                                              max_cat_to_onehot=None,\n","                                              max_delta_step=None, max_depth=11,\n","                                              max_leaves=None,\n","                                              min_child_weight=None,\n","                                              missing=nan,\n","                                              monotone_constraints=None,\n","                                              multi_strategy=None,\n","                                              n_estimators=616, n_jobs=None,\n","                                              num_parallel_tree=None,\n","                                              random_state=None, ...)),\n","                               ('cb',\n","                                <catboost.core.CatBoostClassifier object at 0x79e624f1ce50>)],\n","                   final_estimator=GradientBoostingClassifier(learning_rate=0.02,\n","                                                              random_state=42))"],"text/html":["<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>StackingClassifier(estimators=[(&#x27;lgbm&#x27;,\n","                                LGBMClassifier(learning_rate=0.10258059179395394,\n","                                               max_depth=13,\n","                                               n_estimators=671)),\n","                               (&#x27;xgb&#x27;,\n","                                XGBClassifier(base_score=None, booster=None,\n","                                              callbacks=None,\n","                                              colsample_bylevel=None,\n","                                              colsample_bynode=None,\n","                                              colsample_bytree=None,\n","                                              device=None,\n","                                              early_stopping_rounds=None,\n","                                              enable_categorical=False,\n","                                              eval_metric=None,\n","                                              feature_types=Non...\n","                                              max_cat_to_onehot=None,\n","                                              max_delta_step=None, max_depth=11,\n","                                              max_leaves=None,\n","                                              min_child_weight=None,\n","                                              missing=nan,\n","                                              monotone_constraints=None,\n","                                              multi_strategy=None,\n","                                              n_estimators=616, n_jobs=None,\n","                                              num_parallel_tree=None,\n","                                              random_state=None, ...)),\n","                               (&#x27;cb&#x27;,\n","                                &lt;catboost.core.CatBoostClassifier object at 0x79e624f1ce50&gt;)],\n","                   final_estimator=GradientBoostingClassifier(learning_rate=0.02,\n","                                                              random_state=42))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StackingClassifier</label><div class=\"sk-toggleable__content\"><pre>StackingClassifier(estimators=[(&#x27;lgbm&#x27;,\n","                                LGBMClassifier(learning_rate=0.10258059179395394,\n","                                               max_depth=13,\n","                                               n_estimators=671)),\n","                               (&#x27;xgb&#x27;,\n","                                XGBClassifier(base_score=None, booster=None,\n","                                              callbacks=None,\n","                                              colsample_bylevel=None,\n","                                              colsample_bynode=None,\n","                                              colsample_bytree=None,\n","                                              device=None,\n","                                              early_stopping_rounds=None,\n","                                              enable_categorical=False,\n","                                              eval_metric=None,\n","                                              feature_types=Non...\n","                                              max_cat_to_onehot=None,\n","                                              max_delta_step=None, max_depth=11,\n","                                              max_leaves=None,\n","                                              min_child_weight=None,\n","                                              missing=nan,\n","                                              monotone_constraints=None,\n","                                              multi_strategy=None,\n","                                              n_estimators=616, n_jobs=None,\n","                                              num_parallel_tree=None,\n","                                              random_state=None, ...)),\n","                               (&#x27;cb&#x27;,\n","                                &lt;catboost.core.CatBoostClassifier object at 0x79e624f1ce50&gt;)],\n","                   final_estimator=GradientBoostingClassifier(learning_rate=0.02,\n","                                                              random_state=42))</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>lgbm</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(learning_rate=0.10258059179395394, max_depth=13,\n","               n_estimators=671)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>xgb</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n","              colsample_bylevel=None, colsample_bynode=None,\n","              colsample_bytree=None, device=None, early_stopping_rounds=None,\n","              enable_categorical=False, eval_metric=None, feature_types=None,\n","              gamma=None, grow_policy=None, importance_type=None,\n","              interaction_constraints=None, learning_rate=0.04924166876982857,\n","              max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n","              max_delta_step=None, max_depth=11, max_leaves=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              multi_strategy=None, n_estimators=616, n_jobs=None,\n","              num_parallel_tree=None, random_state=None, ...)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>cb</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CatBoostClassifier</label><div class=\"sk-toggleable__content\"><pre>&lt;catboost.core.CatBoostClassifier object at 0x79e624f1ce50&gt;</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>final_estimator</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier(learning_rate=0.02, random_state=42)</pre></div></div></div></div></div></div></div></div></div></div></div></div>"]},"metadata":{},"execution_count":16}]},{"cell_type":"markdown","source":["## Проверка на исходных данных"],"metadata":{"id":"W_jW2QK1lHaL"}},{"cell_type":"code","source":["#x_train = pd.read_parquet(path + '/x_train.parquet').drop('id', axis=1)\n","x_test = pd.read_parquet(path + '/x_test.parquet').drop('id', axis=1)\n","#y_train = pd.read_parquet(path + '/y_train.parquet').drop('id', axis=1)\n","y_test = pd.read_parquet(path + '/y_test.parquet').drop('id', axis=1)"],"metadata":{"id":"jBSmTLd3lKd7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["with open(path + '/up_ds_3_models.pkl', 'rb') as file:\n","    model_3 = dill.load(file)\n","model_3"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":164},"id":"hELdhOyAocL1","executionInfo":{"status":"ok","timestamp":1708184515507,"user_tz":-240,"elapsed":682,"user":{"displayName":"Евгений Малов","userId":"06257165098392198337"}},"outputId":"1a376ad3-72c4-4922-afa7-b4de8d438413"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["StackingClassifier(estimators=[('lgbm',\n","                                LGBMClassifier(learning_rate=0.6034033282351656,\n","                                               max_depth=11,\n","                                               n_estimators=605)),\n","                               ('xgb',\n","                                XGBClassifier(base_score=None, booster=None,\n","                                              callbacks=None,\n","                                              colsample_bylevel=None,\n","                                              colsample_bynode=None,\n","                                              colsample_bytree=None,\n","                                              device=None,\n","                                              early_stopping_rounds=None,\n","                                              enable_categorical=False,\n","                                              eval_metric=None,\n","                                              feature_types=None...\n","                                              max_cat_to_onehot=None,\n","                                              max_delta_step=None, max_depth=12,\n","                                              max_leaves=None,\n","                                              min_child_weight=None,\n","                                              missing=nan,\n","                                              monotone_constraints=None,\n","                                              multi_strategy=None,\n","                                              n_estimators=539, n_jobs=None,\n","                                              num_parallel_tree=None,\n","                                              random_state=None, ...)),\n","                               ('cb',\n","                                <catboost.core.CatBoostClassifier object at 0x7fcd98266d10>)],\n","                   final_estimator=GradientBoostingClassifier(learning_rate=0.02,\n","                                                              random_state=42))"],"text/html":["<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>StackingClassifier(estimators=[(&#x27;lgbm&#x27;,\n","                                LGBMClassifier(learning_rate=0.6034033282351656,\n","                                               max_depth=11,\n","                                               n_estimators=605)),\n","                               (&#x27;xgb&#x27;,\n","                                XGBClassifier(base_score=None, booster=None,\n","                                              callbacks=None,\n","                                              colsample_bylevel=None,\n","                                              colsample_bynode=None,\n","                                              colsample_bytree=None,\n","                                              device=None,\n","                                              early_stopping_rounds=None,\n","                                              enable_categorical=False,\n","                                              eval_metric=None,\n","                                              feature_types=None...\n","                                              max_cat_to_onehot=None,\n","                                              max_delta_step=None, max_depth=12,\n","                                              max_leaves=None,\n","                                              min_child_weight=None,\n","                                              missing=nan,\n","                                              monotone_constraints=None,\n","                                              multi_strategy=None,\n","                                              n_estimators=539, n_jobs=None,\n","                                              num_parallel_tree=None,\n","                                              random_state=None, ...)),\n","                               (&#x27;cb&#x27;,\n","                                &lt;catboost.core.CatBoostClassifier object at 0x7fcd98266d10&gt;)],\n","                   final_estimator=GradientBoostingClassifier(learning_rate=0.02,\n","                                                              random_state=42))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StackingClassifier</label><div class=\"sk-toggleable__content\"><pre>StackingClassifier(estimators=[(&#x27;lgbm&#x27;,\n","                                LGBMClassifier(learning_rate=0.6034033282351656,\n","                                               max_depth=11,\n","                                               n_estimators=605)),\n","                               (&#x27;xgb&#x27;,\n","                                XGBClassifier(base_score=None, booster=None,\n","                                              callbacks=None,\n","                                              colsample_bylevel=None,\n","                                              colsample_bynode=None,\n","                                              colsample_bytree=None,\n","                                              device=None,\n","                                              early_stopping_rounds=None,\n","                                              enable_categorical=False,\n","                                              eval_metric=None,\n","                                              feature_types=None...\n","                                              max_cat_to_onehot=None,\n","                                              max_delta_step=None, max_depth=12,\n","                                              max_leaves=None,\n","                                              min_child_weight=None,\n","                                              missing=nan,\n","                                              monotone_constraints=None,\n","                                              multi_strategy=None,\n","                                              n_estimators=539, n_jobs=None,\n","                                              num_parallel_tree=None,\n","                                              random_state=None, ...)),\n","                               (&#x27;cb&#x27;,\n","                                &lt;catboost.core.CatBoostClassifier object at 0x7fcd98266d10&gt;)],\n","                   final_estimator=GradientBoostingClassifier(learning_rate=0.02,\n","                                                              random_state=42))</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>lgbm</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(learning_rate=0.6034033282351656, max_depth=11, n_estimators=605)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>xgb</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n","              colsample_bylevel=None, colsample_bynode=None,\n","              colsample_bytree=None, device=None, early_stopping_rounds=None,\n","              enable_categorical=False, eval_metric=None, feature_types=None,\n","              gamma=None, grow_policy=None, importance_type=None,\n","              interaction_constraints=None, learning_rate=0.47555557015719635,\n","              max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n","              max_delta_step=None, max_depth=12, max_leaves=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              multi_strategy=None, n_estimators=539, n_jobs=None,\n","              num_parallel_tree=None, random_state=None, ...)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>cb</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CatBoostClassifier</label><div class=\"sk-toggleable__content\"><pre>&lt;catboost.core.CatBoostClassifier object at 0x7fcd98266d10&gt;</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>final_estimator</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier(learning_rate=0.02, random_state=42)</pre></div></div></div></div></div></div></div></div></div></div></div></div>"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["#pred_train = model_3.predict(x_train)\n","pred_test = model_3.predict(x_test)\n","\n","#print(f'train: {roc_auc_score(y_train, pred_train)}')\n","print(f'test: {roc_auc_score(y_test, pred_test)}')\n","print(f'test conf matrix: \\n {confusion_matrix(y_test, pred_test)}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2PxpzyxqozK6","executionInfo":{"status":"ok","timestamp":1708184578107,"user_tz":-240,"elapsed":59848,"user":{"displayName":"Евгений Малов","userId":"06257165098392198337"}},"outputId":"2c97872a-31dd-4994-8ddc-140c966e8943"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","test: 0.9466929332388552\n","test conf matrix: \n"," [[829339  38675]\n"," [  1985  30001]]\n"]}]},{"cell_type":"code","source":["with open(path + '/up_ds_ONLY2_models.pkl', 'rb') as file:\n","    model_xgb_lgbm = dill.load(file)\n","model_xgb_lgbm"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":164},"id":"lkfJarerocZL","executionInfo":{"status":"ok","timestamp":1708184590673,"user_tz":-240,"elapsed":662,"user":{"displayName":"Евгений Малов","userId":"06257165098392198337"}},"outputId":"9c99d6cf-e8bf-4709-82da-4985e998dcb0"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["StackingClassifier(estimators=[('lgbm',\n","                                LGBMClassifier(learning_rate=0.6034033282351656,\n","                                               max_depth=11,\n","                                               n_estimators=605)),\n","                               ('xgb',\n","                                XGBClassifier(base_score=None, booster=None,\n","                                              callbacks=None,\n","                                              colsample_bylevel=None,\n","                                              colsample_bynode=None,\n","                                              colsample_bytree=None,\n","                                              device=None,\n","                                              early_stopping_rounds=None,\n","                                              enable_categorical=False,\n","                                              eval_metric=None,\n","                                              feature_types=None...\n","                                              learning_rate=0.47555557015719635,\n","                                              max_bin=None,\n","                                              max_cat_threshold=None,\n","                                              max_cat_to_onehot=None,\n","                                              max_delta_step=None, max_depth=12,\n","                                              max_leaves=None,\n","                                              min_child_weight=None,\n","                                              missing=nan,\n","                                              monotone_constraints=None,\n","                                              multi_strategy=None,\n","                                              n_estimators=539, n_jobs=None,\n","                                              num_parallel_tree=None,\n","                                              random_state=None, ...))],\n","                   final_estimator=GradientBoostingClassifier(learning_rate=0.02,\n","                                                              random_state=42))"],"text/html":["<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>StackingClassifier(estimators=[(&#x27;lgbm&#x27;,\n","                                LGBMClassifier(learning_rate=0.6034033282351656,\n","                                               max_depth=11,\n","                                               n_estimators=605)),\n","                               (&#x27;xgb&#x27;,\n","                                XGBClassifier(base_score=None, booster=None,\n","                                              callbacks=None,\n","                                              colsample_bylevel=None,\n","                                              colsample_bynode=None,\n","                                              colsample_bytree=None,\n","                                              device=None,\n","                                              early_stopping_rounds=None,\n","                                              enable_categorical=False,\n","                                              eval_metric=None,\n","                                              feature_types=None...\n","                                              learning_rate=0.47555557015719635,\n","                                              max_bin=None,\n","                                              max_cat_threshold=None,\n","                                              max_cat_to_onehot=None,\n","                                              max_delta_step=None, max_depth=12,\n","                                              max_leaves=None,\n","                                              min_child_weight=None,\n","                                              missing=nan,\n","                                              monotone_constraints=None,\n","                                              multi_strategy=None,\n","                                              n_estimators=539, n_jobs=None,\n","                                              num_parallel_tree=None,\n","                                              random_state=None, ...))],\n","                   final_estimator=GradientBoostingClassifier(learning_rate=0.02,\n","                                                              random_state=42))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StackingClassifier</label><div class=\"sk-toggleable__content\"><pre>StackingClassifier(estimators=[(&#x27;lgbm&#x27;,\n","                                LGBMClassifier(learning_rate=0.6034033282351656,\n","                                               max_depth=11,\n","                                               n_estimators=605)),\n","                               (&#x27;xgb&#x27;,\n","                                XGBClassifier(base_score=None, booster=None,\n","                                              callbacks=None,\n","                                              colsample_bylevel=None,\n","                                              colsample_bynode=None,\n","                                              colsample_bytree=None,\n","                                              device=None,\n","                                              early_stopping_rounds=None,\n","                                              enable_categorical=False,\n","                                              eval_metric=None,\n","                                              feature_types=None...\n","                                              learning_rate=0.47555557015719635,\n","                                              max_bin=None,\n","                                              max_cat_threshold=None,\n","                                              max_cat_to_onehot=None,\n","                                              max_delta_step=None, max_depth=12,\n","                                              max_leaves=None,\n","                                              min_child_weight=None,\n","                                              missing=nan,\n","                                              monotone_constraints=None,\n","                                              multi_strategy=None,\n","                                              n_estimators=539, n_jobs=None,\n","                                              num_parallel_tree=None,\n","                                              random_state=None, ...))],\n","                   final_estimator=GradientBoostingClassifier(learning_rate=0.02,\n","                                                              random_state=42))</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>lgbm</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(learning_rate=0.6034033282351656, max_depth=11, n_estimators=605)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>xgb</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n","              colsample_bylevel=None, colsample_bynode=None,\n","              colsample_bytree=None, device=None, early_stopping_rounds=None,\n","              enable_categorical=False, eval_metric=None, feature_types=None,\n","              gamma=None, grow_policy=None, importance_type=None,\n","              interaction_constraints=None, learning_rate=0.47555557015719635,\n","              max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n","              max_delta_step=None, max_depth=12, max_leaves=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              multi_strategy=None, n_estimators=539, n_jobs=None,\n","              num_parallel_tree=None, random_state=None, ...)</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>final_estimator</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier(learning_rate=0.02, random_state=42)</pre></div></div></div></div></div></div></div></div></div></div></div></div>"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["#pred_train = model_xgb_lgbm.predict(x_train)\n","pred_test = model_xgb_lgbm.predict(x_test)\n","\n","#print(f'train: {roc_auc_score(y_train, pred_train)}')\n","print(f'test: {roc_auc_score(y_test, pred_test)}')\n","print(f'test conf matrix: \\n {confusion_matrix(y_test, pred_test)}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8DODfTPcorD3","executionInfo":{"status":"ok","timestamp":1708184649914,"user_tz":-240,"elapsed":56879,"user":{"displayName":"Евгений Малов","userId":"06257165098392198337"}},"outputId":"ea3fd8db-8b00-41e9-b498-9b04f7993eed"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","test: 0.9470048597887356\n","test conf matrix: \n"," [[828198  39816]\n"," [  1923  30063]]\n"]}]},{"cell_type":"code","source":["with open(path + '/smote_3_models.pkl', 'rb') as file:\n","    smote_3_model = dill.load(file)\n","smote_3_model"],"metadata":{"id":"hB7lhoJuorPD","colab":{"base_uri":"https://localhost:8080/","height":164},"executionInfo":{"status":"ok","timestamp":1708611607530,"user_tz":-240,"elapsed":8086,"user":{"displayName":"Евгений Малов","userId":"06257165098392198337"}},"outputId":"54c9608d-bf5d-440a-90b8-16509f1b9850"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["StackingClassifier(estimators=[('lgbm',\n","                                LGBMClassifier(learning_rate=0.10258059179395394,\n","                                               max_depth=13,\n","                                               n_estimators=671)),\n","                               ('xgb',\n","                                XGBClassifier(base_score=None, booster=None,\n","                                              callbacks=None,\n","                                              colsample_bylevel=None,\n","                                              colsample_bynode=None,\n","                                              colsample_bytree=None,\n","                                              device=None,\n","                                              early_stopping_rounds=None,\n","                                              enable_categorical=False,\n","                                              eval_metric=None,\n","                                              feature_types=Non...\n","                                              max_cat_to_onehot=None,\n","                                              max_delta_step=None, max_depth=11,\n","                                              max_leaves=None,\n","                                              min_child_weight=None,\n","                                              missing=nan,\n","                                              monotone_constraints=None,\n","                                              multi_strategy=None,\n","                                              n_estimators=616, n_jobs=None,\n","                                              num_parallel_tree=None,\n","                                              random_state=None, ...)),\n","                               ('cb',\n","                                <catboost.core.CatBoostClassifier object at 0x796e98f92a10>)],\n","                   final_estimator=GradientBoostingClassifier(learning_rate=0.02,\n","                                                              random_state=42))"],"text/html":["<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>StackingClassifier(estimators=[(&#x27;lgbm&#x27;,\n","                                LGBMClassifier(learning_rate=0.10258059179395394,\n","                                               max_depth=13,\n","                                               n_estimators=671)),\n","                               (&#x27;xgb&#x27;,\n","                                XGBClassifier(base_score=None, booster=None,\n","                                              callbacks=None,\n","                                              colsample_bylevel=None,\n","                                              colsample_bynode=None,\n","                                              colsample_bytree=None,\n","                                              device=None,\n","                                              early_stopping_rounds=None,\n","                                              enable_categorical=False,\n","                                              eval_metric=None,\n","                                              feature_types=Non...\n","                                              max_cat_to_onehot=None,\n","                                              max_delta_step=None, max_depth=11,\n","                                              max_leaves=None,\n","                                              min_child_weight=None,\n","                                              missing=nan,\n","                                              monotone_constraints=None,\n","                                              multi_strategy=None,\n","                                              n_estimators=616, n_jobs=None,\n","                                              num_parallel_tree=None,\n","                                              random_state=None, ...)),\n","                               (&#x27;cb&#x27;,\n","                                &lt;catboost.core.CatBoostClassifier object at 0x796e98f92a10&gt;)],\n","                   final_estimator=GradientBoostingClassifier(learning_rate=0.02,\n","                                                              random_state=42))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StackingClassifier</label><div class=\"sk-toggleable__content\"><pre>StackingClassifier(estimators=[(&#x27;lgbm&#x27;,\n","                                LGBMClassifier(learning_rate=0.10258059179395394,\n","                                               max_depth=13,\n","                                               n_estimators=671)),\n","                               (&#x27;xgb&#x27;,\n","                                XGBClassifier(base_score=None, booster=None,\n","                                              callbacks=None,\n","                                              colsample_bylevel=None,\n","                                              colsample_bynode=None,\n","                                              colsample_bytree=None,\n","                                              device=None,\n","                                              early_stopping_rounds=None,\n","                                              enable_categorical=False,\n","                                              eval_metric=None,\n","                                              feature_types=Non...\n","                                              max_cat_to_onehot=None,\n","                                              max_delta_step=None, max_depth=11,\n","                                              max_leaves=None,\n","                                              min_child_weight=None,\n","                                              missing=nan,\n","                                              monotone_constraints=None,\n","                                              multi_strategy=None,\n","                                              n_estimators=616, n_jobs=None,\n","                                              num_parallel_tree=None,\n","                                              random_state=None, ...)),\n","                               (&#x27;cb&#x27;,\n","                                &lt;catboost.core.CatBoostClassifier object at 0x796e98f92a10&gt;)],\n","                   final_estimator=GradientBoostingClassifier(learning_rate=0.02,\n","                                                              random_state=42))</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>lgbm</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(learning_rate=0.10258059179395394, max_depth=13,\n","               n_estimators=671)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>xgb</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n","              colsample_bylevel=None, colsample_bynode=None,\n","              colsample_bytree=None, device=None, early_stopping_rounds=None,\n","              enable_categorical=False, eval_metric=None, feature_types=None,\n","              gamma=None, grow_policy=None, importance_type=None,\n","              interaction_constraints=None, learning_rate=0.04924166876982857,\n","              max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n","              max_delta_step=None, max_depth=11, max_leaves=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              multi_strategy=None, n_estimators=616, n_jobs=None,\n","              num_parallel_tree=None, random_state=None, ...)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>cb</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CatBoostClassifier</label><div class=\"sk-toggleable__content\"><pre>&lt;catboost.core.CatBoostClassifier object at 0x796e98f92a10&gt;</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>final_estimator</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier(learning_rate=0.02, random_state=42)</pre></div></div></div></div></div></div></div></div></div></div></div></div>"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["#pred_train = model_3.predict(x_train)\n","pred_test = smote_3_model.predict(x_test)\n","\n","#print(f'train: {roc_auc_score(y_train, pred_train)}')\n","print(f'test: {roc_auc_score(y_test, pred_test)}')\n","print(f'test conf matrix: \\n {confusion_matrix(y_test, pred_test)}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"L-Qr1RbnL765","executionInfo":{"status":"ok","timestamp":1708611846803,"user_tz":-240,"elapsed":179943,"user":{"displayName":"Евгений Малов","userId":"06257165098392198337"}},"outputId":"0238b265-319f-4bd6-abb6-359e60fa9a87"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","test: 0.7507139649476412\n","test conf matrix: \n"," [[824694  43320]\n"," [ 14351  17635]]\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"yUV8aviiE2Sp"},"execution_count":null,"outputs":[]}]}